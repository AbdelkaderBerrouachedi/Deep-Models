{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt \n",
    "from pprint import pprint\n",
    "from numpy import array\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = fetch_olivetti_faces()\n",
    "X = data.images\n",
    "y = data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape data\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(280, 4096)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new train shape\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4096)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new test shape\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DeepExtratrees \n",
    "import argparse\n",
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "sys.path.insert(0, \"lib\")\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.utils.config_utils import load_json\n",
    "config = load_json(\"./examples/olivetti.json\")   \n",
    "gc = GCForest(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count of class\n",
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-27 21:55:32,281][cascade_classifier.fit_transform] X_groups_train.shape=[(280, 4096)],y_train.shape=(280,),X_groups_test.shape=[(120, 4096)],y_test.shape=(120,)\n",
      "[ 2018-07-27 21:55:32,284][cascade_classifier.fit_transform] group_dims=[4096]\n",
      "[ 2018-07-27 21:55:32,284][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-27 21:55:32,285][cascade_classifier.fit_transform] group_ends=[4096]\n",
      "[ 2018-07-27 21:55:32,286][cascade_classifier.fit_transform] X_train.shape=(280, 4096),X_test.shape=(120, 4096)\n",
      "[ 2018-07-27 21:55:32,289][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(280, 4096), X_cur_test.shape=(120, 4096)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[ 2018-07-27 21:55:32,828][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=84.62%\n",
      "[ 2018-07-27 21:55:33,464][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-27 21:55:34,078][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=96.15%\n",
      "[ 2018-07-27 21:55:34,677][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=93.10%\n",
      "[ 2018-07-27 21:55:35,279][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=93.94%\n",
      "[ 2018-07-27 21:55:35,874][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=100.00%\n",
      "[ 2018-07-27 21:55:36,472][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=93.10%\n",
      "[ 2018-07-27 21:55:37,076][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=91.30%\n",
      "[ 2018-07-27 21:55:37,682][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=86.21%\n",
      "[ 2018-07-27 21:55:38,273][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=96.67%\n",
      "[ 2018-07-27 21:55:38,379][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=93.57%\n",
      "[ 2018-07-27 21:55:38,379][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=96.67%\n",
      "[ 2018-07-27 21:55:38,381][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=93.57%\n",
      "[ 2018-07-27 21:55:38,381][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=96.67%\n",
      "[ 2018-07-27 21:55:38,382][cascade_classifier.fit_transform] [Result][Reach Max Layer] opt_layer_num=1, accuracy_train=93.57%, accuracy_test=96.67%\n"
     ]
    }
   ],
   "source": [
    "    # X_enc is the concatenated predict_proba result of DeepExtratrees\n",
    "X_train_enc, X_test_enc = gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-27 21:55:38,388][cascade_classifier.transform] X_groups_test.shape=[(120, 4096)]\n",
      "[ 2018-07-27 21:55:38,389][cascade_classifier.transform] group_dims=[4096]\n",
      "[ 2018-07-27 21:55:38,391][cascade_classifier.transform] X_test.shape=(120, 4096)\n",
      "[ 2018-07-27 21:55:38,393][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(120, 4096)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of DeepExtratrees = 96.666667 %\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "y_pred = gc.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy of DeepExtratrees = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0 0 ..., 0 0 0]\n",
      " [0 2 0 ..., 0 0 0]\n",
      " [0 0 4 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 2 0]\n",
      " [0 0 0 ..., 0 0 5]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         3\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       1.00      1.00      1.00         4\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      0.83      0.91         6\n",
      "          5       1.00      1.00      1.00         3\n",
      "          6       1.00      0.75      0.86         4\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       1.00      1.00      1.00         2\n",
      "          9       1.00      0.67      0.80         3\n",
      "         10       0.67      1.00      0.80         2\n",
      "         11       1.00      1.00      1.00         3\n",
      "         12       1.00      1.00      1.00         2\n",
      "         13       1.00      1.00      1.00         4\n",
      "         14       1.00      1.00      1.00         5\n",
      "         15       1.00      1.00      1.00         3\n",
      "         16       1.00      1.00      1.00         3\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       1.00      1.00      1.00         5\n",
      "         19       1.00      1.00      1.00         3\n",
      "         20       0.75      1.00      0.86         3\n",
      "         22       1.00      1.00      1.00         4\n",
      "         23       1.00      1.00      1.00         3\n",
      "         24       1.00      1.00      1.00         3\n",
      "         25       1.00      1.00      1.00         2\n",
      "         26       1.00      1.00      1.00         3\n",
      "         27       1.00      1.00      1.00         3\n",
      "         28       1.00      1.00      1.00         4\n",
      "         29       1.00      0.80      0.89         5\n",
      "         30       1.00      1.00      1.00         1\n",
      "         31       1.00      1.00      1.00         4\n",
      "         32       1.00      1.00      1.00         3\n",
      "         33       1.00      1.00      1.00         2\n",
      "         34       1.00      1.00      1.00         2\n",
      "         35       1.00      1.00      1.00         1\n",
      "         36       1.00      1.00      1.00         4\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         2\n",
      "         39       0.71      1.00      0.83         5\n",
      "\n",
      "avg / total       0.98      0.97      0.97       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-27 21:56:51,195][cascade_classifier.transform] X_groups_test.shape=[(120, 4096)]\n",
      "[ 2018-07-27 21:56:51,197][cascade_classifier.transform] group_dims=[4096]\n",
      "[ 2018-07-27 21:56:51,198][cascade_classifier.transform] X_test.shape=(120, 4096)\n",
      "[ 2018-07-27 21:56:51,199][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(120, 4096)\n"
     ]
    }
   ],
   "source": [
    "# Make data + estimators.\n",
    "X_test_enc = gc.transform(X_test)\n",
    "X_train_enc = X_train_enc.reshape((X_train_enc.shape[0], -1))\n",
    "X_test_enc = X_test_enc.reshape((X_test_enc.shape[0], -1))\n",
    "X_train_origin = X_train.reshape((X_train.shape[0], -1))\n",
    "X_test_origin = X_test.reshape((X_test.shape[0], -1))\n",
    "X_train_enc = np.hstack((X_train_origin, X_train_enc))\n",
    "X_test_enc = np.hstack((X_test_origin, X_test_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-27 21:56:53,278][cascade_classifier.fit_transform] X_groups_train.shape=[(280, 4136)],y_train.shape=(280,),X_groups_test.shape=[(120, 4136)],y_test.shape=(120,)\n",
      "[ 2018-07-27 21:56:53,281][cascade_classifier.fit_transform] group_dims=[4136]\n",
      "[ 2018-07-27 21:56:53,282][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-27 21:56:53,283][cascade_classifier.fit_transform] group_ends=[4136]\n",
      "[ 2018-07-27 21:56:53,284][cascade_classifier.fit_transform] X_train.shape=(280, 4136),X_test.shape=(120, 4136)\n",
      "[ 2018-07-27 21:56:53,288][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(280, 4136), X_cur_test.shape=(120, 4136)\n",
      "[ 2018-07-27 21:56:53,923][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=84.62%\n",
      "[ 2018-07-27 21:56:54,977][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-27 21:56:55,723][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=96.15%\n",
      "[ 2018-07-27 21:56:56,544][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=89.66%\n",
      "[ 2018-07-27 21:56:57,262][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=93.94%\n",
      "[ 2018-07-27 21:56:57,870][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=96.67%\n",
      "[ 2018-07-27 21:56:58,588][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=89.66%\n",
      "[ 2018-07-27 21:56:59,304][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=91.30%\n",
      "[ 2018-07-27 21:57:00,027][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=86.21%\n",
      "[ 2018-07-27 21:57:00,635][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=96.67%\n",
      "[ 2018-07-27 21:57:00,856][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=92.50%\n",
      "[ 2018-07-27 21:57:00,857][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=96.67%\n",
      "[ 2018-07-27 21:57:00,860][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=92.50%\n",
      "[ 2018-07-27 21:57:00,861][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=96.67%\n",
      "[ 2018-07-27 21:57:00,861][cascade_classifier.fit_transform] [Result][Reach Max Layer] opt_layer_num=1, accuracy_train=92.50%, accuracy_test=96.67%\n"
     ]
    }
   ],
   "source": [
    "X_train=X_train_enc\n",
    "X_test=X_test_enc \n",
    "X_train_enc, X_test_enc = gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-27 21:57:00,867][cascade_classifier.transform] X_groups_test.shape=[(120, 4136)]\n",
      "[ 2018-07-27 21:57:00,869][cascade_classifier.transform] group_dims=[4136]\n",
      "[ 2018-07-27 21:57:00,870][cascade_classifier.transform] X_test.shape=(120, 4136)\n",
      "[ 2018-07-27 21:57:00,871][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(120, 4136)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of DeepExtraTrees = 95.833333 %\n"
     ]
    }
   ],
   "source": [
    "# predict  data + Es\n",
    "y_pred = gc.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy of DeepExtraTrees = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0 0 ..., 0 0 0]\n",
      " [0 2 0 ..., 0 0 0]\n",
      " [0 0 4 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 2 0]\n",
      " [0 0 0 ..., 0 0 5]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         3\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       1.00      1.00      1.00         4\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      0.83      0.91         6\n",
      "          5       1.00      1.00      1.00         3\n",
      "          6       1.00      0.75      0.86         4\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       1.00      1.00      1.00         2\n",
      "          9       1.00      0.67      0.80         3\n",
      "         10       0.67      1.00      0.80         2\n",
      "         11       1.00      1.00      1.00         3\n",
      "         12       1.00      1.00      1.00         2\n",
      "         13       1.00      1.00      1.00         4\n",
      "         14       1.00      1.00      1.00         5\n",
      "         15       1.00      1.00      1.00         3\n",
      "         16       1.00      1.00      1.00         3\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       1.00      1.00      1.00         5\n",
      "         19       1.00      1.00      1.00         3\n",
      "         20       0.75      1.00      0.86         3\n",
      "         22       0.80      1.00      0.89         4\n",
      "         23       1.00      1.00      1.00         3\n",
      "         24       1.00      0.67      0.80         3\n",
      "         25       1.00      1.00      1.00         2\n",
      "         26       1.00      1.00      1.00         3\n",
      "         27       1.00      1.00      1.00         3\n",
      "         28       1.00      1.00      1.00         4\n",
      "         29       1.00      0.80      0.89         5\n",
      "         30       1.00      1.00      1.00         1\n",
      "         31       1.00      1.00      1.00         4\n",
      "         32       1.00      1.00      1.00         3\n",
      "         33       1.00      1.00      1.00         2\n",
      "         34       1.00      1.00      1.00         2\n",
      "         35       1.00      1.00      1.00         1\n",
      "         36       1.00      1.00      1.00         4\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         2\n",
      "         39       0.71      1.00      0.83         5\n",
      "\n",
      "avg / total       0.97      0.96      0.96       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-27 21:57:02,081][cascade_classifier.fit_transform] X_groups_train.shape=[(280, 4174)],y_train.shape=(280,),X_groups_test.shape=[(120, 4174)],y_test.shape=(120,)\n",
      "[ 2018-07-27 21:57:02,083][cascade_classifier.fit_transform] group_dims=[4174]\n",
      "[ 2018-07-27 21:57:02,084][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-27 21:57:02,085][cascade_classifier.fit_transform] group_ends=[4174]\n",
      "[ 2018-07-27 21:57:02,086][cascade_classifier.fit_transform] X_train.shape=(280, 4174),X_test.shape=(120, 4174)\n",
      "[ 2018-07-27 21:57:02,088][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(280, 4174), X_cur_test.shape=(120, 4174)\n",
      "[ 2018-07-27 21:57:02,596][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=80.77%\n",
      "[ 2018-07-27 21:57:03,203][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-27 21:57:03,809][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=92.31%\n",
      "[ 2018-07-27 21:57:04,416][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=93.10%\n",
      "[ 2018-07-27 21:57:05,135][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=93.94%\n",
      "[ 2018-07-27 21:57:05,784][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=100.00%\n",
      "[ 2018-07-27 21:57:06,505][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=96.55%\n",
      "[ 2018-07-27 21:57:07,104][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=91.30%\n",
      "[ 2018-07-27 21:57:07,713][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=86.21%\n",
      "[ 2018-07-27 21:57:08,313][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=93.33%\n",
      "[ 2018-07-27 21:57:08,418][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=92.86%\n",
      "[ 2018-07-27 21:57:08,419][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=95.83%\n",
      "[ 2018-07-27 21:57:08,421][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=92.86%\n",
      "[ 2018-07-27 21:57:08,422][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=95.83%\n",
      "[ 2018-07-27 21:57:08,423][cascade_classifier.fit_transform] [Result][Reach Max Layer] opt_layer_num=1, accuracy_train=92.86%, accuracy_test=95.83%\n",
      "[ 2018-07-27 21:57:08,424][cascade_classifier.transform] X_groups_test.shape=[(120, 4174)]\n",
      "[ 2018-07-27 21:57:08,425][cascade_classifier.transform] group_dims=[4174]\n",
      "[ 2018-07-27 21:57:08,426][cascade_classifier.transform] X_test.shape=(120, 4174)\n",
      "[ 2018-07-27 21:57:08,427][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(120, 4174)\n",
      "[ 2018-07-27 21:57:09,482][cascade_classifier.fit_transform] X_groups_train.shape=[(280, 4212)],y_train.shape=(280,),X_groups_test.shape=[(120, 4212)],y_test.shape=(120,)\n",
      "[ 2018-07-27 21:57:09,483][cascade_classifier.fit_transform] group_dims=[4212]\n",
      "[ 2018-07-27 21:57:09,484][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-27 21:57:09,485][cascade_classifier.fit_transform] group_ends=[4212]\n",
      "[ 2018-07-27 21:57:09,486][cascade_classifier.fit_transform] X_train.shape=(280, 4212),X_test.shape=(120, 4212)\n",
      "[ 2018-07-27 21:57:09,488][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(280, 4212), X_cur_test.shape=(120, 4212)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test Accuracy of DeepExtratTrees = 95.833333 %', 'Layer :', 0)\n",
      "[[3 0 0 ..., 0 0 0]\n",
      " [0 2 0 ..., 0 0 0]\n",
      " [0 0 4 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 2 0]\n",
      " [0 0 0 ..., 0 0 5]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         3\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       1.00      1.00      1.00         4\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      0.83      0.91         6\n",
      "          5       1.00      1.00      1.00         3\n",
      "          6       1.00      0.75      0.86         4\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       1.00      1.00      1.00         2\n",
      "          9       1.00      0.67      0.80         3\n",
      "         10       0.67      1.00      0.80         2\n",
      "         11       1.00      1.00      1.00         3\n",
      "         12       1.00      1.00      1.00         2\n",
      "         13       1.00      1.00      1.00         4\n",
      "         14       1.00      1.00      1.00         5\n",
      "         15       1.00      1.00      1.00         3\n",
      "         16       1.00      1.00      1.00         3\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       1.00      1.00      1.00         5\n",
      "         19       1.00      1.00      1.00         3\n",
      "         20       0.75      1.00      0.86         3\n",
      "         22       0.80      1.00      0.89         4\n",
      "         23       1.00      1.00      1.00         3\n",
      "         24       1.00      0.67      0.80         3\n",
      "         25       1.00      1.00      1.00         2\n",
      "         26       1.00      1.00      1.00         3\n",
      "         27       1.00      1.00      1.00         3\n",
      "         28       1.00      1.00      1.00         4\n",
      "         29       1.00      0.80      0.89         5\n",
      "         30       1.00      1.00      1.00         1\n",
      "         31       1.00      1.00      1.00         4\n",
      "         32       1.00      1.00      1.00         3\n",
      "         33       1.00      1.00      1.00         2\n",
      "         34       1.00      1.00      1.00         2\n",
      "         35       1.00      1.00      1.00         1\n",
      "         36       1.00      1.00      1.00         4\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         2\n",
      "         39       0.71      1.00      0.83         5\n",
      "\n",
      "avg / total       0.97      0.96      0.96       120\n",
      "\n",
      "(' Time ', '6.347', ' seconds')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-27 21:57:09,999][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=84.62%\n",
      "[ 2018-07-27 21:57:10,721][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-27 21:57:11,329][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=92.31%\n",
      "[ 2018-07-27 21:57:12,158][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=89.66%\n",
      "[ 2018-07-27 21:57:12,760][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=93.94%\n",
      "[ 2018-07-27 21:57:13,363][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=96.67%\n",
      "[ 2018-07-27 21:57:13,970][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=89.66%\n",
      "[ 2018-07-27 21:57:14,699][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=91.30%\n",
      "[ 2018-07-27 21:57:15,429][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=86.21%\n",
      "[ 2018-07-27 21:57:16,023][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=96.67%\n",
      "[ 2018-07-27 21:57:16,126][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=92.14%\n",
      "[ 2018-07-27 21:57:16,128][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=95.83%\n",
      "[ 2018-07-27 21:57:16,130][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=92.14%\n",
      "[ 2018-07-27 21:57:16,131][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=95.83%\n",
      "[ 2018-07-27 21:57:16,132][cascade_classifier.fit_transform] [Result][Reach Max Layer] opt_layer_num=1, accuracy_train=92.14%, accuracy_test=95.83%\n",
      "[ 2018-07-27 21:57:16,133][cascade_classifier.transform] X_groups_test.shape=[(120, 4212)]\n",
      "[ 2018-07-27 21:57:16,134][cascade_classifier.transform] group_dims=[4212]\n",
      "[ 2018-07-27 21:57:16,135][cascade_classifier.transform] X_test.shape=(120, 4212)\n",
      "[ 2018-07-27 21:57:16,136][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(120, 4212)\n",
      "[ 2018-07-27 21:57:17,185][cascade_classifier.fit_transform] X_groups_train.shape=[(280, 4250)],y_train.shape=(280,),X_groups_test.shape=[(120, 4250)],y_test.shape=(120,)\n",
      "[ 2018-07-27 21:57:17,187][cascade_classifier.fit_transform] group_dims=[4250]\n",
      "[ 2018-07-27 21:57:17,188][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-27 21:57:17,189][cascade_classifier.fit_transform] group_ends=[4250]\n",
      "[ 2018-07-27 21:57:17,190][cascade_classifier.fit_transform] X_train.shape=(280, 4250),X_test.shape=(120, 4250)\n",
      "[ 2018-07-27 21:57:17,193][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(280, 4250), X_cur_test.shape=(120, 4250)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test Accuracy of DeepExtratTrees = 95.833333 %', 'Layer :', 1)\n",
      "[[3 0 0 ..., 0 0 0]\n",
      " [0 2 0 ..., 0 0 0]\n",
      " [0 0 4 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 2 0]\n",
      " [0 0 0 ..., 0 0 5]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         3\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       1.00      1.00      1.00         4\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      0.83      0.91         6\n",
      "          5       1.00      1.00      1.00         3\n",
      "          6       1.00      0.75      0.86         4\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       1.00      1.00      1.00         2\n",
      "          9       1.00      0.67      0.80         3\n",
      "         10       0.67      1.00      0.80         2\n",
      "         11       1.00      1.00      1.00         3\n",
      "         12       1.00      1.00      1.00         2\n",
      "         13       1.00      1.00      1.00         4\n",
      "         14       1.00      1.00      1.00         5\n",
      "         15       1.00      1.00      1.00         3\n",
      "         16       1.00      1.00      1.00         3\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       1.00      1.00      1.00         5\n",
      "         19       1.00      1.00      1.00         3\n",
      "         20       0.75      1.00      0.86         3\n",
      "         22       0.80      1.00      0.89         4\n",
      "         23       1.00      1.00      1.00         3\n",
      "         24       1.00      0.67      0.80         3\n",
      "         25       1.00      1.00      1.00         2\n",
      "         26       1.00      1.00      1.00         3\n",
      "         27       1.00      1.00      1.00         3\n",
      "         28       1.00      1.00      1.00         4\n",
      "         29       1.00      0.80      0.89         5\n",
      "         30       1.00      1.00      1.00         1\n",
      "         31       1.00      1.00      1.00         4\n",
      "         32       1.00      1.00      1.00         3\n",
      "         33       1.00      1.00      1.00         2\n",
      "         34       1.00      1.00      1.00         2\n",
      "         35       1.00      1.00      1.00         1\n",
      "         36       1.00      1.00      1.00         4\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         2\n",
      "         39       0.71      1.00      0.83         5\n",
      "\n",
      "avg / total       0.97      0.96      0.96       120\n",
      "\n",
      "(' Time ', '6.655', ' seconds')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-27 21:57:17,710][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=84.62%\n",
      "[ 2018-07-27 21:57:18,314][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-27 21:57:18,918][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=92.31%\n",
      "[ 2018-07-27 21:57:19,646][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=89.66%\n",
      "[ 2018-07-27 21:57:20,258][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=93.94%\n",
      "[ 2018-07-27 21:57:20,862][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=96.67%\n",
      "[ 2018-07-27 21:57:21,465][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=89.66%\n",
      "[ 2018-07-27 21:57:22,073][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=91.30%\n",
      "[ 2018-07-27 21:57:22,675][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=86.21%\n",
      "[ 2018-07-27 21:57:23,276][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=96.67%\n",
      "[ 2018-07-27 21:57:23,382][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=92.14%\n",
      "[ 2018-07-27 21:57:23,383][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=96.67%\n",
      "[ 2018-07-27 21:57:23,386][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=92.14%\n",
      "[ 2018-07-27 21:57:23,387][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=96.67%\n",
      "[ 2018-07-27 21:57:23,388][cascade_classifier.fit_transform] [Result][Reach Max Layer] opt_layer_num=1, accuracy_train=92.14%, accuracy_test=96.67%\n",
      "[ 2018-07-27 21:57:23,389][cascade_classifier.transform] X_groups_test.shape=[(120, 4250)]\n",
      "[ 2018-07-27 21:57:23,390][cascade_classifier.transform] group_dims=[4250]\n",
      "[ 2018-07-27 21:57:23,391][cascade_classifier.transform] X_test.shape=(120, 4250)\n",
      "[ 2018-07-27 21:57:23,392][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(120, 4250)\n",
      "[ 2018-07-27 21:57:24,674][cascade_classifier.fit_transform] X_groups_train.shape=[(280, 4288)],y_train.shape=(280,),X_groups_test.shape=[(120, 4288)],y_test.shape=(120,)\n",
      "[ 2018-07-27 21:57:24,677][cascade_classifier.fit_transform] group_dims=[4288]\n",
      "[ 2018-07-27 21:57:24,678][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-27 21:57:24,679][cascade_classifier.fit_transform] group_ends=[4288]\n",
      "[ 2018-07-27 21:57:24,680][cascade_classifier.fit_transform] X_train.shape=(280, 4288),X_test.shape=(120, 4288)\n",
      "[ 2018-07-27 21:57:24,684][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(280, 4288), X_cur_test.shape=(120, 4288)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test Accuracy of DeepExtratTrees = 96.666667 %', 'Layer :', 2)\n",
      "[[3 0 0 ..., 0 0 0]\n",
      " [0 2 0 ..., 0 0 0]\n",
      " [0 0 4 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 2 0]\n",
      " [0 0 0 ..., 0 0 5]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         3\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       1.00      1.00      1.00         4\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      0.83      0.91         6\n",
      "          5       1.00      1.00      1.00         3\n",
      "          6       1.00      0.75      0.86         4\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       1.00      1.00      1.00         2\n",
      "          9       1.00      0.67      0.80         3\n",
      "         10       0.67      1.00      0.80         2\n",
      "         11       1.00      1.00      1.00         3\n",
      "         12       1.00      1.00      1.00         2\n",
      "         13       1.00      1.00      1.00         4\n",
      "         14       1.00      1.00      1.00         5\n",
      "         15       1.00      1.00      1.00         3\n",
      "         16       1.00      1.00      1.00         3\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       1.00      1.00      1.00         5\n",
      "         19       1.00      1.00      1.00         3\n",
      "         20       0.75      1.00      0.86         3\n",
      "         22       1.00      1.00      1.00         4\n",
      "         23       1.00      1.00      1.00         3\n",
      "         24       1.00      1.00      1.00         3\n",
      "         25       1.00      1.00      1.00         2\n",
      "         26       1.00      1.00      1.00         3\n",
      "         27       1.00      1.00      1.00         3\n",
      "         28       1.00      1.00      1.00         4\n",
      "         29       1.00      0.80      0.89         5\n",
      "         30       1.00      1.00      1.00         1\n",
      "         31       1.00      1.00      1.00         4\n",
      "         32       1.00      1.00      1.00         3\n",
      "         33       1.00      1.00      1.00         2\n",
      "         34       1.00      1.00      1.00         2\n",
      "         35       1.00      1.00      1.00         1\n",
      "         36       1.00      1.00      1.00         4\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         2\n",
      "         39       0.71      1.00      0.83         5\n",
      "\n",
      "avg / total       0.98      0.97      0.97       120\n",
      "\n",
      "(' Time ', '6.207', ' seconds')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-27 21:57:25,197][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=84.62%\n",
      "[ 2018-07-27 21:57:25,806][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-27 21:57:26,452][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=96.15%\n",
      "[ 2018-07-27 21:57:27,061][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=89.66%\n",
      "[ 2018-07-27 21:57:27,778][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=93.94%\n",
      "[ 2018-07-27 21:57:28,378][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=96.67%\n",
      "[ 2018-07-27 21:57:28,982][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=89.66%\n",
      "[ 2018-07-27 21:57:29,701][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=91.30%\n",
      "[ 2018-07-27 21:57:30,301][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=89.66%\n",
      "[ 2018-07-27 21:57:30,902][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=96.67%\n",
      "[ 2018-07-27 21:57:31,008][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=92.86%\n",
      "[ 2018-07-27 21:57:31,009][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=95.83%\n",
      "[ 2018-07-27 21:57:31,012][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=92.86%\n",
      "[ 2018-07-27 21:57:31,013][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=95.83%\n",
      "[ 2018-07-27 21:57:31,014][cascade_classifier.fit_transform] [Result][Reach Max Layer] opt_layer_num=1, accuracy_train=92.86%, accuracy_test=95.83%\n",
      "[ 2018-07-27 21:57:31,015][cascade_classifier.transform] X_groups_test.shape=[(120, 4288)]\n",
      "[ 2018-07-27 21:57:31,017][cascade_classifier.transform] group_dims=[4288]\n",
      "[ 2018-07-27 21:57:31,018][cascade_classifier.transform] X_test.shape=(120, 4288)\n",
      "[ 2018-07-27 21:57:31,020][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(120, 4288)\n",
      "[ 2018-07-27 21:57:32,070][cascade_classifier.fit_transform] X_groups_train.shape=[(280, 4326)],y_train.shape=(280,),X_groups_test.shape=[(120, 4326)],y_test.shape=(120,)\n",
      "[ 2018-07-27 21:57:32,072][cascade_classifier.fit_transform] group_dims=[4326]\n",
      "[ 2018-07-27 21:57:32,072][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-27 21:57:32,073][cascade_classifier.fit_transform] group_ends=[4326]\n",
      "[ 2018-07-27 21:57:32,074][cascade_classifier.fit_transform] X_train.shape=(280, 4326),X_test.shape=(120, 4326)\n",
      "[ 2018-07-27 21:57:32,077][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(280, 4326), X_cur_test.shape=(120, 4326)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test Accuracy of DeepExtratTrees = 95.833333 %', 'Layer :', 3)\n",
      "[[3 0 0 ..., 0 0 0]\n",
      " [0 2 0 ..., 0 0 0]\n",
      " [0 0 4 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 2 0]\n",
      " [0 0 0 ..., 0 0 5]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         3\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       1.00      1.00      1.00         4\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      0.83      0.91         6\n",
      "          5       1.00      1.00      1.00         3\n",
      "          6       1.00      0.75      0.86         4\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       1.00      1.00      1.00         2\n",
      "          9       1.00      0.67      0.80         3\n",
      "         10       0.67      1.00      0.80         2\n",
      "         11       1.00      1.00      1.00         3\n",
      "         12       1.00      1.00      1.00         2\n",
      "         13       1.00      1.00      1.00         4\n",
      "         14       1.00      1.00      1.00         5\n",
      "         15       1.00      1.00      1.00         3\n",
      "         16       1.00      1.00      1.00         3\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       1.00      1.00      1.00         5\n",
      "         19       1.00      1.00      1.00         3\n",
      "         20       0.75      1.00      0.86         3\n",
      "         22       0.80      1.00      0.89         4\n",
      "         23       1.00      1.00      1.00         3\n",
      "         24       1.00      0.67      0.80         3\n",
      "         25       1.00      1.00      1.00         2\n",
      "         26       1.00      1.00      1.00         3\n",
      "         27       1.00      1.00      1.00         3\n",
      "         28       1.00      1.00      1.00         4\n",
      "         29       1.00      0.80      0.89         5\n",
      "         30       1.00      1.00      1.00         1\n",
      "         31       1.00      1.00      1.00         4\n",
      "         32       1.00      1.00      1.00         3\n",
      "         33       1.00      1.00      1.00         2\n",
      "         34       1.00      1.00      1.00         2\n",
      "         35       1.00      1.00      1.00         1\n",
      "         36       1.00      1.00      1.00         4\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         2\n",
      "         39       0.71      1.00      0.83         5\n",
      "\n",
      "avg / total       0.97      0.96      0.96       120\n",
      "\n",
      "(' Time ', '6.346', ' seconds')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-27 21:57:32,590][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=84.62%\n",
      "[ 2018-07-27 21:57:33,199][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-27 21:57:33,801][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=96.15%\n",
      "[ 2018-07-27 21:57:34,407][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=93.10%\n",
      "[ 2018-07-27 21:57:35,014][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=93.94%\n",
      "[ 2018-07-27 21:57:35,624][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=100.00%\n",
      "[ 2018-07-27 21:57:36,275][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=93.10%\n",
      "[ 2018-07-27 21:57:36,884][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=86.96%\n",
      "[ 2018-07-27 21:57:37,487][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=89.66%\n",
      "[ 2018-07-27 21:57:38,094][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=93.33%\n",
      "[ 2018-07-27 21:57:38,199][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=93.21%\n",
      "[ 2018-07-27 21:57:38,200][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=96.67%\n",
      "[ 2018-07-27 21:57:38,203][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=93.21%\n",
      "[ 2018-07-27 21:57:38,204][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=96.67%\n",
      "[ 2018-07-27 21:57:38,205][cascade_classifier.fit_transform] [Result][Reach Max Layer] opt_layer_num=1, accuracy_train=93.21%, accuracy_test=96.67%\n",
      "[ 2018-07-27 21:57:38,206][cascade_classifier.transform] X_groups_test.shape=[(120, 4326)]\n",
      "[ 2018-07-27 21:57:38,207][cascade_classifier.transform] group_dims=[4326]\n",
      "[ 2018-07-27 21:57:38,208][cascade_classifier.transform] X_test.shape=(120, 4326)\n",
      "[ 2018-07-27 21:57:38,209][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(120, 4326)\n",
      "[ 2018-07-27 21:57:39,487][cascade_classifier.fit_transform] X_groups_train.shape=[(280, 4364)],y_train.shape=(280,),X_groups_test.shape=[(120, 4364)],y_test.shape=(120,)\n",
      "[ 2018-07-27 21:57:39,489][cascade_classifier.fit_transform] group_dims=[4364]\n",
      "[ 2018-07-27 21:57:39,490][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-27 21:57:39,491][cascade_classifier.fit_transform] group_ends=[4364]\n",
      "[ 2018-07-27 21:57:39,492][cascade_classifier.fit_transform] X_train.shape=(280, 4364),X_test.shape=(120, 4364)\n",
      "[ 2018-07-27 21:57:39,495][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(280, 4364), X_cur_test.shape=(120, 4364)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test Accuracy of DeepExtratTrees = 96.666667 %', 'Layer :', 4)\n",
      "[[3 0 0 ..., 0 0 0]\n",
      " [0 2 0 ..., 0 0 0]\n",
      " [0 0 4 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 2 0]\n",
      " [0 0 0 ..., 0 0 5]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         3\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       1.00      1.00      1.00         4\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      0.83      0.91         6\n",
      "          5       1.00      1.00      1.00         3\n",
      "          6       1.00      1.00      1.00         4\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       1.00      1.00      1.00         2\n",
      "          9       1.00      0.67      0.80         3\n",
      "         10       1.00      1.00      1.00         2\n",
      "         11       1.00      1.00      1.00         3\n",
      "         12       1.00      1.00      1.00         2\n",
      "         13       1.00      1.00      1.00         4\n",
      "         14       1.00      1.00      1.00         5\n",
      "         15       1.00      1.00      1.00         3\n",
      "         16       0.75      1.00      0.86         3\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       1.00      1.00      1.00         5\n",
      "         19       1.00      1.00      1.00         3\n",
      "         20       0.75      1.00      0.86         3\n",
      "         22       0.80      1.00      0.89         4\n",
      "         23       1.00      1.00      1.00         3\n",
      "         24       1.00      0.67      0.80         3\n",
      "         25       1.00      1.00      1.00         2\n",
      "         26       1.00      1.00      1.00         3\n",
      "         27       1.00      1.00      1.00         3\n",
      "         28       1.00      1.00      1.00         4\n",
      "         29       1.00      0.80      0.89         5\n",
      "         30       1.00      1.00      1.00         1\n",
      "         31       1.00      1.00      1.00         4\n",
      "         32       1.00      1.00      1.00         3\n",
      "         33       1.00      1.00      1.00         2\n",
      "         34       1.00      1.00      1.00         2\n",
      "         35       1.00      1.00      1.00         1\n",
      "         36       1.00      1.00      1.00         4\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         2\n",
      "         39       0.83      1.00      0.91         5\n",
      "\n",
      "avg / total       0.97      0.97      0.97       120\n",
      "\n",
      "(' Time ', '6.141', ' seconds')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-27 21:57:40,008][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=84.62%\n",
      "[ 2018-07-27 21:57:40,855][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-27 21:57:41,581][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=88.46%\n",
      "[ 2018-07-27 21:57:42,184][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=89.66%\n",
      "[ 2018-07-27 21:57:42,794][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=93.94%\n",
      "[ 2018-07-27 21:57:43,398][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=100.00%\n",
      "[ 2018-07-27 21:57:43,999][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=89.66%\n",
      "[ 2018-07-27 21:57:44,608][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=91.30%\n",
      "[ 2018-07-27 21:57:45,221][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=89.66%\n",
      "[ 2018-07-27 21:57:45,834][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=96.67%\n",
      "[ 2018-07-27 21:57:46,093][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=92.50%\n",
      "[ 2018-07-27 21:57:46,094][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=97.50%\n",
      "[ 2018-07-27 21:57:46,098][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=92.50%\n",
      "[ 2018-07-27 21:57:46,099][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=97.50%\n",
      "[ 2018-07-27 21:57:46,099][cascade_classifier.fit_transform] [Result][Reach Max Layer] opt_layer_num=1, accuracy_train=92.50%, accuracy_test=97.50%\n",
      "[ 2018-07-27 21:57:46,101][cascade_classifier.transform] X_groups_test.shape=[(120, 4364)]\n",
      "[ 2018-07-27 21:57:46,102][cascade_classifier.transform] group_dims=[4364]\n",
      "[ 2018-07-27 21:57:46,103][cascade_classifier.transform] X_test.shape=(120, 4364)\n",
      "[ 2018-07-27 21:57:46,104][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(120, 4364)\n",
      "[ 2018-07-27 21:57:47,500][cascade_classifier.fit_transform] X_groups_train.shape=[(280, 4402)],y_train.shape=(280,),X_groups_test.shape=[(120, 4402)],y_test.shape=(120,)\n",
      "[ 2018-07-27 21:57:47,503][cascade_classifier.fit_transform] group_dims=[4402]\n",
      "[ 2018-07-27 21:57:47,504][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-27 21:57:47,505][cascade_classifier.fit_transform] group_ends=[4402]\n",
      "[ 2018-07-27 21:57:47,506][cascade_classifier.fit_transform] X_train.shape=(280, 4402),X_test.shape=(120, 4402)\n",
      "[ 2018-07-27 21:57:47,508][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(280, 4402), X_cur_test.shape=(120, 4402)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test Accuracy of DeepExtratTrees = 97.500000 %', 'Layer :', 5)\n",
      "[[3 0 0 ..., 0 0 0]\n",
      " [0 2 0 ..., 0 0 0]\n",
      " [0 0 4 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 2 0]\n",
      " [0 0 0 ..., 0 0 5]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         3\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       1.00      1.00      1.00         4\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      0.83      0.91         6\n",
      "          5       1.00      1.00      1.00         3\n",
      "          6       1.00      1.00      1.00         4\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       1.00      1.00      1.00         2\n",
      "          9       1.00      0.67      0.80         3\n",
      "         10       1.00      1.00      1.00         2\n",
      "         11       1.00      1.00      1.00         3\n",
      "         12       1.00      1.00      1.00         2\n",
      "         13       1.00      1.00      1.00         4\n",
      "         14       1.00      1.00      1.00         5\n",
      "         15       1.00      1.00      1.00         3\n",
      "         16       1.00      1.00      1.00         3\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       1.00      1.00      1.00         5\n",
      "         19       1.00      1.00      1.00         3\n",
      "         20       0.75      1.00      0.86         3\n",
      "         22       1.00      1.00      1.00         4\n",
      "         23       1.00      1.00      1.00         3\n",
      "         24       1.00      1.00      1.00         3\n",
      "         25       1.00      1.00      1.00         2\n",
      "         26       1.00      1.00      1.00         3\n",
      "         27       1.00      1.00      1.00         3\n",
      "         28       1.00      1.00      1.00         4\n",
      "         29       1.00      0.80      0.89         5\n",
      "         30       1.00      1.00      1.00         1\n",
      "         31       1.00      1.00      1.00         4\n",
      "         32       1.00      1.00      1.00         3\n",
      "         33       1.00      1.00      1.00         2\n",
      "         34       1.00      1.00      1.00         2\n",
      "         35       1.00      1.00      1.00         1\n",
      "         36       1.00      1.00      1.00         4\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         2\n",
      "         39       0.71      1.00      0.83         5\n",
      "\n",
      "avg / total       0.98      0.97      0.98       120\n",
      "\n",
      "(' Time ', '6.618', ' seconds')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-27 21:57:48,028][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=80.77%\n",
      "[ 2018-07-27 21:57:48,630][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-27 21:57:49,241][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=84.62%\n",
      "[ 2018-07-27 21:57:49,982][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=89.66%\n",
      "[ 2018-07-27 21:57:50,813][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=93.94%\n",
      "[ 2018-07-27 21:57:51,547][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=100.00%\n",
      "[ 2018-07-27 21:57:52,151][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=89.66%\n",
      "[ 2018-07-27 21:57:52,994][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=86.96%\n",
      "[ 2018-07-27 21:57:53,868][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=89.66%\n",
      "[ 2018-07-27 21:57:54,711][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=96.67%\n",
      "[ 2018-07-27 21:57:54,939][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=91.43%\n",
      "[ 2018-07-27 21:57:54,940][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=95.83%\n",
      "[ 2018-07-27 21:57:54,943][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=91.43%\n",
      "[ 2018-07-27 21:57:54,944][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=95.83%\n",
      "[ 2018-07-27 21:57:54,945][cascade_classifier.fit_transform] [Result][Reach Max Layer] opt_layer_num=1, accuracy_train=91.43%, accuracy_test=95.83%\n",
      "[ 2018-07-27 21:57:54,946][cascade_classifier.transform] X_groups_test.shape=[(120, 4402)]\n",
      "[ 2018-07-27 21:57:54,947][cascade_classifier.transform] group_dims=[4402]\n",
      "[ 2018-07-27 21:57:54,948][cascade_classifier.transform] X_test.shape=(120, 4402)\n",
      "[ 2018-07-27 21:57:54,949][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(120, 4402)\n",
      "[ 2018-07-27 21:57:56,813][cascade_classifier.fit_transform] X_groups_train.shape=[(280, 4440)],y_train.shape=(280,),X_groups_test.shape=[(120, 4440)],y_test.shape=(120,)\n",
      "[ 2018-07-27 21:57:56,814][cascade_classifier.fit_transform] group_dims=[4440]\n",
      "[ 2018-07-27 21:57:56,815][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-27 21:57:56,816][cascade_classifier.fit_transform] group_ends=[4440]\n",
      "[ 2018-07-27 21:57:56,817][cascade_classifier.fit_transform] X_train.shape=(280, 4440),X_test.shape=(120, 4440)\n",
      "[ 2018-07-27 21:57:56,819][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(280, 4440), X_cur_test.shape=(120, 4440)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test Accuracy of DeepExtratTrees = 95.833333 %', 'Layer :', 6)\n",
      "[[3 0 0 ..., 0 0 0]\n",
      " [0 2 0 ..., 0 0 0]\n",
      " [0 0 4 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 2 0]\n",
      " [0 0 0 ..., 0 0 5]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         3\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       1.00      1.00      1.00         4\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      0.83      0.91         6\n",
      "          5       1.00      1.00      1.00         3\n",
      "          6       1.00      0.75      0.86         4\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       1.00      1.00      1.00         2\n",
      "          9       1.00      0.67      0.80         3\n",
      "         10       0.67      1.00      0.80         2\n",
      "         11       1.00      1.00      1.00         3\n",
      "         12       1.00      1.00      1.00         2\n",
      "         13       1.00      1.00      1.00         4\n",
      "         14       1.00      1.00      1.00         5\n",
      "         15       1.00      1.00      1.00         3\n",
      "         16       1.00      1.00      1.00         3\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       1.00      1.00      1.00         5\n",
      "         19       1.00      1.00      1.00         3\n",
      "         20       0.75      1.00      0.86         3\n",
      "         22       0.80      1.00      0.89         4\n",
      "         23       1.00      1.00      1.00         3\n",
      "         24       1.00      0.67      0.80         3\n",
      "         25       1.00      1.00      1.00         2\n",
      "         26       1.00      1.00      1.00         3\n",
      "         27       1.00      1.00      1.00         3\n",
      "         28       1.00      1.00      1.00         4\n",
      "         29       1.00      0.80      0.89         5\n",
      "         30       1.00      1.00      1.00         1\n",
      "         31       1.00      1.00      1.00         4\n",
      "         32       1.00      1.00      1.00         3\n",
      "         33       1.00      1.00      1.00         2\n",
      "         34       1.00      1.00      1.00         2\n",
      "         35       1.00      1.00      1.00         1\n",
      "         36       1.00      1.00      1.00         4\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         2\n",
      "         39       0.71      1.00      0.83         5\n",
      "\n",
      "avg / total       0.97      0.96      0.96       120\n",
      "\n",
      "(' Time ', '7.449', ' seconds')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-27 21:57:57,337][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=84.62%\n",
      "[ 2018-07-27 21:57:57,946][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-27 21:57:58,595][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=96.15%\n",
      "[ 2018-07-27 21:57:59,201][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=93.10%\n",
      "[ 2018-07-27 21:57:59,815][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=93.94%\n",
      "[ 2018-07-27 21:58:00,431][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=100.00%\n",
      "[ 2018-07-27 21:58:01,048][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=93.10%\n",
      "[ 2018-07-27 21:58:01,664][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=86.96%\n",
      "[ 2018-07-27 21:58:02,272][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=89.66%\n",
      "[ 2018-07-27 21:58:02,878][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=93.33%\n",
      "[ 2018-07-27 21:58:02,982][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=93.21%\n",
      "[ 2018-07-27 21:58:02,984][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=96.67%\n",
      "[ 2018-07-27 21:58:02,987][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=93.21%\n",
      "[ 2018-07-27 21:58:02,988][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=96.67%\n",
      "[ 2018-07-27 21:58:02,988][cascade_classifier.fit_transform] [Result][Reach Max Layer] opt_layer_num=1, accuracy_train=93.21%, accuracy_test=96.67%\n",
      "[ 2018-07-27 21:58:02,990][cascade_classifier.transform] X_groups_test.shape=[(120, 4440)]\n",
      "[ 2018-07-27 21:58:02,991][cascade_classifier.transform] group_dims=[4440]\n",
      "[ 2018-07-27 21:58:02,992][cascade_classifier.transform] X_test.shape=(120, 4440)\n",
      "[ 2018-07-27 21:58:02,993][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(120, 4440)\n",
      "[ 2018-07-27 21:58:04,039][cascade_classifier.fit_transform] X_groups_train.shape=[(280, 4478)],y_train.shape=(280,),X_groups_test.shape=[(120, 4478)],y_test.shape=(120,)\n",
      "[ 2018-07-27 21:58:04,041][cascade_classifier.fit_transform] group_dims=[4478]\n",
      "[ 2018-07-27 21:58:04,042][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-27 21:58:04,043][cascade_classifier.fit_transform] group_ends=[4478]\n",
      "[ 2018-07-27 21:58:04,044][cascade_classifier.fit_transform] X_train.shape=(280, 4478),X_test.shape=(120, 4478)\n",
      "[ 2018-07-27 21:58:04,046][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(280, 4478), X_cur_test.shape=(120, 4478)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test Accuracy of DeepExtratTrees = 96.666667 %', 'Layer :', 7)\n",
      "[[3 0 0 ..., 0 0 0]\n",
      " [0 2 0 ..., 0 0 0]\n",
      " [0 0 4 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 2 0]\n",
      " [0 0 0 ..., 0 0 5]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         3\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       1.00      1.00      1.00         4\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      0.83      0.91         6\n",
      "          5       1.00      1.00      1.00         3\n",
      "          6       1.00      1.00      1.00         4\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       1.00      1.00      1.00         2\n",
      "          9       1.00      0.67      0.80         3\n",
      "         10       1.00      1.00      1.00         2\n",
      "         11       1.00      1.00      1.00         3\n",
      "         12       1.00      1.00      1.00         2\n",
      "         13       1.00      1.00      1.00         4\n",
      "         14       1.00      1.00      1.00         5\n",
      "         15       1.00      1.00      1.00         3\n",
      "         16       1.00      1.00      1.00         3\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       1.00      1.00      1.00         5\n",
      "         19       1.00      1.00      1.00         3\n",
      "         20       0.75      1.00      0.86         3\n",
      "         22       0.80      1.00      0.89         4\n",
      "         23       1.00      1.00      1.00         3\n",
      "         24       1.00      0.67      0.80         3\n",
      "         25       1.00      1.00      1.00         2\n",
      "         26       1.00      1.00      1.00         3\n",
      "         27       1.00      1.00      1.00         3\n",
      "         28       1.00      1.00      1.00         4\n",
      "         29       1.00      0.80      0.89         5\n",
      "         30       1.00      1.00      1.00         1\n",
      "         31       1.00      1.00      1.00         4\n",
      "         32       1.00      1.00      1.00         3\n",
      "         33       1.00      1.00      1.00         2\n",
      "         34       1.00      1.00      1.00         2\n",
      "         35       1.00      1.00      1.00         1\n",
      "         36       1.00      1.00      1.00         4\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         2\n",
      "         39       0.71      1.00      0.83         5\n",
      "\n",
      "avg / total       0.98      0.97      0.97       120\n",
      "\n",
      "(' Time ', '6.18', ' seconds')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-27 21:58:04,555][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=80.77%\n",
      "[ 2018-07-27 21:58:05,164][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-27 21:58:05,769][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=96.15%\n",
      "[ 2018-07-27 21:58:06,375][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=89.66%\n",
      "[ 2018-07-27 21:58:07,104][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=96.97%\n",
      "[ 2018-07-27 21:58:07,712][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=96.67%\n",
      "[ 2018-07-27 21:58:08,304][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=89.66%\n",
      "[ 2018-07-27 21:58:08,914][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=86.96%\n",
      "[ 2018-07-27 21:58:09,531][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=89.66%\n",
      "[ 2018-07-27 21:58:10,255][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=96.67%\n",
      "[ 2018-07-27 21:58:10,479][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=92.50%\n",
      "[ 2018-07-27 21:58:10,480][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=97.50%\n",
      "[ 2018-07-27 21:58:10,483][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=92.50%\n",
      "[ 2018-07-27 21:58:10,484][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=97.50%\n",
      "[ 2018-07-27 21:58:10,485][cascade_classifier.fit_transform] [Result][Reach Max Layer] opt_layer_num=1, accuracy_train=92.50%, accuracy_test=97.50%\n",
      "[ 2018-07-27 21:58:10,486][cascade_classifier.transform] X_groups_test.shape=[(120, 4478)]\n",
      "[ 2018-07-27 21:58:10,487][cascade_classifier.transform] group_dims=[4478]\n",
      "[ 2018-07-27 21:58:10,488][cascade_classifier.transform] X_test.shape=(120, 4478)\n",
      "[ 2018-07-27 21:58:10,489][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(120, 4478)\n",
      "[ 2018-07-27 21:58:11,657][cascade_classifier.fit_transform] X_groups_train.shape=[(280, 4516)],y_train.shape=(280,),X_groups_test.shape=[(120, 4516)],y_test.shape=(120,)\n",
      "[ 2018-07-27 21:58:11,659][cascade_classifier.fit_transform] group_dims=[4516]\n",
      "[ 2018-07-27 21:58:11,660][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-27 21:58:11,661][cascade_classifier.fit_transform] group_ends=[4516]\n",
      "[ 2018-07-27 21:58:11,662][cascade_classifier.fit_transform] X_train.shape=(280, 4516),X_test.shape=(120, 4516)\n",
      "[ 2018-07-27 21:58:11,665][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(280, 4516), X_cur_test.shape=(120, 4516)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test Accuracy of DeepExtratTrees = 97.500000 %', 'Layer :', 8)\n",
      "[[3 0 0 ..., 0 0 0]\n",
      " [0 2 0 ..., 0 0 0]\n",
      " [0 0 4 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 2 0]\n",
      " [0 0 0 ..., 0 0 5]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         3\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       1.00      1.00      1.00         4\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      0.83      0.91         6\n",
      "          5       1.00      1.00      1.00         3\n",
      "          6       1.00      1.00      1.00         4\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       1.00      1.00      1.00         2\n",
      "          9       1.00      0.67      0.80         3\n",
      "         10       1.00      1.00      1.00         2\n",
      "         11       1.00      1.00      1.00         3\n",
      "         12       1.00      1.00      1.00         2\n",
      "         13       1.00      1.00      1.00         4\n",
      "         14       1.00      1.00      1.00         5\n",
      "         15       1.00      1.00      1.00         3\n",
      "         16       1.00      1.00      1.00         3\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       1.00      1.00      1.00         5\n",
      "         19       1.00      1.00      1.00         3\n",
      "         20       0.75      1.00      0.86         3\n",
      "         22       1.00      1.00      1.00         4\n",
      "         23       1.00      1.00      1.00         3\n",
      "         24       1.00      1.00      1.00         3\n",
      "         25       1.00      1.00      1.00         2\n",
      "         26       1.00      1.00      1.00         3\n",
      "         27       1.00      1.00      1.00         3\n",
      "         28       1.00      1.00      1.00         4\n",
      "         29       1.00      0.80      0.89         5\n",
      "         30       1.00      1.00      1.00         1\n",
      "         31       1.00      1.00      1.00         4\n",
      "         32       1.00      1.00      1.00         3\n",
      "         33       1.00      1.00      1.00         2\n",
      "         34       1.00      1.00      1.00         2\n",
      "         35       1.00      1.00      1.00         1\n",
      "         36       1.00      1.00      1.00         4\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         2\n",
      "         39       0.71      1.00      0.83         5\n",
      "\n",
      "avg / total       0.98      0.97      0.98       120\n",
      "\n",
      "(' Time ', '6.451', ' seconds')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-27 21:58:12,158][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=84.62%\n",
      "[ 2018-07-27 21:58:12,762][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-27 21:58:13,481][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=92.31%\n",
      "[ 2018-07-27 21:58:14,093][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=89.66%\n",
      "[ 2018-07-27 21:58:14,815][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=93.94%\n",
      "[ 2018-07-27 21:58:15,420][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=96.67%\n",
      "[ 2018-07-27 21:58:16,023][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=93.10%\n",
      "[ 2018-07-27 21:58:16,641][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=86.96%\n",
      "[ 2018-07-27 21:58:17,252][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=89.66%\n",
      "[ 2018-07-27 21:58:17,857][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=96.67%\n",
      "[ 2018-07-27 21:58:17,963][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=92.50%\n",
      "[ 2018-07-27 21:58:17,964][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=96.67%\n",
      "[ 2018-07-27 21:58:17,967][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=92.50%\n",
      "[ 2018-07-27 21:58:17,968][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=96.67%\n",
      "[ 2018-07-27 21:58:17,969][cascade_classifier.fit_transform] [Result][Reach Max Layer] opt_layer_num=1, accuracy_train=92.50%, accuracy_test=96.67%\n",
      "[ 2018-07-27 21:58:17,970][cascade_classifier.transform] X_groups_test.shape=[(120, 4516)]\n",
      "[ 2018-07-27 21:58:17,971][cascade_classifier.transform] group_dims=[4516]\n",
      "[ 2018-07-27 21:58:17,972][cascade_classifier.transform] X_test.shape=(120, 4516)\n",
      "[ 2018-07-27 21:58:17,973][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(120, 4516)\n",
      "[ 2018-07-27 21:58:19,297][cascade_classifier.fit_transform] X_groups_train.shape=[(280, 4554)],y_train.shape=(280,),X_groups_test.shape=[(120, 4554)],y_test.shape=(120,)\n",
      "[ 2018-07-27 21:58:19,299][cascade_classifier.fit_transform] group_dims=[4554]\n",
      "[ 2018-07-27 21:58:19,300][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-27 21:58:19,301][cascade_classifier.fit_transform] group_ends=[4554]\n",
      "[ 2018-07-27 21:58:19,302][cascade_classifier.fit_transform] X_train.shape=(280, 4554),X_test.shape=(120, 4554)\n",
      "[ 2018-07-27 21:58:19,306][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(280, 4554), X_cur_test.shape=(120, 4554)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test Accuracy of DeepExtratTrees = 96.666667 %', 'Layer :', 9)\n",
      "[[3 0 0 ..., 0 0 0]\n",
      " [0 2 0 ..., 0 0 0]\n",
      " [0 0 4 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 2 0]\n",
      " [0 0 0 ..., 0 0 5]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      1.00      0.86         3\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       1.00      1.00      1.00         4\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      0.83      0.91         6\n",
      "          5       1.00      1.00      1.00         3\n",
      "          6       1.00      1.00      1.00         4\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       1.00      1.00      1.00         2\n",
      "          9       1.00      0.67      0.80         3\n",
      "         10       1.00      1.00      1.00         2\n",
      "         11       1.00      1.00      1.00         3\n",
      "         12       1.00      1.00      1.00         2\n",
      "         13       1.00      1.00      1.00         4\n",
      "         14       1.00      1.00      1.00         5\n",
      "         15       1.00      1.00      1.00         3\n",
      "         16       1.00      1.00      1.00         3\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       1.00      1.00      1.00         5\n",
      "         19       0.75      1.00      0.86         3\n",
      "         20       0.75      1.00      0.86         3\n",
      "         22       0.80      1.00      0.89         4\n",
      "         23       1.00      1.00      1.00         3\n",
      "         24       1.00      0.67      0.80         3\n",
      "         25       1.00      1.00      1.00         2\n",
      "         26       1.00      1.00      1.00         3\n",
      "         27       1.00      1.00      1.00         3\n",
      "         28       1.00      1.00      1.00         4\n",
      "         29       1.00      0.80      0.89         5\n",
      "         30       1.00      1.00      1.00         1\n",
      "         31       1.00      1.00      1.00         4\n",
      "         32       1.00      1.00      1.00         3\n",
      "         33       1.00      1.00      1.00         2\n",
      "         34       1.00      1.00      1.00         2\n",
      "         35       1.00      1.00      1.00         1\n",
      "         36       1.00      1.00      1.00         4\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         2\n",
      "         39       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       0.97      0.97      0.97       120\n",
      "\n",
      "(' Time ', '6.316', ' seconds')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-27 21:58:19,945][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=80.77%\n",
      "[ 2018-07-27 21:58:20,687][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-27 21:58:21,295][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=96.15%\n",
      "[ 2018-07-27 21:58:21,910][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=89.66%\n",
      "[ 2018-07-27 21:58:22,517][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=96.97%\n",
      "[ 2018-07-27 21:58:23,125][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=100.00%\n",
      "[ 2018-07-27 21:58:23,735][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=89.66%\n",
      "[ 2018-07-27 21:58:24,347][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=91.30%\n",
      "[ 2018-07-27 21:58:24,956][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=89.66%\n",
      "[ 2018-07-27 21:58:25,560][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=96.67%\n",
      "[ 2018-07-27 21:58:25,779][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=93.21%\n",
      "[ 2018-07-27 21:58:25,780][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=96.67%\n",
      "[ 2018-07-27 21:58:25,784][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=93.21%\n",
      "[ 2018-07-27 21:58:25,784][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=96.67%\n",
      "[ 2018-07-27 21:58:25,785][cascade_classifier.fit_transform] [Result][Reach Max Layer] opt_layer_num=1, accuracy_train=93.21%, accuracy_test=96.67%\n",
      "[ 2018-07-27 21:58:25,786][cascade_classifier.transform] X_groups_test.shape=[(120, 4554)]\n",
      "[ 2018-07-27 21:58:25,787][cascade_classifier.transform] group_dims=[4554]\n",
      "[ 2018-07-27 21:58:25,788][cascade_classifier.transform] X_test.shape=(120, 4554)\n",
      "[ 2018-07-27 21:58:25,789][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(120, 4554)\n",
      "[ 2018-07-27 21:58:27,070][cascade_classifier.fit_transform] X_groups_train.shape=[(280, 4592)],y_train.shape=(280,),X_groups_test.shape=[(120, 4592)],y_test.shape=(120,)\n",
      "[ 2018-07-27 21:58:27,071][cascade_classifier.fit_transform] group_dims=[4592]\n",
      "[ 2018-07-27 21:58:27,072][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-27 21:58:27,073][cascade_classifier.fit_transform] group_ends=[4592]\n",
      "[ 2018-07-27 21:58:27,074][cascade_classifier.fit_transform] X_train.shape=(280, 4592),X_test.shape=(120, 4592)\n",
      "[ 2018-07-27 21:58:27,076][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(280, 4592), X_cur_test.shape=(120, 4592)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test Accuracy of DeepExtratTrees = 96.666667 %', 'Layer :', 10)\n",
      "[[3 0 0 ..., 0 0 0]\n",
      " [0 2 0 ..., 0 0 0]\n",
      " [0 0 4 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 2 0]\n",
      " [0 0 0 ..., 0 0 5]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      1.00      0.86         3\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       1.00      1.00      1.00         4\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      0.83      0.91         6\n",
      "          5       1.00      1.00      1.00         3\n",
      "          6       1.00      1.00      1.00         4\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       1.00      1.00      1.00         2\n",
      "          9       1.00      0.67      0.80         3\n",
      "         10       1.00      1.00      1.00         2\n",
      "         11       1.00      1.00      1.00         3\n",
      "         12       1.00      1.00      1.00         2\n",
      "         13       1.00      1.00      1.00         4\n",
      "         14       1.00      1.00      1.00         5\n",
      "         15       1.00      1.00      1.00         3\n",
      "         16       0.75      1.00      0.86         3\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       1.00      1.00      1.00         5\n",
      "         19       1.00      1.00      1.00         3\n",
      "         20       0.75      1.00      0.86         3\n",
      "         22       0.80      1.00      0.89         4\n",
      "         23       1.00      1.00      1.00         3\n",
      "         24       1.00      0.67      0.80         3\n",
      "         25       1.00      1.00      1.00         2\n",
      "         26       1.00      1.00      1.00         3\n",
      "         27       1.00      1.00      1.00         3\n",
      "         28       1.00      1.00      1.00         4\n",
      "         29       1.00      0.80      0.89         5\n",
      "         30       1.00      1.00      1.00         1\n",
      "         31       1.00      1.00      1.00         4\n",
      "         32       1.00      1.00      1.00         3\n",
      "         33       1.00      1.00      1.00         2\n",
      "         34       1.00      1.00      1.00         2\n",
      "         35       1.00      1.00      1.00         1\n",
      "         36       1.00      1.00      1.00         4\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         2\n",
      "         39       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       0.97      0.97      0.97       120\n",
      "\n",
      "(' Time ', '6.494', ' seconds')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-27 21:58:27,594][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=84.62%\n",
      "[ 2018-07-27 21:58:28,202][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-27 21:58:28,823][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=88.46%\n",
      "[ 2018-07-27 21:58:29,437][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=89.66%\n",
      "[ 2018-07-27 21:58:30,159][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=96.97%\n",
      "[ 2018-07-27 21:58:30,765][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=96.67%\n",
      "[ 2018-07-27 21:58:31,374][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=89.66%\n",
      "[ 2018-07-27 21:58:31,982][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=86.96%\n",
      "[ 2018-07-27 21:58:32,598][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=89.66%\n",
      "[ 2018-07-27 21:58:33,211][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=96.67%\n",
      "[ 2018-07-27 21:58:33,316][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=92.14%\n",
      "[ 2018-07-27 21:58:33,317][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=96.67%\n",
      "[ 2018-07-27 21:58:33,320][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=92.14%\n",
      "[ 2018-07-27 21:58:33,321][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=96.67%\n",
      "[ 2018-07-27 21:58:33,322][cascade_classifier.fit_transform] [Result][Reach Max Layer] opt_layer_num=1, accuracy_train=92.14%, accuracy_test=96.67%\n",
      "[ 2018-07-27 21:58:33,323][cascade_classifier.transform] X_groups_test.shape=[(120, 4592)]\n",
      "[ 2018-07-27 21:58:33,324][cascade_classifier.transform] group_dims=[4592]\n",
      "[ 2018-07-27 21:58:33,325][cascade_classifier.transform] X_test.shape=(120, 4592)\n",
      "[ 2018-07-27 21:58:33,326][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(120, 4592)\n",
      "[ 2018-07-27 21:58:34,720][cascade_classifier.fit_transform] X_groups_train.shape=[(280, 4630)],y_train.shape=(280,),X_groups_test.shape=[(120, 4630)],y_test.shape=(120,)\n",
      "[ 2018-07-27 21:58:34,722][cascade_classifier.fit_transform] group_dims=[4630]\n",
      "[ 2018-07-27 21:58:34,723][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-27 21:58:34,723][cascade_classifier.fit_transform] group_ends=[4630]\n",
      "[ 2018-07-27 21:58:34,724][cascade_classifier.fit_transform] X_train.shape=(280, 4630),X_test.shape=(120, 4630)\n",
      "[ 2018-07-27 21:58:34,726][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(280, 4630), X_cur_test.shape=(120, 4630)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test Accuracy of DeepExtratTrees = 96.666667 %', 'Layer :', 11)\n",
      "[[3 0 0 ..., 0 0 0]\n",
      " [0 2 0 ..., 0 0 0]\n",
      " [0 0 4 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 2 0]\n",
      " [0 0 0 ..., 0 0 5]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         3\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       1.00      1.00      1.00         4\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      0.83      0.91         6\n",
      "          5       1.00      1.00      1.00         3\n",
      "          6       1.00      1.00      1.00         4\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       1.00      1.00      1.00         2\n",
      "          9       1.00      0.67      0.80         3\n",
      "         10       1.00      1.00      1.00         2\n",
      "         11       1.00      1.00      1.00         3\n",
      "         12       1.00      1.00      1.00         2\n",
      "         13       1.00      1.00      1.00         4\n",
      "         14       1.00      1.00      1.00         5\n",
      "         15       1.00      1.00      1.00         3\n",
      "         16       1.00      1.00      1.00         3\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       1.00      1.00      1.00         5\n",
      "         19       1.00      1.00      1.00         3\n",
      "         20       0.75      1.00      0.86         3\n",
      "         22       0.80      1.00      0.89         4\n",
      "         23       1.00      1.00      1.00         3\n",
      "         24       1.00      0.67      0.80         3\n",
      "         25       1.00      1.00      1.00         2\n",
      "         26       1.00      1.00      1.00         3\n",
      "         27       1.00      1.00      1.00         3\n",
      "         28       1.00      1.00      1.00         4\n",
      "         29       1.00      0.80      0.89         5\n",
      "         30       1.00      1.00      1.00         1\n",
      "         31       1.00      1.00      1.00         4\n",
      "         32       1.00      1.00      1.00         3\n",
      "         33       1.00      1.00      1.00         2\n",
      "         34       1.00      1.00      1.00         2\n",
      "         35       1.00      1.00      1.00         1\n",
      "         36       1.00      1.00      1.00         4\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         2\n",
      "         39       0.71      1.00      0.83         5\n",
      "\n",
      "avg / total       0.98      0.97      0.97       120\n",
      "\n",
      "(' Time ', '6.257', ' seconds')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-27 21:58:35,243][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=80.77%\n",
      "[ 2018-07-27 21:58:35,851][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-27 21:58:36,456][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=88.46%\n",
      "[ 2018-07-27 21:58:37,175][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=89.66%\n",
      "[ 2018-07-27 21:58:37,899][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=93.94%\n",
      "[ 2018-07-27 21:58:38,508][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=96.67%\n",
      "[ 2018-07-27 21:58:39,098][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=93.10%\n",
      "[ 2018-07-27 21:58:39,703][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=86.96%\n",
      "[ 2018-07-27 21:58:40,312][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=89.66%\n",
      "[ 2018-07-27 21:58:41,151][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=96.67%\n",
      "[ 2018-07-27 21:58:41,257][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=91.79%\n",
      "[ 2018-07-27 21:58:41,258][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=97.50%\n",
      "[ 2018-07-27 21:58:41,261][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=91.79%\n",
      "[ 2018-07-27 21:58:41,261][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=97.50%\n",
      "[ 2018-07-27 21:58:41,262][cascade_classifier.fit_transform] [Result][Reach Max Layer] opt_layer_num=1, accuracy_train=91.79%, accuracy_test=97.50%\n",
      "[ 2018-07-27 21:58:41,263][cascade_classifier.transform] X_groups_test.shape=[(120, 4630)]\n",
      "[ 2018-07-27 21:58:41,264][cascade_classifier.transform] group_dims=[4630]\n",
      "[ 2018-07-27 21:58:41,265][cascade_classifier.transform] X_test.shape=(120, 4630)\n",
      "[ 2018-07-27 21:58:41,266][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(120, 4630)\n",
      "[ 2018-07-27 21:58:42,556][cascade_classifier.fit_transform] X_groups_train.shape=[(280, 4668)],y_train.shape=(280,),X_groups_test.shape=[(120, 4668)],y_test.shape=(120,)\n",
      "[ 2018-07-27 21:58:42,557][cascade_classifier.fit_transform] group_dims=[4668]\n",
      "[ 2018-07-27 21:58:42,558][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-27 21:58:42,559][cascade_classifier.fit_transform] group_ends=[4668]\n",
      "[ 2018-07-27 21:58:42,560][cascade_classifier.fit_transform] X_train.shape=(280, 4668),X_test.shape=(120, 4668)\n",
      "[ 2018-07-27 21:58:42,561][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(280, 4668), X_cur_test.shape=(120, 4668)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test Accuracy of DeepExtratTrees = 97.500000 %', 'Layer :', 12)\n",
      "[[3 0 0 ..., 0 0 0]\n",
      " [0 2 0 ..., 0 0 0]\n",
      " [0 0 4 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 2 0]\n",
      " [0 0 0 ..., 0 0 5]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         3\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       1.00      1.00      1.00         4\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      0.83      0.91         6\n",
      "          5       1.00      1.00      1.00         3\n",
      "          6       1.00      1.00      1.00         4\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       1.00      1.00      1.00         2\n",
      "          9       1.00      0.67      0.80         3\n",
      "         10       1.00      1.00      1.00         2\n",
      "         11       1.00      1.00      1.00         3\n",
      "         12       1.00      1.00      1.00         2\n",
      "         13       1.00      1.00      1.00         4\n",
      "         14       1.00      1.00      1.00         5\n",
      "         15       1.00      1.00      1.00         3\n",
      "         16       1.00      1.00      1.00         3\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       1.00      1.00      1.00         5\n",
      "         19       1.00      1.00      1.00         3\n",
      "         20       0.75      1.00      0.86         3\n",
      "         22       1.00      1.00      1.00         4\n",
      "         23       1.00      1.00      1.00         3\n",
      "         24       1.00      1.00      1.00         3\n",
      "         25       1.00      1.00      1.00         2\n",
      "         26       1.00      1.00      1.00         3\n",
      "         27       1.00      1.00      1.00         3\n",
      "         28       1.00      1.00      1.00         4\n",
      "         29       1.00      0.80      0.89         5\n",
      "         30       1.00      1.00      1.00         1\n",
      "         31       1.00      1.00      1.00         4\n",
      "         32       1.00      1.00      1.00         3\n",
      "         33       1.00      1.00      1.00         2\n",
      "         34       1.00      1.00      1.00         2\n",
      "         35       1.00      1.00      1.00         1\n",
      "         36       1.00      1.00      1.00         4\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         2\n",
      "         39       0.71      1.00      0.83         5\n",
      "\n",
      "avg / total       0.98      0.97      0.98       120\n",
      "\n",
      "(' Time ', '6.547', ' seconds')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-27 21:58:43,074][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=76.92%\n",
      "[ 2018-07-27 21:58:43,676][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-27 21:58:44,293][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=88.46%\n",
      "[ 2018-07-27 21:58:44,906][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=89.66%\n",
      "[ 2018-07-27 21:58:45,518][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=96.97%\n",
      "[ 2018-07-27 21:58:46,127][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=100.00%\n",
      "[ 2018-07-27 21:58:46,738][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=89.66%\n",
      "[ 2018-07-27 21:58:47,354][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=86.96%\n",
      "[ 2018-07-27 21:58:47,961][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=89.66%\n",
      "[ 2018-07-27 21:58:48,567][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=96.67%\n",
      "[ 2018-07-27 21:58:48,820][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=91.79%\n",
      "[ 2018-07-27 21:58:48,821][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=97.50%\n",
      "[ 2018-07-27 21:58:48,824][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=91.79%\n",
      "[ 2018-07-27 21:58:48,825][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=97.50%\n",
      "[ 2018-07-27 21:58:48,826][cascade_classifier.fit_transform] [Result][Reach Max Layer] opt_layer_num=1, accuracy_train=91.79%, accuracy_test=97.50%\n",
      "[ 2018-07-27 21:58:48,826][cascade_classifier.transform] X_groups_test.shape=[(120, 4668)]\n",
      "[ 2018-07-27 21:58:48,828][cascade_classifier.transform] group_dims=[4668]\n",
      "[ 2018-07-27 21:58:48,828][cascade_classifier.transform] X_test.shape=(120, 4668)\n",
      "[ 2018-07-27 21:58:48,830][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(120, 4668)\n",
      "[ 2018-07-27 21:58:50,013][cascade_classifier.fit_transform] X_groups_train.shape=[(280, 4706)],y_train.shape=(280,),X_groups_test.shape=[(120, 4706)],y_test.shape=(120,)\n",
      "[ 2018-07-27 21:58:50,015][cascade_classifier.fit_transform] group_dims=[4706]\n",
      "[ 2018-07-27 21:58:50,017][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-27 21:58:50,018][cascade_classifier.fit_transform] group_ends=[4706]\n",
      "[ 2018-07-27 21:58:50,019][cascade_classifier.fit_transform] X_train.shape=(280, 4706),X_test.shape=(120, 4706)\n",
      "[ 2018-07-27 21:58:50,022][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(280, 4706), X_cur_test.shape=(120, 4706)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test Accuracy of DeepExtratTrees = 97.500000 %', 'Layer :', 13)\n",
      "[[3 0 0 ..., 0 0 0]\n",
      " [0 2 0 ..., 0 0 0]\n",
      " [0 0 4 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 2 0]\n",
      " [0 0 0 ..., 0 0 5]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      1.00      0.86         3\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       1.00      1.00      1.00         4\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      0.83      0.91         6\n",
      "          5       1.00      1.00      1.00         3\n",
      "          6       1.00      1.00      1.00         4\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       1.00      1.00      1.00         2\n",
      "          9       1.00      0.67      0.80         3\n",
      "         10       1.00      1.00      1.00         2\n",
      "         11       1.00      1.00      1.00         3\n",
      "         12       1.00      1.00      1.00         2\n",
      "         13       1.00      1.00      1.00         4\n",
      "         14       1.00      1.00      1.00         5\n",
      "         15       1.00      1.00      1.00         3\n",
      "         16       1.00      1.00      1.00         3\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       1.00      1.00      1.00         5\n",
      "         19       1.00      1.00      1.00         3\n",
      "         20       0.75      1.00      0.86         3\n",
      "         22       1.00      1.00      1.00         4\n",
      "         23       1.00      1.00      1.00         3\n",
      "         24       1.00      1.00      1.00         3\n",
      "         25       1.00      1.00      1.00         2\n",
      "         26       1.00      1.00      1.00         3\n",
      "         27       1.00      1.00      1.00         3\n",
      "         28       1.00      1.00      1.00         4\n",
      "         29       1.00      0.80      0.89         5\n",
      "         30       1.00      1.00      1.00         1\n",
      "         31       1.00      1.00      1.00         4\n",
      "         32       1.00      1.00      1.00         3\n",
      "         33       1.00      1.00      1.00         2\n",
      "         34       1.00      1.00      1.00         2\n",
      "         35       1.00      1.00      1.00         1\n",
      "         36       1.00      1.00      1.00         4\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         2\n",
      "         39       0.83      1.00      0.91         5\n",
      "\n",
      "avg / total       0.98      0.97      0.97       120\n",
      "\n",
      "(' Time ', '6.274', ' seconds')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-27 21:58:50,640][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=84.62%\n",
      "[ 2018-07-27 21:58:51,231][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-27 21:58:51,843][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=96.15%\n",
      "[ 2018-07-27 21:58:52,688][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=89.66%\n",
      "[ 2018-07-27 21:58:53,393][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=93.94%\n",
      "[ 2018-07-27 21:58:54,228][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=96.67%\n",
      "[ 2018-07-27 21:58:54,937][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=93.10%\n",
      "[ 2018-07-27 21:58:55,653][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=86.96%\n",
      "[ 2018-07-27 21:58:56,561][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=89.66%\n",
      "[ 2018-07-27 21:58:57,287][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=93.33%\n",
      "[ 2018-07-27 21:58:57,392][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=92.50%\n",
      "[ 2018-07-27 21:58:57,393][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=97.50%\n",
      "[ 2018-07-27 21:58:57,397][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=92.50%\n",
      "[ 2018-07-27 21:58:57,398][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=97.50%\n",
      "[ 2018-07-27 21:58:57,399][cascade_classifier.fit_transform] [Result][Reach Max Layer] opt_layer_num=1, accuracy_train=92.50%, accuracy_test=97.50%\n",
      "[ 2018-07-27 21:58:57,400][cascade_classifier.transform] X_groups_test.shape=[(120, 4706)]\n",
      "[ 2018-07-27 21:58:57,401][cascade_classifier.transform] group_dims=[4706]\n",
      "[ 2018-07-27 21:58:57,402][cascade_classifier.transform] X_test.shape=(120, 4706)\n",
      "[ 2018-07-27 21:58:57,404][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(120, 4706)\n",
      "[ 2018-07-27 21:58:58,455][cascade_classifier.fit_transform] X_groups_train.shape=[(280, 4744)],y_train.shape=(280,),X_groups_test.shape=[(120, 4744)],y_test.shape=(120,)\n",
      "[ 2018-07-27 21:58:58,457][cascade_classifier.fit_transform] group_dims=[4744]\n",
      "[ 2018-07-27 21:58:58,458][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-27 21:58:58,459][cascade_classifier.fit_transform] group_ends=[4744]\n",
      "[ 2018-07-27 21:58:58,460][cascade_classifier.fit_transform] X_train.shape=(280, 4744),X_test.shape=(120, 4744)\n",
      "[ 2018-07-27 21:58:58,462][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(280, 4744), X_cur_test.shape=(120, 4744)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test Accuracy of DeepExtratTrees = 97.500000 %', 'Layer :', 14)\n",
      "[[3 0 0 ..., 0 0 0]\n",
      " [0 2 0 ..., 0 0 0]\n",
      " [0 0 4 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 2 0]\n",
      " [0 0 0 ..., 0 0 5]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      1.00      0.86         3\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       1.00      1.00      1.00         4\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      0.83      0.91         6\n",
      "          5       1.00      1.00      1.00         3\n",
      "          6       1.00      1.00      1.00         4\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       1.00      1.00      1.00         2\n",
      "          9       1.00      0.67      0.80         3\n",
      "         10       1.00      1.00      1.00         2\n",
      "         11       1.00      1.00      1.00         3\n",
      "         12       1.00      1.00      1.00         2\n",
      "         13       1.00      1.00      1.00         4\n",
      "         14       1.00      1.00      1.00         5\n",
      "         15       1.00      1.00      1.00         3\n",
      "         16       1.00      1.00      1.00         3\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       1.00      1.00      1.00         5\n",
      "         19       1.00      1.00      1.00         3\n",
      "         20       0.75      1.00      0.86         3\n",
      "         22       1.00      1.00      1.00         4\n",
      "         23       1.00      1.00      1.00         3\n",
      "         24       1.00      1.00      1.00         3\n",
      "         25       1.00      1.00      1.00         2\n",
      "         26       1.00      1.00      1.00         3\n",
      "         27       1.00      1.00      1.00         3\n",
      "         28       1.00      1.00      1.00         4\n",
      "         29       1.00      0.80      0.89         5\n",
      "         30       1.00      1.00      1.00         1\n",
      "         31       1.00      1.00      1.00         4\n",
      "         32       1.00      1.00      1.00         3\n",
      "         33       1.00      1.00      1.00         2\n",
      "         34       1.00      1.00      1.00         2\n",
      "         35       1.00      1.00      1.00         1\n",
      "         36       1.00      1.00      1.00         4\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         2\n",
      "         39       0.83      1.00      0.91         5\n",
      "\n",
      "avg / total       0.98      0.97      0.97       120\n",
      "\n",
      "(' Time ', '7.39', ' seconds')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-27 21:58:58,981][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=80.77%\n",
      "[ 2018-07-27 21:58:59,572][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-27 21:59:00,177][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=92.31%\n",
      "[ 2018-07-27 21:59:00,787][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=89.66%\n",
      "[ 2018-07-27 21:59:01,399][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=90.91%\n",
      "[ 2018-07-27 21:59:02,126][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=96.67%\n",
      "[ 2018-07-27 21:59:02,740][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=93.10%\n",
      "[ 2018-07-27 21:59:03,332][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=86.96%\n",
      "[ 2018-07-27 21:59:04,229][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=89.66%\n",
      "[ 2018-07-27 21:59:04,954][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=96.67%\n",
      "[ 2018-07-27 21:59:05,191][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=91.79%\n",
      "[ 2018-07-27 21:59:05,192][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=97.50%\n",
      "[ 2018-07-27 21:59:05,197][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=91.79%\n",
      "[ 2018-07-27 21:59:05,198][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=97.50%\n",
      "[ 2018-07-27 21:59:05,199][cascade_classifier.fit_transform] [Result][Reach Max Layer] opt_layer_num=1, accuracy_train=91.79%, accuracy_test=97.50%\n",
      "[ 2018-07-27 21:59:05,200][cascade_classifier.transform] X_groups_test.shape=[(120, 4744)]\n",
      "[ 2018-07-27 21:59:05,202][cascade_classifier.transform] group_dims=[4744]\n",
      "[ 2018-07-27 21:59:05,203][cascade_classifier.transform] X_test.shape=(120, 4744)\n",
      "[ 2018-07-27 21:59:05,204][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(120, 4744)\n",
      "[ 2018-07-27 21:59:07,439][cascade_classifier.fit_transform] X_groups_train.shape=[(280, 4782)],y_train.shape=(280,),X_groups_test.shape=[(120, 4782)],y_test.shape=(120,)\n",
      "[ 2018-07-27 21:59:07,441][cascade_classifier.fit_transform] group_dims=[4782]\n",
      "[ 2018-07-27 21:59:07,442][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-27 21:59:07,443][cascade_classifier.fit_transform] group_ends=[4782]\n",
      "[ 2018-07-27 21:59:07,444][cascade_classifier.fit_transform] X_train.shape=(280, 4782),X_test.shape=(120, 4782)\n",
      "[ 2018-07-27 21:59:07,447][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(280, 4782), X_cur_test.shape=(120, 4782)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test Accuracy of DeepExtratTrees = 97.500000 %', 'Layer :', 15)\n",
      "[[3 0 0 ..., 0 0 0]\n",
      " [0 2 0 ..., 0 0 0]\n",
      " [0 0 4 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 2 0]\n",
      " [0 0 0 ..., 0 0 5]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      1.00      0.86         3\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       1.00      1.00      1.00         4\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      0.83      0.91         6\n",
      "          5       1.00      1.00      1.00         3\n",
      "          6       1.00      1.00      1.00         4\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       1.00      1.00      1.00         2\n",
      "          9       1.00      0.67      0.80         3\n",
      "         10       1.00      1.00      1.00         2\n",
      "         11       1.00      1.00      1.00         3\n",
      "         12       1.00      1.00      1.00         2\n",
      "         13       1.00      1.00      1.00         4\n",
      "         14       1.00      1.00      1.00         5\n",
      "         15       1.00      1.00      1.00         3\n",
      "         16       1.00      1.00      1.00         3\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       1.00      1.00      1.00         5\n",
      "         19       1.00      1.00      1.00         3\n",
      "         20       0.75      1.00      0.86         3\n",
      "         22       1.00      1.00      1.00         4\n",
      "         23       1.00      1.00      1.00         3\n",
      "         24       1.00      1.00      1.00         3\n",
      "         25       1.00      1.00      1.00         2\n",
      "         26       1.00      1.00      1.00         3\n",
      "         27       1.00      1.00      1.00         3\n",
      "         28       1.00      1.00      1.00         4\n",
      "         29       1.00      0.80      0.89         5\n",
      "         30       1.00      1.00      1.00         1\n",
      "         31       1.00      1.00      1.00         4\n",
      "         32       1.00      1.00      1.00         3\n",
      "         33       1.00      1.00      1.00         2\n",
      "         34       1.00      1.00      1.00         2\n",
      "         35       1.00      1.00      1.00         1\n",
      "         36       1.00      1.00      1.00         4\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         2\n",
      "         39       0.83      1.00      0.91         5\n",
      "\n",
      "avg / total       0.98      0.97      0.97       120\n",
      "\n",
      "(' Time ', '6.749', ' seconds')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-27 21:59:08,211][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=88.46%\n",
      "[ 2018-07-27 21:59:09,194][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-27 21:59:10,218][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=88.46%\n",
      "[ 2018-07-27 21:59:11,162][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=89.66%\n",
      "[ 2018-07-27 21:59:12,119][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=93.94%\n",
      "[ 2018-07-27 21:59:13,065][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=96.67%\n",
      "[ 2018-07-27 21:59:13,913][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=89.66%\n",
      "[ 2018-07-27 21:59:14,769][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=86.96%\n",
      "[ 2018-07-27 21:59:15,482][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=89.66%\n",
      "[ 2018-07-27 21:59:16,337][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=96.67%\n",
      "[ 2018-07-27 21:59:16,567][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=92.14%\n",
      "[ 2018-07-27 21:59:16,569][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=97.50%\n",
      "[ 2018-07-27 21:59:16,572][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=92.14%\n",
      "[ 2018-07-27 21:59:16,573][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=97.50%\n",
      "[ 2018-07-27 21:59:16,574][cascade_classifier.fit_transform] [Result][Reach Max Layer] opt_layer_num=1, accuracy_train=92.14%, accuracy_test=97.50%\n",
      "[ 2018-07-27 21:59:16,575][cascade_classifier.transform] X_groups_test.shape=[(120, 4782)]\n",
      "[ 2018-07-27 21:59:16,576][cascade_classifier.transform] group_dims=[4782]\n",
      "[ 2018-07-27 21:59:16,577][cascade_classifier.transform] X_test.shape=(120, 4782)\n",
      "[ 2018-07-27 21:59:16,579][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(120, 4782)\n",
      "[ 2018-07-27 21:59:18,780][cascade_classifier.fit_transform] X_groups_train.shape=[(280, 4820)],y_train.shape=(280,),X_groups_test.shape=[(120, 4820)],y_test.shape=(120,)\n",
      "[ 2018-07-27 21:59:18,783][cascade_classifier.fit_transform] group_dims=[4820]\n",
      "[ 2018-07-27 21:59:18,783][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-27 21:59:18,785][cascade_classifier.fit_transform] group_ends=[4820]\n",
      "[ 2018-07-27 21:59:18,786][cascade_classifier.fit_transform] X_train.shape=(280, 4820),X_test.shape=(120, 4820)\n",
      "[ 2018-07-27 21:59:18,789][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(280, 4820), X_cur_test.shape=(120, 4820)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test Accuracy of DeepExtratTrees = 97.500000 %', 'Layer :', 16)\n",
      "[[3 0 0 ..., 0 0 0]\n",
      " [0 2 0 ..., 0 0 0]\n",
      " [0 0 4 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 2 0]\n",
      " [0 0 0 ..., 0 0 5]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         3\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       1.00      1.00      1.00         4\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      0.83      0.91         6\n",
      "          5       1.00      1.00      1.00         3\n",
      "          6       1.00      1.00      1.00         4\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       1.00      1.00      1.00         2\n",
      "          9       1.00      0.67      0.80         3\n",
      "         10       1.00      1.00      1.00         2\n",
      "         11       1.00      1.00      1.00         3\n",
      "         12       1.00      1.00      1.00         2\n",
      "         13       1.00      1.00      1.00         4\n",
      "         14       1.00      1.00      1.00         5\n",
      "         15       1.00      1.00      1.00         3\n",
      "         16       1.00      1.00      1.00         3\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       1.00      1.00      1.00         5\n",
      "         19       1.00      1.00      1.00         3\n",
      "         20       0.75      1.00      0.86         3\n",
      "         22       1.00      1.00      1.00         4\n",
      "         23       1.00      1.00      1.00         3\n",
      "         24       1.00      1.00      1.00         3\n",
      "         25       1.00      1.00      1.00         2\n",
      "         26       1.00      1.00      1.00         3\n",
      "         27       1.00      1.00      1.00         3\n",
      "         28       1.00      1.00      1.00         4\n",
      "         29       1.00      0.80      0.89         5\n",
      "         30       1.00      1.00      1.00         1\n",
      "         31       1.00      1.00      1.00         4\n",
      "         32       1.00      1.00      1.00         3\n",
      "         33       1.00      1.00      1.00         2\n",
      "         34       1.00      1.00      1.00         2\n",
      "         35       1.00      1.00      1.00         1\n",
      "         36       1.00      1.00      1.00         4\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         2\n",
      "         39       0.71      1.00      0.83         5\n",
      "\n",
      "avg / total       0.98      0.97      0.98       120\n",
      "\n",
      "(' Time ', '9.14', ' seconds')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-27 21:59:19,291][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=76.92%\n",
      "[ 2018-07-27 21:59:20,168][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-27 21:59:21,199][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=84.62%\n",
      "[ 2018-07-27 21:59:22,118][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=89.66%\n",
      "[ 2018-07-27 21:59:22,967][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=96.97%\n",
      "[ 2018-07-27 21:59:23,938][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=96.67%\n",
      "[ 2018-07-27 21:59:24,933][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=93.10%\n",
      "[ 2018-07-27 21:59:25,904][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=86.96%\n",
      "[ 2018-07-27 21:59:26,867][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=89.66%\n",
      "[ 2018-07-27 21:59:27,835][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=96.67%\n",
      "[ 2018-07-27 21:59:28,060][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=91.43%\n",
      "[ 2018-07-27 21:59:28,061][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=97.50%\n",
      "[ 2018-07-27 21:59:28,064][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=91.43%\n",
      "[ 2018-07-27 21:59:28,065][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=97.50%\n",
      "[ 2018-07-27 21:59:28,066][cascade_classifier.fit_transform] [Result][Reach Max Layer] opt_layer_num=1, accuracy_train=91.43%, accuracy_test=97.50%\n",
      "[ 2018-07-27 21:59:28,067][cascade_classifier.transform] X_groups_test.shape=[(120, 4820)]\n",
      "[ 2018-07-27 21:59:28,068][cascade_classifier.transform] group_dims=[4820]\n",
      "[ 2018-07-27 21:59:28,069][cascade_classifier.transform] X_test.shape=(120, 4820)\n",
      "[ 2018-07-27 21:59:28,070][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(120, 4820)\n",
      "[ 2018-07-27 21:59:30,262][cascade_classifier.fit_transform] X_groups_train.shape=[(280, 4858)],y_train.shape=(280,),X_groups_test.shape=[(120, 4858)],y_test.shape=(120,)\n",
      "[ 2018-07-27 21:59:30,264][cascade_classifier.fit_transform] group_dims=[4858]\n",
      "[ 2018-07-27 21:59:30,265][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-27 21:59:30,266][cascade_classifier.fit_transform] group_ends=[4858]\n",
      "[ 2018-07-27 21:59:30,266][cascade_classifier.fit_transform] X_train.shape=(280, 4858),X_test.shape=(120, 4858)\n",
      "[ 2018-07-27 21:59:30,269][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(280, 4858), X_cur_test.shape=(120, 4858)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test Accuracy of DeepExtratTrees = 97.500000 %', 'Layer :', 17)\n",
      "[[3 0 0 ..., 0 0 0]\n",
      " [0 2 0 ..., 0 0 0]\n",
      " [0 0 4 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 2 0]\n",
      " [0 0 0 ..., 0 0 5]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      1.00      0.86         3\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       1.00      1.00      1.00         4\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      0.83      0.91         6\n",
      "          5       1.00      1.00      1.00         3\n",
      "          6       1.00      1.00      1.00         4\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       1.00      1.00      1.00         2\n",
      "          9       1.00      0.67      0.80         3\n",
      "         10       1.00      1.00      1.00         2\n",
      "         11       1.00      1.00      1.00         3\n",
      "         12       1.00      1.00      1.00         2\n",
      "         13       1.00      1.00      1.00         4\n",
      "         14       1.00      1.00      1.00         5\n",
      "         15       1.00      1.00      1.00         3\n",
      "         16       1.00      1.00      1.00         3\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       1.00      1.00      1.00         5\n",
      "         19       1.00      1.00      1.00         3\n",
      "         20       0.75      1.00      0.86         3\n",
      "         22       1.00      1.00      1.00         4\n",
      "         23       1.00      1.00      1.00         3\n",
      "         24       1.00      1.00      1.00         3\n",
      "         25       1.00      1.00      1.00         2\n",
      "         26       1.00      1.00      1.00         3\n",
      "         27       1.00      1.00      1.00         3\n",
      "         28       1.00      1.00      1.00         4\n",
      "         29       1.00      0.80      0.89         5\n",
      "         30       1.00      1.00      1.00         1\n",
      "         31       1.00      1.00      1.00         4\n",
      "         32       1.00      1.00      1.00         3\n",
      "         33       1.00      1.00      1.00         2\n",
      "         34       1.00      1.00      1.00         2\n",
      "         35       1.00      1.00      1.00         1\n",
      "         36       1.00      1.00      1.00         4\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         2\n",
      "         39       0.83      1.00      0.91         5\n",
      "\n",
      "avg / total       0.98      0.97      0.97       120\n",
      "\n",
      "(' Time ', '9.291', ' seconds')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-27 21:59:30,899][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=76.92%\n",
      "[ 2018-07-27 21:59:31,650][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-27 21:59:32,429][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=92.31%\n",
      "[ 2018-07-27 21:59:33,386][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=89.66%\n",
      "[ 2018-07-27 21:59:34,370][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=96.97%\n",
      "[ 2018-07-27 21:59:35,341][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=96.67%\n",
      "[ 2018-07-27 21:59:36,331][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=93.10%\n",
      "[ 2018-07-27 21:59:37,202][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=86.96%\n",
      "[ 2018-07-27 21:59:38,173][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=89.66%\n",
      "[ 2018-07-27 21:59:39,020][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=96.67%\n",
      "[ 2018-07-27 21:59:39,248][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=92.14%\n",
      "[ 2018-07-27 21:59:39,249][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=97.50%\n",
      "[ 2018-07-27 21:59:39,253][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=92.14%\n",
      "[ 2018-07-27 21:59:39,254][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=97.50%\n",
      "[ 2018-07-27 21:59:39,255][cascade_classifier.fit_transform] [Result][Reach Max Layer] opt_layer_num=1, accuracy_train=92.14%, accuracy_test=97.50%\n",
      "[ 2018-07-27 21:59:39,256][cascade_classifier.transform] X_groups_test.shape=[(120, 4858)]\n",
      "[ 2018-07-27 21:59:39,257][cascade_classifier.transform] group_dims=[4858]\n",
      "[ 2018-07-27 21:59:39,258][cascade_classifier.transform] X_test.shape=(120, 4858)\n",
      "[ 2018-07-27 21:59:39,259][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(120, 4858)\n",
      "[ 2018-07-27 21:59:41,482][cascade_classifier.fit_transform] X_groups_train.shape=[(280, 4896)],y_train.shape=(280,),X_groups_test.shape=[(120, 4896)],y_test.shape=(120,)\n",
      "[ 2018-07-27 21:59:41,484][cascade_classifier.fit_transform] group_dims=[4896]\n",
      "[ 2018-07-27 21:59:41,485][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-27 21:59:41,486][cascade_classifier.fit_transform] group_ends=[4896]\n",
      "[ 2018-07-27 21:59:41,488][cascade_classifier.fit_transform] X_train.shape=(280, 4896),X_test.shape=(120, 4896)\n",
      "[ 2018-07-27 21:59:41,491][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(280, 4896), X_cur_test.shape=(120, 4896)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test Accuracy of DeepExtratTrees = 97.500000 %', 'Layer :', 18)\n",
      "[[3 0 0 ..., 0 0 0]\n",
      " [0 2 0 ..., 0 0 0]\n",
      " [0 0 4 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 2 0]\n",
      " [0 0 0 ..., 0 0 5]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      1.00      0.86         3\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       1.00      1.00      1.00         4\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      0.83      0.91         6\n",
      "          5       1.00      1.00      1.00         3\n",
      "          6       1.00      1.00      1.00         4\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       1.00      1.00      1.00         2\n",
      "          9       1.00      0.67      0.80         3\n",
      "         10       1.00      1.00      1.00         2\n",
      "         11       1.00      1.00      1.00         3\n",
      "         12       1.00      1.00      1.00         2\n",
      "         13       1.00      1.00      1.00         4\n",
      "         14       1.00      1.00      1.00         5\n",
      "         15       1.00      1.00      1.00         3\n",
      "         16       1.00      1.00      1.00         3\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       1.00      1.00      1.00         5\n",
      "         19       1.00      1.00      1.00         3\n",
      "         20       0.75      1.00      0.86         3\n",
      "         22       1.00      1.00      1.00         4\n",
      "         23       1.00      1.00      1.00         3\n",
      "         24       1.00      1.00      1.00         3\n",
      "         25       1.00      1.00      1.00         2\n",
      "         26       1.00      1.00      1.00         3\n",
      "         27       1.00      1.00      1.00         3\n",
      "         28       1.00      1.00      1.00         4\n",
      "         29       1.00      0.80      0.89         5\n",
      "         30       1.00      1.00      1.00         1\n",
      "         31       1.00      1.00      1.00         4\n",
      "         32       1.00      1.00      1.00         3\n",
      "         33       1.00      1.00      1.00         2\n",
      "         34       1.00      1.00      1.00         2\n",
      "         35       1.00      1.00      1.00         1\n",
      "         36       1.00      1.00      1.00         4\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         2\n",
      "         39       0.83      1.00      0.91         5\n",
      "\n",
      "avg / total       0.98      0.97      0.97       120\n",
      "\n",
      "(' Time ', '8.998', ' seconds')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-27 21:59:42,282][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=80.77%\n",
      "[ 2018-07-27 21:59:43,454][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-27 21:59:44,484][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=84.62%\n",
      "[ 2018-07-27 21:59:45,620][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=89.66%\n",
      "[ 2018-07-27 21:59:46,539][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=93.94%\n",
      "[ 2018-07-27 21:59:47,271][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=96.67%\n",
      "[ 2018-07-27 21:59:48,028][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=93.10%\n",
      "[ 2018-07-27 21:59:48,987][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=86.96%\n",
      "[ 2018-07-27 21:59:49,975][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=89.66%\n",
      "[ 2018-07-27 21:59:50,934][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=96.67%\n",
      "[ 2018-07-27 21:59:51,166][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=91.43%\n",
      "[ 2018-07-27 21:59:51,168][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=97.50%\n",
      "[ 2018-07-27 21:59:51,171][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=91.43%\n",
      "[ 2018-07-27 21:59:51,172][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=97.50%\n",
      "[ 2018-07-27 21:59:51,173][cascade_classifier.fit_transform] [Result][Reach Max Layer] opt_layer_num=1, accuracy_train=91.43%, accuracy_test=97.50%\n",
      "[ 2018-07-27 21:59:51,174][cascade_classifier.transform] X_groups_test.shape=[(120, 4896)]\n",
      "[ 2018-07-27 21:59:51,175][cascade_classifier.transform] group_dims=[4896]\n",
      "[ 2018-07-27 21:59:51,176][cascade_classifier.transform] X_test.shape=(120, 4896)\n",
      "[ 2018-07-27 21:59:51,177][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(120, 4896)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test Accuracy of DeepExtratTrees = 97.500000 %', 'Layer :', 19)\n",
      "[[3 0 0 ..., 0 0 0]\n",
      " [0 2 0 ..., 0 0 0]\n",
      " [0 0 4 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 0 2 0]\n",
      " [0 0 0 ..., 0 0 5]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      1.00      0.86         3\n",
      "          1       1.00      1.00      1.00         2\n",
      "          2       1.00      1.00      1.00         4\n",
      "          3       1.00      1.00      1.00         1\n",
      "          4       1.00      0.83      0.91         6\n",
      "          5       1.00      1.00      1.00         3\n",
      "          6       1.00      1.00      1.00         4\n",
      "          7       1.00      1.00      1.00         6\n",
      "          8       1.00      1.00      1.00         2\n",
      "          9       1.00      0.67      0.80         3\n",
      "         10       1.00      1.00      1.00         2\n",
      "         11       1.00      1.00      1.00         3\n",
      "         12       1.00      1.00      1.00         2\n",
      "         13       1.00      1.00      1.00         4\n",
      "         14       1.00      1.00      1.00         5\n",
      "         15       1.00      1.00      1.00         3\n",
      "         16       1.00      1.00      1.00         3\n",
      "         17       1.00      1.00      1.00         1\n",
      "         18       1.00      1.00      1.00         5\n",
      "         19       0.75      1.00      0.86         3\n",
      "         20       0.75      1.00      0.86         3\n",
      "         22       1.00      1.00      1.00         4\n",
      "         23       1.00      1.00      1.00         3\n",
      "         24       1.00      1.00      1.00         3\n",
      "         25       1.00      1.00      1.00         2\n",
      "         26       1.00      1.00      1.00         3\n",
      "         27       1.00      1.00      1.00         3\n",
      "         28       1.00      1.00      1.00         4\n",
      "         29       1.00      0.80      0.89         5\n",
      "         30       1.00      1.00      1.00         1\n",
      "         31       1.00      1.00      1.00         4\n",
      "         32       1.00      1.00      1.00         3\n",
      "         33       1.00      1.00      1.00         2\n",
      "         34       1.00      1.00      1.00         2\n",
      "         35       1.00      1.00      1.00         1\n",
      "         36       1.00      1.00      1.00         4\n",
      "         37       1.00      1.00      1.00         1\n",
      "         38       1.00      1.00      1.00         2\n",
      "         39       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       0.98      0.97      0.98       120\n",
      "\n",
      "(' Time ', '9.696', ' seconds')\n"
     ]
    }
   ],
   "source": [
    "def update(X_train,X_test):\n",
    "    # update Estimators\n",
    "    M = np.delete(X_train, (-1), axis=1)\n",
    "    X_train= np.delete(M, (-1), axis=1)\n",
    "    M = np.delete(X_test, (-1), axis=1)\n",
    "    X_test = np.delete(M, (-1), axis=1)\n",
    "    return X_train,X_test\n",
    "\n",
    "def newdata(X_test_enc, X_train_enc):\n",
    "    # Make Data + Estimators\n",
    "    X_train_origin = X_train.reshape((X_train.shape[0], -1))\n",
    "    X_test_origin = X_test.reshape((X_test.shape[0], -1))\n",
    "    X_train_enc = np.hstack((X_train_origin, X_train_enc))\n",
    "    X_test_enc = np.hstack((X_test_origin, X_test_enc))\n",
    "    return X_test_enc, X_train_enc\n",
    "\n",
    "Accuracy = []\n",
    "def affiche():\n",
    "    # predict\n",
    "    y_pred = gc.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(\"Test Accuracy of DeepExtratTrees = {:.6f} %\".format(acc * 100),\"Layer :\",i)\n",
    "    Accuracy.append(round(acc*100 , 2))\n",
    "    # Matrix de confusion\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print('\\n')\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    \n",
    "# Deep\n",
    "t = []\n",
    "for i in range (20):\n",
    "    t0 = time()\n",
    "    X_train,X_test=update(X_train,X_test)\n",
    "    X_test_enc, X_train_enc=newdata(X_test_enc, X_train_enc)\n",
    "\n",
    "    X_train=X_train_enc\n",
    "    X_test=X_test_enc \n",
    "    X_train_enc, X_test_enc = gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test)\n",
    "    tt = time() - t0\n",
    "    affiche() \n",
    "    t.append(round(tt,2))\n",
    "    print (\" Time \",format(round(tt,3)),\" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Opt_layer_num =', 5, ' Accuracy =', 97.5, 'Time =', 38.32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAAIHCAYAAACCFaoXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzs3XuUZGd53/vvU1Vd1feeW18kRhokDUJISFxsGOTgQMJF\nwtjBMYsYc+DYgeQEln0cwLaMYhNj5+SQAw4QLxInNoZYCVIMMTbEAcGRjY05DBMZkAQSQh5dRpqR\nprtnpqfvXdf3/FG1q3fV9KWquqr27fdZq5c03bv33u+7u7ueevazn9ecc4iIiIiISFUq6BMQERER\nEQkTBcgiIiIiIj4KkEVEREREfBQgi4iIiIj4KEAWEREREfFRgCwiIiIi4qMAWURERETERwGyiIiI\niIiPAmQRERERER8FyCIiIiIiPgqQRURERER8MkGfQFSZmQGXA8tBn4uIiIiIbGsMeNo551r9BgXI\nnbscOB30SYiIiIjIrg4DZ1rdWAFy55YBnnrqKcbHx4M+FxERERFpsrS0xBVXXAFt3vFXgLxH4+Pj\nCpBFREREYkQP6YmIiIiI+ChAFhERERHxUYmFSAI559goVihVKmRSKQYHUlQbs0i3aI7jKajrmqTj\nJmmsQR03SWPtlAJkkYQ4vbDGiccu8MT8Eqfm5lldXwcqQIqRoSGOTE3y7Mlxjl19gMP7h4M+3UjS\nHMdTUNc1ScdN0liDOm6SxtoN1kZLOPExs3FgcXFxUQ/pSajd/9RF7v7uaR558hSjlWc4OniGI0ML\nTOfWGEiVKVbSzOaHObW+n5Mbh1lJzXDtlUd43U2HuenwvqBPPxI0x/EU1HVN0nGTNNagjpuksW5l\naWmJiYkJgAnn3FKr36cAuUMKkCXsVvIl7vzmE5x46CGOph/i1ZOP8qKJWTKp7X/nSxXjO4vT3DN/\nDSfL1/OyG27gZ44dYTSnm01b0RzHU1DXNUnHTdJYgzpuksa6EwXIfaYAWcLsqQtrfPTu+ygsPMxb\nZk5w84GnaafMyzk4fuFy7jx7jOz+63jPrS/kigPhufUVBprjeArquibpuEkaa1DHTdJYd6MAuc8U\nIEtYPXVhjQ/92d9wcP1e3n3VcfZl8x3v62Ihx8cev5nzQy/hth//YQVwNZrjeArquibpuEkaa1DH\nTdJYW9FpgKw2byIxspIv8dG77+Pg+r3cds3X9/QHCmBfNs9t13ydg+v38tG772MlX+rSmUaX5jie\ngrquSTpuksYa1HGTNNZeU4AsEiN3fvMJCgsP8+6rjjOc6c4flOFMiXdfdZzCwsPcdeJUV/YZZZrj\neArquibpuEkaa1DHTdJYe00BskhM3P/URU489BBvmTmx53fvzfZl87xl5gTffPBBHjh9sav7jhLN\ncTwFdV2TdNwkjTWo4yZprP2gAFkkJu7+7mmOph/i5gNP92T/Nx94mqOZh/jSA6d7sv8o0BzHU1DX\nNUnHTdJYgzpuksbaDwqQRWLg9MIajzx5ildPPtrWE8PtMINXHXyUR548xZmL6705SIhpjuMpqOua\npOMmaaxBHTdJY+0XBcgiMXDisQuMVp7hRROzPT3Oi/fNMlo5y4nHzvf0OGGkOY6noK5rko6bpLEG\nddwkjbVfAg2QzWzMzD5mZqfMbN3MvmFmL/F93W3z8Ss77PPntth+Y4vtft7MnjCzDTM7YWYv7dU4\nRXrtifkljuZO79iIvRsyKcfRwdM8Ptdyp5zY0BzHU1DXNUnHTdJYgzpuksbaL0Ev3fQJ4PnA24Cn\ngbcC95jZ9c65M8BlTdu/DvgD4I932e8S8FzfvxuunJn9NPAR4J3ACeDdwJfN7LnOubkOxyISCOcc\np+bmefVwew8wOKCTO2JHhha4Z24e5xzWq3tqIaM5jqdOrytA2TnaXUbgitwCXzk7x9L6UR49O8dr\nBy9SqvR+LYIgj/vlZ2YxIxFj1Ry3J5WCVBt/Ifv9dzGwANnMhoA3Am9wzn2t9ukPmNlPAO8Cft05\nd7bpe94AfNU599guu3fN39vkvcDvO+c+VdvvO4HXA28H/s0255sDcr5Pje1yDiJ9sVGssLq+zvTo\nWsvfs7BW4KmFdfYNDXBlmw3Yp3NrrC6tky9VGBxIt3u6kaQ5jqdOrivAExdWubhWbPt4q6tzPDh/\njp//9Hd48uw5/s7kHN97erHt/UTpuN+bO08K+DtT8R+r5rg9Vx4Y5sBwtuXt+/13McgSiwyQBprL\nH9aBlzdvbGbTVIPYP2hh36O1so2nzOzzZnaDbz9Z4IeAe7zPOecqtX/fvMM+bwcWfR96zFxCoVSp\nABUGUuWWv+fcSoGKc1xYK1BuMw2WsQrg+pKpCIu9znGxUmnreEmc4yB0cl0L5UpHwTFA2soYjkql\nguHIWOvH3YugjwuVxIxVc9w7/f67GFgG2Tm3bGbHgfeb2feBWeBnqAapJ7f4lp8FloHP7bLrH1DN\nBD8ATAC/DHzDzG5wzp0GDlENzJsrymeB63bY7weplmV4xlCQLCGQSaWAFMVK6++o86XNP2ilsiOd\naf12VcmlACOTSs6t/73OcaFUYSDbej4iiXMchM6u6+abnVwmRS7T+vfmilmGsgPceHgfFy6eJTuQ\nZXxwoJ1T7kjQx03hEjNWzXHrBtLt5Wj7/Xcx6BrktwGfBM4AZeDbwF1UM7zN3g582jl3yQN3fs65\n48Bx799m9g3g+8A/A97f6Yk65/JAvQO26gIlLAYHUowMDTGbb+02fqnS+A68VKmQa+Nm0mx+mJGh\nIXKZ5DTB2esc54sVRlq/k5jIOQ5Cu9cVIF/cfOMzOZbj0Ehuh60bfa94kOfM7Oe2W5/L0+fmSA8c\n5OpDvV/8IMjjXjuzDzNLxFg1x73V77+Lgf71dc496px7BTAKXOGceykwADTUGJvZj1J96O4THRyj\nCHwHOFr71Dmqwfh006bTwE51yyKhZGYcmZrk1Nq+lrb3ZzYBym3erjq1vp8jU5OJepO41zn2Zx1b\nkcQ5DkK71xWaM8jt1UF61zWVSrV93L0I8rjPnp5KzFg1x/05br/+LoYiPeGcW3XOPWNm+4FbgM83\nbfIO4FvOufvb3beZpYEbgWdqxyoA3wJe5dsmVfv38a32IRJ2z54c52T+MKXK7n84moO1duq5ShXj\n5MZhrpoab/sco24vc9wcMO8kyXMchHauK1xaYtGq5uva7nE7FYbjJmmsQR03SWPtl6D7IN9iZrea\n2VVm9hrgq8DDwKd824wDb2Kb7LGZ3WFmH/T9+1+a2WvN7GozezHwX4EjTd//EeCfmtnPmtnzgN8F\nRvzHFYmSY1cfYCV1Gd9ZbL4xcqlCU/DWTgb52xenWUnNcOzqg22fY9TtZY7bySAneY6D0M51hc03\nOymztmoom69ru8ftVBiOm6SxBnXcJI21X4LOIE8A/55qUHwH8HXgllpZhOfNVFuJ3rXNPq6ksV/y\nfuD3qdYdfxEYB37EOfeQt4Fz7o+oPrz3W8B9wAuBW51zvV0KRqRHDu8f5torj3DP/DW79mbttMTC\nOfjzc0e59sojPGvfUKenGll7meNCqUIrs5z0OQ5CO9fVsfnmJ5dpvYPrVte1neN2KizHTdJYgzpu\nksbaL0HXIH/GOXeNcy7nnLvMOfcLzrnFpm1+zzk33Px539df6Zz7Od+/3+OcO1Lb54xz7vXOue9s\n8X0f9213zDl3ousDFOmjW288zMny9Ry/cPmO2zVnM1sNkI9fuJyT5efxupsOd3yOUdfxHDtHqbx7\nFllzHIxWr2uhvPlGJ9tGecV217XV43YqTMdN0liDOm6SxtoPQWeQRaRLXnDFPo5dfz13nj3GxcLW\nT9Y7OqtBvljIcefZY7zshhu46XB/HsgIo07nmG0+56c5Dk4r1xUaO1i0+oDeTte11eN2ImzHTdJY\ngzpuksbaDwqQRWLkLS97Ntn91/Gxx29mrXRpF8dypXJJxni3DPJaKcPHHr+Z7P7r+JljR7p6vlG0\n2xyXtphj2DlA1hwHb7frCu0/oNfKdW3luO0K63GTNNagjpuksfaaAmSRGBnNZXjPrS/k/NBL+NCj\nL7/k3fxWQVpph1XeLhZyfOjRl3N+6CW859YXMpoLunV68Hab48I2QdR2nSw0x+Gw23WF7a/tVlq9\nrq0ctx1hPm6SxhrUcZM01l4z16uq6pirdddYXFxcZHxc7ZgkXJ66sMZH776PwsLDvGXmBDcfeBoz\nuLBW4MkLaw3b5jIpnjfT+DPsXLXu686zx8juv4733PpCrjjQ+mIKSdDKHE+O5phfqa4vNDE0wFUH\nR+rfrzkOp+2uK8Bj51ZZ2qg+Q37DZeNbdrHo9LrudNxWROm4SRprUMdN0lh3s7S0xMTEBMCEc26p\n1e9TgNwhBcgSdiv5EnedOMU3H3yQo5mHeNXBR7ksdYrzK+sN26VTxo2XTwDVXpPfvjjNn587ysny\n87j5hht487EjympuY7c5vurgCE+cX8UBg5k0182MaY4jYKvr+uJ9s/zt3CL5UoW0Gc9/1kRDF4tu\nXNftjptJbf86HdXjJmmsQR03SWPdiQLkPlOALFHxwOmLfOmB0zzy5CmKK09yOHWKy7IXOJRdwShT\ncWlGx6c4tb6fkxuHWUnNcO2VR3jdTYf1sFiLtpvjF05XmF9aZb1kLJTGqAxezqN5zXFU+K/rSPkZ\nRvMnuSx7gcuG1rjqwCAll2I2P9z13x3/cUcrZzk6eJojQwtM59bIWCVWx03SWIM6bpLGuhUFyH2m\nAFmi5szFdd733x/gzMIK5eIKQ+kKG8USDuOGw4e4ZmaKq6bGOXb1QfXg7VDzHF99MMvs4jqrhQqk\nBnj1jVdzw7P2a44j5szFdb7yvbP8l+OPUS6uMDrgmBnPAcbI0BBHpiZ78rtz5uI6Jx47z+NzS5ya\nm2d1fZ1qn5T4HTdJYw3quEkaq58C5D5TgCxR45zj5+/8NvlihUOjWY4cHOHEY+cxMz74UzdymQK2\nPfPP8eRYlg/8g+fzmXuf5C8enidl8Mu3XMf1l+vvRRTd/9RFfufP/xbnHK+9YYYff8HlZFJWXTCk\nnSLLDjnnyJcqlCou9sdN0liDOm6SxtppgKyiN5GEWFovkS9Wn8KfmRhi33CWTO0ho7Xi1h0WpD2L\n68X6HE+PDzE4kOaKgyOkU+cAmF3e4HoUIEfR7NIGAGbGFQeG+14zbmYMDrTWeznqx03SWIM6bpLG\n2im1eRNJiNnljfr/T48PMpLb/CO1mi8FcUqxM7uUr///9Phg9b9jg/XPzS1tXPI9Eg2zy/5r293F\nEEQkfJRBFkmIWV9wNjXW+AK/ogC5K+Ya3oRU53hmYjNA9gfQEi3+NzdT44M7bCkicaAMskhCNGc3\nR3y3iFfzKrHohq0yyPuHB+r9cmeVQY4s79oNZdOMqSWfSOwpQBZJCH9wNj2ea6ihVIlFdzRk6WsZ\nZDOr///8cp7KLkt7S/gUyxUurBaA6huffjzMJCLBUoAskhDeLeJUyjg4mmuoQVaJRXd4c5xOGQdH\nNstYvGxyueI4Xwu0JDrml/N4DZ9UfyySDAqQRRLAOVe//T85liOdMmWQu8w/x4dqc+zx13yrzCJ6\nGu++qP5YJAkUIIskwMJakWK51n6s1lVhRAFyV201xx5/UKUAOXr8teVTYwqQRZJAAbJIAjTXHwMM\nZ9N4pZQrekhvz7aa481/q5NFlG3VnURE4k0BskgCbHWL2MwYzlazyMog791Ot+H9QZUyyNGjEguR\n5FGALJIAc/5bxL5gbXSwFiAXFCDv1XZzDDAxNEBuoPrn1p+NlGjwsv4juUxDaZKIxJcCZJEE2C4D\nNpKtdrJYL5Qpq/3YnvjneKYpy2hm9drV+eUCpVqtsoRfvlRmod7iTeUVIkmhAFkkAbxlpjNp4+BI\ntv75hgf1lEXeE2+OB9IpDvjm2OO9MXFOrd6iZG6LxV9EJP4UIIvEnHOO+eXNFm/+RQ7U6q07KhVX\nD6Sa59ijOuRo8pfEaIlpkeRQgCwSc+dXC5TK1fKJ5vZjavXWHRfWCvUSle1uw6uTRTT5r1Vz6YyI\nxJcCZJGY2+kJfH+ArFZvnWtcYnrrIEoZ5GjaqX2fiMSXAmSRmNupu8Kob7lpZZA710obsCktFhJJ\ns6pBFkkkBcgiMbdjBjmrEotuaAyits4yjuUyDNa6hihAjo652rUaHxpgcCC9y9YiEhcKkEVibqcM\nWGOJhQLkTjW8CdlmKWIzq3/twmqhviy1hNdGscziehG49O6LiMSbAmSRmPO3H9s/PNDwtYYuFgXV\nIHfKexOSzaTY1zTHfl522TnqnUUkvBpavG3zxkdE4kkBskiMlSubLd6mxy9tP9aQQd5QBrkT5Yrj\n3Io3x4NbtnjzTKsOOVJml7XEtEhSKUAWibHzK3kqtfZjW3VXGPE9pLemhUI60jjHO9+Gn2roZKEM\nctipg4VIcilAFomx3Z7AHxpI1zOey8ogd2S2jdvw/mvgX4BCwkkdLESSSwGySIztlgEzs3qrN2WQ\nO9NKi7etvq4Si/Cb812jyTFlkEWSRAGySIzNLe+eAfPqkNXFojONdao7B1GjuUx9vlViEX7em5h9\nw1m1eBNJGAXIIjHWSvsxr5NFvlihpNZjbZttWIhl99vwXhC9sFogX1LnkLBaK5TqZUeqPxZJHgXI\nIjHmBci5gRTjQ5kttxlRq7c9mV2szvHgQJrxwa3n2K+hDllZ5NBS/bFIsilAFompUrlSbz82NbZ9\n+7GGAFllFm0plSucX63N8RZt9LYypQf1IkEdLESSTQGySEydWyngqt3HdsyAjfpavSlAbs/8Sr6l\nOfabHlOrtyjwB8itlM6ISLwoQBaJqVYzYFpuunP+AHemxSBqSp0sImFOJRYiiaYAWSSm/MHXTsHb\nSNZfYqEa5HY0Zhlbuw3vf7Myp+WmQ8u7tmYwOaoSC5GkUYAsElOzy611VxgdVAa5U3Nt9ED2DGcz\njA16rd6UQQ4r7/dn/3CWbEYvlSJJo996kZiaa7HEYjirGuROddrpwNt2ca3IRlFZ+7BZyZdYy3st\n3lReIZJECpBFYsrLTg5l0/Vex1sZyw3U/39Vq+m1xZvj4VxmxzluNqVWb6GmDhYiogBZJIYKpQoX\nVgtANQO2U/uxYV8XC5VYtK5QqrCwVpvjNpch9gdds2r1FjrtLB8uIvGkAFkkhs41tB/bffljj0os\nWtdJizfPtDpZhJoCZBFRgCwSQ2fbeIHPZVKkU9UMs7pYtO7sYvsdLDz+Zb/VCzl8tIqeiChAFokh\n/wN6U2M7v8CbWT2LrBKL1nXSwcLjD6jnlEEOHX+Lt0Oj2YDPRkSCoABZJIYaM2C7Zze9OmSVWLRu\nL7fhBwfSTAwPXLIfCZ5zrv7g5KHRHJm0XiZFkki/+SIx1G7w5q2mVyhVKJQqPTuvOPH3me6k04F3\nXZY3Sqype0hoLG2U6q33tMS0SHIpQBaJIS+DPDqYaVhKejujvtX0FKy1xnsTMjaYYTjbeos3z5Sv\n84XqkMOj1f7hIhJvCpBFYiZfKnNxbbPFWyv8QbTqkHe3USyzuFYEOn+Ia6ahF7LKLMKioTxpl/p9\nEYmvQANkMxszs4+Z2SkzWzezb5jZS3xfd9t8/MoO+/ynZvbXZrZQ+7jHzF7atM0Httjnw70cq0i/\n+BeemGqxP29jqzd1stjNfIvLeO/E/33+cg0Jllq8iQgEn0H+BPAa4G3AjcBXgHvM7Fm1r1/W9PF2\nwAF/vMM+XwncBfw94GbgKeArvn16Hmza98v3PhyR4M0tt/8Crwxye7qx0tq0OlmE0uyySixEBNov\nnOsSMxsC3gi8wTn3tdqnP2BmPwG8C/h159zZpu95A/BV59xj2+3XOfe/NX3PP6kd51XAHb4vlZr3\nLxIHnfRwHfGtpqca5N11o0/u1JgWCwkj7w5MKmUcHFWALJJUQWaQM0AaaH5lWGeLbK6ZTQOvB/6g\nzeMMAwPAhabPP8fMnjazx8zs02Z25U47MbOcmY17H8BYm+ch0hf+BSxazYD5SyxWNhQg76ZhIZYO\n61SzmRT7R7K1/anEIgycc/U3K5NjufoCOiKSPIEFyM65ZeA48H4zu9zM0mb2VqplEZdt8S0/CywD\nn2vzUP8P8DRwj+9zJ4CfA26lmq2+CvhrM9sp6L0dWPR9nG7zPET6YnaPJRarBdUg76ZhIZY93Ib3\n3sCs5UsqbQmBi2vFeptDPaAnkmxB1yC/DTDgDJAHfpFq/fBWjVjfDnzaOdfyvUgzex/wZuAf+r/P\nOfcl59xnnXMPOOe+DPwYsA/4Rzvs7oPAhO/jcKvnIdJP3i3i8aEBBgfSu2xd1ZhBLvbkvOLEyzJO\ntDHHW/G/gVGZRfBUfywinkADZOfco865VwCjwBXOuZdSLYdoqDE2sx8Fnkv1ob6WmNkvA+8DXuuc\ne2CX87gIPAIc3WGbvHNuyfugms0WCZX1Qpml9WqA205mUxnk1q0XyizXylCmJ/aWZVQdcrh0o7Zc\nROIh6AwyAM65VefcM2a2H7gF+HzTJu8AvuWcu7+V/ZnZbcD7gVudc3/TwvajVIPjZ9o7c5Fwaehg\n0cYtYv9DerrVvzN/INtqG73tNHayUB1y0Ga7VDojItEXWBcLADO7hWqJxQ+oBqgfBh4GPuXbZhx4\nE/BL2+zjDuCMc+722r9/Ffgt4C3AE2Y2U9t0xTm3Utvmt4H/AZwCLgd+EyhRLe8QiSx/Bmymjexm\nNp0ikzZKZceaAuQddbNPrkoswmVOPZBFpCboDPIE8O+pBsV3AF8HbnHO+Ysg30w1iN4ueL2Sxof6\n3gVkgf9ONSPsffyyb5vDtf39APgMcB54mXNufo/jEQlUp/15zaxeZrGihUJ25F/UY691qpNjOazW\nKEHLTQfPuwbplHFgOBvw2YhIkALNIDvnPkM1QN1pm98Dfm+Hr7+y6d/PbuG4b27tDEWipfH2f3sZ\nsNFchsW1IqvKIO9obg9z3GwgneLgSI5zK3lmlzdwzmGm1mJBcM7VV0icGs+RUos3kUQLOoMsIl00\n17AEcnvZTS+DXCxX6q2u5FLdrlP1stAbhTLLenMSmAurBYpltXgTkSoFyCIx4gVv+4az5DLttR8b\n1XLTLfFuw+8faX+OtzLlq3XVktPBUQcLEfFTgCwSE6v5Un0VvE5qY4ezm8Geyiy2tpIv1eemW31y\n/cHY2UXVIQdFHSxExE8BskhM7LW7gjLIu+tmB4vN/WwGY+pkEZxeXFsRiS4FyCIx0XiLuP0MmH+x\nkLWCAuSt7OUhyO00tHpbVoAcFJVYiIifAmSRmPAvEjK15wyyWr1tZW6Pb0K2cnAkW+9cocVCguO9\nORlIp9g/PBDw2YhI0BQgi8TEXm8R+1fTUw3y1npxGz6TTjE5Vu25O1dr9Sb9Va44ztU6wEyP59Rq\nT0QUIIvEhXeL2AwmR9vPbo7mNrNmqkHemtdGz6y6yEe3eOUa+WKFxfXiLltLt51fzVOuVN+YdHL3\nRUTiRwGySAw45+rZzQMjWbKZ9n+11cViZ81zPJDu3p9P/7LgWlGv/+ZUfywiTRQgi8TASr7EeqFa\nN9zpC/zY4GYNsgLkSy13YY63o04Wwep0iXYRiS8FyCIx4M86dnqLeDirh/R20rDEdJcDZH9HDAXI\n/acOFiLSTAGySAz4g7fpDmtjs5lUvWxAGeRLNQRRXaw/hqZWbwqQ+64hg6xlpkUEBcgisXC2S90V\nRmtlFgqQL9XLhSQOjmRJp6x2HNUg95vXIjE3kGJ8KLPL1iKSBAqQRWKgW7eIR2oP6q3kS2o31qSX\nt+FTKat3xZhfzmvu+6hUrjC/XACqpS5q8SYioABZJBa87KYZHBrNdrwfL4NcrjjypUpXzi0uNufY\n9jTH2/GC7mK5woXVQtf3L1s7t1KovyFR/bGIeBQgi0Scc65+i/jQaI7MHtqP+R/UU5nFJv8cT45l\n9zTH22nsZKEyi35RBwsR2YoCZJGIW1ovkS9Ws7177a7Q2OpNnSw8i+vFzTnu0UNc/ms3u6wH9fql\nl7XlIhJdCpBFIs4fTM3s8QW+sdWbMsiefrQB81+7OXWy6JvZZf+1VQZZRKoUIItEnD8DNrXH9mOj\nOV8GuaAA2TO33Pvb8I2t3lRi0S+97G8tItGlAFkk4rqZ3RzJbS43rQzypn5kkPcPD9T7UKsXcv94\ncz2UTTOWU4s3EalSgCwScd18yGgkp4f0ttKQpe9RBtnM6vueX85TqajVW6/5O4ZMj6vFm4hsUoAs\nEnHeLeJUyjg42sUSCwXIdd4cp1PGwZHe1al62elyxXFuVWUWvVbtOV39f9Ufi4ifAmSRCHPO1W//\nT47l6quxdcqfQV5RFwugcY4PdWGOd+KvIZ9THXLPqYOFiGxHAbJIhC2sFSmWq+3HprvQfmzU18Vi\nTRlkoHGO99olZDeND+qpDrnX/LXlvWrfJyLRpABZJMK6vciBHtK7VD8XklAni/7qR3cSEYkmBcgi\nEdbtW8SZdIrcQPXPgtq8Vc32sQ1Y42p6yiD3mkosRGQ7CpBFIsxfp9qt7gojtTKLlQ0FyNA4x90o\nY9nJxNBA/Q3KnFbT6zkvSz+SyzTU34uIKEAWibBeZMC8QGG1UMY5tRrrZ4mFmdVrYeeXC5Rqtc/S\nfflSmYV6izeVV4hIIwXIIhHmLTOdSRsHR7Jd2afX6q1ScWwUFaB5czyQTnGgS3O8E++NjnOO87UA\nTrpvrg+Lv4hIdClAFoko5xzzy5st3rq1yMGIlpuuq1RcPZDq5hzvRHXI/dH4gJ4CZBFppABZJKLO\nrxYolaslEN2sjR31dbJI+mIhF9YKlGsr2vXrNrw6WfRHP5YPF5HoUoAsElG9egK/cbGQZAfI/exg\n4fEH4meVQe6ZftaWi0j0KEAWiahedLCAphKLhK+m5w+ier1IiMcfiM8pQO4ZZZBFZCcKkEUiqlcZ\n5NGGADnpGeT+B1FjuQyD2XTt+AqQe8V78zE+NMDgQHqXrUUkaRQgi0RUr4I3lVhsCuI2vJnVa8ov\nrBbqy1xL92wUyyyuF4Hu3n0RkfhQgCwSUf72Y/uHB7q2Xz2kt8l7E5IbSDEx1L053o0XjDtHvVOJ\ndE8/F3+S1QPeAAAgAElEQVQRkWhSgCwSQeXKZou36fHuth9TBrmqXHGcW6nO8dTYYF9avHkaO1mo\nzKLbZtXiTUR2oQBZJILOr+Sp1NqPdbu7gh7Sq2qc4/7ehp9q6IWsDHK3qYOFiOxGAbJIBPXy4bFh\n3wNLSV4oZDbA2/D+a+pf0EK6Qx0sRGQ3CpBFIqiXGbBMOlXvopDkEotedQlphUosesvfPm9yTBlk\nEbmUAmSRCJpb7m0GbKQWICf5Ib3GOtX+BlGjuUy91EUlFt3nLcCybzirFm8isiUFyCIR5F9hrRe3\n/0dz1Y4Nq/kSzrmu7z8KZhf7v4qenxeUL6wWyJeSWwvebWuFEisb1Td+qj8Wke0oQBaJIO8WcW4g\nxfhQZpet2zdSa/XmHKwXkxmceZnbwWya8cHuz/FuGuqQlUXuGtUfi0grFCCLREypXOl5+7HRhLd6\nK5UrnF+ttdHrc4s3z5Qe1OsJdbAQkVYoQBaJmHMrBbyqh15lwIYT3uptfiXvm+NggqjpMbV66wV/\ngBxE6YyIRIMCZJGI6UcGLOmr6YXhNvyUOln0xFwIrq2IhJ8CZJGI8QdLMz16gR/JJrvEojHLGFAG\n2XfcOS033TXetTWDyVGVWIjI1hQgi0TMrC9Y6tUt4tGGEovkBchzAfZA9gxnM4wNeq3elEHuFu/3\nZ/9wlmxGL4EisjX9dRCJmLk+lFg0LDddSF4NchhKLPzHXlwrspHQbiLdtJIvsVZ7wzczofIKEdme\nAmSRiPGyiUPZdEOmt5v8AbLXMzZJvDkezmV6NsetmFKrt67SA3oi0ioFyCIRUihVuLBaAKrZxV61\nH/MHhWuFZAXIhVKFhbXaHAe8DLH/DsGsWr3tmX/xl6CvrYiEW6ABspmNmdnHzOyUma2b2TfM7CW+\nr7ttPn5ll/2+ycweNrMNM/uumf3YFtv8vJk9UdvmhJm9tBdjFOmmfrUfG/F1sVhOWAZ5bnmjPsdB\n34afVieLrmpcPlwZZBHZXtAZ5E8ArwHeBtwIfAW4x8yeVfv6ZU0fbwcc8Mfb7dDMfgS4C/gD4EXA\nnwJ/ambP923z08BHgN8EXgzcD3zZzKa6OTiRbpvt08Nj/i4WScsg++uPg74N719GXL2Q9y4steUi\nEn6BBchmNgS8EbjNOfc159xJ59wHgJPAuwCcc2f9H8AbgK865x7bYdf/HLjbOfdh59z3nXPvB74N\n/IJvm/cCv++c+5Rz7iHgncAa1QBcJLT8D+hNjfXuBT6VMoay1Sxy0tq8NTwEGfBteH+LuTllkPfM\n3+Lt0Gg24LMRkTALMoOcAdJA81/9deDlzRub2TTweqqZ4Z3cDNzT9Lkv1z6PmWWBH/Jv45yr1P59\n83Y7NbOcmY17H8DYLuch0nWNGbDeBm9eHXLSVtIL04NcgwNpJoYHAJVY7JVzrv6g46HRHJl00DdQ\nRSTMAvsL4ZxbBo4D7zezy80sbWZvpRqkXrbFt/wssAx8bpddzwCzTZ+brX0e4BDVwHynbbZyO7Do\n+zi9y3mIdF2/Sixgs5PFWqGE84pyE8DfZzqoZab9vOu8vFFKXLlLNy1tlOqt8oJ+4yMi4Rf0W+i3\nAQacAfLAL1KtH65sse3bgU8754JKo3wQmPB9HA7oPCTBvAzy6GCmoRVbL3j7dy5ZvZC9NyFjgxmG\ns8G1ePNM+co8VIfcuX70DxeR+Ag0QHbOPeqcewUwClzhnHspMAA01Bib2Y8Cz6X6UN9uzgLTTZ+b\nrn0e4BxQ3mWbrc4175xb8j6oZrNF+iZfKnNxbbPFW6+N+jpZrCWkDnmjWGZxrQiE5yGumYZeyCqz\n6FRDeVIP6/dFJB6CziAD4Jxbdc49Y2b7gVuAzzdt8g7gW865+1vY3XHgVU2fe03t8zjnCsC3/NuY\nWar27+OdjUCk9/wLRUz14eExf4Z6OSEB8nwflvFul/88/OUf0p5+lieJSPQFev/QzG6hWmLxA+Ao\n8GHgYeBTvm3GgTcBv7TNPu4Azjjnbq996t8Bf2VmvwT8T+DNwA8D/4fv2z4C/KGZ/Q3wv4B3AyP+\n44qEzVyfe7g2LBaSkAf1ZkN4G35anSy6orEHcjiurYiEV9AFdhNUa3sPAxeo9jf+Nedc0bfNm6kG\n0Xdts48r8dUsO+e+YWZvAf4v4P8G/hb4Sefc93zb/JGZTQK/RfXBvPuAW51zzQ/uiYRGv3u4+nsh\nL+eLO2wZH2Hsk+tv53d2UQFyp7xV9FIp4+CoAmQR2VmgAbJz7jPAZ3bZ5veA39vh66/c4nOfBT67\ny34/Dny8pRMVCQF/cNSPDNhIAjPIZxt6IIcjQM5mUuwfybKwWlCJRYecc8zV5m5yLEc61Zsl2kUk\nPkJRgywiu+v3Mrn+EoukLBbSsBBLiG7De2+I1vKlxFyLbrq4VqRQqt5oDMsbHxEJNwXIIhHhPaQ3\nPjTA4EB6l633btjXxWI1If13vRrkieH+zHGr/G+ItGBI+1R/LCLtUoAsEgHrhTJL69U64H5lNsd8\nGeTVBGQt1wtlljeq4wxL/bHHX4esALl9YawtF5FwU4AsEgENHSz6dIt4uKHEIv41yA1LTPehjV47\nGjtZqA65XbMhLZ0RkfBSgCwSAf4M2MxEfwLkkWwaqz3LlIQMcpj75PqvuTLI7ZsL8bUVkXBSgCwS\nAUH05zWz+lLLiQiQl/234cOVZZwczdXfrGi56fZ5c5ZOGQeGswGfjYhEgQJkkQhovP3fvwyY1+ot\nCZ0T5gKa41Zk0ikOjlSD9tnlDZxzAZ9RdDjn6iskTo3nSKnFm4i0QAGySATMNSyB3L/s5mitk8V6\noUy5Eu+gLOx1ql5We6NQTszS391wYbVAsawWbyLSHgXIIhHgBW/7hrPkMv1rP9awWEjMW715t+H3\nj/R3jls15W/1phX1WnZW9cci0gEFyCIht5ovsVJvP9bfzOZoQ6u3+HayWMmX6nXWYas/9jT2QlYd\ncqv8XT/CeGdARMJJAbJIyAXZXcF7SA/iXYcc5g4WHn/grk4WrYvCtRWR8FGALBJyjYsc9DmDPJiM\nxUKCegiyHQ0Z5GUFyK3SIiEi0gkFyCIh518kZKrPL/AjWd9y0zEOkOcCfBPSqoMjWazW602LhbTO\nezMxkE6xf3gg4LMRkahQgCwSckHeIh7NqcQiLDLpFJNj1R6+c2r11pJyxXGu1gFmejxXf4MhIrIb\nBcgiIefdIjarLhjRT/4uFqsx7mLhtdEzg8mQLTPt5wXv+WKFxfViwGcTfudX8/X2hP2++yIi0aYA\nWSTEnHP17OaBkSzZTH9/ZUcaMsjx7GLRPMcD6fD+WVQni/bMqf5YRDoU3lcCEWElX2K9UA1Mg3iB\nH8nFvwZ5OeA5boc6WbQniCXaRSQeFCCLhNhsQw/X/gdvjX2Q4xkgz0Wg/tjj77BxVgHyrtTBQkQ6\npQBZJMQagrcAamOHBtL1B5viulBIlIIo//nNKUDeVUMGOaTt+0QknBQgi4RY0Mvkmlm9zGIlH8+H\nwqJ0G/7gSJZ0qvqGRTXIu/NaJOYGUowPZXbZWkRkkwJkkRALQ3bTe1BvtaAMctBSKat32ZhfzqvV\n2w5K5QrzywWgWpqiFm8i0g4FyCIh5mU3zeDQaDaQc/DqkDcKZUrlSiDn0Eubc2wcHAlmjtvhBfHF\ncoULq4WAzya8zq0U6m8gwv7GR0TCRwGySEg55+q3iA+N5sgE1H5sJLt5a3qtGK8ssn+OJ8eygc1x\nOxo7WajMYjtRKp0RkfAJ/6uBSEItrZfIF6sZ2yAXOfC3elvZiFcni8X14uYcR+QhLv/PwuyyHtTb\nThRWRxSR8FKALBJS/uBnJsAXeH+rt7WYraYXpfpjz4w6WbRkdtl/bZVBFpH2KEAWCSl/BmwqwOWP\n/avpLccsgzy3HL3b8FpNrzVR6m8tIuGjAFkkpMKS3WzMIMerBjksc9yO/cMD9eWwtZre9ry5Gcqm\nG36GRURaoQBZJKTC8pCRP4O8ErPV9KJYp2pmTI1vtnorV9TqrVmhtNnhY3pcLd5EpH0KkEVCyrtF\nnEoZB0eDDJA3H9KL23LT3hynU9Fo8ebxgvlyxXF+VWUWzc6t5PFaREeldEZEwkUBskgIOefqt/8n\nx3L11dOC4L89HacAuXmOUwHOcbv8NelzqkO+RBTvDIhIuChAFgmhhbUixdqiHNMBtx9rLLGITw1y\nwxxHLIhqfFBPdcjN/LXlUWnfJyLhogBZJITCUn8M8c0gh2mO26VOFjuLYncSEQkXBcgiIRSmW8S5\nTKpefhCnh/Qa2uhFLoPsX01PGeRmYfr9EZFoUoAsEkL+utKpgDNgZlbPIscpg+yf46DLWNo1MTRA\nbqD653tOq+ldwsuqj+QyDSVCIiKtUoAsEkJhy4B5nSxWY7SSXpRLLMysXls7v1ygVKulFsiXyizU\nWrzNTAT/uyMi0aQAWSSEvGWmM+lwtB8byVazcPliJTbBmDfHA+kUB0Iwx+3y3jg55zhfCwil6e5L\ngCtQiki0KUAWCRnnHPPLm+3HwrDIQeODetHvZFGpuHogNTUejjlul+qQt9b4gJ4yyCLSGQXIIiFz\nfrVAqVxd5SAstbHD/lZvMSizuLBWqK9AF9Ugyn/eZxcVIHuiuHy4iISPAmSRkAlb/THAWMxavfkD\nyqjehm/IIC+r1ZsnyrXlIhIeCpBFQiZMHSw8w77lpuPQ6i0Ot+H9renmVGJRpwyyiHSDAmSRkAlj\nBjlui4XEIYgay2UYzFbfuKgGeZP3ZmF8aIDBgfQuW4uIbE0BskjIhDF4G4ldgBz92/BmVq9Rv7Ba\nqC+bnWQbxTKL60UgPHdfRCSaFCCLhIy//dj+4YGAz6bKn0FeiUEXC+9NSG4gxcRQOOa4E15w7xz1\nzidJFuXFX0QkXBQgi4RIubLZ4m06RO3HvD7IAGsR72JRrjjOrdRavI0NhmaOO+G/w6Ayi803lxCe\nuy8iEk0KkEVC5PxKnkqt/dhUiF7gR3wP6S1vRDtAbpzjaN+Gn2rohawMsv9NwsxEtK+tiARLAbJI\niISx/hgaa5CjnkH2z/FMiOa4E/6fEX9njqSabVhFL9rXVkSC1XaAbGZX9+JERCS8D4/lMinSqWop\nwkrEM8hh7BLSKZVYNPLPQdTvDohIsDrJIJ80s6+a2VvNLNqvLiIhM7cczgyymTE6WM0irxai/ZBe\nY51qtIOo0Vymnt1XicVmgLxvOEsuoxZvItK5TgLkFwMPAB8BzprZfzKzl3b3tESS6aw/uxmyW8Te\ng3qRzyD7V9EL0ZuQTnlB/sJqgXwp2m9e9mKtUKr/bEb9jY+IBK/tANk5d59z7p8DlwNvBy4Dvm5m\n3zOz95rZZLdPUiQpvEUOcgMpxocyu2zdX14GuViuUChFt+eul2kdzKYbltCOqoY65ARnkcNavy8i\n0dTxQ3rOuZJz7nPAm4BfBY4Cvw08ZWZ3mNllXTpHkUQolSuhbj82kt28ZR3VB/VK5QrnV2tt9EI4\nx52Y0oN6QHjr90UkmjoOkM3sh83sPwDPAO+lGhxfA7yGanb58y3sY8zMPmZmp8xs3cy+YWYvadrm\neWb2BTNbNLNVM7vXzK7cYZ9/aWZui4//6dvmA1t8/eEOp0KkK86tFHDV7mOhzID5O1lEtdXb/Ere\nN8fxCKKmx9TqDZof0Avf74+IREvb9xfN7L3APwaeC3wR+N+BLzrnvHuuj5vZzwFPtLC7TwDPB94G\nPA28FbjHzK53zp0xs2uArwN/APwGsATcAOyUJvkpIOv790HgfuCzTds9CLza9+9ovuJLbIQ9A9bY\n6i2ata5xvA0/pU4WQNMqejG5tiISnE4K8N4FfBL4z865Z7bZZg54x047MbMh4I3AG5xzX6t9+gNm\n9hO1Y/w68K+pBt+3+b710Z3265y70HScNwNrXBogl5xzZ3faV9N+coA/ahlr9XtFWtGwyEEIX+Ab\nl5suBngmnYtjGzD/m6m5BC837V1bM5gcjce1FZHgdPKQ3nOccx/cITjGOVdwzv3hLrvKAGkuzQav\nAy83sxTweuARM/uymc2Z2Qkz+8k2T/kdwH9zzq02ff45Zva0mT1mZp/eqWyj5nZg0fdxus3zENnR\nrC+4CeMtYn8GeTUfzQzyXIx6IHuGsxnGBr1Wb8nNIHu/PwdGsmQzWgNLRPamk4VC/rGZvWmLz7/J\nzH621f0455aB48D7zexyM0ub2VuBm6l2xpgCRoH3AXcDrwX+BPicmb2ixXN9KdUSjk80fekE8HPA\nrVSz1VcBf21mO2WFPwhM+D4Ot3IOIq2aC3mJxahvuemVfDQrkuJYYgGbY1lcK7JRjOabl71YyZdY\ny3st3uJzXUUkOJ28zb4dmN3i83PAv2hzX28DDDgD5IFfBO4CKr5z+7xz7qO19nL/Bvgz4J0t7v8d\nwHedc//L/0nn3Jecc591zj3gnPsy8GPAPuAfbbcj51zeObfkfQDLrQ9TZHde9m8om24oZwiLxgxy\nVAPk6hyP5DKhnONOTSW81dvZmPW2FpHgdRIgXwk8ucXnT9W+1jLn3KPOuVdQzRRf4Zx7KTAAPAac\no/rg3ENN3/b9Vo5jZiPAm6k+4LfbeVwEHqHaqk6k7wqlChdWC0A1AxbG9mPeQiEQzQxyoVRhYc2b\n4/Bl6PfCP57ZBLZ6a7j7MhavaysiwegkQJ4Dbtri8y8AzndyEs65VefcM2a2H7iFata4ANxLtVuG\n37VUg/HdvInqQ3X/dbcNzWyUanC8bV21SC9Fof3YaMS7WMwtb4S6jd5eTCe8k0Xj8uHxurYiEoxO\n7jHeBfyOmS0DXveJVwD/Dvhv7ezIzG6hWmLxA6oB6oeBh4FP1Tb5MPBHZvY14KtUa4Z/Anilbx93\nAGecc7c37f4dwJ865y4J2s3st4H/QTXQvhz4TarZ6rvaOX/pDeccG8UKpUqFTCrF4EAqlBnVbvDG\n+vi5FcoVR8rC+wI/kotmBnlzjlfrcxy32/DesuTOOU4vrLO8Uezr705Qv7PecZ88vxb63x8RiZZO\nAuT3A88G/pzN3sEp4A7ar0GeoPrw22HgAvDHwK8554oAzrk/MbN3Uq17/h2qgfQbnXNf9+3jSqo1\ny3Vm9lzg5VQf7NvKYarB8EFgnmqv5Zc55+bbPH/pktMLa5x47AJPzC9xam6e1fV1vFL0kaEhjkxN\n8uzJcY5dfYDD+4eDPt092WqsF9fynFstQmqAvxxKUyq70I01m0kxkE5RLFdCX4O81RwvrOU5783x\n99MUS5XQzXEnTi+s8Y1Hz/H4/BLl4gpn5s5w78M/oNe/O0H9zm513NMLq2yUHKQG+C/fGOHqqYlY\nXFsRCY45755ju99odi3Vsop1qg/CtVL2EBtmNg4sLi4uMj4+HvTpRNb9T13k7u+e5pEnTzFaeYaj\ng2c4MrTAdG6NgVSZYiXNbH6YU+v7OblxmJXUDNdeeYTX3XSYmw7vC/r027LTWBdW1ji/XuFCcZRC\ndoYnS0dCOdZf+sz9XFwrMDE8wEf+0QuDPp1LtD7Hl/Fk6cpQznGrmsc6VniU6cx5JrMrXDs11LPf\nnaB+Z7c77lRujafOL1GopFiqjFHKXR75vxUi0j1LS0tMTEwATNSaLLSk4wA56RQg781KvsSd33yC\nEw89xNH0Q7x68lFeNDFLJrX9z2OpYnxncZp75q/hZPl6XnbDDfzMsSOh70bQylhPzq/Uyxaef/kE\nkArlWH/j89/j9MI6mbTxH9/6Q6EpfWl3jm981gTOhXOOd7PdWJ84v9wwvrTv2nTjdyeo39ndjlus\nVHjw6epr3tjgANccGons3woR6b6+Bshmdhj4B1TLG/zLOuOce2/bO4wgBcide+rCGh+9+z4KCw/z\nlpkT3HzgadqJs5yD4xcu586zx8juv4733PpCrjgQzluprY71wWeWKJYrZFJWC5CrwjbWD939MD84\nW+1w+B/e+mJymfQu39F7cZvjnew01qcW1jhf64Ry7dQYw9lLr02nYw3qd7aV464USpycWwGqK+g9\na9/Qno8rIvHRtwDZzF4FfIFqK7brgO9RrUk24NvOub/f1g4jSgFyZ566sMaH/uxvOLh+L+++6jj7\nsp33bL1YyPGxx2/m/NBLuO3Hfzh0L3ytjrXsHN89swhUW6k9Z2r0km3CMtZ//9WTfPvUAgAfftML\nODCS3eU7eiuOc7yd3cY6t7zB07V+wEcODLN/ePtr085Yg/qdbfW4F1YLPLmwBsCz9g1tucx02K+t\niPROpwFyJ23ePgj8tnPuRqrLRL8RuAL4K+CzHexPEmIlX+Kjd9/HwfV7ue2ar+/phRZgXzbPbdd8\nnYPr9/LRu+8LVWeFdsZaKG0+Y5rbZoncsIx1NESLhcR1jrfSylizvmx+vlS55Ot+rY41qN/Zdo6b\nj/i1FZFw6iRAfh7VjhVQ7WIx5JxbAf4l8KvdOjGJnzu/+QSFhYd591XHGc505wVqOFPi3Vcdp7Dw\nMHedCM9zou2M1f8Cn93mBR7CMdYwtXrrdI5zA+Ge4620MlZ/cLhbgAytjTWo39l2jrtR2uzJvVPJ\nT1ivrYiEUycB8iqbdcfPANf4vnZoz2cksXT/Uxc58dBDvGXmxJ6zUM32ZfO8ZeYE33zwQR44fbGr\n++5Eu2PN+1/gB3au6Q16rKO5zfMLMoO8pznepW466Dlu1upYGwPk1hZy2WmsQf3Otntc7+6AsfMb\nzN2OKyLi10mA/E2qPYYBvgj8WzP7NeCTta+JXOLu757maPohbj7wdE/2f/OBpzmaeYgvPXC6J/tv\nR7tjzRd3v0XsF+RYw5JBjvMcN2t1rCkzsunq2FrJIHu2G2tQv7PtHNexOdZsJkUrzw2G6dqKSHh1\nEiC/FzhR+//foLpgyE8DT1BdvU6kwemFNR558hSvnny0rSff22EGrzr4KI88eYozF9d7c5AWdDLW\nfLm94C3IsY401CAHs9x0R3PcYhmLJ6o/T97YyhVHqdLaA9hbjTWo39l2j1ssV6jUHjRvtaNKWK6t\niIRbWwGymaWprkL3JIBzbtU5907n3E3OuTcmbbEQac2Jxy4wWnmGF03M9vQ4L943y2jlLCceu2R1\n8b7pZKyFWnZzIJVq6F27k6DGOpIN/iG9TubYKzkYSId/jv3aHWsnZRZw6ViD+p1t97itPHzZynFF\nRJq1FSA758rAV4D9vTkdiaMn5pc4mju944IC3ZBJOY4OnubxuZa7uHRdu2MtO0exUrtFvMPDY82C\nGuuIrwY5qBKLTubYy6a2E0RF8ecp10YnC7/msQb1O9vucVvpYNHKcUVEmnWyrND3gKuBx7t8LhJD\nzjlOzc3z6uHWH4ip4FjeKDE8kGYg3V4V0JGhBe6Zm8c51/dV3joZa8MLfATGGnSbt47muNheeYVf\n1H6e/EHi4lqxXn7QigM2zxcfP81ffP8A3378ND82eI5zq919OK/bx11a3/wZ3Kk7yVaCvLYiEn6d\nBMi/Dvy2mb0f+BbVrhZ17TRhlvjbKFZYXV9nenSt5e85u7jB3HKeXCbFdTPjLT1445nOrbG6tE6+\nVGFwl44Q3dbJWFttP7aVIMba8JBeof8BcmdzvFlqMNhmgBy1nyf/z9DiRpHFjWLrByxc4PT5JT71\n/53i9PklmLzA6YU+1Oh26bjtruoY5LUVkfDrJED+Yu2/X6D6ELHHav/WXxqpK1UqQIWBVOv1kMsb\n1cArX6pQKFXau3VqFaD1B5S6qZOx5outtx9rFsRYB9IpcgMp8sVKIBnkjua44QG98M+xp5Ox5jJp\ncplUW+UVnrSVMRyVSgXDkbH+PITZjeMOZlJt320K8tqKSPh1EiD/va6fhcRWJpUCUhQrrQUm/rZN\nUM3+tRMgl1wKMDKp/t8ybXes0PlDRhDcWIezGfLFAmsBdLFIyhxDZ2M14OjUaPVNZptx33xqmMn1\nQd5687P55F+c48DoMFdO9H5J5j0f12BsMNPWnSYI9tqKSPi1HSA75/6qFyci8TQ4kGJkaIjZfGsv\neCVf2yZo70EjgNn8MCNDQ20HQt3Q7lih/fZjfkGNdTSXYWG1wEq+1Pf6zaTMMXQ2Vqh2QzkwnN19\nwybrSxNctn+cW26Y5kvfGWfdJjgwcq7t/UTluEFeWxEJv7YDZDP7uzt93Tn3tc5PR+LGzDgyNcmp\nM/ta2r45IC60GSCfWt/PkcsnA3nopt2xQmftxzxBjdXrZFGuuL7Xb+5ljrMRmmPobKx74Y01lUol\n6rh6QE9EttLJW+e/3OLjq74PkQbPnhznZP4wpcruL0TNAXI7GeRSxTi5cZirpsbbPsduaWesnbYf\ng2DHGvRqep3OcbvZ46j9PO1F81iTdlwRkWadBMj7mz6mgFuBe4HXdu/UJC6OXX2AldRlfGdxetdt\nLw2QW69z/fbFaVZSMxy7+mDb59gtbY11D+3Hghyrv9VbEHXInc5xu29CovbztBfNY03acUVEmrUd\nIDvnFps+zjnn/l/gV4EPdf8UJeoO7x/m2iuPcM/8NezWlrU5IC6UKlRaeNrIOfjzc0e59sojPGvf\n0F5Od086HWs7wVvQY/Wvprecb6ONWJckYY497Yy1U1uNNWnHFRFp1s2nE2aB53ZxfxIjt954mJPl\n6zl+4fIdt2uuOXZAsbT7K+XxC5dzsvw8XnfT4b2cZle0OtbGVcBar+MNeqz+Eou1Qv8zyNDZHLfT\n4i3oOfZrdayd2m6sSTuuiIhf2wGymd3U9PECM7sV+I/Afd0/RYmDF1yxj2PXX8+dZ49xsZDbcpvm\nFm+e3cosLhZy3Hn2GC+74QZuOtyfB3x20spYobP2Y2EYq7/EYmUjmOWm4z7Hfq2OtRM7jTVpxxUR\n8eskg3wf8J3af73//yKQBf5J905N4uYtL3s22f3X8bHHb2atdGkDlWJTizfPTg/qrZUyfOzxm8nu\nv46fOXakq+e7F7uNFdpvPxaWsXpdLABWA1hNz9PaHLdXYhGWOW7Wyljb1cpYk3ZcERFPJwHyVcDV\ntXkKn8YAACAASURBVP9eBRwBhp1zP+Kce7ibJyfxMprL8J5bX8j5oZfwoUdffkl2yJ/tG/a1Dtuu\n1dvFQo4PPfpyzg+9hPfc+sKGzGbQdhsrtNfiLUxj9R87iNX0/Oex+xxXf3ay6RSpCM1xs1bG2o5W\nx5q044qIeMz16kmImDOzcWBxcXGR8XG1CmrHUxfW+Ojd91FYeJi3zJzg5gNPYwbnVws8tbAGwMz4\nIGeXNgAYHxzg6kMj9e93rlpHeOfZY2T3X8d7bn0hVxzo/YpfndhurGXn+O6ZRaAaDBydHN3y+8M4\n1qcvrvP+P/0eAD9y9BDvePlVgZ5PHOd4O9uNtVWdjjVpxxWR+FhaWmJiYgJgwjm31Or3tR0gm9nv\nAI845z7e9PlfAI46597d1g4jSgHy3qzkS9x14hTffPBBjmYe4lUHH2Um9QQXVqpB8dWHRjh1fo2y\nc+QyKZ43M06pYnz74jR/fu4oJ8vP4+YbbuDNx46EPhu01VivG36ax85Vf08PjmS5Yn/ji3aYx7q4\nXuS9f1R93OAFV+zjF1/1nIDPKH5zvJOtxvrifbNkUtv/Le/GWJN2XBGJh34GyGeA1zvn7mv6/IuB\nLzjnEvFosALk7njg9EW+9MBpHnnyFMWVJzmcOsVl2Qu8aKbC/NIaa0W4UBzFDV3Oo/krWEnNcO2V\nR3jdTYcj95CNf6zpjTMcqjzGZdkLPGdfgcmRDCWXYjY/zKn1/ZzcOBzasZbKFf7Zf/kWAEenRrn9\nx54X8Bltissct8I/1tHKWY4OnubI0ALTuTUyVunZWJN2XBGJtn4GyBvADc65R5s+fxT4nnNusK0d\nRpQC5O46c3GdX/3v9/P0wiqV4gpXH8wxu7TOSr4MqQH+/vOv4sbDBzh29cHI9y49c3Gd3/3LR/nG\n385SLq4wM5pmNJcGjJGhIY5MTXLV1Hiox/rzn/42G8UyMxOD/Ot/eGPQp3OJS+Z4LM1oNlpz3Koz\nF9c58dh5Hp9b4tTcPKvr61R7wvR2rEk7rohEU6cBcif3m04CrwM+3vT51wGPdbA/ES6fGGQ0N8BV\nk+NMjU/yGz9xA5/79mm+8uAsKYN/+OIrY5MFeta+IZ59cJhnLo7j3Bj/4seex8y+ITIpI5dJYe0U\nWQZkJJdmo1gO9CG9nTTP8a//+PVMjQ9Gao5b9ax9Q/zUi6s37pxz5EsVShXX87Em7bgikiydBMgf\nAT5uZpPAX9Q+9yrgl4BE1B9L911cK1IsVzsOzIwPMTiQ5soDI6RT1Re7uaV8kKfXdXPL1fGYGVcc\nHG5roZAwGMllOL9SYCVfxjkXyqBktvaQp5lxeP9w28t5R5GZMTjQ/5+lpB1XROKv7QDZOfdJM8sB\nvwa8v/bpJ4B3Oefu6OK5SYLMLm/U/396PNfw3+avx4EXvO0bzkYuOIbNVm/OOdaLZYaz4Xv4abb2\npmr/SDYRwbGIiHRPR69qzrnfBX63lkVed86tdPe0JGlmfRni6fFqGfvU+OCWX4+6tUKpvgKd/01A\nlIw09EIOX4C8mi/Vyz+iOsciIhKcTpaavsrMngPgnJv3gmMze46ZPbu7pydJMbe0mSGeHKsGNOOD\nGXID1R/R+RhlkP3B/tRYNIO3kZAsFrIdr4QFNt9wiYiItKqT+47/GTi2xeeP1b4m0ratAhozY2qs\n+v/zywVK5e2XnI4S/5uBqAZvo77lpldCGCDP+ubY+xkSERFpVScB8ouA41t8/pvAC/d2OpJUXkCT\nThkHR7L1z3sBpHOOcyuFQM6t22Z9bwamIhogj2TDnUGeXbq0pl1ERKRVnQTIDtiq8e8EEL2njSRw\nzrl6l4pDYzlSqc2OCP7gZi4mZRZzDdnNaAZvDSUWhfAFyPMxeBMiIiLB6SRA/hpwu5nVg+Ha/98O\nfL1bJybJseBr8TbddDt8OoYP6jXc/o9odtO/ZO9KvhzgmWxts8UbTI5Gc45FRCQ4nTx6/qtUg+Qf\nmNlf1z73o1QzyH+vWycmybHT7fCGVm9L8cgg+9uPRbHFG1QXCvGEs8SiOsf7htXiTURE2tf2K4dz\n7iHgJuAzwBQwBtwBXNvdU5Ok2KnjwKQvo+zfLqr87ceiWl4BMJobqP9/2ALkFbV4ExGRPeq0D/LT\nwL8AMLNx4M3A3cAPozpkadNOJQfjgxkGB6rLGs/FIIMcl/Zjww0Z5HCVWMShS4iIiASr43uPZvZ3\nzewPgaeBXwa+CrysWycmybFTQGNm9aD53Eo+8q3e4tJdwd/FYiVfDPBMLtXYZ1oBsoiItK+tANnM\nZszsfWb2t8BngSUgB/ykc+59zrl7e3GSEm9eVjWdMg4MZy/5uhfkOEfkW735M8iTEQ7e0iljKFvN\nIq8WQpZB3mLZchERkXa0HCCb2f8AfkC1/vjdwOXOuf+zVycmyeBv8TbZ1OLNE6cH9eZikkGGzU4W\n3rLZYTG3xbLlIiIi7WinBvl1wO8Av+uc+9senY8kTEOLt22CmcZWb9EOkOO0wttILsP8cp61Qgnn\nHGaXvrkJgr/F2yG1eBMRkQ60U2LxcqodK75lZifM7BfM7FCPzksSYraFRTMaFwuJdicLf4u3qLcf\nG6mVWDgHayEqs/B+RvarxZuIiHSo5VcP59w3nXP/FLgM+E9UO1c8XdvHa8xsrDenKHE220LHAf9K\naFHuZLEas/ZjDavphaTVW2OLt2hn6EVEJDid9EFedc590jn3cuBG4N8C7wPmzOwL3T5BiTd/veh2\nq8qN5TIM1rKVUV5Nr5U3A1Ey0rCaXjgC5DisUigiIsHb0/1H59wPnHO3AYeBn+nOKUmSNHYc2Dpo\nNLN6+cX51ei2evOXh0R5kRDPaEMGORwlFnNq8SYiIl3QlQI951zZOfenzrl/0I39SXJ4GeHtWrx5\nvOA5yq3eGrOb0Q/eGkosCuHIIKvFm4iIdIOeYJHAOOeYr2VVp8a3bvHmiUOrt7i1HxvxraYXllZv\ncStjERGRYChAlsD4W7ztdjvc//XIBsi+7OZkDNqPjYYxg1x7E6IWbyIisheBBshmNmZmHzOzU2a2\nbmbfMLOXNG3zPDP7gpktmtmqmd1rZlfusM+fMzPX9HFJRGVmP29mT5jZRq1t3Ut7MUbZXjvLLjdk\nkCPa6i1OLd6guYtFOGqQvZ+NAzGZYxERCUbQryCfAF4DvI1qR4yvAPeY2bMAzOwa4OvAw8Arqa7i\n96+A3VKIS1Tb0XkfR/xfNLOfBj4C/CbwYuB+4MtmNtWNQUlr2qnJjXqrt5WYtXiD5of0gs8gr+RL\nrNXOQw/oiYjIXgQWIJvZEPBG4Dbn3Neccyedcx8ATgLvqm32r4EvOuduc859xzn3qHPuC865uV12\n75xzZ30fs01ffy/w+865TznnHgLeCawBb+/aAGVXjR0Hdg4a/a3e5iLY6m0uhrWxYWvz1s4dCRER\nkZ0EmUHOAGkuzQavAy83sxTweuARM/uymc3VSiF+soV9j9bKNp4ys8+b2Q3eF8wsC/wQcI/3Oedc\npfbvm7fboZnlzGzc+6C6qqDsQTsPVJkZ07WsYBRbvc3GsP3Y8EAab3XpMGSQ49YlREREghNYgOyc\nWwaOA+83s8vNLG1mb6UapF4GTAGjVBchuRt4LfAnwOfM7BU77PoHVDPBbwDeSnWM3zCzw7WvH6Ia\nmDdnlWeBmR32ezuw6Ps43eJQZRteX+BM2jg4sn2LN4+XFYxiq7c4th9LpYyhbDWLHIaH9Nq5IyEi\nIrKToGuQ3wYYcAbIA78I3AVU2Dy3zzvnPuqcu88592+AP6NaErEl59xx59wdte3/CvgpYB74Z3s8\n1w8CE76PwztvLjvxt3ibHMthtn2LN89UhFu9Na4YGJ/s5mit1dtKCB7Sa2XRGRERkVYEGiDXaopf\nQTVTfIVz7qXAAPAYcA4oAQ81fdv3gW27WGxxjCLwHeBo7VPngDIw3bTpNHB2h/3knXNL3gew3Oo5\nyKUurBbqLd6mWyw5mI5wqzfvfM3i0eLNM1LLIK8XSlQqLtBzmfW1eJtUBllERPYg6AwyAM65Vefc\nM2a2H7iFata4ANwLPLdp82uBU63u28zSVDtkPFM7VgH4FvAq3zap2r+P72Uc0rqGZZdbLDmYinCr\nN+989w/Hq/2Y96Cec7BWDC6L7Jyrvwk5MJJlIB2fORYRkf7L7L5J75jZLVRLLH5ANcP7Yaot3T5V\n2+TDwB+Z2deArwK3Aj9BteWbt487gDPOudtr//6XwDepdsPYB/wK1TZvn/Ad+iPAH5rZ3wD/C3g3\nMOI7rvRYJw9URbXVW0P7sZjUH3uaW735/91Pq4Uy64VqgK7yChER2atAA2SqtbwfpFrPewH4Y+DX\namUROOf+xMzeSfUBud+hGki/0Tn3dd8+rqRas+zZD/w+1QfuFqhmi3+k1s6N2n7/yMwmgd+qbXcf\ncOsW7eCkRxqWXW6xxGIsl2Eom2a9UI5UiUWclz9ubvXWXLfUL+pgISIi3RRogOyc+wzwmV22+STw\nyR2+/sqmf78HeE8Lx/448PGWTlS6rjGgaS2ramZMjQ1y6vxqvYY5CrfSG8YakxZvnpHaQ3oQbKu3\nxjmOV5ZeRET6L/zRhcTSbK3jQKst3jyNrd6iUYc876uXjkuLt/+/vTuPs6yu7/z/+tTatfRG091A\nWhoEMSoyuELPOIEEUOLyCIk/E2M0wegkOsn405iQ+FMT1JlxyyjJ6Ezy+7ln3DBRjBoafzgxxoAd\nXBACAmmWhm66q6rXWru2+5k/zj3V33OpW3W3s9S97+fjUQ+oW+ee5cuh6nO/5/t9f2PxJD3Id7GQ\nxBMJ9SCLiEiTVCBL5hqJeIuFxc/IGllRr52HWAyvC8cg5zdJT6voiYhIK6lAlswdnZpjYTGKBKt1\n/HEsfHy+VibqhfFjp7dRxBske5DzHGIRp6K0YxuLiEj2VCBL5kaaeBweTsBaK1Fvo20a8QbJHuS8\nhlgo4k1ERFpNf0kkcyMT9U/Qi4WPz9dCD3IY8dZuwysAhvryn6Q3ObugiDcREWkpFciSubFw2eU6\nh1gMl6PeYG2sptfuY2OTY5DzKZBH2nQZbxERyY8KZMlcM0WjmS31EobLVRdVeK1b2yziDWCgt5t4\njuXUXD6T9EaDJxLbFfEmIiItoAJZMhdGvJ1WR8RbLJ6o556MUCuiZPxY+xVvZsZgeaLe5Ml8epAV\n8SYiIq2mAlkyVSr5UkFTb8RbLCyCRgteILdzxFssHmYxNZfXEIvGx7SLiIgsRwWyZOro9ByLpcYi\n3mJhEVT0ccidED8WT9SbmVtc+m+bpbCNt7ZpG4uISLZUIEumWtGjmuhBLnCBXBk/1m4Rb7Hh/t6l\nf8+6Fzls4y1D/fQo4k1ERFpAf00kU+GQiEYfhycWCynwEItOiR8b6j8V9Tad8Wp6E0Eba3iFiIi0\nigpkydRoC3qQ10rUW+LDQBunKwz3h4uFzGd67FFFvImISApUIEummllFL1YZ9Ta3UMyot+TksfYt\n3gb7wyzkbHuQEx+42vhDiIiIZEsFsmQqzqzt7e5i82DvKltXF0a9HZ4s5jCLTokfW9+f33LT4aqM\n7dzGIiKSLRXIkplWRLzFwmKoqMMsEj3Ibdy7OZjjctOd8iFERESypQJZMpOIeGtyQlUy6q2gPchh\n/FgbF8hDefYgj4cxevUvOiMiIrIcFciSmWSPanO9fWFv4dhE8XqQKyPeets4fiycpJflctPuvjTE\nQhFvIiLSSvqLIplJJg4016OaHGJRvB7kTol4g2QPcpZDLCZmFzi51Mbt20MvIiLZU4EsmWnlssvD\n/T1L6QlFHIM80kHxY8M5FcijHZISIiIi2VOBLJkJc4Fb0asaT3w7Nl28qLdOih9b19tFV1c04TLL\nMciJDyFt3sYiIpItFciSmbint9mIt1j8WL2IUW/JFQPbu3fTzBgqJ1lk2oOsiDcREUmJCmTJRKnk\njJWLxm0bmot4ixU56i05nKT9ezfjcchZLhTSikVnRERElqMCWTIRRry16nF4GJ1WtIl6yfix9i+Q\n43HIJ+cXWVjMZrhL/CFEEW8iItJqKpAlE2ksuxz2Go4WKOrN3ZfOp90j3mJDGUe9RW0cfQg5fVgR\nbyIi0lr6qyKZSGPFs6IOsZjooIi3WNZRb2HEW7uP8RYRkeypQJZMpLHschj1NlqgIRadGD823J/t\nctOjHbKMt4iI5EMFsmQirQlV2wsY9ZboLe+Q4i3r5aY1QU9ERNKkAlkyES8J3KqIt1hcHLnDWEGi\n3kY6MH4sOcQi/THInZYSIiIi2VKBLKkrlZzDLY54i4VLVo8WZBxyJ/ZuDufYg7xtfWe0sYiIZEcF\nsqTuyNSpiLdWF4xhcVSUqLfRRMRbZ8SPDfVlO0kvTgkxs45pYxERyY4KZEldGhP0YuHj9SJEvbn7\n0hCLLUOdEz82nIh5S7dAdvelDyFb1/d1TBuLiEh29JdFUjeW4rLL2woW9RbGj3XS2NihIMUi7SEW\n4ycXODkftfFWDa8QEZEUqECW1KU5oWq4v2dpglgRhliE46C3dsj4Y8g2B3lsQhP0REQkXSqQJXWJ\nSWsp9PjFRdKxqfyj3kY6MOINoL+ni+6uaPJl2ikWmqAnIiJpU4EsqQsj3ja1MOItFhZJeUe9JXvL\nO6d4M7OlcchpD7FQxJuIiKRNBbKkajGIeNve4oi3WBj1lvc45NGJzot4iw2WxyFPpzxJrxNj9ERE\nJFsqkCVVR4OIt7SWXQ6LpLyzkOMCvZMi3mLD/dHTgdn5EvOL6Q11OdXGxpahzmpjERHJhgpkSVWa\nEW/L7Tfswc1aGD92+nDnRLzFhvpOJVmkNVHP3Zfi/BTxJiIiadFfF0nVaAbLLm8vSNTbxOyp+LG0\nPgwU2fC69FfTGz+5wOx81DutCXoiIpIWFciSqtEMxosOFSTqLRzekdZwkiJLrqaXTpJFso0770OI\niIhkQwWypCoZyZVeQVOEqLdOnzyWRQ9y2pGBIiIioAJZUhZHvPX1pBPxFktM1MtpyeksxlsX2WAw\nBjmtJIsshuyIiIioQJbUhBFv29anE/EWSy45nc8wi47vQc5gNb3EEwkNsRARkZSoQJbUHJmaTT3i\nLRb22I7l3INsZh0X8QbJ5aYnUxqDrIg3ERHJggpkSU0WE/SW238ePcjuzthEHPHWmfFjafcgK+JN\nRESyor8wkprkeNF0H4cns5Cz70EePxlEvHXg8Aqo7EFufYE8PqOINxERyYYKZElNMsEi3YIm76i3\nMH4s7Q8DRTXUn+5CISOaoCciIhlRgSypGcm4aAyj3mYX0hkDW024gl+n9m7293TTWx72kEaBPJpR\nZKCIiIgKZElNXDT29XSxcSC9iLdY2Ks4lvGS01l/GCiqwXIvchqT9JJt3JkfQkREJBsqkCUVi6VT\nk9bSjniL5Rn11ukRb7F4ol76Qyw690OIiIikL9cC2czWm9kNZrbPzGbM7DYze17FNk8zs781sxNm\nNmVmd5jZ2Svs8z+Y2T+a2bHy161m9vyKba43M6/4ui+t6+xERyZnKWUU8RbbHk7UG892op7ixyLx\nOPD5xVLLVzSMh1h0dRlbhlUgi4hIevLuQf4YcBXwGuCZwDeBW83spwDM7Dzgu8B9wOXARcB7gJWq\nn8uBzwM/C+wCHgO+Ge8zcA9wZvD1glZckETCMblZ9ahuS6yml10PsuLHTkkr6i1s49OH++juSv+J\nhIiIdK6e1TdJh5kNAC8HfsHdv1N++XozexnwRuAdwH8B/s7drwve+uBK+3X3X6s4zuvLx7kC+Ezw\nowV3P9TcVUg1eYzJDY8zkmEPsuLHThkKlpuenF1gc4t600/MzKuNRUQkM3l2dfUA3TyxN3gGeIGZ\ndQEvAR4ws1vMbNTM9pjZNXUeZxDoBY5WvP4UM3vczB4ys8+uNGwDwMz6zWxD/AWsr/M8OkqWEW+x\nwb4ehtdlH/UW5i53+vLHYRby1FzrepDzeCIhIiKdK7cC2d0ngNuBd5rZWWbWbWavJhoWcSawDRgG\n/gjYDbwQ+ArwZTO7rI5DvR94HLg1eG0PcC1wNVFv9bnAP5rZSkXv24ATwdf+Os6h42S5SEgojv86\nPp1d1Ftigl6H926mNcQifCKgiDcREUlb3oMlXwMYcACYBd5ENH64xKlz+6q7f9jd73T39wFfB95Q\ny87N7I+AVwK/6O5Lf2Hd/WZ3/5K73+XutwAvBjYBv7zC7t4LbAy+dtR+mZ0nLhr7e7OJeIuFvYuj\nGfUiK37slORqeq37gKKUEBERyVKuBbK7P+julxH1FD/J3Z9PNBziIeAwsADcW/G2nwArDocAMLPf\nJ+p9fqG737XKeRwHHgDOX2GbWXcfj7+AidXOoVMtlpzDk3HE27pMIt5iyYl62YxDTiwSoiEWS//e\nyh7kvJ5IiIhIZ8q7BxkAd59y94Nmthl4EVGv8RxwB/DUis0vAPattD8zuw54J3C1u39/teOb2TBR\ncXywkfOXpDDibWvGj8OTUW/Z9iB3esQbJIdYTLayQFbEm4iIZCi3FAsAM3sR0RCL+4kK1A8SRbp9\nsrzJB4Evmtl3gL8nGjP8MqIot3gfnwEOuPvbyt//IfBu4FXAI2Z2RnnTSXefLG/zp8DXiArts4B3\nEfVWfz6ta+0keT4OTy4Wkn4PsiLekgaDFItW9SAnI976FfEmIiKpy/uv+Ubgo0RF8WeIMo9f5O7z\nAO7+FaLxxtcBdwOvB17u7t8N9nE20aS+2BuBPuCviXqE46/fD7bZQVQM3w/cCBwBLnX3sRZfX0fK\nc9nlRNRbBlnIinhLWr+u9UMswog3Da8QEZEs5NqD7O43EhWoK23zCeATK/z88orvz6nhuK+s7Qyl\nEYkxuRkXjXHU2+TJhUyGWCSXP1aBPNgXxry1ZpJeHpGBIiLS2fLuQZY2lGcPcnTMqIjKIupN8WNJ\nfT1d9PVEv1YmT7amB1kT9EREJGsqkKXl4oIm64i32LYMJ+qNKn7sCeIki1YtFKKINxERyZoKZGmp\nhcUShyfngOwj3mJZRr2NqHfzCeIki8mTC7h70/tTL72IiGRNBbK01NGpuaWIt7wygcOot7SXnFb8\n2BMN9UdJFoslZ3ah1PT+RssFstpYRESyogJZWqoIyy5vzyjqLRk/1qf4sbJWLhYStXF0T21dr4g3\nERHJhgpkaanE4/CcepDD446mGPUWxo8pXeGU4USB3NwkyRMz88wtxG2s3mMREcmGCmRpqbAgzWtC\n1WBfz1Ieb5o9yJo8trxk1FtzPchqYxERyYMKZGmpRMRbjr2qcTF1Ynqek/PpRL2FEwDVu3lKK5eb\nVsSbiIjkQQWytFQY8bZhIL91aLYGBetYSsMs1Lu5vHiSHjQ/BlmLhIiISB5UIEvLLCyWGJvIN+It\ntj2DqLe8F0Qpqlb2IBdhTLuIiHQeFcjSMkem5pZyb/PuUU0mWaTTgxz3TCt+LClMsZhucpJeHPHW\n3WVsGVIbi4hINlQgS8uMJh6H51vMbEtkIbe+BzkZ8ab4sVDYgzzRRA9yGPF2uiLeREQkQyqQpWWS\nQw6K04OcRtRbGPGm4RVJQ31hD3LjBfLx6VMRb3lO+BQRkc6jAllapkjLLg/0daca9abJY9WFk/Sa\nGYOcjAzUhxAREcmOCmRpmdGCFY1pRr0pfqy6nu4u+nujXy3N5CBrgp6IiORFBbK0TFEi3mLbgmEW\nrY56U8TbyuJhFs2spJcokAvwgUtERDqHCmRpiSJFvMXCnt1WD7NIFm/q3awUJ1lMzi4sJZvUqwir\nMoqISGdSgSwtUaSIt1jY69jqiXpx/Jgi3pYXJ1mUSs5seaJdvcKIt9OG+lp2biIiIqtRgSwtUcRF\nM9LqQQ7jx7YqfmxZQ00uFuLuS8NYFPEmIiJZU4EsLTFawDG5YQ9yKxcLOTFzKn5MwyuWN9zkctPH\np+eZX1TEm4iI5EMFsrREGPFWlKIxjHpr5XLTmqC3umZ7kIsUGSgiIp1HBbK0RCIXuEBFYxpRb0Uc\nTlI0YYHcSJKFPoSIiEieVCBLS4yVe/zW9XazYV3+EW+xsFgfbdEwi3DCn+LHljecKJDr70EeVQay\niIjkSAWyNC2MeNu6vr8QEW+xsIe3VcMstIDF6podYqEPISIikicVyNK0w5PFi3iLhefTqol6YfzY\nliEVyMtpdpLeSKKNFfEmIiLZUoEsTSvyssvbE0kWzfcgK36sNs30ILv70nCYrev76VIbi4hIxlQg\nS9OKPKFqW2KIRfM9yIofq00zk/SOBW2s4RUiIpIHFcjStCKnOqzr7WbDQC+QnPjVKMWP1WaoLyiQ\n5+rrQS7y/SQiIp1BBbI0LTGhqmA9yHCqF/nETPNRb6OJODsVb9V0dxnr+qJxyPUOsQjvp6I9kRAR\nkc6gAlmaFvfMruvtZn1/cSLeYuFj+maj3hIJFnr8v6Lhci9yvZP0lBIiIiJ5U4EsTVlYLHF4Mio6\nt20oVsRbLHxMP9Jk1Jt6N2sXj0Oeml1YSjmpxWhiiIXaWEREsqcCWZoSRbxF/17UYiYZ9dZkgRzE\nj52m+LEVxVFv7jBTx9CW+ENId5dx2qDaWEREsqcCWZqSHHJQzMfh21s0xEIRb/VpJOpNEW8iIlIE\nKpClKSNr4HH4thYNsTimiLe6DDYQ9ZZo44LeTyIi0v5UIEtTkmNyi9mDvK63m41LUW+N9yAXeUGU\nIlqfKJBr60FeC08kRESk/alAlqaMJhIHitvjt7Vc0I43EfVW5AVRimiwr/7lptfCEwkREWl/KpCl\nKXHRuK6vmBFvsVaMQ1b8WH2G19U/Blk50yIiUgQqkKVhC4sljkxFBc329esKGfEWSyRZNDgOeSxc\nEEVjkFeVXE2vtl775DAWtbGIiORDBbI0LIx4K3pvX2KiXoNRbyNBxNsWRbytKtGDfLLWIRaKeBMR\nkfypQJaGJceLFrtADodYjDQwxELxY/ULe5Cn51YvkN19qZd+2wa1sYiI5EcFsjRsLS27HPYgg0M4\nCwAAIABJREFUjzYwxCKMHyv6tRbFUP+pSXq1jEFWG4uISFGoQJaGjayBiLdYs1Fva6m3vCgSY5Br\nKJDVxiIiUhQqkKVhayXiLRaf4/jMPDM1ThqLKX6sfl1dxkA56m2yhoVCRtbY/SQiIu1LBbI0bHSN\nRLzFwoUnwkSKWoQLohR9QmKRrC9P1KulBzkR8aZFQkREJEcqkKUhayniLdZM1NuoepAbMlgeZjE9\nt4DHkSdVqJdeRESKQgWyNGRscnYp4m2tjBfd3kTUm+LHGjNcfrLgvnoWcvyhpadbMXoiIpIvFcjS\nkLW44tm2BqPewvgxRbzVJ0yymF5hmEVlG6+FJxIiItK+VCBLQxKPw9dIJFci6q2OHuQwfkyP/usz\n3N+79O8rRb0dnZpjYTF6JLFW7icREWlfKpClISOJSWtro6BZ19vNxsGoYKtniIXixxoX9iBPrZBk\nEfbo60OIiIjkTQWyNCQZ8bZ2isZ4mMXEyYWao97W0oIoRRNmIa/Ugxwu3rJ1Dd1PIiLSnnItkM1s\nvZndYGb7zGzGzG4zs+dVbPM0M/tbMzthZlNmdoeZnb3Kfl9hZveZ2Ukzu9vMXrzMNr9jZo+Ut9lj\nZs9v9fW1s7hoHFgjEW+x7Q2sqLcWx1sXxVB/bYuFhG2sIRYiIpK3vHuQPwZcBbwGeCbwTeBWM/sp\nADM7D/gucB9wOXAR8B6gamVjZv8W+DzwceBZwE3ATWZ2YbDNrwAfAt4FPBv4MXCLmW1r7eW1p/nF\nEken5oDocfhamlCViHqrcaKe4scaNxwWyHPVC2QNYxERkSLJrUA2swHg5cB17v4dd9/r7tcDe4E3\nljf7L8Dfuft17v4jd3/Q3f/W3UdX2PX/Dex29w+6+0/c/Z3AD4HfDbb5PeD/c/dPuvu9wBuAaeA3\nW3uV7elwEPG21hZ0CM+35h7kCUW8NSocg7zSEIsw4u00RbyJiEjO8uxB7gG6eWJv8AzwAjPrAl4C\nPGBmt5jZaHkoxDWr7HcXcGvFa7eUX8fM+oDnhNu4e6n8/a5qOzWzfjPbEH8B61e9wja1lidU1duD\nHMaPbdugiLd6DdcwxEIRbyIiUjS5FcjuPgHcDrzTzM4ys24zezVRkXomsA0YBv4I2A28EPgK8GUz\nu2yFXZ8BjFS8NlJ+HeB0osJ8pW2W8zbgRPC1f8ULbGMja3SCHkQFWKyWqLejU3OnIt40NrZu4Rjk\nySopFkcU8SYiIgWT9xjk1wAGHABmgTcRjR8ucercvuruH3b3O939fcDXiYZEZO29wMbga0cO51AI\no2HE2xoraOqNektc6xr7MFAEg33dxB3C1XqQR9fwEwkREWlPuRbI5THFlxH1FD/J3Z8P9AIPAYeB\nBeDeirf9BFgpxeIQsL3ite3l1ynvd3GVbZY711l3H4+/gIkVzqGtja7xCVVxEVZL1Fuyt1zFW73M\njMFy1Nt0lUl6IxNr94mEiIi0p7x7kAFw9yl3P2hmm4EXEfUazwF3AE+t2PwCYN8Ku7sduKLitavK\nr1Pe7w/Cbcrjna+It5GVhRFvw2so4i0WTtRbrRc5EfG2xiYkFkU8zGLiZLUeZKWEiIhIseRa3ZjZ\ni4iGWNwPnA98kCjS7ZPlTT4IfNHMvgP8PXA18DKiyLd4H58BDrj728ov/RnwD2b2VuAbwCuB5wK/\nFRz6Q8Cnzez7wD8DbwaGguNKFWs54i0WFmGjE7Occ/pQ1W0V8da84f5uRoGZuUVKJX/CREd9CBER\nkaLJu/tvI9HY3h3AUeBvgLe7+zyAu3/FzN5ANEHuz4kK6Ze7+3eDfZxNNGaZ8ntuM7NXAf8Z+K/A\nvwLXuPu/BNt80cy2Au8mmph3J3C1u1dO3JMKYxNrN+ItFg4LWa0HOYwf26L4sYYMVWQhr1/Xm/h5\n3Ma93V2KeBMRkULItUB29xuBG1fZ5hPAJ1b4+eXLvPYl4Eur7PcjwEdqOlFZ0g49quHEwpUKZMWP\ntUYy6m0xUSCXSr7Ug6w2FhGRoijEGGRZO9oh1SGMehubqJ6FfFTxYy2RjHpLjkM+Oj3HYilq47X6\nREJERNqPCmSpSztMqKo16m0tL4hSJEMrLBbSDk8kRESk/ahAlrq0S9EYRr3VEj+2dY32lhfBcLDc\n9FRFWycm6KmNRUSkIFQgS11GJ05FvA31da+ydXFtS6yot/wwi7Hww4CGWDRsqC8YYlER9TY6oR5k\nEREpHhXIUrO5hbUf8RYLi7FqwyxG1viCKEURDrGYrliYpV2eSIiISHtRgSw1Ozx5KuJtrReMiai3\nKhP1wog3xY81LiyQJ6qMQe7t7mLzYDL+TUREJC8qkKVmiWWX1/iQg/D8R5fpQVb8WOsMBWOQp4MC\nuVRSjJ6IiBSTCmSp2UgbTagKz390mR7kMH5M44+bM1wl5i3Rxmv8fhIRkfaiAllqNtZGE6r6e7rZ\nNBgNm1huDLLix1pnoLd7qXd4avbUGOTEEwm1sYiIFIgKZKlZu02oinuRJ5eJemuHBVGKwsyWot4m\nZ+eXXk9EvGmREBERKRAVyFKzuMdvsL8n8dh8rdoeFGUjFVFv7bAgSpEMlu+Xqbnle5DVxiIiUiQq\nkKUmcwsljk2XI97apLcvLMoqJ+qNqHezpdaXC+STc4ssLJaA9nsiISIi7UMFstQkjHhrlyEH21aI\neosXsOjt7lLEWwsMBouFTM9HvchhGyviTUREikQFstSkHR+HV4t6U8Rb6w2vO1UgT80uJCLetm1Q\nG4uISLGs/YGkkonkkIM2KZDDHuSgQA7jxzS8ojXCZcmnZhc40hVGvLXH/SQiIu1DPchSk9GJMJKr\nPYrGMOotTK1ox97yvA0lspAXE/fTVn0IERGRglGBLDVp16Jx+zJRb6NttCBKUYSpJ1OzC4k2bqf7\nSURE2oMKZKlJXNAMtUnEWywszuJhJO36YSBPQxWr6SXbWB9CRESkWFQgy6rCiLd2G5MbXk88US8c\nbqECuTWG+pNjkNtxTLuIiLQPFciyqrEg4q3dCsZwieM46i3u3VT8WOtUDrEYUcSbiIgUWPs8K29j\n7s7J+RILpRI9XV2s6+3KJBYrPu4jhydZLDld1n5jcuPH++7OgWPTnJie49CJk7i7It5aaKi/B3en\n5NEHrpFyG29XxJuIiBSQCuSC2n9smj0PHeWRsXH2jY4xNTMDlIAuhgYG2LltK+ds3cAlTz6NHZsH\nUz3u8elZDk/NQ1cv3x7oZmHRW37cPOw/Ns0/7T3Mw2PjLM5PcmB0P7ffez/7js5AVy8zc1v4mx/s\nb4trzUt8P+0dOcGDBw9CaZ4DIzC3SNTG86erjUVEpHDM42fnUhcz2wCcOHHiBBs2bGjZfn/82HF2\n372fBx7dx3DpIOevO8DOgWNs75+mt2uR+VI3I7OD7JvZzN6TO5jsOoMLzt7Jz1+0g4t2bErluMcm\npzkyU+Lo/DBzfWfw6MLOlh03D5XXun7uQbb3HGFr3yQ7NvWy79g8R+eHGbdtjNq5a/pa81LZxuf1\nH8BmDnBa7yQ9tsiCd6uNRUQkdePj42zcuBFgo7uP1/o+FcgNanWBPDm7wOe+9wh77r2X87vv5cqt\nD/KsjSP0dFX/77NQMn50Yju3jp3H3sWnc+kznsGvXrKzrpSJWo67d2ySydkoAu3CszYCXU0fNw/V\nrvWRIxNL13fmxnUcPBGNj92xeYBNA+vW5LXmZaX76Z7Hx5kvlRLbP2nzIBsH+tXGIiKSChXIGWtl\ngfzY0Wk+vPtO5o7dx6vO2MOu0x6nnmGZ7nD70bP43KFL6Nv807zl6ot50mmrP66u9bj3HhxnbrFE\nT5eVC+TmjpuHla71sWPTHJmKUjqG+nuYKhfL520dZn25SFtL15qX1e6n+w6Nc3IhWSCfv3V4qRBW\nG4uISKupQM5Yqwrkx45O84Gvf58tM3fw5nNvZ1Pf7OpvquL4XD83PLyLIwPP47qXPnfF4qLW45bc\nuevACSBaLvgp29Y3ddw8rHatoxMnebzca2xA/H/E08/cQF93Muil6Neal1rup38dm1z68BFTG4uI\nSJoaLZAV85ajydkFPrz7TrbM3MF15323qeIYYFPfLNed9122zNzBh3ffuTRsoJnjzi6e6vHr7+le\ndptaj5uHWq41vK64OO4yo7f7if97FPla81Lr/dRT8XhCbSwiIkWlAjlHn/veI8wdu483n3s7gz2t\nKQIGexZ487m3M3fsPj6/Z1/Tx52bP1Ug9/VUv11qOW4earnW5a6rv6eLaqNcinqtean1furuSrao\n2lhERIpKBXJOfvzYcfbcey+vOmNP0z3HlTb1zfKqM/bwvXvu4a79x5s67uzC4tK/969QIK923DzU\neq3LXddKHwageNeal3rup57uZDmsNhYRkaJSgZyT3Xfv5/zue9l12uOp7H/XaY9zfs+93HzX/qaO\nO7uw+hCLWo6bh1qvtcvsCeNgV/swAMW61rzUcz89sQd5bd1PIiLSOVQg52D/sWkeeHQfV259sK60\ninqYwRVbHuSBR/dx4PhMw8cNC+TVevyqHTcP9V5r5bXVUrwV5VrzUm8bLzfEYjWd3sYiIpIPFcg5\n2PPQUYZLB3nWxpFUj/PsTSMMlw6x56EjDR93rlwg93QZPV21VdWVx81DvddaWazVUrxBMa41L/W2\ncU+X2lhERNYGFcg5eGRsnPP796+4CEgr9HQ556/bz8Oj4w0dt+TOXDnFotZiZrnj5qHea628vlp6\ny6EY15qXetu4sgdZbSwiIkWlpaoy5u7sGx3jysHaJx05NBx1tb3nCLsfO8g9B87inscOcnX/USZq\n3Nd8DRFv1ewcOMato2O4O5bWOJIqGmnj8PqqxY9Vk+e15qWRNg6fQKiNRUSkyFQgZ+zkfImpmRm2\nD0/X/J6SOw+OTTZ0vPmZwzw4doz33Xw/j44cY37r4Yb2VWtvX2x7/zRT4zPMLpRY11tfcd2sRtq4\nr/fU9a0UP7acPK81L420cdiDrDYWEZEi0xCLjC2USkCJ3q7FVbdthW5bxHBKpRKG02ONHXeov77P\nUj1WApyFUvYrNTbSxv09XfSWx8gO9dVXgOV5rXlppI17uu1UG6+h+0lERDqPepAzFk1U6mK+VHsR\nZsD29esaOt7jPsCmwX5edOGZfPl7Y6wfGKh7XwN93QzXWdAseBdQ+8S+Vmqkjbswnrx1iKnZBTYP\n9dV1vDyvNS9qYxERaWcqkDO2rreLoYEBRmYHa35PlxlnbmysQL5jehNnn76RV196Nt/fu4+Fnk2c\nuTH9NICR2UGGBgbqmtzXKo20McBAbzcDDTy+z/Na86I2FhGRdqa/NhkzM3Zu28q+6U2ZHG/fzGZ2\nbttKV1dXLsfNY0JVXm3cSZPH1MYiItLOVCDn4JytG9g7u4OFUrp/7BdKxt6TOzh324Zcj5uHTrrW\nvKiNRUSkXalAzsElTz6Nya4z+dGJ7ake54fHtzPZdQaXPHlLrsfNQydda17UxiIi0q5UIOdgx+ZB\nLjh7J7eOnYenNCnfHb51+HwuOHsnP7VpINfj5qGTrjUvamMREWlXKpBzcvUzd7B38encfvSsVPZ/\n+9Gz2Lv4NH7+oh2FOG4eOula86I2FhGRdqQCOSf/5kmbuOTpT+dzhy7h+Fx/S/d9fK6fzx26hEuf\n8Qwu2pGcRJXXcfPQSdeaF7WxiIi0IxXIOXrVpefQt/mnueHhXUwvtCZxb3qhhxse3kXf5p/mVy/Z\nWajj5qGTrjUvamMREWk3KpBzNNzfw1uuvpgjA8/jAw++oOkeuONz/XzgwRdwZOB5vOXqi6su7pHX\ncfPQSdeaF7WxiIi0G/O0Zte0OTPbAJw4ceIEGzY0Fz/12NFpPrz7TuaO3cerztjDrtMep564V/do\nrObnDl1C3+af5i1XX8yTTlt9AYe8jpuHTrrWvKiNRUSkaMbHx9m4cSPARncfr/V9KpAb1MoCGWBy\ndoHP79nH9+65h/N77uWKLQ/y7E0j9HRV/++zUDJ+eHw73zp8PnsXn8auZzyDV16ys64et7yOm4dO\nuta8qI1FRKRIVCBnrNUFcuyu/ce5+a79PPDoPoZLhzh/3X52Dhxje/80PVZiwbsYmR1k38xm9p7c\nwWTXGVxw9k5+/qIdTU1kyuu4eeika82L2lhERIpABXLG0iqQYweOz7DnoSM8PDrOvtExpmZmAAeM\noYEBdm7byrnbNnDJk7e0NB82r+PmoZOuNS9qYxERyZMK5IylXSCH3J3ZhRILJaeny+jv6cLqGdy5\nxo6bh0661ryojUVEJGuNFsi5pliY2Xozu8HM9pnZjJndZmbPC37+KTPziq/dq+zz28u8x83sG8E2\n1y/z8/vSvNZmmBnrersZ7u9hXW93ZkVFXsfNQydda17UxiIislbkPQvmY8CFwGuAx4FXA7ea2dPd\n/UB5m93Aa4P3zK6yz18C+oLvtwA/Br5Usd09wJXB9wv1nbqIiIiItKPcCmQzGwBeDvyCu3+n/PL1\nZvYy4I3AO8qvzbr7oVr36+5HK47zSmCaJxbIC/XsV0REREQ6Q55DLHqAbuBkxeszwAuC7y83s1Ez\nu9/M/qeZbanzOK8DvuDuUxWvP8XMHjezh8zss2Z29ko7MbN+M9sQfwHr6zwPEREREVkDcutBdvcJ\nM7sdeKeZ/QQYAX4V2AXsLW+2G/gy8DBwHvBfgZvNbJe7L652DDN7PtEQjtdV/GgPcC1wP3Am8CfA\nP5rZhe4+UWV3bytvlzA+XvN4bxERERHJUKN1Wq4pFmZ2HvAJ4GeAReCHwAPAc9z9acts/2TgQeBK\nd/9WDfv/S2CXu1+0ynabgH3A77n7x6ts0w+Ea+ieCRR2Yp+IiIiILNkRzG9bVa6T9Nz9QeAyMxsC\nNrj7QTP7IvBQle0fMrPDwPnAigVyeZ+vBP64hvM4bmYPlPdbbZtZggmCZjYB7ACq9Ti32npgf8bH\nXIvUTrVTW9VG7VQbtVNt1E61UTvVRu1Um/VEYRA1yzvFAoDy+OApM9sMvAi4brntzGwHUSrFwRp2\n+wqiHt//tdqGZjZMVBz/VR3n7EDNn0SaFURiTdST49dp1E61U1vVRu1UG7VTbdROtVE71UbtVLO6\n2ybvHOQXmdnVZnaumV0F/D3RsIVPmtmwmX3QzC41s3PM7Argq0Tjk28J9vEZM3vvMrt/HXCTux9Z\n5rh/amaXlff7b4GvEMW8fT6FyxQRERGRNSTvHuSNwHuJHg0cBf4GeLu7z5tZD3AR8BvAJqKu8W8C\n7ywPd4idDZTCnZrZU4mSMF5Y5bg7iIrhLcAY8F3gUncfa9F1iYiIiMgalfcY5BuBG6v8bIZouMVq\n+7h8mdfuB6ou0+Xur6z9LAtjFngXqy+U0unUTrVTW9VG7VQbtVNt1E61UTvVRu2UklxTLERERERE\niibXMcgiIiIiIkWjAllEREREJKACWUREREQkoAJZRERERCSgArlAzOx3zOwRMztpZnvM7PmrbH+5\nmf3QzGbNbK+ZXZvRqebCzN5mZneY2YSZjZrZTeVIv5Xec7mZ+TJfZ2R13nkws+uXueYVl0bvtPsJ\noPz/23L3x0erbN8R95OZ/YyZfc3MHi9f3zUVPzcze7eZHTSzGTO71cyeUsN+X2Fm95V/x91tZi9O\n7yrSt1I7mVmvmb2/fJ1T5W0+Y2ZnrbLPa5e5v06mfzXpqeF++tQy17y7hv221f0ENbXVcr9/3Mz+\nYIV9tt09lQUVyAVhZr8CfIgoruXZwI+BW8xsW5XtzwW+QbS4ysXADcDHzGzVaLw17DLgo8ClwFVA\nL/BNi5YVX81TgTODr9G0TrJA7iF5zS+otmGH3k8AzyPZRleVX//SKu9r9/tpiOh30O9U+fl1wJuA\nNwCXAFNEv6/WVduhRYsyfR74OPAs4CbgJjO7sIXnnbWV2mmQ6Hf5e8r//CWi++Zva9jvOMn7a2cr\nTjZHq91PALtJXvOvrrTDNr2fYPW2OrPi6zcBJ1pHYiXtdk+lTjFvBWFme4A73P13y993AY8B/93d\n37fM9u8HXuLuFwavfQHY5O5XZ3TauTKzrUSFyWXu/p0q21xOVPRtdvfjGZ5erszseuAad7+4xu07\n/n4CMLMbgJcCT/Flfjl24v1kZg78orvfVP7eiBZu+m/u/qfl1zYCI8C17v6FKvv5IjDk7i8NXvse\ncKe7vyHly0hdZTtV2eZ5wD8DO9390SrbXAvc4O6bUjnRnC3XTmb2KaLfNddUfeMT99PW9xPUfE/d\nBKx39ytW2OZa2vieSot6kAvAzPqA5wC3xq+5e6n8/a4qb9sVbl92ywrbt6ON5X8erWHbO8uPg/9/\nM/t3aZ5UgTyl/JjuITP7rJmdvcK2HX8/lf8/fDXwieWK4wqdeD/FzgXOIPn76gSwh5Xvl46/x4h+\nZzmw2oerYTPbZ2aPmdlXzewZGZxb3i63aOjc/Wb2P81syyrbd/z9ZGbbgZcQ9aKvphPvqaaoQC6G\n04Fuoh6Y0AjRH6LlnFFl+w1mNtDa0yuecg/7DcA/ufu/rLDpQaLHwC8vfz0GfNvMnp3+WeZqD3At\ncDXwRqKi5h/NbH2V7Tv6fiq7hmhZ+0+tsE2n3k+h+HdSPb+v4vfV+562UR5+8n7g8+4+vsKm9xM9\nNv8Fog9sXcBtZrYj/bPMzW7g14ErgD8kGk53s5l1r/Cejr6fyn4DmAC+vMp2nXhPNS3XpaZFmvBR\n4EJWGFcLS8uO3x+8dJuZnQe8BXhNeqeXL3e/Ofj2rvIQnn3AL1Nbb0Mneh1ws7s/Xm2DTr2fpDlm\n1gvcCBjRB9aq3P124PbgvbcBPwF+G3hniqeZm4phOXeb2V3Ag8DlwLdyOam14TeBz7r7ihPuOvGe\nagX1IBfDYWAR2F7x+nbgUJX3HKqy/bi7z7T29IrFzD5CNE70Z919fwO7+Gfg/NaeVbGVx8s+QPXr\n7tj7CcDMdgJXAh9r4O2ddj/Fv5Pq+X0Vv6/e96x5QXG8E7hqld7jJ3D3eeBHdNA95u4PEf1dXOma\nO/J+ipnZvyea9Fn376xOvKcaoQK5ANx9DvgB0eMlYGkIwRUEn/oq3B5uX3bVCtuveRb5CPCLwM+5\n+8MN7upiokflHcPMhol+GVa77o67nyq8lmjC5zcaeG+n3U8PExUh4e+rDURpFivdLx13jwXF8VOA\nK939SAP76AaeSQfdY+VH/1tY+Zo77n6q8DrgB+7+43rf2In3VCM0xKI4PgR82sy+T9Qj9WaiuJdP\nApjZe4GfcvdfL2//F8DvmtkHgE8AP0f0+PwlWZ94hj4KvIpoHNWEncqePRH3cla2k5m9megP+j3A\nOuD1RG31wozPPVNm9qfA14iGVZxFFB+4QBSLpPspUP4w+lrg0+6+UPGzjryfgg9UsXPN7GLgqLs/\nWk77eIeZ/StRe7yHKNkiTCb4DHDA3d9WfunPgH8ws7cSfRB5JfBc4LdSv6CUrNRORMXHXxNFvL0U\n6A5+Zx0td4w8oZ3M7I+B7wF7icbE/wFR73MjTzcKYZV2Ogr8CVFM2SHgPOADRNd/S7CPtr+fYPX/\n98rbbABeAby1yj7a/p7KhLvrqyBfwO8SFTSzRJOsLgl+9ing2xXbX070mGSWaLzWtXlfQ8rt41W+\nrg22SbQTUV7rXmAGOEIU0fWzeV9LBm31BaKCZRbYX/7+PN1Py7bVC8v30QXL/Kwj76fyvbDc/2uf\nKv/cgHcTFTQnidIELqjYx7fj7YPXXkE0hnsW+BfgxXlfa1rtBJyzwu+sy6u1E/Dh4O/AIaLi71l5\nX2uK7TRAVAiPAnPAI8D/C2zvtPtptbYKtvktYBrYWGUfbX9PZfGlHGQRERERkYDGIIuIiIiIBFQg\ni4iIiIgEVCCLiIiIiARUIIuIiIiIBFQgi4iIiIgEVCCLiIiIiARUIIuIiIiIBFQgi4iIiIgEVCCL\niEgmzOx6M7sz7/MQEVmNCmQRkSaZ2afM7Ka8z0NERFpDBbKISBsys768zyErZtab9zmISHtRgSwi\nkjIz+z0zu9vMpszsMTP7H2Y2XP7ZkJmNm9n/VfGea8rbry9//yQzu9HMjpvZUTP7qpmdE2z/KTO7\nyczebmaPA/dXOZfrzexOM3uNmT1iZifM7AvxccrbPGJmb654351mdn3wvZvZb5vZ181s2sx+Yma7\nzOx8M/t2+dxvM7PzljmH3y63w3T5mjZW/Pz15f2dNLP7zOw/Bj87p3zsXzGzfzCzk8CvmdlOM/ua\nmR0rH/seM3txDf95RESeQAWyiEj6SsCbgGcAvwH8HPABAHefAr4AvLbiPa8F/trdJ8o9pLcAE8C/\nB/4dMAnsrugpvgJ4KnAV8NIVzuc84JryNi8FLgP+qIHreifwGeBi4D7gc8BfAu8FngsY8JGK95wP\n/DLwMuBq4FnA/4h/aGa/BrwbeDvwNOD/Ad5jZr9RsZ/3AX9W3uYW4KNAP/AzwDOBPyRqIxGRuvXk\nfQIiIu3O3W8Ivn3EzN4B/AUQ94x+DLjNzM5094Nmtg14MXBl+ee/QtSh8Xp3dwAzey1wHLgc+GZ5\nu6nyNnOrnFIXcK27T5T39VdExfXb67y0T7r7jeV9vB+4HXiPu99Sfu3PgE9WvGcd8OvufqC8zX8C\nvmFmb3X3Q8C7gLe6+5fL2z9sZk8Hfhv4dLCfG4JtMLOzgb9x97vLLz1U57WIiCxRD7KISMrM7Eoz\n+5aZHTCzCeCvgC1mNgjg7v8M3EPUuwzwamAf8J3y9/+GqOd1wswmzWwSOEpUbIZDGO6uoTgGeCQu\njssOAtsauLS7gn8fic+h4rV1ZrYheO3RuDguu53ob9FTzWyI6Ho+Hl9n+VrfQfI6Ab5f8f2fA+8w\ns38ys3eZ2UUNXI+ICKACWUQkVeVxwl8nKiZfDjwH+J3yj8PhER8Dri3/+2uJeme9/P0w8AOioQzh\n1wVEwxpiUzWe1nzF907y70GJaHhEaLmJcOF+fIXXav1bM1z+538geZ0XApdWbJu4Vnc3hpxcAAAB\n+0lEQVT/GPBkog8fzwS+X+6dFhGpmwpkEZF0PYfod+1b3f177v4AcNYy2/0vYKeZvQl4OsnhBD8E\nngKMuvveiq8TKZzzGHBm/E25B/jcFu37bDMLr/9SooL8fncfAR4HnrzMdT682o7d/TF3/wt3/yXg\nvxEV2iIiddMYZBGR1thoZhdXvHYE2EvU+/qfzOxrRBPs3lD5Znc/ZmZfBj4IfNPd9wc//izwB8BX\nzeyPgf3ATuCXgA9UbNsK/xu4tny+x4kmzS22aN8ngU+b2e8DG4iGRtxYHn8M8CfAn5vZCWA30cS7\n5wKb3f1D1XZqZjcANwMPAJuBnwV+0qJzFpEOox5kEZHWuBz4UcXXn7j7j4HfI0pV+Bfg14C3VdnH\nx4mGXXwifNHdp4nSGR4FvkxU+H2caAzyeIuvA6IUin8gGhryDeAm4MEW7Xsv0TX8HdHkwrs4NVkx\nHirxeqJhJneXz+NaYLUe5G6iJIufEBXWD4T7FRGph50a4iYiInkys9cAHwbOqnGynYiIpEBDLERE\nclZOsziTKIv4L1Uci4jkS0MsRETydx3RQhuHiIY3iIhIjjTEQkREREQkoB5kEREREZGACmQRERER\nkYAKZBERERGRgApkEREREZGACmQRERERkYAKZBERERGRgApkEREREZGACmQRERERkcD/AUhtVmA2\n0yhZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7cb0291c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (\"Opt_layer_num =\",Accuracy.index(max(Accuracy)), \" Accuracy =\", max(Accuracy) ,\n",
    "       \"Time =\" , np.sum(t[0:Accuracy.index(max(Accuracy))+1]))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(8, 6), dpi=100)\n",
    "plt.plot(Accuracy, '-o', ms=20, lw=2, alpha=0.7, mfc='orange')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Layer numbers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[95.83,\n",
       " 95.83,\n",
       " 96.67,\n",
       " 95.83,\n",
       " 96.67,\n",
       " 97.5,\n",
       " 95.83,\n",
       " 96.67,\n",
       " 97.5,\n",
       " 96.67,\n",
       " 96.67,\n",
       " 96.67,\n",
       " 97.5,\n",
       " 97.5,\n",
       " 97.5,\n",
       " 97.5,\n",
       " 97.5,\n",
       " 97.5,\n",
       " 97.5,\n",
       " 97.5]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
