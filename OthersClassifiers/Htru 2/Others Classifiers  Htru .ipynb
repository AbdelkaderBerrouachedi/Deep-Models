{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt \n",
    "from pprint import pprint\n",
    "from numpy import array\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "import names\n",
    "df = pd.read_csv(\"htru.csv\", names = names.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Profile_mean</th>\n",
       "      <th>Profile_stdev</th>\n",
       "      <th>Profile_skewness</th>\n",
       "      <th>Profile_kurtosis</th>\n",
       "      <th>DM_mean</th>\n",
       "      <th>DM_stdev</th>\n",
       "      <th>DM_skewness</th>\n",
       "      <th>DM_kurtosis</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140.562500</td>\n",
       "      <td>55.683782</td>\n",
       "      <td>-0.234571</td>\n",
       "      <td>-0.699648</td>\n",
       "      <td>3.199833</td>\n",
       "      <td>19.110426</td>\n",
       "      <td>7.975532</td>\n",
       "      <td>74.242225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102.507812</td>\n",
       "      <td>58.882430</td>\n",
       "      <td>0.465318</td>\n",
       "      <td>-0.515088</td>\n",
       "      <td>1.677258</td>\n",
       "      <td>14.860146</td>\n",
       "      <td>10.576487</td>\n",
       "      <td>127.393580</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103.015625</td>\n",
       "      <td>39.341649</td>\n",
       "      <td>0.323328</td>\n",
       "      <td>1.051164</td>\n",
       "      <td>3.121237</td>\n",
       "      <td>21.744669</td>\n",
       "      <td>7.735822</td>\n",
       "      <td>63.171909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136.750000</td>\n",
       "      <td>57.178449</td>\n",
       "      <td>-0.068415</td>\n",
       "      <td>-0.636238</td>\n",
       "      <td>3.642977</td>\n",
       "      <td>20.959280</td>\n",
       "      <td>6.896499</td>\n",
       "      <td>53.593661</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.726562</td>\n",
       "      <td>40.672225</td>\n",
       "      <td>0.600866</td>\n",
       "      <td>1.123492</td>\n",
       "      <td>1.178930</td>\n",
       "      <td>11.468720</td>\n",
       "      <td>14.269573</td>\n",
       "      <td>252.567306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Profile_mean  Profile_stdev  Profile_skewness  Profile_kurtosis   DM_mean  \\\n",
       "0    140.562500      55.683782         -0.234571         -0.699648  3.199833   \n",
       "1    102.507812      58.882430          0.465318         -0.515088  1.677258   \n",
       "2    103.015625      39.341649          0.323328          1.051164  3.121237   \n",
       "3    136.750000      57.178449         -0.068415         -0.636238  3.642977   \n",
       "4     88.726562      40.672225          0.600866          1.123492  1.178930   \n",
       "\n",
       "    DM_stdev  DM_skewness  DM_kurtosis  class  \n",
       "0  19.110426     7.975532    74.242225      0  \n",
       "1  14.860146    10.576487   127.393580      0  \n",
       "2  21.744669     7.735822    63.171909      0  \n",
       "3  20.959280     6.896499    53.593661      0  \n",
       "4  11.468720    14.269573   252.567306      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 5 \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df to values\n",
    "df = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GC Forest\n",
    "import argparse\n",
    "import sys\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "sys.path.insert(0, \"lib\")\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.utils.config_utils import load_json\n",
    "config = load_json(\"./examples/htru.json\")  # layer = 1   k=10   Extree + DTree\n",
    "gc = GCForest(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# train test \n",
    "from sklearn.cross_validation import train_test_split\n",
    "y = df[:,8]\n",
    "X = df[:,0:8]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of class\n",
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 17:51:37,163][cascade_classifier.fit_transform] X_groups_train.shape=[(12528, 8)],y_train.shape=(12528,),X_groups_test.shape=[(5370, 8)],y_test.shape=(5370,)\n",
      "[ 2018-07-31 17:51:37,165][cascade_classifier.fit_transform] group_dims=[8]\n",
      "[ 2018-07-31 17:51:37,167][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-31 17:51:37,168][cascade_classifier.fit_transform] group_ends=[8]\n",
      "[ 2018-07-31 17:51:37,169][cascade_classifier.fit_transform] X_train.shape=(12528, 8),X_test.shape=(5370, 8)\n",
      "[ 2018-07-31 17:51:37,170][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(12528, 8), X_cur_test.shape=(5370, 8)\n",
      "[ 2018-07-31 17:51:38,165][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=98.41%\n",
      "[ 2018-07-31 17:51:39,719][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=97.85%\n",
      "[ 2018-07-31 17:51:41,260][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=98.80%\n",
      "[ 2018-07-31 17:51:42,455][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=97.45%\n",
      "[ 2018-07-31 17:51:43,515][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=97.45%\n",
      "[ 2018-07-31 17:51:44,558][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=98.08%\n",
      "[ 2018-07-31 17:51:45,598][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=97.76%\n",
      "[ 2018-07-31 17:51:46,658][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=97.52%\n",
      "[ 2018-07-31 17:51:47,719][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=97.76%\n",
      "[ 2018-07-31 17:51:48,772][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=98.16%\n",
      "[ 2018-07-31 17:51:49,002][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=97.92%\n",
      "[ 2018-07-31 17:51:49,003][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=98.04%\n",
      "[ 2018-07-31 17:51:49,632][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_0.predict)=97.61%\n",
      "[ 2018-07-31 17:51:50,476][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_1.predict)=97.37%\n",
      "[ 2018-07-31 17:51:51,323][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_2.predict)=98.01%\n",
      "[ 2018-07-31 17:51:52,050][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_3.predict)=98.64%\n",
      "[ 2018-07-31 17:51:52,892][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_4.predict)=97.92%\n",
      "[ 2018-07-31 17:51:53,741][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_5.predict)=98.40%\n",
      "[ 2018-07-31 17:51:54,577][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_6.predict)=98.08%\n",
      "[ 2018-07-31 17:51:55,426][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_7.predict)=97.52%\n",
      "[ 2018-07-31 17:51:56,327][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_8.predict)=97.60%\n",
      "[ 2018-07-31 17:51:57,343][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_9.predict)=97.52%\n",
      "[ 2018-07-31 17:51:57,593][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_cv.predict)=97.87%\n",
      "[ 2018-07-31 17:51:57,594][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.test.predict)=98.10%\n",
      "[ 2018-07-31 17:51:57,761][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_0.predict)=98.01%\n",
      "[ 2018-07-31 17:51:57,895][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_1.predict)=97.93%\n",
      "[ 2018-07-31 17:51:58,017][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_2.predict)=97.85%\n",
      "[ 2018-07-31 17:51:58,179][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_3.predict)=98.08%\n",
      "[ 2018-07-31 17:51:58,313][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_4.predict)=97.21%\n",
      "[ 2018-07-31 17:51:58,447][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_5.predict)=97.68%\n",
      "[ 2018-07-31 17:51:58,557][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_6.predict)=97.04%\n",
      "[ 2018-07-31 17:51:58,678][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_7.predict)=98.48%\n",
      "[ 2018-07-31 17:51:58,798][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_8.predict)=98.16%\n",
      "[ 2018-07-31 17:51:58,924][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_9.predict)=97.84%\n",
      "[ 2018-07-31 17:51:58,927][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_cv.predict)=97.83%\n",
      "[ 2018-07-31 17:51:58,938][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.test.predict)=97.97%\n",
      "[ 2018-07-31 17:51:58,942][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=97.91%\n",
      "[ 2018-07-31 17:51:58,946][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=98.08%\n",
      "[ 2018-07-31 17:51:58,950][cascade_classifier.fit_transform] [layer=1] look_indexs=[0], X_cur_train.shape=(12528, 14), X_cur_test.shape=(5370, 14)\n",
      "[ 2018-07-31 17:52:00,293][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_0.predict)=98.72%\n",
      "[ 2018-07-31 17:52:01,804][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_1.predict)=98.01%\n",
      "[ 2018-07-31 17:52:02,973][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_2.predict)=97.69%\n",
      "[ 2018-07-31 17:52:04,135][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_3.predict)=97.61%\n",
      "[ 2018-07-31 17:52:05,279][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_4.predict)=98.24%\n",
      "[ 2018-07-31 17:52:06,470][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_5.predict)=97.92%\n",
      "[ 2018-07-31 17:52:07,642][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_6.predict)=98.00%\n",
      "[ 2018-07-31 17:52:08,786][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_7.predict)=97.76%\n",
      "[ 2018-07-31 17:52:09,955][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_8.predict)=97.92%\n",
      "[ 2018-07-31 17:52:11,159][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_9.predict)=97.92%\n",
      "[ 2018-07-31 17:52:11,391][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_cv.predict)=97.98%\n",
      "[ 2018-07-31 17:52:11,392][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.test.predict)=98.06%\n",
      "[ 2018-07-31 17:52:12,008][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_0.predict)=98.41%\n",
      "[ 2018-07-31 17:52:12,849][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_1.predict)=98.17%\n",
      "[ 2018-07-31 17:52:13,732][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_2.predict)=98.09%\n",
      "[ 2018-07-31 17:52:14,681][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_3.predict)=98.00%\n",
      "[ 2018-07-31 17:52:15,523][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_4.predict)=98.00%\n",
      "[ 2018-07-31 17:52:16,480][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_5.predict)=98.24%\n",
      "[ 2018-07-31 17:52:17,489][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_6.predict)=97.84%\n",
      "[ 2018-07-31 17:52:18,553][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_7.predict)=97.92%\n",
      "[ 2018-07-31 17:52:19,655][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_8.predict)=97.92%\n",
      "[ 2018-07-31 17:52:20,775][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_9.predict)=97.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 17:52:21,008][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_cv.predict)=98.04%\n",
      "[ 2018-07-31 17:52:21,009][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.test.predict)=98.08%\n",
      "[ 2018-07-31 17:52:21,151][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_0.predict)=98.09%\n",
      "[ 2018-07-31 17:52:21,329][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_1.predict)=98.33%\n",
      "[ 2018-07-31 17:52:21,461][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_2.predict)=97.85%\n",
      "[ 2018-07-31 17:52:21,607][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_3.predict)=97.77%\n",
      "[ 2018-07-31 17:52:21,781][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_4.predict)=98.08%\n",
      "[ 2018-07-31 17:52:21,946][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_5.predict)=97.92%\n",
      "[ 2018-07-31 17:52:22,094][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_6.predict)=97.68%\n",
      "[ 2018-07-31 17:52:22,232][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_7.predict)=98.16%\n",
      "[ 2018-07-31 17:52:22,362][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_8.predict)=98.08%\n",
      "[ 2018-07-31 17:52:22,470][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_9.predict)=97.44%\n",
      "[ 2018-07-31 17:52:22,472][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_cv.predict)=97.94%\n",
      "[ 2018-07-31 17:52:22,473][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.test.predict)=98.04%\n",
      "[ 2018-07-31 17:52:22,474][cascade_classifier.calc_accuracy] Accuracy(layer_1 - train.classifier_average)=98.00%\n",
      "[ 2018-07-31 17:52:22,476][cascade_classifier.calc_accuracy] Accuracy(layer_1 - test.classifier_average)=98.06%\n",
      "[ 2018-07-31 17:52:22,478][cascade_classifier.fit_transform] [layer=2] look_indexs=[0], X_cur_train.shape=(12528, 14), X_cur_test.shape=(5370, 14)\n",
      "[ 2018-07-31 17:52:23,431][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_0.predict)=97.77%\n",
      "[ 2018-07-31 17:52:24,566][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_1.predict)=97.93%\n",
      "[ 2018-07-31 17:52:25,752][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_2.predict)=97.53%\n",
      "[ 2018-07-31 17:52:26,815][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_3.predict)=97.92%\n",
      "[ 2018-07-31 17:52:27,963][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_4.predict)=98.32%\n",
      "[ 2018-07-31 17:52:29,157][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_5.predict)=97.68%\n",
      "[ 2018-07-31 17:52:30,480][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_6.predict)=98.08%\n",
      "[ 2018-07-31 17:52:31,574][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_7.predict)=97.68%\n",
      "[ 2018-07-31 17:52:32,933][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_8.predict)=97.92%\n",
      "[ 2018-07-31 17:52:34,171][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_9.predict)=98.00%\n",
      "[ 2018-07-31 17:52:34,400][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_cv.predict)=97.88%\n",
      "[ 2018-07-31 17:52:34,401][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.test.predict)=98.08%\n",
      "[ 2018-07-31 17:52:35,024][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_0.predict)=97.61%\n",
      "[ 2018-07-31 17:52:36,017][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_1.predict)=98.25%\n",
      "[ 2018-07-31 17:52:37,065][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_2.predict)=97.61%\n",
      "[ 2018-07-31 17:52:38,016][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_3.predict)=97.85%\n",
      "[ 2018-07-31 17:52:39,105][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_4.predict)=97.77%\n",
      "[ 2018-07-31 17:52:40,190][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_5.predict)=98.48%\n",
      "[ 2018-07-31 17:52:41,128][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_6.predict)=97.44%\n",
      "[ 2018-07-31 17:52:42,120][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_7.predict)=98.08%\n",
      "[ 2018-07-31 17:52:43,118][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_8.predict)=98.16%\n",
      "[ 2018-07-31 17:52:44,085][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_9.predict)=97.68%\n",
      "[ 2018-07-31 17:52:44,329][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_cv.predict)=97.89%\n",
      "[ 2018-07-31 17:52:44,330][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.test.predict)=98.01%\n",
      "[ 2018-07-31 17:52:44,487][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_0.predict)=97.53%\n",
      "[ 2018-07-31 17:52:44,635][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_1.predict)=97.77%\n",
      "[ 2018-07-31 17:52:44,767][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_2.predict)=97.69%\n",
      "[ 2018-07-31 17:52:44,907][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_3.predict)=97.92%\n",
      "[ 2018-07-31 17:52:45,034][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_4.predict)=98.08%\n",
      "[ 2018-07-31 17:52:45,216][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_5.predict)=98.24%\n",
      "[ 2018-07-31 17:52:45,385][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_6.predict)=98.00%\n",
      "[ 2018-07-31 17:52:45,554][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_7.predict)=98.40%\n",
      "[ 2018-07-31 17:52:45,699][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_8.predict)=97.28%\n",
      "[ 2018-07-31 17:52:45,834][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_9.predict)=98.96%\n",
      "[ 2018-07-31 17:52:45,836][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_cv.predict)=97.99%\n",
      "[ 2018-07-31 17:52:45,837][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.test.predict)=98.01%\n",
      "[ 2018-07-31 17:52:45,839][cascade_classifier.calc_accuracy] Accuracy(layer_2 - train.classifier_average)=97.96%\n",
      "[ 2018-07-31 17:52:45,840][cascade_classifier.calc_accuracy] Accuracy(layer_2 - test.classifier_average)=98.12%\n",
      "[ 2018-07-31 17:52:45,842][cascade_classifier.fit_transform] [layer=3] look_indexs=[0], X_cur_train.shape=(12528, 14), X_cur_test.shape=(5370, 14)\n",
      "[ 2018-07-31 17:52:46,789][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_0.predict)=98.41%\n",
      "[ 2018-07-31 17:52:47,981][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_1.predict)=98.33%\n",
      "[ 2018-07-31 17:52:49,176][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_2.predict)=97.93%\n",
      "[ 2018-07-31 17:52:50,366][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_3.predict)=98.40%\n",
      "[ 2018-07-31 17:52:51,553][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_4.predict)=97.53%\n",
      "[ 2018-07-31 17:52:52,813][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_5.predict)=98.08%\n",
      "[ 2018-07-31 17:52:53,962][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_6.predict)=97.92%\n",
      "[ 2018-07-31 17:52:55,150][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_7.predict)=98.08%\n",
      "[ 2018-07-31 17:52:56,343][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_8.predict)=97.92%\n",
      "[ 2018-07-31 17:52:57,504][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_9.predict)=97.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 17:52:57,743][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_cv.predict)=98.00%\n",
      "[ 2018-07-31 17:52:57,744][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.test.predict)=97.82%\n",
      "[ 2018-07-31 17:52:58,475][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_0.predict)=97.77%\n",
      "[ 2018-07-31 17:52:59,448][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_1.predict)=98.01%\n",
      "[ 2018-07-31 17:53:00,422][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_2.predict)=98.56%\n",
      "[ 2018-07-31 17:53:01,266][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_3.predict)=98.40%\n",
      "[ 2018-07-31 17:53:02,106][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_4.predict)=98.24%\n",
      "[ 2018-07-31 17:53:03,121][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_5.predict)=97.92%\n",
      "[ 2018-07-31 17:53:04,115][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_6.predict)=98.24%\n",
      "[ 2018-07-31 17:53:05,110][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_7.predict)=97.12%\n",
      "[ 2018-07-31 17:53:06,122][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_8.predict)=98.24%\n",
      "[ 2018-07-31 17:53:07,068][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_9.predict)=97.44%\n",
      "[ 2018-07-31 17:53:07,325][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_cv.predict)=98.00%\n",
      "[ 2018-07-31 17:53:07,326][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.test.predict)=97.91%\n",
      "[ 2018-07-31 17:53:07,477][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_0.predict)=98.17%\n",
      "[ 2018-07-31 17:53:07,647][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_1.predict)=97.61%\n",
      "[ 2018-07-31 17:53:07,852][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_2.predict)=98.01%\n",
      "[ 2018-07-31 17:53:07,969][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_3.predict)=98.16%\n",
      "[ 2018-07-31 17:53:08,096][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_4.predict)=97.61%\n",
      "[ 2018-07-31 17:53:08,225][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_5.predict)=98.00%\n",
      "[ 2018-07-31 17:53:08,347][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_6.predict)=97.60%\n",
      "[ 2018-07-31 17:53:08,486][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_7.predict)=98.00%\n",
      "[ 2018-07-31 17:53:08,630][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_8.predict)=98.48%\n",
      "[ 2018-07-31 17:53:08,770][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_9.predict)=98.08%\n",
      "[ 2018-07-31 17:53:08,772][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_cv.predict)=97.97%\n",
      "[ 2018-07-31 17:53:08,773][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.test.predict)=98.06%\n",
      "[ 2018-07-31 17:53:08,775][cascade_classifier.calc_accuracy] Accuracy(layer_3 - train.classifier_average)=98.00%\n",
      "[ 2018-07-31 17:53:08,776][cascade_classifier.calc_accuracy] Accuracy(layer_3 - test.classifier_average)=98.04%\n",
      "[ 2018-07-31 17:53:08,777][cascade_classifier.fit_transform] [layer=4] look_indexs=[0], X_cur_train.shape=(12528, 14), X_cur_test.shape=(5370, 14)\n",
      "[ 2018-07-31 17:53:09,701][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_0.predict)=98.17%\n",
      "[ 2018-07-31 17:53:10,863][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_1.predict)=97.61%\n",
      "[ 2018-07-31 17:53:12,058][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_2.predict)=98.48%\n",
      "[ 2018-07-31 17:53:13,249][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_3.predict)=98.24%\n",
      "[ 2018-07-31 17:53:14,448][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_4.predict)=98.24%\n",
      "[ 2018-07-31 17:53:15,646][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_5.predict)=97.12%\n",
      "[ 2018-07-31 17:53:16,830][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_6.predict)=97.76%\n",
      "[ 2018-07-31 17:53:18,018][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_7.predict)=97.52%\n",
      "[ 2018-07-31 17:53:19,211][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_8.predict)=98.08%\n",
      "[ 2018-07-31 17:53:20,245][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_9.predict)=98.24%\n",
      "[ 2018-07-31 17:53:20,477][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_cv.predict)=97.95%\n",
      "[ 2018-07-31 17:53:20,478][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.test.predict)=97.90%\n",
      "[ 2018-07-31 17:53:21,206][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_0.predict)=97.85%\n",
      "[ 2018-07-31 17:53:22,188][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_1.predict)=98.56%\n",
      "[ 2018-07-31 17:53:23,026][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_2.predict)=97.37%\n",
      "[ 2018-07-31 17:53:23,980][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_3.predict)=97.77%\n",
      "[ 2018-07-31 17:53:24,938][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_4.predict)=97.77%\n",
      "[ 2018-07-31 17:53:25,890][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_5.predict)=98.24%\n",
      "[ 2018-07-31 17:53:26,849][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_6.predict)=97.60%\n",
      "[ 2018-07-31 17:53:27,803][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_7.predict)=98.08%\n",
      "[ 2018-07-31 17:53:28,764][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_8.predict)=97.76%\n",
      "[ 2018-07-31 17:53:29,791][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_9.predict)=98.16%\n",
      "[ 2018-07-31 17:53:30,026][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_cv.predict)=97.92%\n",
      "[ 2018-07-31 17:53:30,028][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.test.predict)=97.84%\n",
      "[ 2018-07-31 17:53:30,163][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_0.predict)=98.56%\n",
      "[ 2018-07-31 17:53:30,295][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_1.predict)=97.77%\n",
      "[ 2018-07-31 17:53:30,411][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_2.predict)=98.09%\n",
      "[ 2018-07-31 17:53:30,543][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_3.predict)=97.85%\n",
      "[ 2018-07-31 17:53:30,675][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_4.predict)=97.77%\n",
      "[ 2018-07-31 17:53:30,826][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_5.predict)=97.92%\n",
      "[ 2018-07-31 17:53:30,958][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_6.predict)=98.48%\n",
      "[ 2018-07-31 17:53:31,096][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_7.predict)=98.00%\n",
      "[ 2018-07-31 17:53:31,227][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_8.predict)=97.60%\n",
      "[ 2018-07-31 17:53:31,357][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_9.predict)=98.08%\n",
      "[ 2018-07-31 17:53:31,359][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_cv.predict)=98.01%\n",
      "[ 2018-07-31 17:53:31,360][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.test.predict)=97.91%\n",
      "[ 2018-07-31 17:53:31,362][cascade_classifier.calc_accuracy] Accuracy(layer_4 - train.classifier_average)=97.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 17:53:31,363][cascade_classifier.calc_accuracy] Accuracy(layer_4 - test.classifier_average)=97.97%\n",
      "[ 2018-07-31 17:53:31,363][cascade_classifier.fit_transform] [Result][Optimal Level Detected] opt_layer_num=2, accuracy_train=98.00%, accuracy_test=98.06%\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "# X_enc is the concatenated predict_proba result of each estimators of the last layer of the GCForest model\n",
    "    # X_enc.shape =\n",
    "    #   (n_datas, n_estimators * n_classes): If cascade is provided\n",
    "    #   (n_datas, n_estimators * n_classes, dimX, dimY): If only finegrained part is provided\n",
    "    # You can also pass X_test, y_test to fit_transform method, then the accracy on test data will be logged when training.\n",
    "X_train_enc, X_test_enc = gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test)\n",
    "    # WARNING: if you set gc.set_keep_model_in_mem(True), you would have to use\n",
    "    # gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test) to evaluate your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 17:53:31,388][cascade_classifier.transform] X_groups_test.shape=[(5370, 8)]\n",
      "[ 2018-07-31 17:53:31,389][cascade_classifier.transform] group_dims=[8]\n",
      "[ 2018-07-31 17:53:31,391][cascade_classifier.transform] X_test.shape=(5370, 8)\n",
      "[ 2018-07-31 17:53:31,393][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(5370, 8)\n",
      "[ 2018-07-31 17:53:36,031][cascade_classifier.transform] [layer=1] look_indexs=[0], X_cur_test.shape=(5370, 14)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GCForest = 98.063315 %\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "y_pred = gc.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy of GCForest = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' Time ', '123.493', ' seconds')\n",
      "[[4895   31]\n",
      " [  73  371]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.99      0.99      4926\n",
      "        1.0       0.92      0.84      0.88       444\n",
      "\n",
      "avg / total       0.98      0.98      0.98      5370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "11275/11275 [==============================] - 2s 201us/step - loss: 0.1460 - acc: 0.9627\n",
      "Epoch 2/50\n",
      "11275/11275 [==============================] - 2s 167us/step - loss: 0.0980 - acc: 0.9725\n",
      "Epoch 3/50\n",
      "11275/11275 [==============================] - 2s 165us/step - loss: 0.0914 - acc: 0.9741\n",
      "Epoch 4/50\n",
      "11275/11275 [==============================] - 2s 167us/step - loss: 0.0883 - acc: 0.9742\n",
      "Epoch 5/50\n",
      "11275/11275 [==============================] - 2s 169us/step - loss: 0.0875 - acc: 0.9745\n",
      "Epoch 6/50\n",
      "11275/11275 [==============================] - 2s 168us/step - loss: 0.0868 - acc: 0.9750\n",
      "Epoch 7/50\n",
      "11275/11275 [==============================] - 2s 168us/step - loss: 0.0855 - acc: 0.9741\n",
      "Epoch 8/50\n",
      "11275/11275 [==============================] - 2s 164us/step - loss: 0.0861 - acc: 0.9760\n",
      "Epoch 9/50\n",
      "11275/11275 [==============================] - 2s 167us/step - loss: 0.0854 - acc: 0.9748\n",
      "Epoch 10/50\n",
      "11275/11275 [==============================] - 2s 176us/step - loss: 0.0860 - acc: 0.9755\n",
      "Epoch 11/50\n",
      "11275/11275 [==============================] - 3s 236us/step - loss: 0.0865 - acc: 0.9737\n",
      "Epoch 12/50\n",
      "11275/11275 [==============================] - 4s 311us/step - loss: 0.0847 - acc: 0.9755\n",
      "Epoch 13/50\n",
      "11275/11275 [==============================] - 3s 232us/step - loss: 0.0880 - acc: 0.9738\n",
      "Epoch 14/50\n",
      "11275/11275 [==============================] - 2s 164us/step - loss: 0.0838 - acc: 0.9759\n",
      "Epoch 15/50\n",
      "11275/11275 [==============================] - 2s 165us/step - loss: 0.0853 - acc: 0.9745\n",
      "Epoch 16/50\n",
      "11275/11275 [==============================] - 2s 164us/step - loss: 0.0846 - acc: 0.9740\n",
      "Epoch 17/50\n",
      "11275/11275 [==============================] - 2s 167us/step - loss: 0.0837 - acc: 0.9750\n",
      "Epoch 18/50\n",
      "11275/11275 [==============================] - 2s 165us/step - loss: 0.0851 - acc: 0.9758\n",
      "Epoch 19/50\n",
      "11275/11275 [==============================] - 2s 171us/step - loss: 0.0818 - acc: 0.9746\n",
      "Epoch 20/50\n",
      "11275/11275 [==============================] - 2s 168us/step - loss: 0.0817 - acc: 0.9756\n",
      "Epoch 21/50\n",
      "11275/11275 [==============================] - 2s 165us/step - loss: 0.0827 - acc: 0.9754\n",
      "Epoch 22/50\n",
      "11275/11275 [==============================] - 2s 164us/step - loss: 0.0827 - acc: 0.9751\n",
      "Epoch 23/50\n",
      "11275/11275 [==============================] - 2s 164us/step - loss: 0.0825 - acc: 0.9768\n",
      "Epoch 24/50\n",
      "11275/11275 [==============================] - 2s 165us/step - loss: 0.0819 - acc: 0.9762\n",
      "Epoch 25/50\n",
      "11275/11275 [==============================] - 2s 167us/step - loss: 0.0809 - acc: 0.9766\n",
      "Epoch 26/50\n",
      "11275/11275 [==============================] - 2s 165us/step - loss: 0.0813 - acc: 0.9757\n",
      "Epoch 27/50\n",
      "11275/11275 [==============================] - 2s 165us/step - loss: 0.0817 - acc: 0.9760\n",
      "Epoch 28/50\n",
      "11275/11275 [==============================] - 2s 166us/step - loss: 0.0819 - acc: 0.9765\n",
      "Epoch 29/50\n",
      "11275/11275 [==============================] - 2s 166us/step - loss: 0.0801 - acc: 0.9761\n",
      "Epoch 30/50\n",
      "11275/11275 [==============================] - 2s 166us/step - loss: 0.0821 - acc: 0.9761\n",
      "Epoch 31/50\n",
      "11275/11275 [==============================] - 2s 167us/step - loss: 0.0802 - acc: 0.9763\n",
      "Epoch 32/50\n",
      "11275/11275 [==============================] - 2s 168us/step - loss: 0.0812 - acc: 0.9767\n",
      "Epoch 33/50\n",
      "11275/11275 [==============================] - 2s 168us/step - loss: 0.0801 - acc: 0.9760\n",
      "Epoch 34/50\n",
      "11275/11275 [==============================] - 2s 169us/step - loss: 0.0798 - acc: 0.9760\n",
      "Epoch 35/50\n",
      "11275/11275 [==============================] - 2s 170us/step - loss: 0.0791 - acc: 0.9767\n",
      "Epoch 36/50\n",
      "11275/11275 [==============================] - 2s 171us/step - loss: 0.0800 - acc: 0.9759\n",
      "Epoch 37/50\n",
      "11275/11275 [==============================] - 2s 170us/step - loss: 0.0789 - acc: 0.9769\n",
      "Epoch 38/50\n",
      "11275/11275 [==============================] - 2s 168us/step - loss: 0.0799 - acc: 0.9765\n",
      "Epoch 39/50\n",
      "11275/11275 [==============================] - 2s 177us/step - loss: 0.0791 - acc: 0.9776\n",
      "Epoch 40/50\n",
      "11275/11275 [==============================] - 2s 180us/step - loss: 0.0769 - acc: 0.9777\n",
      "Epoch 41/50\n",
      "11275/11275 [==============================] - 2s 194us/step - loss: 0.0771 - acc: 0.9772\n",
      "Epoch 42/50\n",
      "11275/11275 [==============================] - 2s 196us/step - loss: 0.0804 - acc: 0.9764\n",
      "Epoch 43/50\n",
      "11275/11275 [==============================] - 2s 188us/step - loss: 0.0781 - acc: 0.9767\n",
      "Epoch 44/50\n",
      "11275/11275 [==============================] - 2s 175us/step - loss: 0.0792 - acc: 0.9776\n",
      "Epoch 45/50\n",
      "11275/11275 [==============================] - 2s 169us/step - loss: 0.0780 - acc: 0.9776\n",
      "Epoch 46/50\n",
      "11275/11275 [==============================] - 2s 168us/step - loss: 0.0777 - acc: 0.9775\n",
      "Epoch 47/50\n",
      "11275/11275 [==============================] - 2s 172us/step - loss: 0.0790 - acc: 0.9774\n",
      "Epoch 48/50\n",
      "11275/11275 [==============================] - 2s 175us/step - loss: 0.0789 - acc: 0.9776\n",
      "Epoch 49/50\n",
      "11275/11275 [==============================] - 2s 174us/step - loss: 0.0781 - acc: 0.9775\n",
      "Epoch 50/50\n",
      "11275/11275 [==============================] - 2s 172us/step - loss: 0.0765 - acc: 0.9769\n",
      "1253/1253 [==============================] - 0s 58us/step\n",
      "Epoch 1/50\n",
      "11275/11275 [==============================] - 2s 210us/step - loss: 0.1527 - acc: 0.9644\n",
      "Epoch 2/50\n",
      "11275/11275 [==============================] - 2s 183us/step - loss: 0.0973 - acc: 0.9729\n",
      "Epoch 3/50\n",
      "11275/11275 [==============================] - 2s 171us/step - loss: 0.0939 - acc: 0.9746\n",
      "Epoch 4/50\n",
      "11275/11275 [==============================] - 2s 192us/step - loss: 0.0920 - acc: 0.9744\n",
      "Epoch 5/50\n",
      "11275/11275 [==============================] - 3s 298us/step - loss: 0.0900 - acc: 0.9730\n",
      "Epoch 6/50\n",
      "11275/11275 [==============================] - 3s 293us/step - loss: 0.0896 - acc: 0.9739\n",
      "Epoch 7/50\n",
      "11275/11275 [==============================] - 3s 236us/step - loss: 0.0875 - acc: 0.9749\n",
      "Epoch 8/50\n",
      "11275/11275 [==============================] - 2s 174us/step - loss: 0.0883 - acc: 0.9749\n",
      "Epoch 9/50\n",
      "11275/11275 [==============================] - 2s 170us/step - loss: 0.0873 - acc: 0.9751\n",
      "Epoch 10/50\n",
      "11275/11275 [==============================] - 2s 170us/step - loss: 0.0875 - acc: 0.9746\n",
      "Epoch 11/50\n",
      "11275/11275 [==============================] - 2s 169us/step - loss: 0.0883 - acc: 0.9757\n",
      "Epoch 12/50\n",
      "11275/11275 [==============================] - 2s 169us/step - loss: 0.0878 - acc: 0.9744\n",
      "Epoch 13/50\n",
      "11275/11275 [==============================] - 2s 166us/step - loss: 0.0863 - acc: 0.9745\n",
      "Epoch 14/50\n",
      "11275/11275 [==============================] - 2s 168us/step - loss: 0.0867 - acc: 0.9758\n",
      "Epoch 15/50\n",
      "11275/11275 [==============================] - 2s 190us/step - loss: 0.0845 - acc: 0.9751\n",
      "Epoch 16/50\n",
      "11275/11275 [==============================] - 3s 259us/step - loss: 0.0848 - acc: 0.9743\n",
      "Epoch 17/50\n",
      "11275/11275 [==============================] - 2s 199us/step - loss: 0.0843 - acc: 0.9745\n",
      "Epoch 18/50\n",
      "11275/11275 [==============================] - 2s 189us/step - loss: 0.0853 - acc: 0.9760\n",
      "Epoch 19/50\n",
      "11275/11275 [==============================] - 2s 171us/step - loss: 0.0833 - acc: 0.9754\n",
      "Epoch 20/50\n",
      "11275/11275 [==============================] - 2s 172us/step - loss: 0.0836 - acc: 0.9751\n",
      "Epoch 21/50\n",
      "11275/11275 [==============================] - 2s 171us/step - loss: 0.0836 - acc: 0.9752\n",
      "Epoch 22/50\n",
      "11275/11275 [==============================] - 2s 178us/step - loss: 0.0823 - acc: 0.9756\n",
      "Epoch 23/50\n",
      "11275/11275 [==============================] - 2s 172us/step - loss: 0.0837 - acc: 0.9749\n",
      "Epoch 24/50\n",
      "11275/11275 [==============================] - 2s 173us/step - loss: 0.0829 - acc: 0.9761\n",
      "Epoch 25/50\n",
      "11275/11275 [==============================] - 3s 233us/step - loss: 0.0830 - acc: 0.9751\n",
      "Epoch 26/50\n",
      "11275/11275 [==============================] - 3s 256us/step - loss: 0.0847 - acc: 0.9758\n",
      "Epoch 27/50\n",
      "11275/11275 [==============================] - 2s 175us/step - loss: 0.0820 - acc: 0.9758\n",
      "Epoch 28/50\n",
      "11275/11275 [==============================] - 2s 175us/step - loss: 0.0816 - acc: 0.9760\n",
      "Epoch 29/50\n",
      "11275/11275 [==============================] - 2s 167us/step - loss: 0.0829 - acc: 0.9753\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11275/11275 [==============================] - 2s 168us/step - loss: 0.0817 - acc: 0.9759\n",
      "Epoch 31/50\n",
      "11275/11275 [==============================] - 2s 168us/step - loss: 0.0808 - acc: 0.9767\n",
      "Epoch 32/50\n",
      "11275/11275 [==============================] - 2s 166us/step - loss: 0.0821 - acc: 0.9762\n",
      "Epoch 33/50\n",
      "11275/11275 [==============================] - 2s 165us/step - loss: 0.0800 - acc: 0.9758\n",
      "Epoch 34/50\n",
      "11275/11275 [==============================] - 2s 181us/step - loss: 0.0814 - acc: 0.9759\n",
      "Epoch 35/50\n",
      "11275/11275 [==============================] - 3s 232us/step - loss: 0.0807 - acc: 0.9769\n",
      "Epoch 36/50\n",
      "11275/11275 [==============================] - 3s 243us/step - loss: 0.0804 - acc: 0.9760\n",
      "Epoch 37/50\n",
      "11275/11275 [==============================] - 2s 168us/step - loss: 0.0813 - acc: 0.9760\n",
      "Epoch 38/50\n",
      "11275/11275 [==============================] - 2s 165us/step - loss: 0.0815 - acc: 0.9765\n",
      "Epoch 39/50\n",
      "11275/11275 [==============================] - 2s 167us/step - loss: 0.0796 - acc: 0.9764\n",
      "Epoch 40/50\n",
      "11275/11275 [==============================] - 2s 165us/step - loss: 0.0805 - acc: 0.9768\n",
      "Epoch 41/50\n",
      "11275/11275 [==============================] - 2s 173us/step - loss: 0.0800 - acc: 0.9759\n",
      "Epoch 42/50\n",
      "11275/11275 [==============================] - 2s 165us/step - loss: 0.0788 - acc: 0.9775\n",
      "Epoch 43/50\n",
      "11275/11275 [==============================] - 2s 164us/step - loss: 0.0795 - acc: 0.9769\n",
      "Epoch 44/50\n",
      "11275/11275 [==============================] - 2s 183us/step - loss: 0.0798 - acc: 0.9761\n",
      "Epoch 45/50\n",
      "11275/11275 [==============================] - 3s 246us/step - loss: 0.0794 - acc: 0.9762\n",
      "Epoch 46/50\n",
      "11275/11275 [==============================] - 3s 236us/step - loss: 0.0795 - acc: 0.9775\n",
      "Epoch 47/50\n",
      "11275/11275 [==============================] - 3s 223us/step - loss: 0.0808 - acc: 0.9755\n",
      "Epoch 48/50\n",
      "11275/11275 [==============================] - 3s 272us/step - loss: 0.0790 - acc: 0.9769\n",
      "Epoch 49/50\n",
      "11275/11275 [==============================] - 2s 192us/step - loss: 0.0773 - acc: 0.9769\n",
      "Epoch 50/50\n",
      "11275/11275 [==============================] - 2s 173us/step - loss: 0.0788 - acc: 0.9765\n",
      "1253/1253 [==============================] - 0s 66us/step\n",
      "Epoch 1/50\n",
      "11275/11275 [==============================] - 2s 203us/step - loss: 0.1162 - acc: 0.9670\n",
      "Epoch 2/50\n",
      "11275/11275 [==============================] - 2s 181us/step - loss: 0.0949 - acc: 0.9729\n",
      "Epoch 3/50\n",
      "11275/11275 [==============================] - 3s 245us/step - loss: 0.0943 - acc: 0.9732\n",
      "Epoch 4/50\n",
      "11275/11275 [==============================] - 3s 231us/step - loss: 0.0917 - acc: 0.9739\n",
      "Epoch 5/50\n",
      "11275/11275 [==============================] - 2s 172us/step - loss: 0.0913 - acc: 0.9744\n",
      "Epoch 6/50\n",
      "11275/11275 [==============================] - 2s 167us/step - loss: 0.0904 - acc: 0.9730\n",
      "Epoch 7/50\n",
      "11275/11275 [==============================] - 2s 168us/step - loss: 0.0903 - acc: 0.9737\n",
      "Epoch 8/50\n",
      "11275/11275 [==============================] - 2s 167us/step - loss: 0.0882 - acc: 0.9745\n",
      "Epoch 9/50\n",
      "11275/11275 [==============================] - 2s 170us/step - loss: 0.0896 - acc: 0.9739\n",
      "Epoch 10/50\n",
      "11275/11275 [==============================] - 2s 168us/step - loss: 0.0881 - acc: 0.9746\n",
      "Epoch 11/50\n",
      "11275/11275 [==============================] - 2s 165us/step - loss: 0.0861 - acc: 0.9741\n",
      "Epoch 12/50\n",
      "11275/11275 [==============================] - 3s 222us/step - loss: 0.0877 - acc: 0.9741\n",
      "Epoch 13/50\n",
      "11275/11275 [==============================] - 3s 254us/step - loss: 0.0872 - acc: 0.9751\n",
      "Epoch 14/50\n",
      "11275/11275 [==============================] - 3s 291us/step - loss: 0.0879 - acc: 0.9749\n",
      "Epoch 15/50\n",
      "11275/11275 [==============================] - 2s 216us/step - loss: 0.0860 - acc: 0.9748\n",
      "Epoch 16/50\n",
      "11275/11275 [==============================] - 2s 194us/step - loss: 0.0866 - acc: 0.9742\n",
      "Epoch 17/50\n",
      "11275/11275 [==============================] - 2s 191us/step - loss: 0.0852 - acc: 0.9755\n",
      "Epoch 18/50\n",
      "11275/11275 [==============================] - 3s 235us/step - loss: 0.0858 - acc: 0.9748\n",
      "Epoch 19/50\n",
      "11275/11275 [==============================] - ETA: 0s - loss: 0.0846 - acc: 0.974 - 2s 178us/step - loss: 0.0850 - acc: 0.9745\n",
      "Epoch 20/50\n",
      "11275/11275 [==============================] - 2s 176us/step - loss: 0.0851 - acc: 0.9747\n",
      "Epoch 21/50\n",
      "11275/11275 [==============================] - 2s 170us/step - loss: 0.0855 - acc: 0.9748\n",
      "Epoch 22/50\n",
      "11275/11275 [==============================] - 2s 180us/step - loss: 0.0848 - acc: 0.9745\n",
      "Epoch 23/50\n",
      "11275/11275 [==============================] - 2s 193us/step - loss: 0.0837 - acc: 0.9746\n",
      "Epoch 24/50\n",
      "11275/11275 [==============================] - 2s 191us/step - loss: 0.0841 - acc: 0.9752\n",
      "Epoch 25/50\n",
      "11275/11275 [==============================] - 2s 187us/step - loss: 0.0849 - acc: 0.9747\n",
      "Epoch 26/50\n",
      "11275/11275 [==============================] - 2s 172us/step - loss: 0.0847 - acc: 0.9764\n",
      "Epoch 27/50\n",
      "11275/11275 [==============================] - 2s 169us/step - loss: 0.0848 - acc: 0.9749\n",
      "Epoch 28/50\n",
      "11275/11275 [==============================] - 2s 167us/step - loss: 0.0823 - acc: 0.9757\n",
      "Epoch 29/50\n",
      "11275/11275 [==============================] - 2s 173us/step - loss: 0.0837 - acc: 0.9751\n",
      "Epoch 30/50\n",
      "11275/11275 [==============================] - 2s 173us/step - loss: 0.0830 - acc: 0.9753\n",
      "Epoch 31/50\n",
      "11275/11275 [==============================] - 2s 167us/step - loss: 0.0827 - acc: 0.9755\n",
      "Epoch 32/50\n",
      "11275/11275 [==============================] - 2s 168us/step - loss: 0.0823 - acc: 0.9754\n",
      "Epoch 33/50\n",
      "11275/11275 [==============================] - 2s 170us/step - loss: 0.0821 - acc: 0.9760\n",
      "Epoch 34/50\n",
      "11275/11275 [==============================] - 2s 174us/step - loss: 0.0836 - acc: 0.9750\n",
      "Epoch 35/50\n",
      "11275/11275 [==============================] - 2s 170us/step - loss: 0.0816 - acc: 0.9753\n",
      "Epoch 36/50\n",
      "11275/11275 [==============================] - 2s 169us/step - loss: 0.0829 - acc: 0.9758\n",
      "Epoch 37/50\n",
      "11275/11275 [==============================] - 2s 171us/step - loss: 0.0826 - acc: 0.9757\n",
      "Epoch 38/50\n",
      "11275/11275 [==============================] - 2s 170us/step - loss: 0.0832 - acc: 0.9767\n",
      "Epoch 39/50\n",
      "11275/11275 [==============================] - 2s 170us/step - loss: 0.0816 - acc: 0.9763\n",
      "Epoch 40/50\n",
      "11275/11275 [==============================] - 2s 172us/step - loss: 0.0816 - acc: 0.9764\n",
      "Epoch 41/50\n",
      "11275/11275 [==============================] - 2s 171us/step - loss: 0.0823 - acc: 0.9749\n",
      "Epoch 42/50\n",
      "11275/11275 [==============================] - 2s 170us/step - loss: 0.0844 - acc: 0.9760\n",
      "Epoch 43/50\n",
      "11275/11275 [==============================] - 2s 168us/step - loss: 0.0817 - acc: 0.9756\n",
      "Epoch 44/50\n",
      "11275/11275 [==============================] - 2s 167us/step - loss: 0.0809 - acc: 0.9760\n",
      "Epoch 45/50\n",
      "11275/11275 [==============================] - 2s 169us/step - loss: 0.0816 - acc: 0.9759\n",
      "Epoch 46/50\n",
      "11275/11275 [==============================] - 2s 167us/step - loss: 0.0807 - acc: 0.9762\n",
      "Epoch 47/50\n",
      "11275/11275 [==============================] - 2s 170us/step - loss: 0.0806 - acc: 0.9759\n",
      "Epoch 48/50\n",
      "11275/11275 [==============================] - 2s 170us/step - loss: 0.0802 - acc: 0.9762\n",
      "Epoch 49/50\n",
      "11275/11275 [==============================] - 2s 167us/step - loss: 0.0802 - acc: 0.9764\n",
      "Epoch 50/50\n",
      "11275/11275 [==============================] - 2s 170us/step - loss: 0.0797 - acc: 0.9754\n",
      "1253/1253 [==============================] - 0s 76us/step\n",
      "Epoch 1/50\n",
      "11275/11275 [==============================] - 2s 201us/step - loss: 0.1402 - acc: 0.9643\n",
      "Epoch 2/50\n",
      "11275/11275 [==============================] - 2s 172us/step - loss: 0.1020 - acc: 0.9720\n",
      "Epoch 3/50\n",
      "11275/11275 [==============================] - 2s 189us/step - loss: 0.0912 - acc: 0.9741\n",
      "Epoch 4/50\n",
      "11275/11275 [==============================] - 2s 196us/step - loss: 0.0920 - acc: 0.9745\n",
      "Epoch 5/50\n",
      "11275/11275 [==============================] - 2s 191us/step - loss: 0.0921 - acc: 0.9740\n",
      "Epoch 6/50\n",
      "11275/11275 [==============================] - 2s 192us/step - loss: 0.0910 - acc: 0.9745\n",
      "Epoch 7/50\n",
      "11275/11275 [==============================] - 2s 170us/step - loss: 0.0893 - acc: 0.9750\n",
      "Epoch 8/50\n",
      "11275/11275 [==============================] - 2s 172us/step - loss: 0.0887 - acc: 0.9755\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11275/11275 [==============================] - 2s 171us/step - loss: 0.0886 - acc: 0.9746\n",
      "Epoch 10/50\n",
      "11275/11275 [==============================] - 2s 170us/step - loss: 0.0869 - acc: 0.9745\n",
      "Epoch 11/50\n",
      "11275/11275 [==============================] - 2s 172us/step - loss: 0.0883 - acc: 0.9752\n",
      "Epoch 12/50\n",
      "11275/11275 [==============================] - 2s 169us/step - loss: 0.0863 - acc: 0.9754\n",
      "Epoch 13/50\n",
      "11275/11275 [==============================] - 2s 168us/step - loss: 0.0871 - acc: 0.9750\n",
      "Epoch 14/50\n",
      "11275/11275 [==============================] - 2s 171us/step - loss: 0.0857 - acc: 0.9761\n",
      "Epoch 15/50\n",
      "11275/11275 [==============================] - 2s 175us/step - loss: 0.0855 - acc: 0.9758\n",
      "Epoch 16/50\n",
      "11275/11275 [==============================] - 2s 174us/step - loss: 0.0860 - acc: 0.9741\n",
      "Epoch 17/50\n",
      "11275/11275 [==============================] - 2s 169us/step - loss: 0.0858 - acc: 0.9755\n",
      "Epoch 18/50\n",
      "11275/11275 [==============================] - 2s 173us/step - loss: 0.0846 - acc: 0.9752\n",
      "Epoch 19/50\n",
      "11275/11275 [==============================] - 2s 173us/step - loss: 0.0845 - acc: 0.9761\n",
      "Epoch 20/50\n",
      "11275/11275 [==============================] - 2s 174us/step - loss: 0.0847 - acc: 0.9754\n",
      "Epoch 21/50\n",
      "11275/11275 [==============================] - 2s 170us/step - loss: 0.0858 - acc: 0.9754\n",
      "Epoch 22/50\n",
      "11275/11275 [==============================] - 2s 171us/step - loss: 0.0838 - acc: 0.9760\n",
      "Epoch 23/50\n",
      "11275/11275 [==============================] - 2s 171us/step - loss: 0.0836 - acc: 0.9762\n",
      "Epoch 24/50\n",
      "11275/11275 [==============================] - 2s 171us/step - loss: 0.0839 - acc: 0.9763\n",
      "Epoch 25/50\n",
      "11275/11275 [==============================] - 2s 171us/step - loss: 0.0845 - acc: 0.9759\n",
      "Epoch 26/50\n",
      "11275/11275 [==============================] - 2s 173us/step - loss: 0.0826 - acc: 0.9758\n",
      "Epoch 27/50\n",
      "11275/11275 [==============================] - 2s 175us/step - loss: 0.0830 - acc: 0.9754\n",
      "Epoch 28/50\n",
      "11275/11275 [==============================] - 2s 176us/step - loss: 0.0820 - acc: 0.9760\n",
      "Epoch 29/50\n",
      "11275/11275 [==============================] - 2s 172us/step - loss: 0.0833 - acc: 0.9753\n",
      "Epoch 30/50\n",
      "11275/11275 [==============================] - 2s 177us/step - loss: 0.0836 - acc: 0.9755\n",
      "Epoch 31/50\n",
      "11275/11275 [==============================] - 2s 172us/step - loss: 0.0817 - acc: 0.9764\n",
      "Epoch 32/50\n",
      "11275/11275 [==============================] - 2s 173us/step - loss: 0.0820 - acc: 0.9758\n",
      "Epoch 33/50\n",
      "11275/11275 [==============================] - 2s 192us/step - loss: 0.0833 - acc: 0.9753\n",
      "Epoch 34/50\n",
      "11275/11275 [==============================] - 3s 257us/step - loss: 0.0818 - acc: 0.9763\n",
      "Epoch 35/50\n",
      "11275/11275 [==============================] - 4s 324us/step - loss: 0.0816 - acc: 0.9760\n",
      "Epoch 36/50\n",
      "11275/11275 [==============================] - 2s 213us/step - loss: 0.0818 - acc: 0.9766\n",
      "Epoch 37/50\n",
      "11275/11275 [==============================] - 2s 171us/step - loss: 0.0820 - acc: 0.9764\n",
      "Epoch 38/50\n",
      "11275/11275 [==============================] - 2s 172us/step - loss: 0.0834 - acc: 0.9769\n",
      "Epoch 39/50\n",
      "11275/11275 [==============================] - 2s 171us/step - loss: 0.0816 - acc: 0.9757\n",
      "Epoch 40/50\n",
      "11275/11275 [==============================] - 2s 171us/step - loss: 0.0806 - acc: 0.9765\n",
      "Epoch 41/50\n",
      "11275/11275 [==============================] - 2s 169us/step - loss: 0.0802 - acc: 0.9766\n",
      "Epoch 42/50\n",
      "11275/11275 [==============================] - 2s 171us/step - loss: 0.0804 - acc: 0.9763\n",
      "Epoch 43/50\n",
      "11275/11275 [==============================] - 2s 167us/step - loss: 0.0807 - acc: 0.9768\n",
      "Epoch 44/50\n",
      "11275/11275 [==============================] - 2s 184us/step - loss: 0.0803 - acc: 0.9761\n",
      "Epoch 45/50\n",
      "11275/11275 [==============================] - 2s 173us/step - loss: 0.0790 - acc: 0.9772\n",
      "Epoch 46/50\n",
      "11275/11275 [==============================] - 2s 168us/step - loss: 0.0802 - acc: 0.9771\n",
      "Epoch 47/50\n",
      "11275/11275 [==============================] - 2s 180us/step - loss: 0.0800 - acc: 0.9766\n",
      "Epoch 48/50\n",
      "11275/11275 [==============================] - 2s 176us/step - loss: 0.0800 - acc: 0.9770\n",
      "Epoch 49/50\n",
      "11275/11275 [==============================] - 2s 168us/step - loss: 0.0790 - acc: 0.9773\n",
      "Epoch 50/50\n",
      "11275/11275 [==============================] - 2s 173us/step - loss: 0.0794 - acc: 0.9766\n",
      "1253/1253 [==============================] - 0s 84us/step\n",
      "Epoch 1/50\n",
      "11275/11275 [==============================] - 2s 205us/step - loss: 0.1326 - acc: 0.9670\n",
      "Epoch 2/50\n",
      "11275/11275 [==============================] - 2s 203us/step - loss: 0.0974 - acc: 0.9726\n",
      "Epoch 3/50\n",
      "11275/11275 [==============================] - 3s 289us/step - loss: 0.0924 - acc: 0.9738\n",
      "Epoch 4/50\n",
      "11275/11275 [==============================] - 3s 301us/step - loss: 0.0894 - acc: 0.9737\n",
      "Epoch 5/50\n",
      "11275/11275 [==============================] - 3s 230us/step - loss: 0.0872 - acc: 0.9754\n",
      "Epoch 6/50\n",
      "11275/11275 [==============================] - 2s 170us/step - loss: 0.0881 - acc: 0.9745\n",
      "Epoch 7/50\n",
      "11275/11275 [==============================] - 2s 167us/step - loss: 0.0860 - acc: 0.9744\n",
      "Epoch 8/50\n",
      "11275/11275 [==============================] - 2s 169us/step - loss: 0.0870 - acc: 0.9757\n",
      "Epoch 9/50\n",
      "11275/11275 [==============================] - 2s 171us/step - loss: 0.0850 - acc: 0.9752\n",
      "Epoch 10/50\n",
      "11275/11275 [==============================] - 2s 186us/step - loss: 0.0859 - acc: 0.9753\n",
      "Epoch 11/50\n",
      "11275/11275 [==============================] - 2s 182us/step - loss: 0.0836 - acc: 0.9753\n",
      "Epoch 12/50\n",
      "11275/11275 [==============================] - 2s 172us/step - loss: 0.0842 - acc: 0.9757\n",
      "Epoch 13/50\n",
      "11275/11275 [==============================] - 3s 231us/step - loss: 0.0852 - acc: 0.9748\n",
      "Epoch 14/50\n",
      "11275/11275 [==============================] - 3s 255us/step - loss: 0.0840 - acc: 0.9753\n",
      "Epoch 15/50\n",
      "11275/11275 [==============================] - 2s 175us/step - loss: 0.0841 - acc: 0.9753\n",
      "Epoch 16/50\n",
      "11275/11275 [==============================] - 2s 173us/step - loss: 0.0819 - acc: 0.9765\n",
      "Epoch 17/50\n",
      "11275/11275 [==============================] - 2s 172us/step - loss: 0.0848 - acc: 0.9749\n",
      "Epoch 18/50\n",
      "11275/11275 [==============================] - 2s 173us/step - loss: 0.0827 - acc: 0.9763\n",
      "Epoch 19/50\n",
      "11275/11275 [==============================] - 2s 174us/step - loss: 0.0831 - acc: 0.9757\n",
      "Epoch 20/50\n",
      "11275/11275 [==============================] - 2s 170us/step - loss: 0.0836 - acc: 0.9765\n",
      "Epoch 21/50\n",
      "11275/11275 [==============================] - 2s 169us/step - loss: 0.0820 - acc: 0.9759\n",
      "Epoch 22/50\n",
      "11275/11275 [==============================] - 2s 193us/step - loss: 0.0818 - acc: 0.9756\n",
      "Epoch 23/50\n",
      "11275/11275 [==============================] - 3s 258us/step - loss: 0.0813 - acc: 0.9760\n",
      "Epoch 24/50\n",
      "11275/11275 [==============================] - 2s 214us/step - loss: 0.0815 - acc: 0.9765\n",
      "Epoch 25/50\n",
      "11275/11275 [==============================] - 2s 174us/step - loss: 0.0812 - acc: 0.9761\n",
      "Epoch 26/50\n",
      "11275/11275 [==============================] - 2s 174us/step - loss: 0.0817 - acc: 0.9761\n",
      "Epoch 27/50\n",
      "11275/11275 [==============================] - 2s 175us/step - loss: 0.0815 - acc: 0.9764\n",
      "Epoch 28/50\n",
      "11275/11275 [==============================] - 2s 172us/step - loss: 0.0800 - acc: 0.9769\n",
      "Epoch 29/50\n",
      "11275/11275 [==============================] - 2s 173us/step - loss: 0.0813 - acc: 0.9764\n",
      "Epoch 30/50\n",
      "11275/11275 [==============================] - 2s 173us/step - loss: 0.0805 - acc: 0.9762\n",
      "Epoch 31/50\n",
      "11275/11275 [==============================] - 2s 173us/step - loss: 0.0792 - acc: 0.9761\n",
      "Epoch 32/50\n",
      "11275/11275 [==============================] - 2s 216us/step - loss: 0.0800 - acc: 0.9756\n",
      "Epoch 33/50\n",
      "11275/11275 [==============================] - 3s 256us/step - loss: 0.0805 - acc: 0.9765\n",
      "Epoch 34/50\n",
      "11275/11275 [==============================] - 2s 189us/step - loss: 0.0810 - acc: 0.9757\n",
      "Epoch 35/50\n",
      "11275/11275 [==============================] - 2s 172us/step - loss: 0.0800 - acc: 0.9768\n",
      "Epoch 36/50\n",
      "11275/11275 [==============================] - 2s 177us/step - loss: 0.0788 - acc: 0.9771\n",
      "Epoch 37/50\n",
      "11275/11275 [==============================] - 2s 171us/step - loss: 0.0791 - acc: 0.9771\n",
      "Epoch 38/50\n",
      "11275/11275 [==============================] - 2s 189us/step - loss: 0.0802 - acc: 0.9768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "11275/11275 [==============================] - 2s 187us/step - loss: 0.0802 - acc: 0.9770\n",
      "Epoch 40/50\n",
      "11275/11275 [==============================] - 2s 174us/step - loss: 0.0776 - acc: 0.9775\n",
      "Epoch 41/50\n",
      "11275/11275 [==============================] - 2s 190us/step - loss: 0.0794 - acc: 0.9766\n",
      "Epoch 42/50\n",
      "11275/11275 [==============================] - 3s 264us/step - loss: 0.0794 - acc: 0.9765\n",
      "Epoch 43/50\n",
      "11275/11275 [==============================] - 2s 197us/step - loss: 0.0787 - acc: 0.9769\n",
      "Epoch 44/50\n",
      "11275/11275 [==============================] - 2s 171us/step - loss: 0.0786 - acc: 0.9782\n",
      "Epoch 45/50\n",
      "11275/11275 [==============================] - 2s 175us/step - loss: 0.0776 - acc: 0.9776\n",
      "Epoch 46/50\n",
      "11275/11275 [==============================] - 2s 172us/step - loss: 0.0794 - acc: 0.9779\n",
      "Epoch 47/50\n",
      "11275/11275 [==============================] - 2s 173us/step - loss: 0.0788 - acc: 0.9764\n",
      "Epoch 48/50\n",
      "11275/11275 [==============================] - 2s 174us/step - loss: 0.0773 - acc: 0.9778\n",
      "Epoch 49/50\n",
      "11275/11275 [==============================] - 2s 174us/step - loss: 0.0778 - acc: 0.9777\n",
      "Epoch 50/50\n",
      "11275/11275 [==============================] - 2s 180us/step - loss: 0.0763 - acc: 0.9780\n",
      "1253/1253 [==============================] - 0s 103us/step\n",
      "Epoch 1/50\n",
      "11275/11275 [==============================] - 3s 309us/step - loss: 0.1344 - acc: 0.9644\n",
      "Epoch 2/50\n",
      "11275/11275 [==============================] - 2s 193us/step - loss: 0.0987 - acc: 0.9729\n",
      "Epoch 3/50\n",
      "11275/11275 [==============================] - 2s 174us/step - loss: 0.0947 - acc: 0.9737\n",
      "Epoch 4/50\n",
      "11275/11275 [==============================] - 2s 176us/step - loss: 0.0904 - acc: 0.9741\n",
      "Epoch 5/50\n",
      "11275/11275 [==============================] - 2s 171us/step - loss: 0.0899 - acc: 0.9738\n",
      "Epoch 6/50\n",
      "11275/11275 [==============================] - 2s 178us/step - loss: 0.0883 - acc: 0.9742\n",
      "Epoch 7/50\n",
      "11275/11275 [==============================] - 2s 176us/step - loss: 0.0902 - acc: 0.9737\n",
      "Epoch 8/50\n",
      "11275/11275 [==============================] - 2s 173us/step - loss: 0.0882 - acc: 0.9741\n",
      "Epoch 9/50\n",
      "11275/11275 [==============================] - 2s 183us/step - loss: 0.0863 - acc: 0.9745\n",
      "Epoch 10/50\n",
      "11275/11275 [==============================] - 3s 285us/step - loss: 0.0876 - acc: 0.9749\n",
      "Epoch 11/50\n",
      "11275/11275 [==============================] - 3s 235us/step - loss: 0.0871 - acc: 0.9746\n",
      "Epoch 12/50\n",
      "11275/11275 [==============================] - 3s 241us/step - loss: 0.0858 - acc: 0.9755\n",
      "Epoch 13/50\n",
      "11275/11275 [==============================] - 2s 216us/step - loss: 0.0867 - acc: 0.9751\n",
      "Epoch 14/50\n",
      "11275/11275 [==============================] - 2s 200us/step - loss: 0.0874 - acc: 0.9744\n",
      "Epoch 15/50\n",
      "11275/11275 [==============================] - 3s 269us/step - loss: 0.0844 - acc: 0.9753\n",
      "Epoch 16/50\n",
      "11275/11275 [==============================] - 5s 405us/step - loss: 0.0854 - acc: 0.9755\n",
      "Epoch 17/50\n",
      "11275/11275 [==============================] - 3s 273us/step - loss: 0.0844 - acc: 0.9752\n",
      "Epoch 18/50\n",
      "11275/11275 [==============================] - 2s 192us/step - loss: 0.0838 - acc: 0.9755\n",
      "Epoch 19/50\n",
      "11275/11275 [==============================] - 2s 176us/step - loss: 0.0847 - acc: 0.9745\n",
      "Epoch 20/50\n",
      "11275/11275 [==============================] - 2s 178us/step - loss: 0.0839 - acc: 0.9753\n",
      "Epoch 21/50\n",
      "11275/11275 [==============================] - 2s 174us/step - loss: 0.0839 - acc: 0.9754\n",
      "Epoch 22/50\n",
      "11275/11275 [==============================] - 2s 171us/step - loss: 0.0827 - acc: 0.9761\n",
      "Epoch 23/50\n",
      "11275/11275 [==============================] - 2s 169us/step - loss: 0.0834 - acc: 0.9753\n",
      "Epoch 24/50\n",
      "11275/11275 [==============================] - 2s 177us/step - loss: 0.0831 - acc: 0.9754\n",
      "Epoch 25/50\n",
      "11275/11275 [==============================] - 2s 178us/step - loss: 0.0835 - acc: 0.9758\n",
      "Epoch 26/50\n",
      "11275/11275 [==============================] - 2s 170us/step - loss: 0.0815 - acc: 0.9758\n",
      "Epoch 27/50\n",
      "11275/11275 [==============================] - 2s 173us/step - loss: 0.0816 - acc: 0.9762\n",
      "Epoch 28/50\n",
      "11275/11275 [==============================] - 2s 172us/step - loss: 0.0823 - acc: 0.9757\n",
      "Epoch 29/50\n",
      "11275/11275 [==============================] - 2s 172us/step - loss: 0.0821 - acc: 0.9754\n",
      "Epoch 30/50\n",
      "11275/11275 [==============================] - 2s 174us/step - loss: 0.0816 - acc: 0.9753\n",
      "Epoch 31/50\n",
      "11275/11275 [==============================] - 2s 166us/step - loss: 0.0823 - acc: 0.9761\n",
      "Epoch 32/50\n",
      "11275/11275 [==============================] - 2s 168us/step - loss: 0.0809 - acc: 0.9757\n",
      "Epoch 33/50\n",
      "11275/11275 [==============================] - 2s 170us/step - loss: 0.0807 - acc: 0.9758\n",
      "Epoch 34/50\n",
      "11275/11275 [==============================] - 2s 171us/step - loss: 0.0811 - acc: 0.9758\n",
      "Epoch 35/50\n",
      "11275/11275 [==============================] - 2s 174us/step - loss: 0.0814 - acc: 0.9764\n",
      "Epoch 36/50\n",
      "11275/11275 [==============================] - 2s 171us/step - loss: 0.0797 - acc: 0.9761\n",
      "Epoch 37/50\n",
      "11275/11275 [==============================] - 2s 170us/step - loss: 0.0805 - acc: 0.9764\n",
      "Epoch 38/50\n",
      "11275/11275 [==============================] - 2s 172us/step - loss: 0.0805 - acc: 0.9764\n",
      "Epoch 39/50\n",
      "11275/11275 [==============================] - 2s 172us/step - loss: 0.0804 - acc: 0.9760\n",
      "Epoch 40/50\n",
      "11275/11275 [==============================] - 2s 169us/step - loss: 0.0809 - acc: 0.9759\n",
      "Epoch 41/50\n",
      "11275/11275 [==============================] - 2s 170us/step - loss: 0.0804 - acc: 0.9761\n",
      "Epoch 42/50\n",
      "11275/11275 [==============================] - 2s 170us/step - loss: 0.0802 - acc: 0.9763\n",
      "Epoch 43/50\n",
      "11275/11275 [==============================] - 2s 175us/step - loss: 0.0802 - acc: 0.9761\n",
      "Epoch 44/50\n",
      "11275/11275 [==============================] - 2s 196us/step - loss: 0.0789 - acc: 0.9764\n",
      "Epoch 45/50\n",
      "11275/11275 [==============================] - 2s 187us/step - loss: 0.0797 - acc: 0.9765\n",
      "Epoch 46/50\n",
      "11275/11275 [==============================] - 2s 190us/step - loss: 0.0793 - acc: 0.9769\n",
      "Epoch 47/50\n",
      "11275/11275 [==============================] - 2s 186us/step - loss: 0.0791 - acc: 0.9755\n",
      "Epoch 48/50\n",
      "11275/11275 [==============================] - 2s 172us/step - loss: 0.0786 - acc: 0.9767\n",
      "Epoch 49/50\n",
      "11275/11275 [==============================] - 2s 170us/step - loss: 0.0789 - acc: 0.9762\n",
      "Epoch 50/50\n",
      "11275/11275 [==============================] - 2s 170us/step - loss: 0.0788 - acc: 0.9766\n",
      "1253/1253 [==============================] - 0s 101us/step\n",
      "Epoch 1/50\n",
      "11275/11275 [==============================] - 2s 208us/step - loss: 0.1599 - acc: 0.9654\n",
      "Epoch 2/50\n",
      "11275/11275 [==============================] - 2s 170us/step - loss: 0.0969 - acc: 0.9744\n",
      "Epoch 3/50\n",
      "11275/11275 [==============================] - 2s 169us/step - loss: 0.0882 - acc: 0.9745\n",
      "Epoch 4/50\n",
      "11275/11275 [==============================] - 2s 171us/step - loss: 0.0884 - acc: 0.9752\n",
      "Epoch 5/50\n",
      "11275/11275 [==============================] - 2s 177us/step - loss: 0.0863 - acc: 0.9744\n",
      "Epoch 6/50\n",
      "11275/11275 [==============================] - 2s 170us/step - loss: 0.0878 - acc: 0.9750\n",
      "Epoch 7/50\n",
      "11275/11275 [==============================] - 2s 172us/step - loss: 0.0853 - acc: 0.9762\n",
      "Epoch 8/50\n",
      "11275/11275 [==============================] - 2s 171us/step - loss: 0.0847 - acc: 0.9760\n",
      "Epoch 9/50\n",
      "11275/11275 [==============================] - 2s 174us/step - loss: 0.0828 - acc: 0.9753\n",
      "Epoch 10/50\n",
      "11275/11275 [==============================] - 2s 173us/step - loss: 0.0833 - acc: 0.9752\n",
      "Epoch 11/50\n",
      "11275/11275 [==============================] - 2s 174us/step - loss: 0.0825 - acc: 0.9760\n",
      "Epoch 12/50\n",
      "11275/11275 [==============================] - 2s 177us/step - loss: 0.0822 - acc: 0.9754\n",
      "Epoch 13/50\n",
      "11275/11275 [==============================] - 2s 178us/step - loss: 0.0826 - acc: 0.9758\n",
      "Epoch 14/50\n",
      "11275/11275 [==============================] - 2s 167us/step - loss: 0.0836 - acc: 0.9755\n",
      "Epoch 15/50\n",
      "11275/11275 [==============================] - 2s 172us/step - loss: 0.0804 - acc: 0.9757\n",
      "Epoch 16/50\n",
      "11275/11275 [==============================] - 2s 169us/step - loss: 0.0797 - acc: 0.9765\n",
      "Epoch 17/50\n",
      "11275/11275 [==============================] - 2s 170us/step - loss: 0.0821 - acc: 0.9762\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11275/11275 [==============================] - 2s 172us/step - loss: 0.0808 - acc: 0.9764\n",
      "Epoch 19/50\n",
      "11275/11275 [==============================] - 2s 171us/step - loss: 0.0812 - acc: 0.9757\n",
      "Epoch 20/50\n",
      "11275/11275 [==============================] - 2s 174us/step - loss: 0.0797 - acc: 0.9770\n",
      "Epoch 21/50\n",
      "11275/11275 [==============================] - 2s 172us/step - loss: 0.0805 - acc: 0.9752\n",
      "Epoch 22/50\n",
      "11275/11275 [==============================] - 2s 174us/step - loss: 0.0812 - acc: 0.9761\n",
      "Epoch 23/50\n",
      "11275/11275 [==============================] - 2s 190us/step - loss: 0.0790 - acc: 0.9761\n",
      "Epoch 24/50\n",
      "11275/11275 [==============================] - 2s 193us/step - loss: 0.0801 - acc: 0.9767\n",
      "Epoch 25/50\n",
      "11275/11275 [==============================] - 2s 192us/step - loss: 0.0801 - acc: 0.9765\n",
      "Epoch 26/50\n",
      "11275/11275 [==============================] - 2s 193us/step - loss: 0.0792 - acc: 0.9772\n",
      "Epoch 27/50\n",
      "11275/11275 [==============================] - 2s 187us/step - loss: 0.0797 - acc: 0.9758\n",
      "Epoch 28/50\n",
      "11275/11275 [==============================] - 2s 172us/step - loss: 0.0779 - acc: 0.9780\n",
      "Epoch 29/50\n",
      "11275/11275 [==============================] - 2s 174us/step - loss: 0.0783 - acc: 0.9760\n",
      "Epoch 30/50\n",
      "11275/11275 [==============================] - 2s 176us/step - loss: 0.0786 - acc: 0.9771\n",
      "Epoch 31/50\n",
      "11275/11275 [==============================] - 2s 175us/step - loss: 0.0787 - acc: 0.9769\n",
      "Epoch 32/50\n",
      "11275/11275 [==============================] - 2s 174us/step - loss: 0.0785 - acc: 0.9770\n",
      "Epoch 33/50\n",
      "11275/11275 [==============================] - 2s 173us/step - loss: 0.0797 - acc: 0.9769\n",
      "Epoch 34/50\n",
      "11275/11275 [==============================] - 2s 172us/step - loss: 0.0790 - acc: 0.9774\n",
      "Epoch 35/50\n",
      "11275/11275 [==============================] - 2s 179us/step - loss: 0.0780 - acc: 0.9769\n",
      "Epoch 36/50\n",
      "11275/11275 [==============================] - 2s 182us/step - loss: 0.0779 - acc: 0.9762\n",
      "Epoch 37/50\n",
      "11275/11275 [==============================] - 2s 176us/step - loss: 0.0780 - acc: 0.9772\n",
      "Epoch 38/50\n",
      "11275/11275 [==============================] - 2s 175us/step - loss: 0.0778 - acc: 0.9765\n",
      "Epoch 39/50\n",
      "11275/11275 [==============================] - 2s 185us/step - loss: 0.0765 - acc: 0.9768\n",
      "Epoch 40/50\n",
      "11275/11275 [==============================] - 2s 173us/step - loss: 0.0776 - acc: 0.9769\n",
      "Epoch 41/50\n",
      "11275/11275 [==============================] - 2s 172us/step - loss: 0.0767 - acc: 0.9770\n",
      "Epoch 42/50\n",
      "11275/11275 [==============================] - 2s 175us/step - loss: 0.0783 - acc: 0.9770\n",
      "Epoch 43/50\n",
      "11275/11275 [==============================] - 2s 175us/step - loss: 0.0769 - acc: 0.9775\n",
      "Epoch 44/50\n",
      "11275/11275 [==============================] - 2s 188us/step - loss: 0.0769 - acc: 0.9774\n",
      "Epoch 45/50\n",
      "11275/11275 [==============================] - 3s 295us/step - loss: 0.0768 - acc: 0.9763\n",
      "Epoch 46/50\n",
      "11275/11275 [==============================] - 4s 315us/step - loss: 0.0760 - acc: 0.9774\n",
      "Epoch 47/50\n",
      "11275/11275 [==============================] - 3s 253us/step - loss: 0.0759 - acc: 0.9778\n",
      "Epoch 48/50\n",
      "11275/11275 [==============================] - 2s 174us/step - loss: 0.0758 - acc: 0.9781\n",
      "Epoch 49/50\n",
      "11275/11275 [==============================] - 2s 171us/step - loss: 0.0747 - acc: 0.9771\n",
      "Epoch 50/50\n",
      "11275/11275 [==============================] - 2s 175us/step - loss: 0.0761 - acc: 0.9769\n",
      "1253/1253 [==============================] - 0s 115us/step\n",
      "Epoch 1/50\n",
      "11275/11275 [==============================] - 4s 339us/step - loss: 0.1429 - acc: 0.9678\n",
      "Epoch 2/50\n",
      "11275/11275 [==============================] - 3s 266us/step - loss: 0.0922 - acc: 0.9736\n",
      "Epoch 3/50\n",
      "11275/11275 [==============================] - 2s 217us/step - loss: 0.0877 - acc: 0.9748\n",
      "Epoch 4/50\n",
      "11275/11275 [==============================] - 3s 262us/step - loss: 0.0855 - acc: 0.9744\n",
      "Epoch 5/50\n",
      "11275/11275 [==============================] - 2s 209us/step - loss: 0.0845 - acc: 0.9753\n",
      "Epoch 6/50\n",
      "11275/11275 [==============================] - 2s 181us/step - loss: 0.0856 - acc: 0.9753\n",
      "Epoch 7/50\n",
      "11275/11275 [==============================] - 2s 177us/step - loss: 0.0862 - acc: 0.9760\n",
      "Epoch 8/50\n",
      "11275/11275 [==============================] - 2s 175us/step - loss: 0.0834 - acc: 0.9762\n",
      "Epoch 9/50\n",
      "11275/11275 [==============================] - 2s 178us/step - loss: 0.0829 - acc: 0.9756\n",
      "Epoch 10/50\n",
      "11275/11275 [==============================] - 2s 174us/step - loss: 0.0824 - acc: 0.9765\n",
      "Epoch 11/50\n",
      "11275/11275 [==============================] - 2s 174us/step - loss: 0.0830 - acc: 0.9755\n",
      "Epoch 12/50\n",
      "11275/11275 [==============================] - 2s 194us/step - loss: 0.0824 - acc: 0.9757\n",
      "Epoch 13/50\n",
      "11275/11275 [==============================] - 3s 269us/step - loss: 0.0822 - acc: 0.9762\n",
      "Epoch 14/50\n",
      "11275/11275 [==============================] - 2s 218us/step - loss: 0.0811 - acc: 0.9756\n",
      "Epoch 15/50\n",
      "11275/11275 [==============================] - 2s 174us/step - loss: 0.0819 - acc: 0.9750\n",
      "Epoch 16/50\n",
      "11275/11275 [==============================] - 2s 173us/step - loss: 0.0816 - acc: 0.9760\n",
      "Epoch 17/50\n",
      "11275/11275 [==============================] - 2s 176us/step - loss: 0.0841 - acc: 0.9747\n",
      "Epoch 18/50\n",
      "11275/11275 [==============================] - 2s 177us/step - loss: 0.0805 - acc: 0.9760\n",
      "Epoch 19/50\n",
      "11275/11275 [==============================] - 2s 180us/step - loss: 0.0814 - acc: 0.9769\n",
      "Epoch 20/50\n",
      "11275/11275 [==============================] - 2s 176us/step - loss: 0.0812 - acc: 0.9764\n",
      "Epoch 21/50\n",
      "11275/11275 [==============================] - 2s 180us/step - loss: 0.0794 - acc: 0.9769\n",
      "Epoch 22/50\n",
      "11275/11275 [==============================] - 3s 231us/step - loss: 0.0806 - acc: 0.9761\n",
      "Epoch 23/50\n",
      "11275/11275 [==============================] - 3s 263us/step - loss: 0.0799 - acc: 0.9765\n",
      "Epoch 24/50\n",
      "11275/11275 [==============================] - 2s 176us/step - loss: 0.0783 - acc: 0.9770\n",
      "Epoch 25/50\n",
      "11275/11275 [==============================] - 2s 176us/step - loss: 0.0796 - acc: 0.9770\n",
      "Epoch 26/50\n",
      "11275/11275 [==============================] - 2s 176us/step - loss: 0.0799 - acc: 0.9760\n",
      "Epoch 27/50\n",
      "11275/11275 [==============================] - 2s 196us/step - loss: 0.0794 - acc: 0.9771\n",
      "Epoch 28/50\n",
      "11275/11275 [==============================] - 2s 183us/step - loss: 0.0780 - acc: 0.9766\n",
      "Epoch 29/50\n",
      "11275/11275 [==============================] - 2s 176us/step - loss: 0.0775 - acc: 0.9777\n",
      "Epoch 30/50\n",
      "11275/11275 [==============================] - 2s 174us/step - loss: 0.0779 - acc: 0.9774\n",
      "Epoch 31/50\n",
      "11275/11275 [==============================] - 3s 222us/step - loss: 0.0786 - acc: 0.9764\n",
      "Epoch 32/50\n",
      "11275/11275 [==============================] - 3s 251us/step - loss: 0.0784 - acc: 0.9775\n",
      "Epoch 33/50\n",
      "11275/11275 [==============================] - 2s 186us/step - loss: 0.0781 - acc: 0.9775\n",
      "Epoch 34/50\n",
      "11275/11275 [==============================] - 2s 177us/step - loss: 0.0762 - acc: 0.9778\n",
      "Epoch 35/50\n",
      "11275/11275 [==============================] - 2s 174us/step - loss: 0.0769 - acc: 0.9778\n",
      "Epoch 36/50\n",
      "11275/11275 [==============================] - 2s 171us/step - loss: 0.0769 - acc: 0.9767\n",
      "Epoch 37/50\n",
      "11275/11275 [==============================] - 2s 176us/step - loss: 0.0775 - acc: 0.9782\n",
      "Epoch 38/50\n",
      "11275/11275 [==============================] - 2s 176us/step - loss: 0.0762 - acc: 0.9780\n",
      "Epoch 39/50\n",
      "11275/11275 [==============================] - 2s 172us/step - loss: 0.0770 - acc: 0.9770\n",
      "Epoch 40/50\n",
      "11275/11275 [==============================] - 2s 198us/step - loss: 0.0763 - acc: 0.9776\n",
      "Epoch 41/50\n",
      "11275/11275 [==============================] - 3s 265us/step - loss: 0.0769 - acc: 0.9773\n",
      "Epoch 42/50\n",
      "11275/11275 [==============================] - 2s 210us/step - loss: 0.0771 - acc: 0.9779\n",
      "Epoch 43/50\n",
      "11275/11275 [==============================] - 2s 177us/step - loss: 0.0756 - acc: 0.9780\n",
      "Epoch 44/50\n",
      "11275/11275 [==============================] - 2s 175us/step - loss: 0.0769 - acc: 0.9778\n",
      "Epoch 45/50\n",
      "11275/11275 [==============================] - 2s 176us/step - loss: 0.0749 - acc: 0.9783\n",
      "Epoch 46/50\n",
      "11275/11275 [==============================] - 2s 175us/step - loss: 0.0760 - acc: 0.9787\n",
      "Epoch 47/50\n",
      "11275/11275 [==============================] - 2s 178us/step - loss: 0.0755 - acc: 0.9774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50\n",
      "11275/11275 [==============================] - 2s 194us/step - loss: 0.0763 - acc: 0.9779\n",
      "Epoch 49/50\n",
      "11275/11275 [==============================] - 2s 187us/step - loss: 0.0766 - acc: 0.9781\n",
      "Epoch 50/50\n",
      "11275/11275 [==============================] - 3s 266us/step - loss: 0.0750 - acc: 0.9775\n",
      "1253/1253 [==============================] - 0s 229us/step\n",
      "Epoch 1/50\n",
      "11276/11276 [==============================] - 3s 284us/step - loss: 0.1379 - acc: 0.9648\n",
      "Epoch 2/50\n",
      "11276/11276 [==============================] - 3s 237us/step - loss: 0.0970 - acc: 0.9734\n",
      "Epoch 3/50\n",
      "11276/11276 [==============================] - 2s 211us/step - loss: 0.0907 - acc: 0.9740\n",
      "Epoch 4/50\n",
      "11276/11276 [==============================] - 2s 204us/step - loss: 0.0900 - acc: 0.9737\n",
      "Epoch 5/50\n",
      "11276/11276 [==============================] - 3s 242us/step - loss: 0.0883 - acc: 0.9752\n",
      "Epoch 6/50\n",
      "11276/11276 [==============================] - 2s 211us/step - loss: 0.0876 - acc: 0.9746\n",
      "Epoch 7/50\n",
      "11276/11276 [==============================] - 2s 191us/step - loss: 0.0867 - acc: 0.9755\n",
      "Epoch 8/50\n",
      "11276/11276 [==============================] - 2s 177us/step - loss: 0.0875 - acc: 0.9740\n",
      "Epoch 9/50\n",
      "11276/11276 [==============================] - 2s 179us/step - loss: 0.0852 - acc: 0.9754\n",
      "Epoch 10/50\n",
      "11276/11276 [==============================] - 2s 172us/step - loss: 0.0855 - acc: 0.9749\n",
      "Epoch 11/50\n",
      "11276/11276 [==============================] - 2s 174us/step - loss: 0.0865 - acc: 0.9747\n",
      "Epoch 12/50\n",
      "11276/11276 [==============================] - 2s 175us/step - loss: 0.0852 - acc: 0.9753\n",
      "Epoch 13/50\n",
      "11276/11276 [==============================] - 2s 173us/step - loss: 0.0848 - acc: 0.9758\n",
      "Epoch 14/50\n",
      "11276/11276 [==============================] - 2s 176us/step - loss: 0.0844 - acc: 0.9753\n",
      "Epoch 15/50\n",
      "11276/11276 [==============================] - 2s 178us/step - loss: 0.0838 - acc: 0.9761\n",
      "Epoch 16/50\n",
      "11276/11276 [==============================] - 2s 187us/step - loss: 0.0850 - acc: 0.9761\n",
      "Epoch 17/50\n",
      "11276/11276 [==============================] - 2s 178us/step - loss: 0.0824 - acc: 0.9756\n",
      "Epoch 18/50\n",
      "11276/11276 [==============================] - 2s 182us/step - loss: 0.0836 - acc: 0.9757\n",
      "Epoch 19/50\n",
      "11276/11276 [==============================] - 2s 178us/step - loss: 0.0848 - acc: 0.9763\n",
      "Epoch 20/50\n",
      "11276/11276 [==============================] - 2s 176us/step - loss: 0.0838 - acc: 0.9762\n",
      "Epoch 21/50\n",
      "11276/11276 [==============================] - 2s 181us/step - loss: 0.0829 - acc: 0.9759\n",
      "Epoch 22/50\n",
      "11276/11276 [==============================] - 2s 178us/step - loss: 0.0821 - acc: 0.9761\n",
      "Epoch 23/50\n",
      "11276/11276 [==============================] - 2s 175us/step - loss: 0.0826 - acc: 0.9758\n",
      "Epoch 24/50\n",
      "11276/11276 [==============================] - 2s 174us/step - loss: 0.0822 - acc: 0.9759\n",
      "Epoch 25/50\n",
      "11276/11276 [==============================] - 2s 172us/step - loss: 0.0815 - acc: 0.9754\n",
      "Epoch 26/50\n",
      "11276/11276 [==============================] - 2s 174us/step - loss: 0.0827 - acc: 0.9761\n",
      "Epoch 27/50\n",
      "11276/11276 [==============================] - 2s 175us/step - loss: 0.0821 - acc: 0.9761\n",
      "Epoch 28/50\n",
      "11276/11276 [==============================] - 2s 174us/step - loss: 0.0815 - acc: 0.9766\n",
      "Epoch 29/50\n",
      "11276/11276 [==============================] - 2s 174us/step - loss: 0.0801 - acc: 0.9770\n",
      "Epoch 30/50\n",
      "11276/11276 [==============================] - 2s 178us/step - loss: 0.0812 - acc: 0.9765\n",
      "Epoch 31/50\n",
      "11276/11276 [==============================] - 2s 172us/step - loss: 0.0822 - acc: 0.9761\n",
      "Epoch 32/50\n",
      "11276/11276 [==============================] - 2s 181us/step - loss: 0.0805 - acc: 0.9769\n",
      "Epoch 33/50\n",
      "11276/11276 [==============================] - 4s 317us/step - loss: 0.0801 - acc: 0.9767\n",
      "Epoch 34/50\n",
      "11276/11276 [==============================] - 3s 305us/step - loss: 0.0808 - acc: 0.9758\n",
      "Epoch 35/50\n",
      "11276/11276 [==============================] - 2s 192us/step - loss: 0.0813 - acc: 0.9761\n",
      "Epoch 36/50\n",
      "11276/11276 [==============================] - 2s 175us/step - loss: 0.0801 - acc: 0.9769\n",
      "Epoch 37/50\n",
      "11276/11276 [==============================] - 2s 172us/step - loss: 0.0802 - acc: 0.9764\n",
      "Epoch 38/50\n",
      "11276/11276 [==============================] - 2s 177us/step - loss: 0.0802 - acc: 0.9761\n",
      "Epoch 39/50\n",
      "11276/11276 [==============================] - 2s 172us/step - loss: 0.0787 - acc: 0.9763\n",
      "Epoch 40/50\n",
      "11276/11276 [==============================] - 2s 175us/step - loss: 0.0784 - acc: 0.9770\n",
      "Epoch 41/50\n",
      "11276/11276 [==============================] - 2s 171us/step - loss: 0.0805 - acc: 0.9761\n",
      "Epoch 42/50\n",
      "11276/11276 [==============================] - 2s 171us/step - loss: 0.0791 - acc: 0.9769\n",
      "Epoch 43/50\n",
      "11276/11276 [==============================] - 2s 175us/step - loss: 0.0792 - acc: 0.9768\n",
      "Epoch 44/50\n",
      "11276/11276 [==============================] - 2s 174us/step - loss: 0.0803 - acc: 0.9760\n",
      "Epoch 45/50\n",
      "11276/11276 [==============================] - 2s 181us/step - loss: 0.0780 - acc: 0.9758\n",
      "Epoch 46/50\n",
      "11276/11276 [==============================] - 2s 175us/step - loss: 0.0781 - acc: 0.9770\n",
      "Epoch 47/50\n",
      "11276/11276 [==============================] - 2s 178us/step - loss: 0.0775 - acc: 0.9770\n",
      "Epoch 48/50\n",
      "11276/11276 [==============================] - 2s 176us/step - loss: 0.0776 - acc: 0.9768\n",
      "Epoch 49/50\n",
      "11276/11276 [==============================] - 2s 175us/step - loss: 0.0782 - acc: 0.9769\n",
      "Epoch 50/50\n",
      "11276/11276 [==============================] - 2s 180us/step - loss: 0.0763 - acc: 0.9767\n",
      "1252/1252 [==============================] - 0s 138us/step\n",
      "Epoch 1/50\n",
      "11276/11276 [==============================] - 3s 223us/step - loss: 0.1587 - acc: 0.9641\n",
      "Epoch 2/50\n",
      "11276/11276 [==============================] - 2s 173us/step - loss: 0.0990 - acc: 0.9736\n",
      "Epoch 3/50\n",
      "11276/11276 [==============================] - 2s 172us/step - loss: 0.0940 - acc: 0.9727\n",
      "Epoch 4/50\n",
      "11276/11276 [==============================] - 2s 172us/step - loss: 0.0905 - acc: 0.9744\n",
      "Epoch 5/50\n",
      "11276/11276 [==============================] - 2s 170us/step - loss: 0.0872 - acc: 0.9750\n",
      "Epoch 6/50\n",
      "11276/11276 [==============================] - 2s 173us/step - loss: 0.0878 - acc: 0.9753\n",
      "Epoch 7/50\n",
      "11276/11276 [==============================] - 2s 172us/step - loss: 0.0874 - acc: 0.9741\n",
      "Epoch 8/50\n",
      "11276/11276 [==============================] - 2s 174us/step - loss: 0.0879 - acc: 0.9756\n",
      "Epoch 9/50\n",
      "11276/11276 [==============================] - 2s 174us/step - loss: 0.0879 - acc: 0.9748\n",
      "Epoch 10/50\n",
      "11276/11276 [==============================] - 2s 181us/step - loss: 0.0875 - acc: 0.9753\n",
      "Epoch 11/50\n",
      "11276/11276 [==============================] - 2s 191us/step - loss: 0.0864 - acc: 0.9753\n",
      "Epoch 12/50\n",
      "11276/11276 [==============================] - 2s 188us/step - loss: 0.0854 - acc: 0.9753\n",
      "Epoch 13/50\n",
      "11276/11276 [==============================] - 2s 197us/step - loss: 0.0857 - acc: 0.9750\n",
      "Epoch 14/50\n",
      "11276/11276 [==============================] - 2s 197us/step - loss: 0.0841 - acc: 0.9760\n",
      "Epoch 15/50\n",
      "11276/11276 [==============================] - 2s 177us/step - loss: 0.0863 - acc: 0.9752\n",
      "Epoch 16/50\n",
      "11276/11276 [==============================] - 2s 176us/step - loss: 0.0859 - acc: 0.9753\n",
      "Epoch 17/50\n",
      "11276/11276 [==============================] - 2s 177us/step - loss: 0.0838 - acc: 0.9754\n",
      "Epoch 18/50\n",
      "11276/11276 [==============================] - 2s 173us/step - loss: 0.0834 - acc: 0.9761\n",
      "Epoch 19/50\n",
      "11276/11276 [==============================] - 2s 173us/step - loss: 0.0831 - acc: 0.9751\n",
      "Epoch 20/50\n",
      "11276/11276 [==============================] - 2s 175us/step - loss: 0.0830 - acc: 0.9758\n",
      "Epoch 21/50\n",
      "11276/11276 [==============================] - 2s 177us/step - loss: 0.0850 - acc: 0.9758\n",
      "Epoch 22/50\n",
      "11276/11276 [==============================] - 2s 175us/step - loss: 0.0826 - acc: 0.9759\n",
      "Epoch 23/50\n",
      "11276/11276 [==============================] - 2s 176us/step - loss: 0.0836 - acc: 0.9757\n",
      "Epoch 24/50\n",
      "11276/11276 [==============================] - 2s 183us/step - loss: 0.0843 - acc: 0.9768\n",
      "Epoch 25/50\n",
      "11276/11276 [==============================] - 2s 174us/step - loss: 0.0838 - acc: 0.9761\n",
      "Epoch 26/50\n",
      "11276/11276 [==============================] - 2s 172us/step - loss: 0.0819 - acc: 0.9765\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11276/11276 [==============================] - 2s 174us/step - loss: 0.0819 - acc: 0.9762\n",
      "Epoch 28/50\n",
      "11276/11276 [==============================] - 2s 170us/step - loss: 0.0815 - acc: 0.9761\n",
      "Epoch 29/50\n",
      "11276/11276 [==============================] - 2s 174us/step - loss: 0.0825 - acc: 0.9761\n",
      "Epoch 30/50\n",
      "11276/11276 [==============================] - 2s 170us/step - loss: 0.0815 - acc: 0.9753\n",
      "Epoch 31/50\n",
      "11276/11276 [==============================] - 2s 173us/step - loss: 0.0810 - acc: 0.9769\n",
      "Epoch 32/50\n",
      "11276/11276 [==============================] - 2s 171us/step - loss: 0.0822 - acc: 0.9762\n",
      "Epoch 33/50\n",
      "11276/11276 [==============================] - 2s 170us/step - loss: 0.0803 - acc: 0.9757\n",
      "Epoch 34/50\n",
      "11276/11276 [==============================] - 2s 167us/step - loss: 0.0808 - acc: 0.9773\n",
      "Epoch 35/50\n",
      "11276/11276 [==============================] - 2s 172us/step - loss: 0.0809 - acc: 0.9764\n",
      "Epoch 36/50\n",
      "11276/11276 [==============================] - 2s 166us/step - loss: 0.0799 - acc: 0.9763\n",
      "Epoch 37/50\n",
      "11276/11276 [==============================] - 2s 169us/step - loss: 0.0819 - acc: 0.9763\n",
      "Epoch 38/50\n",
      "11276/11276 [==============================] - 2s 172us/step - loss: 0.0804 - acc: 0.9770\n",
      "Epoch 39/50\n",
      "11276/11276 [==============================] - 2s 172us/step - loss: 0.0799 - acc: 0.9771\n",
      "Epoch 40/50\n",
      "11276/11276 [==============================] - 2s 175us/step - loss: 0.0796 - acc: 0.9773\n",
      "Epoch 41/50\n",
      "11276/11276 [==============================] - 2s 194us/step - loss: 0.0799 - acc: 0.9766\n",
      "Epoch 42/50\n",
      "11276/11276 [==============================] - 2s 184us/step - loss: 0.0790 - acc: 0.9766\n",
      "Epoch 43/50\n",
      "11276/11276 [==============================] - 2s 201us/step - loss: 0.0777 - acc: 0.9765\n",
      "Epoch 44/50\n",
      "11276/11276 [==============================] - 2s 197us/step - loss: 0.0788 - acc: 0.9769\n",
      "Epoch 45/50\n",
      "11276/11276 [==============================] - 2s 179us/step - loss: 0.0795 - acc: 0.9769\n",
      "Epoch 46/50\n",
      "11276/11276 [==============================] - 2s 179us/step - loss: 0.0796 - acc: 0.9766\n",
      "Epoch 47/50\n",
      "11276/11276 [==============================] - 2s 178us/step - loss: 0.0799 - acc: 0.9774\n",
      "Epoch 48/50\n",
      "11276/11276 [==============================] - 2s 177us/step - loss: 0.0803 - acc: 0.9761\n",
      "Epoch 49/50\n",
      "11276/11276 [==============================] - 2s 173us/step - loss: 0.0789 - acc: 0.9773\n",
      "Epoch 50/50\n",
      "11276/11276 [==============================] - 2s 175us/step - loss: 0.0779 - acc: 0.9765\n",
      "1252/1252 [==============================] - 0s 145us/step\n",
      "Accuracy mean: 0.975494978187\n",
      "Accuracy variance: 0.00615114104107\n",
      "(' Time ', '1062.3', ' seconds')\n",
      "[[4895   31]\n",
      " [  73  371]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.99      0.99      4926\n",
      "        1.0       0.92      0.84      0.88       444\n",
      "\n",
      "avg / total       0.98      0.98      0.98      5370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# estimators \n",
    "# Evaluating the ANN\n",
    "t0 = time()\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 1024, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n",
    "    classifier.add(Dense(units = 512, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 50)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of DecisionTreeClassifier = 96.759777 %\n",
      "(' Time ', '0.116', ' seconds')\n",
      "[[4833   93]\n",
      " [  81  363]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.98      0.98      4926\n",
      "        1.0       0.80      0.82      0.81       444\n",
      "\n",
      "avg / total       0.97      0.97      0.97      5370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of DecisionTreeClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of RandomForestClassifier = 98.100559 %\n",
      "(' Time ', '2.389', ' seconds')\n",
      "[[4896   30]\n",
      " [  72  372]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.99      0.99      4926\n",
      "        1.0       0.93      0.84      0.88       444\n",
      "\n",
      "avg / total       0.98      0.98      0.98      5370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of RandomForestClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of ExtraTreesClassifier = 98.063315 %\n",
      "(' Time ', '0.858', ' seconds')\n",
      "[[4898   28]\n",
      " [  76  368]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.99      0.99      4926\n",
      "        1.0       0.93      0.83      0.88       444\n",
      "\n",
      "avg / total       0.98      0.98      0.98      5370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of ExtraTreesClassifier = {:.6f} %\".format(acc * 100))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of AdaBoostClassifier = 97.802607 %\n",
      "(' Time ', '1.79', ' seconds')\n",
      "[[4892   34]\n",
      " [  84  360]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.99      0.99      4926\n",
      "        1.0       0.91      0.81      0.86       444\n",
      "\n",
      "avg / total       0.98      0.98      0.98      5370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of AdaBoostClassifier = {:.6f} %\".format(acc * 100))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Naive_bayes  GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GaussianNB = 94.897579 %\n",
      "(' Time ', '0.007', ' seconds')\n",
      "[[4718  208]\n",
      " [  66  378]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.96      0.97      4926\n",
      "        1.0       0.65      0.85      0.73       444\n",
      "\n",
      "avg / total       0.96      0.95      0.95      5370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred= gnb.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of GaussianNB = {:.6f} %\".format(acc * 100))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
