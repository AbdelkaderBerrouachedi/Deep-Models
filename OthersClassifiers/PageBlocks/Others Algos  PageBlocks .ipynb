{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt \n",
    "from pprint import pprint\n",
    "from numpy import array\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>att1</th>\n",
       "      <th>att2</th>\n",
       "      <th>att3</th>\n",
       "      <th>att4</th>\n",
       "      <th>att5</th>\n",
       "      <th>att6</th>\n",
       "      <th>att7</th>\n",
       "      <th>att8</th>\n",
       "      <th>att9</th>\n",
       "      <th>att10</th>\n",
       "      <th>outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.400</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.657</td>\n",
       "      <td>2.33</td>\n",
       "      <td>14.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.167</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.881</td>\n",
       "      <td>3.60</td>\n",
       "      <td>18.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.741</td>\n",
       "      <td>4.43</td>\n",
       "      <td>31.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.400</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.743</td>\n",
       "      <td>4.33</td>\n",
       "      <td>13.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.944</td>\n",
       "      <td>2.25</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   att1  att2   att3   att4   att5   att6  att7  att8  att9  att10  outlier\n",
       "0   5.0   7.0   35.0  1.400  0.400  0.657  2.33  14.0  23.0    6.0        0\n",
       "1   6.0   7.0   42.0  1.167  0.429  0.881  3.60  18.0  37.0    5.0        0\n",
       "2   6.0  18.0  108.0  3.000  0.287  0.741  4.43  31.0  80.0    7.0        0\n",
       "3   5.0   7.0   35.0  1.400  0.371  0.743  4.33  13.0  26.0    3.0        0\n",
       "4   6.0   3.0   18.0  0.500  0.500  0.944  2.25   9.0  17.0    4.0        0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df=pd.read_csv('PageBlocks_withoutdupl_02_v02.csv')  \n",
    "\n",
    "del df['id']\n",
    "del df['Unnamed: 0']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4982, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df to values\n",
    "df = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GC Forest\n",
    "import argparse\n",
    "import sys\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "sys.path.insert(0, \"lib\")\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.utils.config_utils import load_json\n",
    "config = load_json(\"./examples/PageBlocks.json\")   \n",
    "gc = GCForest(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# train test \n",
    "from sklearn.cross_validation import train_test_split\n",
    "y = df[:,10]\n",
    "X = df[:,0:10]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of class\n",
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:11:04,111][cascade_classifier.fit_transform] X_groups_train.shape=[(3487, 10)],y_train.shape=(3487,),X_groups_test.shape=[(1495, 10)],y_test.shape=(1495,)\n",
      "[ 2018-07-31 22:11:04,114][cascade_classifier.fit_transform] group_dims=[10]\n",
      "[ 2018-07-31 22:11:04,115][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-31 22:11:04,117][cascade_classifier.fit_transform] group_ends=[10]\n",
      "[ 2018-07-31 22:11:04,118][cascade_classifier.fit_transform] X_train.shape=(3487, 10),X_test.shape=(1495, 10)\n",
      "[ 2018-07-31 22:11:04,119][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(3487, 10), X_cur_test.shape=(1495, 10)\n",
      "[ 2018-07-31 22:11:05,015][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=99.43%\n",
      "[ 2018-07-31 22:11:06,193][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=99.14%\n",
      "[ 2018-07-31 22:11:07,276][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=99.43%\n",
      "[ 2018-07-31 22:11:08,336][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=98.28%\n",
      "[ 2018-07-31 22:11:09,360][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=98.85%\n",
      "[ 2018-07-31 22:11:10,503][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=97.70%\n",
      "[ 2018-07-31 22:11:11,604][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=98.85%\n",
      "[ 2018-07-31 22:11:12,677][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=98.85%\n",
      "[ 2018-07-31 22:11:13,726][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=98.85%\n",
      "[ 2018-07-31 22:11:14,827][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=98.85%\n",
      "[ 2018-07-31 22:11:15,083][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=98.82%\n",
      "[ 2018-07-31 22:11:15,084][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=99.13%\n",
      "[ 2018-07-31 22:11:15,929][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_0.predict)=99.43%\n",
      "[ 2018-07-31 22:11:16,970][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_1.predict)=98.29%\n",
      "[ 2018-07-31 22:11:17,987][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_2.predict)=98.85%\n",
      "[ 2018-07-31 22:11:19,083][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_3.predict)=98.85%\n",
      "[ 2018-07-31 22:11:20,163][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_4.predict)=98.57%\n",
      "[ 2018-07-31 22:11:21,231][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_5.predict)=98.56%\n",
      "[ 2018-07-31 22:11:22,310][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_6.predict)=98.28%\n",
      "[ 2018-07-31 22:11:23,434][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_7.predict)=99.14%\n",
      "[ 2018-07-31 22:11:24,462][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_8.predict)=97.99%\n",
      "[ 2018-07-31 22:11:25,582][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_9.predict)=98.56%\n",
      "[ 2018-07-31 22:11:25,835][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_cv.predict)=98.65%\n",
      "[ 2018-07-31 22:11:25,837][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.test.predict)=99.20%\n",
      "[ 2018-07-31 22:11:26,021][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_0.predict)=98.29%\n",
      "[ 2018-07-31 22:11:26,145][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_1.predict)=98.29%\n",
      "[ 2018-07-31 22:11:26,278][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_2.predict)=97.71%\n",
      "[ 2018-07-31 22:11:26,405][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_3.predict)=97.13%\n",
      "[ 2018-07-31 22:11:26,541][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_4.predict)=97.99%\n",
      "[ 2018-07-31 22:11:26,680][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_5.predict)=97.99%\n",
      "[ 2018-07-31 22:11:26,817][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_6.predict)=98.28%\n",
      "[ 2018-07-31 22:11:26,944][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_7.predict)=96.84%\n",
      "[ 2018-07-31 22:11:27,097][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_8.predict)=97.99%\n",
      "[ 2018-07-31 22:11:27,227][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_9.predict)=98.28%\n",
      "[ 2018-07-31 22:11:27,229][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_cv.predict)=97.88%\n",
      "[ 2018-07-31 22:11:27,234][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.test.predict)=98.33%\n",
      "[ 2018-07-31 22:11:27,236][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=98.45%\n",
      "[ 2018-07-31 22:11:27,237][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=98.80%\n",
      "[ 2018-07-31 22:11:27,239][cascade_classifier.fit_transform] [layer=1] look_indexs=[0], X_cur_train.shape=(3487, 16), X_cur_test.shape=(1495, 16)\n",
      "[ 2018-07-31 22:11:28,073][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_0.predict)=98.57%\n",
      "[ 2018-07-31 22:11:29,158][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_1.predict)=98.86%\n",
      "[ 2018-07-31 22:11:30,361][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_2.predict)=98.85%\n",
      "[ 2018-07-31 22:11:31,534][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_3.predict)=98.28%\n",
      "[ 2018-07-31 22:11:32,628][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_4.predict)=99.43%\n",
      "[ 2018-07-31 22:11:33,745][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_5.predict)=99.43%\n",
      "[ 2018-07-31 22:11:34,874][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_6.predict)=99.14%\n",
      "[ 2018-07-31 22:11:35,938][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_7.predict)=99.14%\n",
      "[ 2018-07-31 22:11:37,245][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_8.predict)=98.85%\n",
      "[ 2018-07-31 22:11:38,474][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_9.predict)=99.14%\n",
      "[ 2018-07-31 22:11:38,685][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_cv.predict)=98.97%\n",
      "[ 2018-07-31 22:11:38,686][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.test.predict)=98.53%\n",
      "[ 2018-07-31 22:11:39,605][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_0.predict)=99.14%\n",
      "[ 2018-07-31 22:11:40,716][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_1.predict)=98.00%\n",
      "[ 2018-07-31 22:11:42,192][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_2.predict)=99.14%\n",
      "[ 2018-07-31 22:11:43,283][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_3.predict)=98.28%\n",
      "[ 2018-07-31 22:11:44,386][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_4.predict)=98.57%\n",
      "[ 2018-07-31 22:11:45,461][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_5.predict)=98.56%\n",
      "[ 2018-07-31 22:11:46,586][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_6.predict)=99.14%\n",
      "[ 2018-07-31 22:11:47,670][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_7.predict)=99.14%\n",
      "[ 2018-07-31 22:11:48,805][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_8.predict)=98.56%\n",
      "[ 2018-07-31 22:11:49,912][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_9.predict)=99.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:11:50,143][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_cv.predict)=98.77%\n",
      "[ 2018-07-31 22:11:50,144][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.test.predict)=98.73%\n",
      "[ 2018-07-31 22:11:50,318][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_0.predict)=98.00%\n",
      "[ 2018-07-31 22:11:50,524][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_1.predict)=97.71%\n",
      "[ 2018-07-31 22:11:50,776][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_2.predict)=98.28%\n",
      "[ 2018-07-31 22:11:50,987][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_3.predict)=98.28%\n",
      "[ 2018-07-31 22:11:51,229][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_4.predict)=98.28%\n",
      "[ 2018-07-31 22:11:51,485][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_5.predict)=97.99%\n",
      "[ 2018-07-31 22:11:51,747][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_6.predict)=97.99%\n",
      "[ 2018-07-31 22:11:51,986][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_7.predict)=97.70%\n",
      "[ 2018-07-31 22:11:52,216][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_8.predict)=98.28%\n",
      "[ 2018-07-31 22:11:52,410][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_9.predict)=97.70%\n",
      "[ 2018-07-31 22:11:52,417][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_cv.predict)=98.02%\n",
      "[ 2018-07-31 22:11:52,426][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.test.predict)=98.39%\n",
      "[ 2018-07-31 22:11:52,431][cascade_classifier.calc_accuracy] Accuracy(layer_1 - train.classifier_average)=98.62%\n",
      "[ 2018-07-31 22:11:52,435][cascade_classifier.calc_accuracy] Accuracy(layer_1 - test.classifier_average)=98.73%\n",
      "[ 2018-07-31 22:11:52,436][cascade_classifier.fit_transform] [layer=2] look_indexs=[0], X_cur_train.shape=(3487, 16), X_cur_test.shape=(1495, 16)\n",
      "[ 2018-07-31 22:11:53,364][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_0.predict)=99.14%\n",
      "[ 2018-07-31 22:11:54,503][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_1.predict)=97.71%\n",
      "[ 2018-07-31 22:11:55,586][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_2.predict)=98.28%\n",
      "[ 2018-07-31 22:11:56,916][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_3.predict)=98.57%\n",
      "[ 2018-07-31 22:11:58,041][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_4.predict)=98.57%\n",
      "[ 2018-07-31 22:11:59,144][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_5.predict)=98.85%\n",
      "[ 2018-07-31 22:12:00,262][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_6.predict)=98.28%\n",
      "[ 2018-07-31 22:12:01,443][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_7.predict)=99.43%\n",
      "[ 2018-07-31 22:12:02,809][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_8.predict)=99.14%\n",
      "[ 2018-07-31 22:12:04,528][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_9.predict)=98.56%\n",
      "[ 2018-07-31 22:12:04,771][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_cv.predict)=98.65%\n",
      "[ 2018-07-31 22:12:04,773][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.test.predict)=98.66%\n",
      "[ 2018-07-31 22:12:05,858][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_0.predict)=98.29%\n",
      "[ 2018-07-31 22:12:07,518][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_1.predict)=98.57%\n",
      "[ 2018-07-31 22:12:09,263][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_2.predict)=98.57%\n",
      "[ 2018-07-31 22:12:10,781][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_3.predict)=98.28%\n",
      "[ 2018-07-31 22:12:12,571][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_4.predict)=98.85%\n",
      "[ 2018-07-31 22:12:14,229][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_5.predict)=99.14%\n",
      "[ 2018-07-31 22:12:15,512][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_6.predict)=98.56%\n",
      "[ 2018-07-31 22:12:16,826][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_7.predict)=99.14%\n",
      "[ 2018-07-31 22:12:18,175][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_8.predict)=97.99%\n",
      "[ 2018-07-31 22:12:19,367][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_9.predict)=99.14%\n",
      "[ 2018-07-31 22:12:19,589][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_cv.predict)=98.65%\n",
      "[ 2018-07-31 22:12:19,590][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.test.predict)=98.33%\n",
      "[ 2018-07-31 22:12:19,811][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_0.predict)=98.86%\n",
      "[ 2018-07-31 22:12:20,157][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_1.predict)=97.71%\n",
      "[ 2018-07-31 22:12:20,453][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_2.predict)=98.57%\n",
      "[ 2018-07-31 22:12:20,772][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_3.predict)=98.57%\n",
      "[ 2018-07-31 22:12:21,110][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_4.predict)=98.85%\n",
      "[ 2018-07-31 22:12:21,360][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_5.predict)=96.84%\n",
      "[ 2018-07-31 22:12:21,570][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_6.predict)=97.99%\n",
      "[ 2018-07-31 22:12:21,865][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_7.predict)=97.99%\n",
      "[ 2018-07-31 22:12:22,145][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_8.predict)=97.70%\n",
      "[ 2018-07-31 22:12:22,419][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_9.predict)=98.28%\n",
      "[ 2018-07-31 22:12:22,425][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_cv.predict)=98.14%\n",
      "[ 2018-07-31 22:12:22,429][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.test.predict)=98.46%\n",
      "[ 2018-07-31 22:12:22,433][cascade_classifier.calc_accuracy] Accuracy(layer_2 - train.classifier_average)=98.71%\n",
      "[ 2018-07-31 22:12:22,437][cascade_classifier.calc_accuracy] Accuracy(layer_2 - test.classifier_average)=98.80%\n",
      "[ 2018-07-31 22:12:22,441][cascade_classifier.fit_transform] [layer=3] look_indexs=[0], X_cur_train.shape=(3487, 16), X_cur_test.shape=(1495, 16)\n",
      "[ 2018-07-31 22:12:23,523][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_0.predict)=98.86%\n",
      "[ 2018-07-31 22:12:24,916][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_1.predict)=98.57%\n",
      "[ 2018-07-31 22:12:26,183][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_2.predict)=98.28%\n",
      "[ 2018-07-31 22:12:27,578][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_3.predict)=99.14%\n",
      "[ 2018-07-31 22:12:28,926][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_4.predict)=98.85%\n",
      "[ 2018-07-31 22:12:30,276][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_5.predict)=97.99%\n",
      "[ 2018-07-31 22:12:31,828][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_6.predict)=98.56%\n",
      "[ 2018-07-31 22:12:33,130][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_7.predict)=98.56%\n",
      "[ 2018-07-31 22:12:34,288][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_8.predict)=98.28%\n",
      "[ 2018-07-31 22:12:35,413][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_9.predict)=99.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:12:35,672][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_cv.predict)=98.62%\n",
      "[ 2018-07-31 22:12:35,673][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.test.predict)=98.46%\n",
      "[ 2018-07-31 22:12:36,850][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_0.predict)=98.86%\n",
      "[ 2018-07-31 22:12:38,260][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_1.predict)=98.29%\n",
      "[ 2018-07-31 22:12:39,969][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_2.predict)=98.85%\n",
      "[ 2018-07-31 22:12:41,413][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_3.predict)=99.14%\n",
      "[ 2018-07-31 22:12:42,829][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_4.predict)=98.57%\n",
      "[ 2018-07-31 22:12:44,428][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_5.predict)=98.28%\n",
      "[ 2018-07-31 22:12:45,782][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_6.predict)=99.43%\n",
      "[ 2018-07-31 22:12:47,235][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_7.predict)=97.70%\n",
      "[ 2018-07-31 22:12:48,346][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_8.predict)=98.28%\n",
      "[ 2018-07-31 22:12:49,526][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_9.predict)=98.85%\n",
      "[ 2018-07-31 22:12:49,745][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_cv.predict)=98.62%\n",
      "[ 2018-07-31 22:12:49,747][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.test.predict)=98.46%\n",
      "[ 2018-07-31 22:12:50,023][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_0.predict)=98.00%\n",
      "[ 2018-07-31 22:12:50,373][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_1.predict)=97.71%\n",
      "[ 2018-07-31 22:12:50,672][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_2.predict)=97.71%\n",
      "[ 2018-07-31 22:12:51,024][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_3.predict)=97.71%\n",
      "[ 2018-07-31 22:12:51,424][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_4.predict)=97.99%\n",
      "[ 2018-07-31 22:12:51,750][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_5.predict)=97.99%\n",
      "[ 2018-07-31 22:12:52,038][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_6.predict)=97.41%\n",
      "[ 2018-07-31 22:12:52,386][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_7.predict)=98.56%\n",
      "[ 2018-07-31 22:12:52,703][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_8.predict)=98.28%\n",
      "[ 2018-07-31 22:12:53,040][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_9.predict)=97.99%\n",
      "[ 2018-07-31 22:12:53,057][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_cv.predict)=97.94%\n",
      "[ 2018-07-31 22:12:53,061][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.test.predict)=98.39%\n",
      "[ 2018-07-31 22:12:53,065][cascade_classifier.calc_accuracy] Accuracy(layer_3 - train.classifier_average)=98.65%\n",
      "[ 2018-07-31 22:12:53,066][cascade_classifier.calc_accuracy] Accuracy(layer_3 - test.classifier_average)=98.86%\n",
      "[ 2018-07-31 22:12:53,068][cascade_classifier.fit_transform] [layer=4] look_indexs=[0], X_cur_train.shape=(3487, 16), X_cur_test.shape=(1495, 16)\n",
      "[ 2018-07-31 22:12:54,345][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_0.predict)=99.14%\n",
      "[ 2018-07-31 22:12:55,773][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_1.predict)=97.71%\n",
      "[ 2018-07-31 22:12:57,073][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_2.predict)=98.85%\n",
      "[ 2018-07-31 22:12:58,545][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_3.predict)=99.43%\n",
      "[ 2018-07-31 22:12:59,807][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_4.predict)=98.28%\n",
      "[ 2018-07-31 22:13:01,134][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_5.predict)=98.56%\n",
      "[ 2018-07-31 22:13:02,368][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_6.predict)=98.56%\n",
      "[ 2018-07-31 22:13:03,832][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_7.predict)=98.28%\n",
      "[ 2018-07-31 22:13:05,242][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_8.predict)=98.85%\n",
      "[ 2018-07-31 22:13:06,714][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_9.predict)=98.28%\n",
      "[ 2018-07-31 22:13:06,926][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_cv.predict)=98.59%\n",
      "[ 2018-07-31 22:13:06,928][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.test.predict)=98.60%\n",
      "[ 2018-07-31 22:13:08,064][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_0.predict)=98.86%\n",
      "[ 2018-07-31 22:13:09,473][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_1.predict)=99.43%\n",
      "[ 2018-07-31 22:13:10,813][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_2.predict)=98.85%\n",
      "[ 2018-07-31 22:13:12,020][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_3.predict)=97.99%\n",
      "[ 2018-07-31 22:13:13,473][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_4.predict)=97.13%\n",
      "[ 2018-07-31 22:13:14,687][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_5.predict)=97.99%\n",
      "[ 2018-07-31 22:13:16,033][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_6.predict)=98.85%\n",
      "[ 2018-07-31 22:13:17,261][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_7.predict)=98.85%\n",
      "[ 2018-07-31 22:13:18,575][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_8.predict)=98.56%\n",
      "[ 2018-07-31 22:13:20,143][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_9.predict)=97.70%\n",
      "[ 2018-07-31 22:13:20,380][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_cv.predict)=98.42%\n",
      "[ 2018-07-31 22:13:20,382][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.test.predict)=98.53%\n",
      "[ 2018-07-31 22:13:20,613][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_0.predict)=97.43%\n",
      "[ 2018-07-31 22:13:20,919][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_1.predict)=98.57%\n",
      "[ 2018-07-31 22:13:21,226][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_2.predict)=98.28%\n",
      "[ 2018-07-31 22:13:21,491][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_3.predict)=97.99%\n",
      "[ 2018-07-31 22:13:21,888][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_4.predict)=97.71%\n",
      "[ 2018-07-31 22:13:22,316][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_5.predict)=97.99%\n",
      "[ 2018-07-31 22:13:22,708][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_6.predict)=98.28%\n",
      "[ 2018-07-31 22:13:23,106][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_7.predict)=98.28%\n",
      "[ 2018-07-31 22:13:23,382][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_8.predict)=97.70%\n",
      "[ 2018-07-31 22:13:23,610][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_9.predict)=98.56%\n",
      "[ 2018-07-31 22:13:23,662][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_cv.predict)=98.08%\n",
      "[ 2018-07-31 22:13:23,672][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.test.predict)=98.39%\n",
      "[ 2018-07-31 22:13:23,676][cascade_classifier.calc_accuracy] Accuracy(layer_4 - train.classifier_average)=98.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:13:23,680][cascade_classifier.calc_accuracy] Accuracy(layer_4 - test.classifier_average)=98.93%\n",
      "[ 2018-07-31 22:13:23,684][cascade_classifier.fit_transform] [layer=5] look_indexs=[0], X_cur_train.shape=(3487, 16), X_cur_test.shape=(1495, 16)\n",
      "[ 2018-07-31 22:13:24,885][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_0.predict)=98.29%\n",
      "[ 2018-07-31 22:13:26,489][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_1.predict)=97.71%\n",
      "[ 2018-07-31 22:13:28,101][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_2.predict)=98.85%\n",
      "[ 2018-07-31 22:13:29,813][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_3.predict)=99.14%\n",
      "[ 2018-07-31 22:13:32,295][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_4.predict)=98.28%\n",
      "[ 2018-07-31 22:13:34,000][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_5.predict)=98.85%\n",
      "[ 2018-07-31 22:13:35,487][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_6.predict)=99.14%\n",
      "[ 2018-07-31 22:13:36,901][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_7.predict)=97.70%\n",
      "[ 2018-07-31 22:13:38,794][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_8.predict)=97.99%\n",
      "[ 2018-07-31 22:13:40,557][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_9.predict)=98.56%\n",
      "[ 2018-07-31 22:13:40,785][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_cv.predict)=98.45%\n",
      "[ 2018-07-31 22:13:40,787][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.test.predict)=98.46%\n",
      "[ 2018-07-31 22:13:42,275][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_0.predict)=97.71%\n",
      "[ 2018-07-31 22:13:43,733][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_1.predict)=98.57%\n",
      "[ 2018-07-31 22:13:45,296][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_2.predict)=98.57%\n",
      "[ 2018-07-31 22:13:47,025][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_3.predict)=98.28%\n",
      "[ 2018-07-31 22:13:48,368][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_4.predict)=99.14%\n",
      "[ 2018-07-31 22:13:49,850][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_5.predict)=98.56%\n",
      "[ 2018-07-31 22:13:51,525][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_6.predict)=99.43%\n",
      "[ 2018-07-31 22:13:52,985][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_7.predict)=98.56%\n",
      "[ 2018-07-31 22:13:54,424][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_8.predict)=97.99%\n",
      "[ 2018-07-31 22:13:55,732][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_9.predict)=98.28%\n",
      "[ 2018-07-31 22:13:56,101][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_cv.predict)=98.51%\n",
      "[ 2018-07-31 22:13:56,103][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.test.predict)=98.73%\n",
      "[ 2018-07-31 22:13:56,459][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_0.predict)=97.71%\n",
      "[ 2018-07-31 22:13:56,903][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_1.predict)=98.29%\n",
      "[ 2018-07-31 22:13:57,207][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_2.predict)=98.28%\n",
      "[ 2018-07-31 22:13:57,612][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_3.predict)=97.42%\n",
      "[ 2018-07-31 22:13:57,956][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_4.predict)=98.28%\n",
      "[ 2018-07-31 22:13:58,558][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_5.predict)=97.99%\n",
      "[ 2018-07-31 22:13:59,057][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_6.predict)=97.99%\n",
      "[ 2018-07-31 22:13:59,360][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_7.predict)=97.99%\n",
      "[ 2018-07-31 22:13:59,781][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_8.predict)=98.56%\n",
      "[ 2018-07-31 22:14:00,620][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_9.predict)=98.56%\n",
      "[ 2018-07-31 22:14:00,661][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_cv.predict)=98.11%\n",
      "[ 2018-07-31 22:14:00,683][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.test.predict)=98.39%\n",
      "[ 2018-07-31 22:14:00,694][cascade_classifier.calc_accuracy] Accuracy(layer_5 - train.classifier_average)=98.65%\n",
      "[ 2018-07-31 22:14:00,702][cascade_classifier.calc_accuracy] Accuracy(layer_5 - test.classifier_average)=98.80%\n",
      "[ 2018-07-31 22:14:00,704][cascade_classifier.fit_transform] [Result][Optimal Level Detected] opt_layer_num=3, accuracy_train=98.71%, accuracy_test=98.80%\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "# X_enc is the concatenated predict_proba result of each estimators of the last layer of the GCForest model\n",
    "    # X_enc.shape =\n",
    "    #   (n_datas, n_estimators * n_classes): If cascade is provided\n",
    "    #   (n_datas, n_estimators * n_classes, dimX, dimY): If only finegrained part is provided\n",
    "    # You can also pass X_test, y_test to fit_transform method, then the accracy on test data will be logged when training.\n",
    "X_train_enc, X_test_enc = gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test)\n",
    "    # WARNING: if you set gc.set_keep_model_in_mem(True), you would have to use\n",
    "    # gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test) to evaluate your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:14:00,798][cascade_classifier.transform] X_groups_test.shape=[(1495, 10)]\n",
      "[ 2018-07-31 22:14:00,806][cascade_classifier.transform] group_dims=[10]\n",
      "[ 2018-07-31 22:14:00,808][cascade_classifier.transform] X_test.shape=(1495, 10)\n",
      "[ 2018-07-31 22:14:00,810][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(1495, 10)\n",
      "[ 2018-07-31 22:14:06,528][cascade_classifier.transform] [layer=1] look_indexs=[0], X_cur_test.shape=(1495, 16)\n",
      "[ 2018-07-31 22:14:12,479][cascade_classifier.transform] [layer=2] look_indexs=[0], X_cur_test.shape=(1495, 16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GCForest = 98.795987 %\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "y_pred = gc.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy of GCForest = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' Time ', '194.548', ' seconds')\n",
      "[[1460    8]\n",
      " [  10   17]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.99      0.99      1468\n",
      "        1.0       0.68      0.63      0.65        27\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3138/3138 [==============================] - 3s 1ms/step - loss: 0.3349 - acc: 0.9697\n",
      "Epoch 2/50\n",
      "3138/3138 [==============================] - 2s 608us/step - loss: 0.2437 - acc: 0.9780\n",
      "Epoch 3/50\n",
      "3138/3138 [==============================] - 2s 631us/step - loss: 0.2580 - acc: 0.9739\n",
      "Epoch 4/50\n",
      "3138/3138 [==============================] - 2s 534us/step - loss: 0.2426 - acc: 0.9793\n",
      "Epoch 5/50\n",
      "3138/3138 [==============================] - 2s 680us/step - loss: 0.2076 - acc: 0.9796\n",
      "Epoch 6/50\n",
      "3138/3138 [==============================] - 2s 565us/step - loss: 0.2382 - acc: 0.9812\n",
      "Epoch 7/50\n",
      "3138/3138 [==============================] - 2s 551us/step - loss: 0.2304 - acc: 0.9799\n",
      "Epoch 8/50\n",
      "3138/3138 [==============================] - 2s 679us/step - loss: 0.2174 - acc: 0.9802 1s - loss: 0.\n",
      "Epoch 9/50\n",
      "3138/3138 [==============================] - 2s 685us/step - loss: 0.2059 - acc: 0.9831\n",
      "Epoch 10/50\n",
      "3138/3138 [==============================] - 2s 696us/step - loss: 0.1414 - acc: 0.9844\n",
      "Epoch 11/50\n",
      "3138/3138 [==============================] - 2s 554us/step - loss: 0.1235 - acc: 0.9869\n",
      "Epoch 12/50\n",
      "3138/3138 [==============================] - 2s 573us/step - loss: 0.1386 - acc: 0.9863\n",
      "Epoch 13/50\n",
      "3138/3138 [==============================] - 2s 556us/step - loss: 0.1404 - acc: 0.9850\n",
      "Epoch 14/50\n",
      "3138/3138 [==============================] - 2s 550us/step - loss: 0.1174 - acc: 0.9873\n",
      "Epoch 15/50\n",
      "3138/3138 [==============================] - 2s 523us/step - loss: 0.2641 - acc: 0.9774\n",
      "Epoch 16/50\n",
      "3138/3138 [==============================] - 2s 602us/step - loss: 0.1687 - acc: 0.9834\n",
      "Epoch 17/50\n",
      "3138/3138 [==============================] - 2s 566us/step - loss: 0.1314 - acc: 0.9876\n",
      "Epoch 18/50\n",
      "3138/3138 [==============================] - 2s 524us/step - loss: 0.1267 - acc: 0.9860\n",
      "Epoch 19/50\n",
      "3138/3138 [==============================] - 2s 521us/step - loss: 0.1204 - acc: 0.9888\n",
      "Epoch 20/50\n",
      "3138/3138 [==============================] - 2s 586us/step - loss: 0.1126 - acc: 0.9873\n",
      "Epoch 21/50\n",
      "3138/3138 [==============================] - 2s 596us/step - loss: 0.1183 - acc: 0.9885\n",
      "Epoch 22/50\n",
      "3138/3138 [==============================] - 2s 549us/step - loss: 0.1112 - acc: 0.9873\n",
      "Epoch 23/50\n",
      "3138/3138 [==============================] - 2s 629us/step - loss: 0.1148 - acc: 0.9876\n",
      "Epoch 24/50\n",
      "3138/3138 [==============================] - 2s 606us/step - loss: 0.1053 - acc: 0.9888\n",
      "Epoch 25/50\n",
      "3138/3138 [==============================] - 2s 569us/step - loss: 0.1028 - acc: 0.9888\n",
      "Epoch 26/50\n",
      "3138/3138 [==============================] - 2s 595us/step - loss: 0.1072 - acc: 0.9863\n",
      "Epoch 27/50\n",
      "3138/3138 [==============================] - 2s 545us/step - loss: 0.0994 - acc: 0.9869\n",
      "Epoch 28/50\n",
      "3138/3138 [==============================] - 2s 622us/step - loss: 0.0990 - acc: 0.9888\n",
      "Epoch 29/50\n",
      "3138/3138 [==============================] - 2s 552us/step - loss: 0.2146 - acc: 0.9822\n",
      "Epoch 30/50\n",
      "3138/3138 [==============================] - 2s 700us/step - loss: 0.2204 - acc: 0.9841\n",
      "Epoch 31/50\n",
      "3138/3138 [==============================] - 2s 754us/step - loss: 0.2189 - acc: 0.9828\n",
      "Epoch 32/50\n",
      "3138/3138 [==============================] - 2s 710us/step - loss: 0.2161 - acc: 0.9841\n",
      "Epoch 33/50\n",
      "3138/3138 [==============================] - 2s 545us/step - loss: 0.2162 - acc: 0.9844\n",
      "Epoch 34/50\n",
      "3138/3138 [==============================] - 2s 610us/step - loss: 0.2169 - acc: 0.9844\n",
      "Epoch 35/50\n",
      "3138/3138 [==============================] - 2s 548us/step - loss: 0.2167 - acc: 0.9844\n",
      "Epoch 36/50\n",
      "3138/3138 [==============================] - 2s 513us/step - loss: 0.2194 - acc: 0.9837\n",
      "Epoch 37/50\n",
      "3138/3138 [==============================] - 2s 714us/step - loss: 0.2189 - acc: 0.9825\n",
      "Epoch 38/50\n",
      "3138/3138 [==============================] - 3s 839us/step - loss: 0.2171 - acc: 0.9841\n",
      "Epoch 39/50\n",
      "3138/3138 [==============================] - 3s 874us/step - loss: 0.2158 - acc: 0.9847\n",
      "Epoch 40/50\n",
      "3138/3138 [==============================] - 3s 879us/step - loss: 0.2159 - acc: 0.9844\n",
      "Epoch 41/50\n",
      "3138/3138 [==============================] - 3s 859us/step - loss: 0.2159 - acc: 0.9844\n",
      "Epoch 42/50\n",
      "3138/3138 [==============================] - 2s 789us/step - loss: 0.2221 - acc: 0.9822\n",
      "Epoch 43/50\n",
      "3138/3138 [==============================] - 2s 782us/step - loss: 0.2194 - acc: 0.9822\n",
      "Epoch 44/50\n",
      "3138/3138 [==============================] - 2s 751us/step - loss: 0.2161 - acc: 0.9844\n",
      "Epoch 45/50\n",
      "3138/3138 [==============================] - 2s 795us/step - loss: 0.2159 - acc: 0.9841\n",
      "Epoch 46/50\n",
      "3138/3138 [==============================] - 2s 765us/step - loss: 0.2156 - acc: 0.9844\n",
      "Epoch 47/50\n",
      "3138/3138 [==============================] - 2s 605us/step - loss: 0.2160 - acc: 0.9847\n",
      "Epoch 48/50\n",
      "3138/3138 [==============================] - 2s 757us/step - loss: 0.2153 - acc: 0.9850\n",
      "Epoch 49/50\n",
      "3138/3138 [==============================] - 2s 670us/step - loss: 0.2153 - acc: 0.9844\n",
      "Epoch 50/50\n",
      "3138/3138 [==============================] - 2s 593us/step - loss: 0.2153 - acc: 0.9850\n",
      "349/349 [==============================] - 0s 247us/step\n",
      "Epoch 1/50\n",
      "3138/3138 [==============================] - 4s 1ms/step - loss: 0.2497 - acc: 0.9786\n",
      "Epoch 2/50\n",
      "3138/3138 [==============================] - 2s 630us/step - loss: 0.1724 - acc: 0.9828\n",
      "Epoch 3/50\n",
      "3138/3138 [==============================] - 2s 726us/step - loss: 0.1691 - acc: 0.9831\n",
      "Epoch 4/50\n",
      "3138/3138 [==============================] - 2s 728us/step - loss: 0.1626 - acc: 0.9841\n",
      "Epoch 5/50\n",
      "3138/3138 [==============================] - 2s 749us/step - loss: 0.2031 - acc: 0.9736 1s \n",
      "Epoch 6/50\n",
      "3138/3138 [==============================] - 2s 765us/step - loss: 0.1453 - acc: 0.9815\n",
      "Epoch 7/50\n",
      "3138/3138 [==============================] - 2s 778us/step - loss: 0.1302 - acc: 0.9863\n",
      "Epoch 8/50\n",
      "3138/3138 [==============================] - 2s 691us/step - loss: 0.1461 - acc: 0.9844\n",
      "Epoch 9/50\n",
      "3138/3138 [==============================] - 2s 609us/step - loss: 0.1598 - acc: 0.9809\n",
      "Epoch 10/50\n",
      "3138/3138 [==============================] - 2s 596us/step - loss: 0.2197 - acc: 0.9818\n",
      "Epoch 11/50\n",
      "3138/3138 [==============================] - 2s 528us/step - loss: 0.2288 - acc: 0.9825\n",
      "Epoch 12/50\n",
      "3138/3138 [==============================] - 2s 590us/step - loss: 0.2211 - acc: 0.9831\n",
      "Epoch 13/50\n",
      "3138/3138 [==============================] - 2s 765us/step - loss: 0.1629 - acc: 0.9802\n",
      "Epoch 14/50\n",
      "3138/3138 [==============================] - 3s 852us/step - loss: 0.2195 - acc: 0.9818\n",
      "Epoch 15/50\n",
      "3138/3138 [==============================] - 3s 861us/step - loss: 0.1559 - acc: 0.9831\n",
      "Epoch 16/50\n",
      "3138/3138 [==============================] - 2s 696us/step - loss: 0.1294 - acc: 0.9869\n",
      "Epoch 17/50\n",
      "3138/3138 [==============================] - 2s 793us/step - loss: 0.1510 - acc: 0.9831\n",
      "Epoch 18/50\n",
      "3138/3138 [==============================] - 3s 834us/step - loss: 0.2204 - acc: 0.9822\n",
      "Epoch 19/50\n",
      "3138/3138 [==============================] - 2s 734us/step - loss: 0.2147 - acc: 0.9834\n",
      "Epoch 20/50\n",
      "3138/3138 [==============================] - 2s 770us/step - loss: 0.2016 - acc: 0.9793\n",
      "Epoch 21/50\n",
      "3138/3138 [==============================] - 2s 736us/step - loss: 0.1495 - acc: 0.9825\n",
      "Epoch 22/50\n",
      "3138/3138 [==============================] - 3s 797us/step - loss: 0.1260 - acc: 0.9857\n",
      "Epoch 23/50\n",
      "3138/3138 [==============================] - 2s 679us/step - loss: 0.1498 - acc: 0.9857 1s - \n",
      "Epoch 24/50\n",
      "3138/3138 [==============================] - 2s 567us/step - loss: 0.1342 - acc: 0.9869\n",
      "Epoch 25/50\n",
      "3138/3138 [==============================] - 2s 631us/step - loss: 0.1230 - acc: 0.9869\n",
      "Epoch 26/50\n",
      "3138/3138 [==============================] - 2s 663us/step - loss: 0.1207 - acc: 0.9857\n",
      "Epoch 27/50\n",
      "3138/3138 [==============================] - 2s 729us/step - loss: 0.1390 - acc: 0.9850\n",
      "Epoch 28/50\n",
      "3138/3138 [==============================] - 2s 755us/step - loss: 0.1473 - acc: 0.9873\n",
      "Epoch 29/50\n",
      "3138/3138 [==============================] - 2s 750us/step - loss: 0.1304 - acc: 0.9876\n",
      "Epoch 30/50\n",
      "3138/3138 [==============================] - 2s 748us/step - loss: 0.1173 - acc: 0.9876\n",
      "Epoch 31/50\n",
      "3138/3138 [==============================] - 2s 639us/step - loss: 0.1175 - acc: 0.9876\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3138/3138 [==============================] - 2s 675us/step - loss: 0.1100 - acc: 0.9876\n",
      "Epoch 33/50\n",
      "3138/3138 [==============================] - 2s 589us/step - loss: 0.1223 - acc: 0.9866\n",
      "Epoch 34/50\n",
      "3138/3138 [==============================] - 2s 541us/step - loss: 0.1105 - acc: 0.9876\n",
      "Epoch 35/50\n",
      "3138/3138 [==============================] - 2s 646us/step - loss: 0.1976 - acc: 0.9822\n",
      "Epoch 36/50\n",
      "3138/3138 [==============================] - 2s 729us/step - loss: 0.1236 - acc: 0.9869\n",
      "Epoch 37/50\n",
      "3138/3138 [==============================] - 2s 786us/step - loss: 0.1637 - acc: 0.9863\n",
      "Epoch 38/50\n",
      "3138/3138 [==============================] - 2s 710us/step - loss: 0.1228 - acc: 0.9876\n",
      "Epoch 39/50\n",
      "3138/3138 [==============================] - 3s 811us/step - loss: 0.1072 - acc: 0.9873\n",
      "Epoch 40/50\n",
      "3138/3138 [==============================] - 2s 735us/step - loss: 0.1247 - acc: 0.9844\n",
      "Epoch 41/50\n",
      "3138/3138 [==============================] - 2s 680us/step - loss: 0.1271 - acc: 0.9866\n",
      "Epoch 42/50\n",
      "3138/3138 [==============================] - 2s 777us/step - loss: 0.0920 - acc: 0.9885\n",
      "Epoch 43/50\n",
      "3138/3138 [==============================] - 2s 694us/step - loss: 0.0898 - acc: 0.9882 1s - loss:\n",
      "Epoch 44/50\n",
      "3138/3138 [==============================] - 2s 763us/step - loss: 0.0825 - acc: 0.9892\n",
      "Epoch 45/50\n",
      "3138/3138 [==============================] - 2s 735us/step - loss: 0.1354 - acc: 0.9863 \n",
      "Epoch 46/50\n",
      "3138/3138 [==============================] - 2s 712us/step - loss: 0.1162 - acc: 0.9869\n",
      "Epoch 47/50\n",
      "3138/3138 [==============================] - 3s 823us/step - loss: 0.1117 - acc: 0.9888\n",
      "Epoch 48/50\n",
      "3138/3138 [==============================] - 2s 769us/step - loss: 0.1134 - acc: 0.9866\n",
      "Epoch 49/50\n",
      "3138/3138 [==============================] - 2s 737us/step - loss: 0.1597 - acc: 0.9825\n",
      "Epoch 50/50\n",
      "3138/3138 [==============================] - 2s 671us/step - loss: 0.1460 - acc: 0.9873\n",
      "349/349 [==============================] - 0s 785us/step\n",
      "Epoch 1/50\n",
      "3138/3138 [==============================] - 5s 2ms/step - loss: 0.2453 - acc: 0.9783\n",
      "Epoch 2/50\n",
      "3138/3138 [==============================] - 2s 704us/step - loss: 0.2472 - acc: 0.9809 0s - loss: 0.2453 - acc: 0.98\n",
      "Epoch 3/50\n",
      "3138/3138 [==============================] - 2s 741us/step - loss: 0.2127 - acc: 0.9745\n",
      "Epoch 4/50\n",
      "3138/3138 [==============================] - 2s 752us/step - loss: 0.1585 - acc: 0.9783\n",
      "Epoch 5/50\n",
      "3138/3138 [==============================] - 3s 859us/step - loss: 0.1790 - acc: 0.9837\n",
      "Epoch 6/50\n",
      "3138/3138 [==============================] - 3s 843us/step - loss: 0.1587 - acc: 0.9831\n",
      "Epoch 7/50\n",
      "3138/3138 [==============================] - 2s 773us/step - loss: 0.1462 - acc: 0.9850\n",
      "Epoch 8/50\n",
      "3138/3138 [==============================] - 3s 844us/step - loss: 0.1632 - acc: 0.9841 1s - loss\n",
      "Epoch 9/50\n",
      "3138/3138 [==============================] - 3s 826us/step - loss: 0.2190 - acc: 0.9818\n",
      "Epoch 10/50\n",
      "3138/3138 [==============================] - 3s 805us/step - loss: 0.1511 - acc: 0.9873\n",
      "Epoch 11/50\n",
      "3138/3138 [==============================] - 2s 782us/step - loss: 0.1382 - acc: 0.9863\n",
      "Epoch 12/50\n",
      "3138/3138 [==============================] - 3s 853us/step - loss: 0.1354 - acc: 0.9860\n",
      "Epoch 13/50\n",
      "3138/3138 [==============================] - 3s 897us/step - loss: 0.1307 - acc: 0.9860\n",
      "Epoch 14/50\n",
      "3138/3138 [==============================] - 2s 774us/step - loss: 0.1243 - acc: 0.9876\n",
      "Epoch 15/50\n",
      "3138/3138 [==============================] - 2s 721us/step - loss: 0.1190 - acc: 0.9879\n",
      "Epoch 16/50\n",
      "3138/3138 [==============================] - 2s 577us/step - loss: 0.1371 - acc: 0.9863\n",
      "Epoch 17/50\n",
      "3138/3138 [==============================] - 2s 582us/step - loss: 0.1062 - acc: 0.9879\n",
      "Epoch 18/50\n",
      "3138/3138 [==============================] - 2s 700us/step - loss: 0.2441 - acc: 0.9793\n",
      "Epoch 19/50\n",
      "3138/3138 [==============================] - 2s 648us/step - loss: 0.2182 - acc: 0.9831\n",
      "Epoch 20/50\n",
      "3138/3138 [==============================] - 2s 730us/step - loss: 0.1496 - acc: 0.9822\n",
      "Epoch 21/50\n",
      "3138/3138 [==============================] - 2s 643us/step - loss: 0.1943 - acc: 0.9815\n",
      "Epoch 22/50\n",
      "3138/3138 [==============================] - 2s 639us/step - loss: 0.2310 - acc: 0.9828\n",
      "Epoch 23/50\n",
      "3138/3138 [==============================] - 2s 650us/step - loss: 0.2260 - acc: 0.9796\n",
      "Epoch 24/50\n",
      "3138/3138 [==============================] - 2s 605us/step - loss: 0.1743 - acc: 0.9850\n",
      "Epoch 25/50\n",
      "3138/3138 [==============================] - 2s 687us/step - loss: 0.1578 - acc: 0.9860ETA: 2\n",
      "Epoch 26/50\n",
      "3138/3138 [==============================] - 2s 687us/step - loss: 0.1488 - acc: 0.9869\n",
      "Epoch 27/50\n",
      "3138/3138 [==============================] - 2s 702us/step - loss: 0.1392 - acc: 0.9831\n",
      "Epoch 28/50\n",
      "3138/3138 [==============================] - 2s 563us/step - loss: 0.1308 - acc: 0.9879 0s - loss: 0.1282 - acc: 0.9\n",
      "Epoch 29/50\n",
      "3138/3138 [==============================] - 2s 588us/step - loss: 0.1293 - acc: 0.9869\n",
      "Epoch 30/50\n",
      "3138/3138 [==============================] - 2s 550us/step - loss: 0.1301 - acc: 0.9888\n",
      "Epoch 31/50\n",
      "3138/3138 [==============================] - 2s 577us/step - loss: 0.1240 - acc: 0.9873\n",
      "Epoch 32/50\n",
      "3138/3138 [==============================] - 2s 518us/step - loss: 0.1299 - acc: 0.9882\n",
      "Epoch 33/50\n",
      "3138/3138 [==============================] - 2s 572us/step - loss: 0.1288 - acc: 0.9879\n",
      "Epoch 34/50\n",
      "3138/3138 [==============================] - 2s 595us/step - loss: 0.1304 - acc: 0.9869\n",
      "Epoch 35/50\n",
      "3138/3138 [==============================] - 2s 541us/step - loss: 0.1225 - acc: 0.9866\n",
      "Epoch 36/50\n",
      "3138/3138 [==============================] - 2s 527us/step - loss: 0.1213 - acc: 0.9879\n",
      "Epoch 37/50\n",
      "3138/3138 [==============================] - 2s 530us/step - loss: 0.1304 - acc: 0.9863\n",
      "Epoch 38/50\n",
      "3138/3138 [==============================] - 2s 611us/step - loss: 0.2152 - acc: 0.9786\n",
      "Epoch 39/50\n",
      "3138/3138 [==============================] - 2s 716us/step - loss: 0.2289 - acc: 0.9831\n",
      "Epoch 40/50\n",
      "3138/3138 [==============================] - 2s 789us/step - loss: 0.2237 - acc: 0.9834 0s - loss: 0.1900 - \n",
      "Epoch 41/50\n",
      "3138/3138 [==============================] - 3s 823us/step - loss: 0.2178 - acc: 0.9847\n",
      "Epoch 42/50\n",
      "3138/3138 [==============================] - 3s 818us/step - loss: 0.2018 - acc: 0.9857\n",
      "Epoch 43/50\n",
      "3138/3138 [==============================] - 2s 771us/step - loss: 0.1568 - acc: 0.9866 0s - loss: 0.1569 - acc: 0.986\n",
      "Epoch 44/50\n",
      "3138/3138 [==============================] - 2s 699us/step - loss: 0.1483 - acc: 0.9873\n",
      "Epoch 45/50\n",
      "3138/3138 [==============================] - 2s 652us/step - loss: 0.1580 - acc: 0.9850\n",
      "Epoch 46/50\n",
      "3138/3138 [==============================] - 2s 616us/step - loss: 0.1429 - acc: 0.9873\n",
      "Epoch 47/50\n",
      "3138/3138 [==============================] - 2s 642us/step - loss: 0.1389 - acc: 0.9879\n",
      "Epoch 48/50\n",
      "3138/3138 [==============================] - 2s 695us/step - loss: 0.1412 - acc: 0.9853\n",
      "Epoch 49/50\n",
      "3138/3138 [==============================] - 2s 662us/step - loss: 0.1606 - acc: 0.9869\n",
      "Epoch 50/50\n",
      "3138/3138 [==============================] - 2s 678us/step - loss: 0.1441 - acc: 0.9873\n",
      "349/349 [==============================] - 0s 417us/step\n",
      "Epoch 1/50\n",
      "3138/3138 [==============================] - 5s 1ms/step - loss: 0.2526 - acc: 0.9774\n",
      "Epoch 2/50\n",
      "3138/3138 [==============================] - 2s 712us/step - loss: 0.2180 - acc: 0.9793\n",
      "Epoch 3/50\n",
      "3138/3138 [==============================] - 2s 645us/step - loss: 0.2548 - acc: 0.9777\n",
      "Epoch 4/50\n",
      "3138/3138 [==============================] - 2s 607us/step - loss: 0.1711 - acc: 0.9806\n",
      "Epoch 5/50\n",
      "3138/3138 [==============================] - 2s 670us/step - loss: 0.1851 - acc: 0.9815\n",
      "Epoch 6/50\n",
      "3138/3138 [==============================] - 2s 638us/step - loss: 0.1773 - acc: 0.9828\n",
      "Epoch 7/50\n",
      "3138/3138 [==============================] - 2s 663us/step - loss: 0.1417 - acc: 0.9866\n",
      "Epoch 8/50\n",
      "3138/3138 [==============================] - 2s 601us/step - loss: 0.1984 - acc: 0.9822\n",
      "Epoch 9/50\n",
      "3138/3138 [==============================] - 2s 583us/step - loss: 0.2804 - acc: 0.9793\n",
      "Epoch 10/50\n",
      "3138/3138 [==============================] - 2s 614us/step - loss: 0.2159 - acc: 0.9790\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3138/3138 [==============================] - 2s 606us/step - loss: 0.1637 - acc: 0.9853\n",
      "Epoch 12/50\n",
      "3138/3138 [==============================] - 2s 646us/step - loss: 0.2006 - acc: 0.9831\n",
      "Epoch 13/50\n",
      "3138/3138 [==============================] - 2s 542us/step - loss: 0.1826 - acc: 0.9828\n",
      "Epoch 14/50\n",
      "3138/3138 [==============================] - 2s 686us/step - loss: 0.1447 - acc: 0.9844\n",
      "Epoch 15/50\n",
      "3138/3138 [==============================] - 2s 765us/step - loss: 0.1772 - acc: 0.9802\n",
      "Epoch 16/50\n",
      "3138/3138 [==============================] - 2s 662us/step - loss: 0.2254 - acc: 0.9818\n",
      "Epoch 17/50\n",
      "3138/3138 [==============================] - 2s 791us/step - loss: 0.1846 - acc: 0.9802\n",
      "Epoch 18/50\n",
      "3138/3138 [==============================] - 2s 758us/step - loss: 0.1583 - acc: 0.9786\n",
      "Epoch 19/50\n",
      "3138/3138 [==============================] - 2s 770us/step - loss: 0.1288 - acc: 0.9853\n",
      "Epoch 20/50\n",
      "3138/3138 [==============================] - 2s 544us/step - loss: 0.1120 - acc: 0.9882\n",
      "Epoch 21/50\n",
      "3138/3138 [==============================] - 2s 513us/step - loss: 0.1293 - acc: 0.9876\n",
      "Epoch 22/50\n",
      "3138/3138 [==============================] - 2s 569us/step - loss: 0.1418 - acc: 0.9844\n",
      "Epoch 23/50\n",
      "3138/3138 [==============================] - 2s 574us/step - loss: 0.1240 - acc: 0.9873\n",
      "Epoch 24/50\n",
      "3138/3138 [==============================] - 2s 651us/step - loss: 0.1698 - acc: 0.9841\n",
      "Epoch 25/50\n",
      "3138/3138 [==============================] - 2s 627us/step - loss: 0.1351 - acc: 0.9876\n",
      "Epoch 26/50\n",
      "3138/3138 [==============================] - 2s 569us/step - loss: 0.1244 - acc: 0.9879\n",
      "Epoch 27/50\n",
      "3138/3138 [==============================] - 2s 563us/step - loss: 0.2010 - acc: 0.9802\n",
      "Epoch 28/50\n",
      "3138/3138 [==============================] - 2s 605us/step - loss: 0.2321 - acc: 0.9822\n",
      "Epoch 29/50\n",
      "3138/3138 [==============================] - 2s 615us/step - loss: 0.1963 - acc: 0.9841\n",
      "Epoch 30/50\n",
      "3138/3138 [==============================] - 2s 649us/step - loss: 0.1770 - acc: 0.9818\n",
      "Epoch 31/50\n",
      "3138/3138 [==============================] - 2s 690us/step - loss: 0.1763 - acc: 0.9828\n",
      "Epoch 32/50\n",
      "3138/3138 [==============================] - 2s 687us/step - loss: 0.1417 - acc: 0.9866\n",
      "Epoch 33/50\n",
      "3138/3138 [==============================] - 2s 674us/step - loss: 0.1429 - acc: 0.9876\n",
      "Epoch 34/50\n",
      "3138/3138 [==============================] - 2s 731us/step - loss: 0.1419 - acc: 0.9876\n",
      "Epoch 35/50\n",
      "3138/3138 [==============================] - 2s 681us/step - loss: 0.1385 - acc: 0.9873\n",
      "Epoch 36/50\n",
      "3138/3138 [==============================] - 2s 749us/step - loss: 0.1314 - acc: 0.9869\n",
      "Epoch 37/50\n",
      "3138/3138 [==============================] - 2s 722us/step - loss: 0.1535 - acc: 0.9866\n",
      "Epoch 38/50\n",
      "3138/3138 [==============================] - 2s 724us/step - loss: 0.1527 - acc: 0.9873\n",
      "Epoch 39/50\n",
      "3138/3138 [==============================] - 2s 757us/step - loss: 0.1710 - acc: 0.9844\n",
      "Epoch 40/50\n",
      "3138/3138 [==============================] - 2s 712us/step - loss: 0.1556 - acc: 0.9844\n",
      "Epoch 41/50\n",
      "3138/3138 [==============================] - 2s 605us/step - loss: 0.1261 - acc: 0.9869\n",
      "Epoch 42/50\n",
      "3138/3138 [==============================] - 2s 653us/step - loss: 0.1185 - acc: 0.9876\n",
      "Epoch 43/50\n",
      "3138/3138 [==============================] - 2s 699us/step - loss: 0.1047 - acc: 0.9882\n",
      "Epoch 44/50\n",
      "3138/3138 [==============================] - 2s 706us/step - loss: 0.1430 - acc: 0.9860\n",
      "Epoch 45/50\n",
      "3138/3138 [==============================] - 2s 623us/step - loss: 0.1441 - acc: 0.9869\n",
      "Epoch 46/50\n",
      "3138/3138 [==============================] - 2s 673us/step - loss: 0.1305 - acc: 0.9876\n",
      "Epoch 47/50\n",
      "3138/3138 [==============================] - 2s 758us/step - loss: 0.1535 - acc: 0.9828\n",
      "Epoch 48/50\n",
      "3138/3138 [==============================] - 2s 755us/step - loss: 0.1416 - acc: 0.9866\n",
      "Epoch 49/50\n",
      "3138/3138 [==============================] - 2s 685us/step - loss: 0.1387 - acc: 0.9876\n",
      "Epoch 50/50\n",
      "3138/3138 [==============================] - 2s 657us/step - loss: 0.1491 - acc: 0.9847\n",
      "349/349 [==============================] - 0s 543us/step\n",
      "Epoch 1/50\n",
      "3138/3138 [==============================] - 5s 1ms/step - loss: 0.3682 - acc: 0.9694\n",
      "Epoch 2/50\n",
      "3138/3138 [==============================] - 2s 635us/step - loss: 0.2365 - acc: 0.9764\n",
      "Epoch 3/50\n",
      "3138/3138 [==============================] - 2s 676us/step - loss: 0.1922 - acc: 0.9806\n",
      "Epoch 4/50\n",
      "3138/3138 [==============================] - 2s 552us/step - loss: 0.1781 - acc: 0.9857\n",
      "Epoch 5/50\n",
      "3138/3138 [==============================] - 2s 500us/step - loss: 0.3193 - acc: 0.9796\n",
      "Epoch 6/50\n",
      "3138/3138 [==============================] - 2s 558us/step - loss: 0.2556 - acc: 0.9799\n",
      "Epoch 7/50\n",
      "3138/3138 [==============================] - 2s 603us/step - loss: 0.2273 - acc: 0.9822\n",
      "Epoch 8/50\n",
      "3138/3138 [==============================] - 2s 618us/step - loss: 0.2218 - acc: 0.9822\n",
      "Epoch 9/50\n",
      "3138/3138 [==============================] - 2s 603us/step - loss: 0.2228 - acc: 0.9825\n",
      "Epoch 10/50\n",
      "3138/3138 [==============================] - 2s 606us/step - loss: 0.2191 - acc: 0.9834\n",
      "Epoch 11/50\n",
      "3138/3138 [==============================] - 2s 717us/step - loss: 0.2198 - acc: 0.9822\n",
      "Epoch 12/50\n",
      "3138/3138 [==============================] - 2s 593us/step - loss: 0.2181 - acc: 0.9837\n",
      "Epoch 13/50\n",
      "3138/3138 [==============================] - 2s 573us/step - loss: 0.2182 - acc: 0.9831\n",
      "Epoch 14/50\n",
      "3138/3138 [==============================] - 2s 627us/step - loss: 0.2171 - acc: 0.9831\n",
      "Epoch 15/50\n",
      "3138/3138 [==============================] - 2s 561us/step - loss: 0.2178 - acc: 0.9818\n",
      "Epoch 16/50\n",
      "3138/3138 [==============================] - 2s 628us/step - loss: 0.2172 - acc: 0.9834\n",
      "Epoch 17/50\n",
      "3138/3138 [==============================] - 2s 656us/step - loss: 0.2209 - acc: 0.9815\n",
      "Epoch 18/50\n",
      "3138/3138 [==============================] - 2s 675us/step - loss: 0.2174 - acc: 0.9831\n",
      "Epoch 19/50\n",
      "3138/3138 [==============================] - 2s 600us/step - loss: 0.2165 - acc: 0.9837\n",
      "Epoch 20/50\n",
      "3138/3138 [==============================] - 2s 638us/step - loss: 0.2172 - acc: 0.9841\n",
      "Epoch 21/50\n",
      "3138/3138 [==============================] - 2s 692us/step - loss: 0.2176 - acc: 0.9841\n",
      "Epoch 22/50\n",
      "3138/3138 [==============================] - 2s 668us/step - loss: 0.2194 - acc: 0.9825\n",
      "Epoch 23/50\n",
      "3138/3138 [==============================] - 2s 731us/step - loss: 0.2167 - acc: 0.9844\n",
      "Epoch 24/50\n",
      "3138/3138 [==============================] - 2s 607us/step - loss: 0.2198 - acc: 0.9828\n",
      "Epoch 25/50\n",
      "3138/3138 [==============================] - 2s 710us/step - loss: 0.2169 - acc: 0.9844\n",
      "Epoch 26/50\n",
      "3138/3138 [==============================] - 2s 528us/step - loss: 0.2180 - acc: 0.9837\n",
      "Epoch 27/50\n",
      "3138/3138 [==============================] - 2s 563us/step - loss: 0.2172 - acc: 0.9841\n",
      "Epoch 28/50\n",
      "3138/3138 [==============================] - 2s 520us/step - loss: 0.2178 - acc: 0.9837\n",
      "Epoch 29/50\n",
      "3138/3138 [==============================] - 2s 648us/step - loss: 0.2170 - acc: 0.9837\n",
      "Epoch 30/50\n",
      "3138/3138 [==============================] - 2s 597us/step - loss: 0.2169 - acc: 0.9841\n",
      "Epoch 31/50\n",
      "3138/3138 [==============================] - 2s 699us/step - loss: 0.2161 - acc: 0.9847\n",
      "Epoch 32/50\n",
      "3138/3138 [==============================] - 2s 662us/step - loss: 0.2160 - acc: 0.9844\n",
      "Epoch 33/50\n",
      "3138/3138 [==============================] - 2s 740us/step - loss: 0.2168 - acc: 0.9834\n",
      "Epoch 34/50\n",
      "3138/3138 [==============================] - 2s 647us/step - loss: 0.2193 - acc: 0.9828\n",
      "Epoch 35/50\n",
      "3138/3138 [==============================] - 2s 630us/step - loss: 0.2163 - acc: 0.9844\n",
      "Epoch 36/50\n",
      "3138/3138 [==============================] - 2s 712us/step - loss: 0.2163 - acc: 0.9847 0s - loss: 0.2027 -\n",
      "Epoch 37/50\n",
      "3138/3138 [==============================] - 2s 583us/step - loss: 0.2175 - acc: 0.9837\n",
      "Epoch 38/50\n",
      "3138/3138 [==============================] - 2s 709us/step - loss: 0.2154 - acc: 0.9847\n",
      "Epoch 39/50\n",
      "3138/3138 [==============================] - 2s 693us/step - loss: 0.2197 - acc: 0.9822\n",
      "Epoch 40/50\n",
      "3138/3138 [==============================] - 2s 676us/step - loss: 0.2162 - acc: 0.9844\n",
      "Epoch 41/50\n",
      "3138/3138 [==============================] - 2s 629us/step - loss: 0.2155 - acc: 0.9847\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3138/3138 [==============================] - 2s 579us/step - loss: 0.2161 - acc: 0.9847\n",
      "Epoch 43/50\n",
      "3138/3138 [==============================] - 2s 544us/step - loss: 0.2158 - acc: 0.9853\n",
      "Epoch 44/50\n",
      "3138/3138 [==============================] - 2s 506us/step - loss: 0.2157 - acc: 0.9853\n",
      "Epoch 45/50\n",
      "3138/3138 [==============================] - 2s 516us/step - loss: 0.2161 - acc: 0.9850\n",
      "Epoch 46/50\n",
      "3138/3138 [==============================] - 2s 532us/step - loss: 0.2163 - acc: 0.9844\n",
      "Epoch 47/50\n",
      "3138/3138 [==============================] - 2s 606us/step - loss: 0.2183 - acc: 0.9841\n",
      "Epoch 48/50\n",
      "3138/3138 [==============================] - 2s 647us/step - loss: 0.2167 - acc: 0.9847 \n",
      "Epoch 49/50\n",
      "3138/3138 [==============================] - 2s 636us/step - loss: 0.2162 - acc: 0.9844 0s - loss: 0.2173 - acc: 0.98\n",
      "Epoch 50/50\n",
      "3138/3138 [==============================] - 2s 631us/step - loss: 0.2163 - acc: 0.9841\n",
      "349/349 [==============================] - 0s 694us/step\n",
      "Epoch 1/50\n",
      "3138/3138 [==============================] - 5s 1ms/step - loss: 0.3270 - acc: 0.9710\n",
      "Epoch 2/50\n",
      "3138/3138 [==============================] - 2s 756us/step - loss: 0.2348 - acc: 0.9771\n",
      "Epoch 3/50\n",
      "3138/3138 [==============================] - 2s 651us/step - loss: 0.2066 - acc: 0.9786\n",
      "Epoch 4/50\n",
      "3138/3138 [==============================] - 2s 689us/step - loss: 0.3038 - acc: 0.9739\n",
      "Epoch 5/50\n",
      "3138/3138 [==============================] - 2s 541us/step - loss: 0.2431 - acc: 0.9825\n",
      "Epoch 6/50\n",
      "3138/3138 [==============================] - 2s 606us/step - loss: 0.2286 - acc: 0.9790\n",
      "Epoch 7/50\n",
      "3138/3138 [==============================] - 2s 598us/step - loss: 0.1645 - acc: 0.9831\n",
      "Epoch 8/50\n",
      "3138/3138 [==============================] - 2s 619us/step - loss: 0.1608 - acc: 0.9853\n",
      "Epoch 9/50\n",
      "3138/3138 [==============================] - 2s 590us/step - loss: 0.1735 - acc: 0.9809\n",
      "Epoch 10/50\n",
      "3138/3138 [==============================] - 2s 731us/step - loss: 0.1687 - acc: 0.9860\n",
      "Epoch 11/50\n",
      "3138/3138 [==============================] - 2s 633us/step - loss: 0.1580 - acc: 0.9853\n",
      "Epoch 12/50\n",
      "3138/3138 [==============================] - 2s 688us/step - loss: 0.2072 - acc: 0.9799\n",
      "Epoch 13/50\n",
      "3138/3138 [==============================] - 2s 705us/step - loss: 0.2321 - acc: 0.9841\n",
      "Epoch 14/50\n",
      "3138/3138 [==============================] - 2s 630us/step - loss: 0.2193 - acc: 0.9828\n",
      "Epoch 15/50\n",
      "3138/3138 [==============================] - 2s 641us/step - loss: 0.1846 - acc: 0.9828\n",
      "Epoch 16/50\n",
      "3138/3138 [==============================] - 2s 643us/step - loss: 0.1518 - acc: 0.9860\n",
      "Epoch 17/50\n",
      "3138/3138 [==============================] - 2s 702us/step - loss: 0.1435 - acc: 0.9876\n",
      "Epoch 18/50\n",
      "3138/3138 [==============================] - 2s 734us/step - loss: 0.1413 - acc: 0.9888\n",
      "Epoch 19/50\n",
      "3138/3138 [==============================] - 2s 698us/step - loss: 0.1422 - acc: 0.9876\n",
      "Epoch 20/50\n",
      "3138/3138 [==============================] - 2s 615us/step - loss: 0.1425 - acc: 0.9876\n",
      "Epoch 21/50\n",
      "3138/3138 [==============================] - 2s 740us/step - loss: 0.1411 - acc: 0.9876\n",
      "Epoch 22/50\n",
      "3138/3138 [==============================] - 2s 616us/step - loss: 0.1398 - acc: 0.9879\n",
      "Epoch 23/50\n",
      "3138/3138 [==============================] - 2s 576us/step - loss: 0.2175 - acc: 0.9786\n",
      "Epoch 24/50\n",
      "3138/3138 [==============================] - 2s 653us/step - loss: 0.2115 - acc: 0.9793\n",
      "Epoch 25/50\n",
      "3138/3138 [==============================] - 2s 544us/step - loss: 0.1771 - acc: 0.9844\n",
      "Epoch 26/50\n",
      "3138/3138 [==============================] - 2s 546us/step - loss: 0.1502 - acc: 0.9822\n",
      "Epoch 27/50\n",
      "3138/3138 [==============================] - 2s 626us/step - loss: 0.1377 - acc: 0.9857\n",
      "Epoch 28/50\n",
      "3138/3138 [==============================] - 2s 576us/step - loss: 0.1412 - acc: 0.9863\n",
      "Epoch 29/50\n",
      "3138/3138 [==============================] - 2s 569us/step - loss: 0.1411 - acc: 0.9879\n",
      "Epoch 30/50\n",
      "3138/3138 [==============================] - 2s 631us/step - loss: 0.1403 - acc: 0.9866\n",
      "Epoch 31/50\n",
      "3138/3138 [==============================] - 2s 708us/step - loss: 0.1275 - acc: 0.9879\n",
      "Epoch 32/50\n",
      "3138/3138 [==============================] - 2s 726us/step - loss: 0.1351 - acc: 0.9866\n",
      "Epoch 33/50\n",
      "3138/3138 [==============================] - 2s 775us/step - loss: 0.1252 - acc: 0.9879\n",
      "Epoch 34/50\n",
      "3138/3138 [==============================] - 2s 636us/step - loss: 0.1190 - acc: 0.9879\n",
      "Epoch 35/50\n",
      "3138/3138 [==============================] - 2s 657us/step - loss: 0.1339 - acc: 0.9866\n",
      "Epoch 36/50\n",
      "3138/3138 [==============================] - 2s 665us/step - loss: 0.1394 - acc: 0.9869\n",
      "Epoch 37/50\n",
      "3138/3138 [==============================] - 2s 681us/step - loss: 0.1413 - acc: 0.9882\n",
      "Epoch 38/50\n",
      "3138/3138 [==============================] - 2s 664us/step - loss: 0.1277 - acc: 0.9885\n",
      "Epoch 39/50\n",
      "3138/3138 [==============================] - 2s 665us/step - loss: 0.1220 - acc: 0.9882\n",
      "Epoch 40/50\n",
      "3138/3138 [==============================] - 2s 652us/step - loss: 0.1300 - acc: 0.9860\n",
      "Epoch 41/50\n",
      "3138/3138 [==============================] - 2s 658us/step - loss: 0.1360 - acc: 0.9863\n",
      "Epoch 42/50\n",
      "3138/3138 [==============================] - 2s 580us/step - loss: 0.1185 - acc: 0.9885\n",
      "Epoch 43/50\n",
      "3138/3138 [==============================] - 2s 565us/step - loss: 0.1878 - acc: 0.9831\n",
      "Epoch 44/50\n",
      "3138/3138 [==============================] - 2s 624us/step - loss: 0.1384 - acc: 0.9873\n",
      "Epoch 45/50\n",
      "3138/3138 [==============================] - 2s 541us/step - loss: 0.1337 - acc: 0.9876 1s - l\n",
      "Epoch 46/50\n",
      "3138/3138 [==============================] - 2s 623us/step - loss: 0.1282 - acc: 0.9876\n",
      "Epoch 47/50\n",
      "3138/3138 [==============================] - 2s 663us/step - loss: 0.1206 - acc: 0.9876\n",
      "Epoch 48/50\n",
      "3138/3138 [==============================] - 2s 548us/step - loss: 0.1334 - acc: 0.9882\n",
      "Epoch 49/50\n",
      "3138/3138 [==============================] - 2s 662us/step - loss: 0.1216 - acc: 0.9888\n",
      "Epoch 50/50\n",
      "3138/3138 [==============================] - 2s 715us/step - loss: 0.1824 - acc: 0.9825\n",
      "349/349 [==============================] - 0s 611us/step\n",
      "Epoch 1/50\n",
      "3138/3138 [==============================] - 6s 2ms/step - loss: 0.3810 - acc: 0.9688\n",
      "Epoch 2/50\n",
      "3138/3138 [==============================] - 2s 627us/step - loss: 0.1855 - acc: 0.9802\n",
      "Epoch 3/50\n",
      "3138/3138 [==============================] - 2s 695us/step - loss: 0.2100 - acc: 0.9780\n",
      "Epoch 4/50\n",
      "3138/3138 [==============================] - 2s 787us/step - loss: 0.1832 - acc: 0.9825\n",
      "Epoch 5/50\n",
      "3138/3138 [==============================] - 2s 747us/step - loss: 0.1841 - acc: 0.9806\n",
      "Epoch 6/50\n",
      "3138/3138 [==============================] - 3s 896us/step - loss: 0.2008 - acc: 0.9793\n",
      "Epoch 7/50\n",
      "3138/3138 [==============================] - 3s 829us/step - loss: 0.1844 - acc: 0.9837 0s - loss: 0.1680 - acc:\n",
      "Epoch 8/50\n",
      "3138/3138 [==============================] - 3s 817us/step - loss: 0.1560 - acc: 0.9850\n",
      "Epoch 9/50\n",
      "3138/3138 [==============================] - 2s 764us/step - loss: 0.1470 - acc: 0.9847\n",
      "Epoch 10/50\n",
      "3138/3138 [==============================] - 2s 725us/step - loss: 0.1834 - acc: 0.9825 1s - l\n",
      "Epoch 11/50\n",
      "3138/3138 [==============================] - 2s 719us/step - loss: 0.2423 - acc: 0.9828\n",
      "Epoch 12/50\n",
      "3138/3138 [==============================] - 2s 711us/step - loss: 0.2062 - acc: 0.9844\n",
      "Epoch 13/50\n",
      "3138/3138 [==============================] - 2s 643us/step - loss: 0.2061 - acc: 0.9847\n",
      "Epoch 14/50\n",
      "3138/3138 [==============================] - 2s 570us/step - loss: 0.2019 - acc: 0.9847 0s - loss: 0.1970 - acc: 0.9\n",
      "Epoch 15/50\n",
      "3138/3138 [==============================] - 2s 587us/step - loss: 0.2097 - acc: 0.9818\n",
      "Epoch 16/50\n",
      "3138/3138 [==============================] - 2s 673us/step - loss: 0.1934 - acc: 0.9818\n",
      "Epoch 17/50\n",
      "3138/3138 [==============================] - 2s 746us/step - loss: 0.1452 - acc: 0.9876\n",
      "Epoch 18/50\n",
      "3138/3138 [==============================] - 2s 694us/step - loss: 0.1345 - acc: 0.9863\n",
      "Epoch 19/50\n",
      "3138/3138 [==============================] - 2s 711us/step - loss: 0.1884 - acc: 0.9853 2\n",
      "Epoch 20/50\n",
      "3138/3138 [==============================] - 2s 750us/step - loss: 0.1647 - acc: 0.9828\n",
      "Epoch 21/50\n",
      "3138/3138 [==============================] - 2s 743us/step - loss: 0.1368 - acc: 0.9882\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3138/3138 [==============================] - 2s 623us/step - loss: 0.1259 - acc: 0.9869\n",
      "Epoch 23/50\n",
      "3138/3138 [==============================] - 2s 616us/step - loss: 0.1440 - acc: 0.9857\n",
      "Epoch 24/50\n",
      "3138/3138 [==============================] - 2s 628us/step - loss: 0.1351 - acc: 0.9853\n",
      "Epoch 25/50\n",
      "3138/3138 [==============================] - 2s 585us/step - loss: 0.1280 - acc: 0.9898 0s - loss: 0.1218 - acc: 0.\n",
      "Epoch 26/50\n",
      "3138/3138 [==============================] - 2s 642us/step - loss: 0.1248 - acc: 0.9885\n",
      "Epoch 27/50\n",
      "3138/3138 [==============================] - 2s 712us/step - loss: 0.1213 - acc: 0.9853\n",
      "Epoch 28/50\n",
      "3138/3138 [==============================] - 2s 698us/step - loss: 0.1094 - acc: 0.9888\n",
      "Epoch 29/50\n",
      "3138/3138 [==============================] - 2s 680us/step - loss: 0.1140 - acc: 0.9888\n",
      "Epoch 30/50\n",
      "3138/3138 [==============================] - 2s 722us/step - loss: 0.1077 - acc: 0.9888\n",
      "Epoch 31/50\n",
      "3138/3138 [==============================] - 2s 755us/step - loss: 0.1033 - acc: 0.9882\n",
      "Epoch 32/50\n",
      "3138/3138 [==============================] - 3s 850us/step - loss: 0.0973 - acc: 0.9888\n",
      "Epoch 33/50\n",
      "3138/3138 [==============================] - 3s 851us/step - loss: 0.0978 - acc: 0.9895\n",
      "Epoch 34/50\n",
      "3138/3138 [==============================] - 3s 872us/step - loss: 0.1389 - acc: 0.9847\n",
      "Epoch 35/50\n",
      "3138/3138 [==============================] - 3s 804us/step - loss: 0.1325 - acc: 0.9876\n",
      "Epoch 36/50\n",
      "3138/3138 [==============================] - 2s 703us/step - loss: 0.1108 - acc: 0.9860\n",
      "Epoch 37/50\n",
      "3138/3138 [==============================] - 2s 735us/step - loss: 0.1031 - acc: 0.9885\n",
      "Epoch 38/50\n",
      "3138/3138 [==============================] - 2s 664us/step - loss: 0.0987 - acc: 0.9898\n",
      "Epoch 39/50\n",
      "3138/3138 [==============================] - 2s 699us/step - loss: 0.0994 - acc: 0.9873\n",
      "Epoch 40/50\n",
      "3138/3138 [==============================] - 2s 725us/step - loss: 0.0886 - acc: 0.9885\n",
      "Epoch 41/50\n",
      "3138/3138 [==============================] - 2s 604us/step - loss: 0.1137 - acc: 0.9885\n",
      "Epoch 42/50\n",
      "3138/3138 [==============================] - 2s 655us/step - loss: 0.0976 - acc: 0.9888\n",
      "Epoch 43/50\n",
      "3138/3138 [==============================] - 2s 631us/step - loss: 0.0879 - acc: 0.9908\n",
      "Epoch 44/50\n",
      "3138/3138 [==============================] - 2s 668us/step - loss: 0.0949 - acc: 0.9892\n",
      "Epoch 45/50\n",
      "3138/3138 [==============================] - 2s 761us/step - loss: 0.0877 - acc: 0.9904\n",
      "Epoch 46/50\n",
      "3138/3138 [==============================] - 3s 842us/step - loss: 0.1029 - acc: 0.9879\n",
      "Epoch 47/50\n",
      "3138/3138 [==============================] - 3s 803us/step - loss: 0.0897 - acc: 0.9882\n",
      "Epoch 48/50\n",
      "3138/3138 [==============================] - 2s 714us/step - loss: 0.1371 - acc: 0.9860\n",
      "Epoch 49/50\n",
      "3138/3138 [==============================] - 2s 672us/step - loss: 0.1122 - acc: 0.9888\n",
      "Epoch 50/50\n",
      "3138/3138 [==============================] - 2s 771us/step - loss: 0.1084 - acc: 0.9873\n",
      "349/349 [==============================] - 1s 3ms/step\n",
      "Epoch 1/50\n",
      "3139/3139 [==============================] - 6s 2ms/step - loss: 0.2374 - acc: 0.9783\n",
      "Epoch 2/50\n",
      "3139/3139 [==============================] - 2s 696us/step - loss: 0.1433 - acc: 0.9857\n",
      "Epoch 3/50\n",
      "3139/3139 [==============================] - 2s 717us/step - loss: 0.1990 - acc: 0.9822\n",
      "Epoch 4/50\n",
      "3139/3139 [==============================] - 2s 729us/step - loss: 0.1528 - acc: 0.9853\n",
      "Epoch 5/50\n",
      "3139/3139 [==============================] - 3s 857us/step - loss: 0.1507 - acc: 0.9847\n",
      "Epoch 6/50\n",
      "3139/3139 [==============================] - 3s 823us/step - loss: 0.1427 - acc: 0.9841\n",
      "Epoch 7/50\n",
      "3139/3139 [==============================] - 3s 869us/step - loss: 0.1510 - acc: 0.9844\n",
      "Epoch 8/50\n",
      "3139/3139 [==============================] - 2s 635us/step - loss: 0.1307 - acc: 0.9869\n",
      "Epoch 9/50\n",
      "3139/3139 [==============================] - 2s 761us/step - loss: 0.1272 - acc: 0.9873\n",
      "Epoch 10/50\n",
      "3139/3139 [==============================] - 2s 775us/step - loss: 0.1580 - acc: 0.9844\n",
      "Epoch 11/50\n",
      "3139/3139 [==============================] - 2s 673us/step - loss: 0.1538 - acc: 0.9841\n",
      "Epoch 12/50\n",
      "3139/3139 [==============================] - 2s 694us/step - loss: 0.2174 - acc: 0.9838\n",
      "Epoch 13/50\n",
      "3139/3139 [==============================] - 2s 701us/step - loss: 0.1571 - acc: 0.9822\n",
      "Epoch 14/50\n",
      "3139/3139 [==============================] - 2s 758us/step - loss: 0.1351 - acc: 0.9888\n",
      "Epoch 15/50\n",
      "3139/3139 [==============================] - 2s 689us/step - loss: 0.1313 - acc: 0.9876\n",
      "Epoch 16/50\n",
      "3139/3139 [==============================] - 2s 755us/step - loss: 0.1289 - acc: 0.9869\n",
      "Epoch 17/50\n",
      "3139/3139 [==============================] - 2s 684us/step - loss: 0.1211 - acc: 0.9857\n",
      "Epoch 18/50\n",
      "3139/3139 [==============================] - 2s 716us/step - loss: 0.1110 - acc: 0.9892\n",
      "Epoch 19/50\n",
      "3139/3139 [==============================] - 2s 703us/step - loss: 0.1094 - acc: 0.9895\n",
      "Epoch 20/50\n",
      "3139/3139 [==============================] - 2s 617us/step - loss: 0.1246 - acc: 0.9876\n",
      "Epoch 21/50\n",
      "3139/3139 [==============================] - 2s 595us/step - loss: 0.1257 - acc: 0.9892\n",
      "Epoch 22/50\n",
      "3139/3139 [==============================] - 2s 632us/step - loss: 0.1477 - acc: 0.9812\n",
      "Epoch 23/50\n",
      "3139/3139 [==============================] - 2s 671us/step - loss: 0.1204 - acc: 0.9885\n",
      "Epoch 24/50\n",
      "3139/3139 [==============================] - 2s 707us/step - loss: 0.1301 - acc: 0.9885\n",
      "Epoch 25/50\n",
      "3139/3139 [==============================] - 2s 761us/step - loss: 0.1123 - acc: 0.9895\n",
      "Epoch 26/50\n",
      "3139/3139 [==============================] - 2s 690us/step - loss: 0.1105 - acc: 0.9888\n",
      "Epoch 27/50\n",
      "3139/3139 [==============================] - 2s 685us/step - loss: 0.1134 - acc: 0.9895\n",
      "Epoch 28/50\n",
      "3139/3139 [==============================] - 2s 774us/step - loss: 0.1036 - acc: 0.9895\n",
      "Epoch 29/50\n",
      "3139/3139 [==============================] - 2s 739us/step - loss: 0.1060 - acc: 0.9885\n",
      "Epoch 30/50\n",
      "3139/3139 [==============================] - 2s 727us/step - loss: 0.1019 - acc: 0.9898\n",
      "Epoch 31/50\n",
      "3139/3139 [==============================] - 2s 737us/step - loss: 0.1262 - acc: 0.9876\n",
      "Epoch 32/50\n",
      "3139/3139 [==============================] - 3s 905us/step - loss: 0.0997 - acc: 0.9898\n",
      "Epoch 33/50\n",
      "3139/3139 [==============================] - 3s 825us/step - loss: 0.1438 - acc: 0.9853\n",
      "Epoch 34/50\n",
      "3139/3139 [==============================] - 3s 851us/step - loss: 0.2279 - acc: 0.9790\n",
      "Epoch 35/50\n",
      "3139/3139 [==============================] - 2s 732us/step - loss: 0.1798 - acc: 0.9866\n",
      "Epoch 36/50\n",
      "3139/3139 [==============================] - 2s 742us/step - loss: 0.1986 - acc: 0.9834\n",
      "Epoch 37/50\n",
      "3139/3139 [==============================] - 2s 644us/step - loss: 0.2067 - acc: 0.9850\n",
      "Epoch 38/50\n",
      "3139/3139 [==============================] - 2s 603us/step - loss: 0.1407 - acc: 0.9841\n",
      "Epoch 39/50\n",
      "3139/3139 [==============================] - 2s 640us/step - loss: 0.1404 - acc: 0.9860\n",
      "Epoch 40/50\n",
      "3139/3139 [==============================] - 2s 661us/step - loss: 0.1660 - acc: 0.9850\n",
      "Epoch 41/50\n",
      "3139/3139 [==============================] - 2s 655us/step - loss: 0.1389 - acc: 0.9857\n",
      "Epoch 42/50\n",
      "3139/3139 [==============================] - 1s 472us/step - loss: 0.1063 - acc: 0.9860\n",
      "Epoch 43/50\n",
      "3139/3139 [==============================] - 2s 510us/step - loss: 0.1245 - acc: 0.9873\n",
      "Epoch 44/50\n",
      "3139/3139 [==============================] - 2s 497us/step - loss: 0.0983 - acc: 0.9892\n",
      "Epoch 45/50\n",
      "3139/3139 [==============================] - 2s 595us/step - loss: 0.2201 - acc: 0.9847\n",
      "Epoch 46/50\n",
      "3139/3139 [==============================] - 2s 603us/step - loss: 0.1837 - acc: 0.9866 0s - loss: 0.1977 - a\n",
      "Epoch 47/50\n",
      "3139/3139 [==============================] - 2s 582us/step - loss: 0.1276 - acc: 0.9879\n",
      "Epoch 48/50\n",
      "3139/3139 [==============================] - 2s 623us/step - loss: 0.1153 - acc: 0.9888\n",
      "Epoch 49/50\n",
      "3139/3139 [==============================] - 2s 589us/step - loss: 0.1779 - acc: 0.9841\n",
      "Epoch 50/50\n",
      "3139/3139 [==============================] - 2s 587us/step - loss: 0.1193 - acc: 0.9882\n",
      "348/348 [==============================] - 0s 761us/step\n",
      "Epoch 1/50\n",
      "3139/3139 [==============================] - 5s 2ms/step - loss: 0.2206 - acc: 0.9755\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3139/3139 [==============================] - 2s 633us/step - loss: 0.1648 - acc: 0.9815\n",
      "Epoch 3/50\n",
      "3139/3139 [==============================] - 2s 596us/step - loss: 0.2032 - acc: 0.9806\n",
      "Epoch 4/50\n",
      "3139/3139 [==============================] - 2s 623us/step - loss: 0.1420 - acc: 0.9863\n",
      "Epoch 5/50\n",
      "3139/3139 [==============================] - 2s 617us/step - loss: 0.1349 - acc: 0.9860\n",
      "Epoch 6/50\n",
      "3139/3139 [==============================] - 2s 627us/step - loss: 0.1839 - acc: 0.9828\n",
      "Epoch 7/50\n",
      "3139/3139 [==============================] - 2s 618us/step - loss: 0.1631 - acc: 0.9822\n",
      "Epoch 8/50\n",
      "3139/3139 [==============================] - 3s 803us/step - loss: 0.1456 - acc: 0.9876\n",
      "Epoch 9/50\n",
      "3139/3139 [==============================] - 2s 746us/step - loss: 0.1733 - acc: 0.9806\n",
      "Epoch 10/50\n",
      "3139/3139 [==============================] - 2s 695us/step - loss: 0.1305 - acc: 0.9863\n",
      "Epoch 11/50\n",
      "3139/3139 [==============================] - 2s 763us/step - loss: 0.1350 - acc: 0.9863\n",
      "Epoch 12/50\n",
      "3139/3139 [==============================] - 2s 662us/step - loss: 0.1796 - acc: 0.9850\n",
      "Epoch 13/50\n",
      "3139/3139 [==============================] - 2s 570us/step - loss: 0.1792 - acc: 0.9806\n",
      "Epoch 14/50\n",
      "3139/3139 [==============================] - 2s 620us/step - loss: 0.2021 - acc: 0.9834\n",
      "Epoch 15/50\n",
      "3139/3139 [==============================] - 2s 648us/step - loss: 0.1540 - acc: 0.9857\n",
      "Epoch 16/50\n",
      "3139/3139 [==============================] - 2s 639us/step - loss: 0.1417 - acc: 0.9866\n",
      "Epoch 17/50\n",
      "3139/3139 [==============================] - 2s 687us/step - loss: 0.1328 - acc: 0.9876\n",
      "Epoch 18/50\n",
      "3139/3139 [==============================] - 2s 659us/step - loss: 0.1719 - acc: 0.9831\n",
      "Epoch 19/50\n",
      "3139/3139 [==============================] - 2s 560us/step - loss: 0.1391 - acc: 0.9885\n",
      "Epoch 20/50\n",
      "3139/3139 [==============================] - 2s 541us/step - loss: 0.1452 - acc: 0.9882\n",
      "Epoch 21/50\n",
      "3139/3139 [==============================] - 2s 522us/step - loss: 0.1733 - acc: 0.9860\n",
      "Epoch 22/50\n",
      "3139/3139 [==============================] - 2s 562us/step - loss: 0.1345 - acc: 0.9860\n",
      "Epoch 23/50\n",
      "3139/3139 [==============================] - 2s 620us/step - loss: 0.1311 - acc: 0.9885\n",
      "Epoch 24/50\n",
      "3139/3139 [==============================] - 2s 656us/step - loss: 0.1274 - acc: 0.9892\n",
      "Epoch 25/50\n",
      "3139/3139 [==============================] - 2s 604us/step - loss: 0.1284 - acc: 0.9860\n",
      "Epoch 26/50\n",
      "3139/3139 [==============================] - 2s 600us/step - loss: 0.1253 - acc: 0.9879 1s - loss: 0.\n",
      "Epoch 27/50\n",
      "3139/3139 [==============================] - 2s 618us/step - loss: 0.1287 - acc: 0.9882\n",
      "Epoch 28/50\n",
      "3139/3139 [==============================] - 2s 675us/step - loss: 0.1186 - acc: 0.9888\n",
      "Epoch 29/50\n",
      "3139/3139 [==============================] - 2s 662us/step - loss: 0.1375 - acc: 0.9869\n",
      "Epoch 30/50\n",
      "3139/3139 [==============================] - 2s 639us/step - loss: 0.1450 - acc: 0.9863\n",
      "Epoch 31/50\n",
      "3139/3139 [==============================] - 2s 592us/step - loss: 0.1363 - acc: 0.9882\n",
      "Epoch 32/50\n",
      "3139/3139 [==============================] - 2s 646us/step - loss: 0.1845 - acc: 0.9809\n",
      "Epoch 33/50\n",
      "3139/3139 [==============================] - 2s 601us/step - loss: 0.1776 - acc: 0.9860\n",
      "Epoch 34/50\n",
      "3139/3139 [==============================] - 2s 591us/step - loss: 0.1414 - acc: 0.9850\n",
      "Epoch 35/50\n",
      "3139/3139 [==============================] - 2s 486us/step - loss: 0.1191 - acc: 0.9879\n",
      "Epoch 36/50\n",
      "3139/3139 [==============================] - 1s 408us/step - loss: 0.1163 - acc: 0.9888\n",
      "Epoch 37/50\n",
      "3139/3139 [==============================] - 2s 493us/step - loss: 0.1108 - acc: 0.9888\n",
      "Epoch 38/50\n",
      "3139/3139 [==============================] - 2s 695us/step - loss: 0.1121 - acc: 0.9885\n",
      "Epoch 39/50\n",
      "3139/3139 [==============================] - 2s 665us/step - loss: 0.1101 - acc: 0.9888\n",
      "Epoch 40/50\n",
      "3139/3139 [==============================] - 2s 730us/step - loss: 0.1202 - acc: 0.9882\n",
      "Epoch 41/50\n",
      "3139/3139 [==============================] - 2s 662us/step - loss: 0.1084 - acc: 0.9879\n",
      "Epoch 42/50\n",
      "3139/3139 [==============================] - 2s 716us/step - loss: 0.1092 - acc: 0.9885\n",
      "Epoch 43/50\n",
      "3139/3139 [==============================] - 2s 662us/step - loss: 0.1081 - acc: 0.9882\n",
      "Epoch 44/50\n",
      "3139/3139 [==============================] - 2s 561us/step - loss: 0.1053 - acc: 0.9898\n",
      "Epoch 45/50\n",
      "3139/3139 [==============================] - 2s 662us/step - loss: 0.1067 - acc: 0.9882\n",
      "Epoch 46/50\n",
      "3139/3139 [==============================] - 2s 532us/step - loss: 0.1066 - acc: 0.9888\n",
      "Epoch 47/50\n",
      "3139/3139 [==============================] - 2s 604us/step - loss: 0.1058 - acc: 0.9885\n",
      "Epoch 48/50\n",
      "3139/3139 [==============================] - 2s 624us/step - loss: 0.1041 - acc: 0.9895\n",
      "Epoch 49/50\n",
      "3139/3139 [==============================] - 2s 563us/step - loss: 0.1058 - acc: 0.9895\n",
      "Epoch 50/50\n",
      "3139/3139 [==============================] - 2s 577us/step - loss: 0.1046 - acc: 0.9892\n",
      "348/348 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "3139/3139 [==============================] - 4s 1ms/step - loss: 0.3582 - acc: 0.9720\n",
      "Epoch 2/50\n",
      "3139/3139 [==============================] - 2s 625us/step - loss: 0.2254 - acc: 0.9809\n",
      "Epoch 3/50\n",
      "3139/3139 [==============================] - 2s 583us/step - loss: 0.2323 - acc: 0.9822\n",
      "Epoch 4/50\n",
      "3139/3139 [==============================] - 2s 598us/step - loss: 0.1567 - acc: 0.9847\n",
      "Epoch 5/50\n",
      "3139/3139 [==============================] - 2s 580us/step - loss: 0.1502 - acc: 0.9831\n",
      "Epoch 6/50\n",
      "3139/3139 [==============================] - 2s 660us/step - loss: 0.1434 - acc: 0.9873\n",
      "Epoch 7/50\n",
      "3139/3139 [==============================] - 2s 581us/step - loss: 0.1357 - acc: 0.9869\n",
      "Epoch 8/50\n",
      "3139/3139 [==============================] - 2s 626us/step - loss: 0.1658 - acc: 0.9860\n",
      "Epoch 9/50\n",
      "3139/3139 [==============================] - 2s 605us/step - loss: 0.2410 - acc: 0.9752\n",
      "Epoch 10/50\n",
      "3139/3139 [==============================] - 2s 585us/step - loss: 0.1553 - acc: 0.9866\n",
      "Epoch 11/50\n",
      "3139/3139 [==============================] - 2s 647us/step - loss: 0.1392 - acc: 0.9876\n",
      "Epoch 12/50\n",
      "3139/3139 [==============================] - 2s 637us/step - loss: 0.1341 - acc: 0.9869\n",
      "Epoch 13/50\n",
      "3139/3139 [==============================] - 2s 637us/step - loss: 0.1765 - acc: 0.9828\n",
      "Epoch 14/50\n",
      "3139/3139 [==============================] - 2s 596us/step - loss: 0.1334 - acc: 0.9866\n",
      "Epoch 15/50\n",
      "3139/3139 [==============================] - 2s 637us/step - loss: 0.1539 - acc: 0.9857\n",
      "Epoch 16/50\n",
      "3139/3139 [==============================] - 2s 652us/step - loss: 0.1574 - acc: 0.9876\n",
      "Epoch 17/50\n",
      "3139/3139 [==============================] - 2s 627us/step - loss: 0.1349 - acc: 0.9882\n",
      "Epoch 18/50\n",
      "3139/3139 [==============================] - 2s 747us/step - loss: 0.1921 - acc: 0.9838 1s\n",
      "Epoch 19/50\n",
      "3139/3139 [==============================] - 2s 638us/step - loss: 0.2193 - acc: 0.9841\n",
      "Epoch 20/50\n",
      "3139/3139 [==============================] - 2s 584us/step - loss: 0.2171 - acc: 0.9844\n",
      "Epoch 21/50\n",
      "3139/3139 [==============================] - 2s 553us/step - loss: 0.2169 - acc: 0.9841\n",
      "Epoch 22/50\n",
      "3139/3139 [==============================] - 2s 505us/step - loss: 0.2175 - acc: 0.9841\n",
      "Epoch 23/50\n",
      "3139/3139 [==============================] - 2s 601us/step - loss: 0.2171 - acc: 0.9850\n",
      "Epoch 24/50\n",
      "3139/3139 [==============================] - 2s 601us/step - loss: 0.2165 - acc: 0.9841\n",
      "Epoch 25/50\n",
      "3139/3139 [==============================] - 2s 592us/step - loss: 0.2164 - acc: 0.9844\n",
      "Epoch 26/50\n",
      "3139/3139 [==============================] - 2s 631us/step - loss: 0.2158 - acc: 0.9844\n",
      "Epoch 27/50\n",
      "3139/3139 [==============================] - 2s 549us/step - loss: 0.2172 - acc: 0.9841\n",
      "Epoch 28/50\n",
      "3139/3139 [==============================] - 2s 576us/step - loss: 0.2291 - acc: 0.9787\n",
      "Epoch 29/50\n",
      "3139/3139 [==============================] - 2s 500us/step - loss: 0.1646 - acc: 0.9876 1s - los\n",
      "Epoch 30/50\n",
      "3139/3139 [==============================] - 2s 490us/step - loss: 0.1524 - acc: 0.9863\n",
      "Epoch 31/50\n",
      "3139/3139 [==============================] - 2s 537us/step - loss: 0.1402 - acc: 0.9876\n",
      "Epoch 32/50\n",
      "3139/3139 [==============================] - 2s 653us/step - loss: 0.1340 - acc: 0.9879\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3139/3139 [==============================] - 2s 610us/step - loss: 0.1320 - acc: 0.9873\n",
      "Epoch 34/50\n",
      "3139/3139 [==============================] - 2s 605us/step - loss: 0.1334 - acc: 0.9882\n",
      "Epoch 35/50\n",
      "3139/3139 [==============================] - 2s 630us/step - loss: 0.1600 - acc: 0.9834\n",
      "Epoch 36/50\n",
      "3139/3139 [==============================] - 2s 639us/step - loss: 0.1538 - acc: 0.9869\n",
      "Epoch 37/50\n",
      "3139/3139 [==============================] - 2s 611us/step - loss: 0.1491 - acc: 0.9860\n",
      "Epoch 38/50\n",
      "3139/3139 [==============================] - 2s 632us/step - loss: 0.1337 - acc: 0.9882\n",
      "Epoch 39/50\n",
      "3139/3139 [==============================] - 2s 623us/step - loss: 0.1361 - acc: 0.9882\n",
      "Epoch 40/50\n",
      "3139/3139 [==============================] - 2s 632us/step - loss: 0.1348 - acc: 0.9873\n",
      "Epoch 41/50\n",
      "3139/3139 [==============================] - 2s 663us/step - loss: 0.1344 - acc: 0.9879\n",
      "Epoch 42/50\n",
      "3139/3139 [==============================] - 2s 531us/step - loss: 0.1482 - acc: 0.9847\n",
      "Epoch 43/50\n",
      "3139/3139 [==============================] - 2s 645us/step - loss: 0.1530 - acc: 0.9873\n",
      "Epoch 44/50\n",
      "3139/3139 [==============================] - 2s 670us/step - loss: 0.1447 - acc: 0.9831\n",
      "Epoch 45/50\n",
      "3139/3139 [==============================] - 2s 640us/step - loss: 0.1358 - acc: 0.9879\n",
      "Epoch 46/50\n",
      "3139/3139 [==============================] - 2s 607us/step - loss: 0.1325 - acc: 0.9866 0s - loss: 0.1358 - acc\n",
      "Epoch 47/50\n",
      "3139/3139 [==============================] - 2s 708us/step - loss: 0.1268 - acc: 0.9876\n",
      "Epoch 48/50\n",
      "3139/3139 [==============================] - 2s 671us/step - loss: 0.1347 - acc: 0.9857\n",
      "Epoch 49/50\n",
      "3139/3139 [==============================] - 2s 671us/step - loss: 0.1248 - acc: 0.9882\n",
      "Epoch 50/50\n",
      "3139/3139 [==============================] - 2s 717us/step - loss: 0.1241 - acc: 0.9876\n",
      "348/348 [==============================] - 0s 1ms/step\n",
      "Accuracy mean: 0.98536788162\n",
      "Accuracy variance: 0.00754617247976\n",
      "(' Time ', '1109.393', ' seconds')\n",
      "[[1460    8]\n",
      " [  10   17]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.99      0.99      1468\n",
      "        1.0       0.68      0.63      0.65        27\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# estimators \n",
    "# Evaluating the ANN\n",
    "t0 = time()\n",
    "# estimators \n",
    "# Evaluating the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 1024, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n",
    "    classifier.add(Dense(units = 512, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 50)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of DecisionTreeClassifier = 98.327759 %\n",
      "(' Time ', '0.113', ' seconds')\n",
      "[[1454   14]\n",
      " [  11   16]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.99      0.99      1468\n",
      "        1.0       0.53      0.59      0.56        27\n",
      "\n",
      "avg / total       0.98      0.98      0.98      1495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of DecisionTreeClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of RandomForestClassifier = 99.264214 %\n",
      "(' Time ', '3.542', ' seconds')\n",
      "[[1465    3]\n",
      " [   8   19]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      1.00      1468\n",
      "        1.0       0.86      0.70      0.78        27\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of RandomForestClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of ExtraTreesClassifier = 99.063545 %\n",
      "(' Time ', '2.0', ' seconds')\n",
      "[[1464    4]\n",
      " [  10   17]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      1.00      1468\n",
      "        1.0       0.81      0.63      0.71        27\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of ExtraTreesClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of AdaBoostClassifier = 98.795987 %\n",
      "(' Time ', '1.482', ' seconds')\n",
      "[[1463    5]\n",
      " [  13   14]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      0.99      1468\n",
      "        1.0       0.74      0.52      0.61        27\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of AdaBoostClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Naive_bayes  GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GaussianNB = 94.314381 %\n",
      "(' Time ', '0.007', ' seconds')\n",
      "[[1396   72]\n",
      " [  13   14]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.95      0.97      1468\n",
      "        1.0       0.16      0.52      0.25        27\n",
      "\n",
      "avg / total       0.98      0.94      0.96      1495\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred= gnb.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of GaussianNB = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
