{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt \n",
    "from pprint import pprint\n",
    "from numpy import array\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df=pd.read_csv('diabetes.csv')  \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df to values\n",
    "df = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GC Forest\n",
    "import argparse\n",
    "import sys\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "sys.path.insert(0, \"lib\")\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.utils.config_utils import load_json\n",
    "config = load_json(\"./examples/aloi.json\")   \n",
    "gc = GCForest(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kader/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# train test \n",
    "from sklearn.cross_validation import train_test_split\n",
    "y = df[:,8]\n",
    "X = df[:,0:8]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of class\n",
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2019-01-12 10:38:55,802][cascade_classifier.fit_transform] X_groups_train.shape=[(537, 8)],y_train.shape=(537,),X_groups_test.shape=[(231, 8)],y_test.shape=(231,)\n",
      "[ 2019-01-12 10:38:55,806][cascade_classifier.fit_transform] group_dims=[8]\n",
      "[ 2019-01-12 10:38:55,810][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2019-01-12 10:38:55,812][cascade_classifier.fit_transform] group_ends=[8]\n",
      "[ 2019-01-12 10:38:55,813][cascade_classifier.fit_transform] X_train.shape=(537, 8),X_test.shape=(231, 8)\n",
      "[ 2019-01-12 10:38:55,815][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(537, 8), X_cur_test.shape=(231, 8)\n",
      "[ 2019-01-12 10:38:56,500][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=72.73%\n",
      "[ 2019-01-12 10:38:57,328][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=70.91%\n",
      "[ 2019-01-12 10:38:58,102][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=61.82%\n",
      "[ 2019-01-12 10:38:58,864][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=75.93%\n",
      "[ 2019-01-12 10:38:59,621][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=79.25%\n",
      "[ 2019-01-12 10:39:00,422][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=90.57%\n",
      "[ 2019-01-12 10:39:01,239][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=73.58%\n",
      "[ 2019-01-12 10:39:02,079][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=69.81%\n",
      "[ 2019-01-12 10:39:02,879][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=77.36%\n",
      "[ 2019-01-12 10:39:03,683][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=71.70%\n",
      "[ 2019-01-12 10:39:03,798][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=74.30%\n",
      "[ 2019-01-12 10:39:03,799][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=76.19%\n",
      "[ 2019-01-12 10:39:04,444][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_0.predict)=78.18%\n",
      "[ 2019-01-12 10:39:05,204][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_1.predict)=67.27%\n",
      "[ 2019-01-12 10:39:05,979][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_2.predict)=67.27%\n",
      "[ 2019-01-12 10:39:06,740][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_3.predict)=77.78%\n",
      "[ 2019-01-12 10:39:07,531][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_4.predict)=81.13%\n",
      "[ 2019-01-12 10:39:08,304][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_5.predict)=84.91%\n",
      "[ 2019-01-12 10:39:09,088][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_6.predict)=77.36%\n",
      "[ 2019-01-12 10:39:09,844][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_7.predict)=71.70%\n",
      "[ 2019-01-12 10:39:10,607][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_8.predict)=77.36%\n",
      "[ 2019-01-12 10:39:11,428][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_9.predict)=75.47%\n",
      "[ 2019-01-12 10:39:11,552][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_cv.predict)=75.79%\n",
      "[ 2019-01-12 10:39:11,555][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.test.predict)=78.79%\n",
      "[ 2019-01-12 10:39:11,895][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_0.predict)=72.73%\n",
      "[ 2019-01-12 10:39:11,932][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_1.predict)=72.73%\n",
      "[ 2019-01-12 10:39:11,944][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_2.predict)=85.45%\n",
      "[ 2019-01-12 10:39:11,954][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_3.predict)=79.63%\n",
      "[ 2019-01-12 10:39:11,966][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_4.predict)=69.81%\n",
      "[ 2019-01-12 10:39:11,974][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_5.predict)=77.36%\n",
      "[ 2019-01-12 10:39:11,981][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_6.predict)=77.36%\n",
      "[ 2019-01-12 10:39:11,988][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_7.predict)=62.26%\n",
      "[ 2019-01-12 10:39:11,997][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_8.predict)=77.36%\n",
      "[ 2019-01-12 10:39:12,005][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_9.predict)=73.58%\n",
      "[ 2019-01-12 10:39:12,009][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_cv.predict)=74.86%\n",
      "[ 2019-01-12 10:39:12,010][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.test.predict)=78.35%\n",
      "[ 2019-01-12 10:39:12,011][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=74.12%\n",
      "[ 2019-01-12 10:39:12,012][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=78.35%\n",
      "[ 2019-01-12 10:39:12,014][cascade_classifier.fit_transform] [layer=1] look_indexs=[0], X_cur_train.shape=(537, 14), X_cur_test.shape=(231, 14)\n",
      "[ 2019-01-12 10:39:12,704][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_0.predict)=81.82%\n",
      "[ 2019-01-12 10:39:13,503][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_1.predict)=72.73%\n",
      "[ 2019-01-12 10:39:14,287][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_2.predict)=69.09%\n",
      "[ 2019-01-12 10:39:15,083][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_3.predict)=81.48%\n",
      "[ 2019-01-12 10:39:15,901][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_4.predict)=67.92%\n",
      "[ 2019-01-12 10:39:16,702][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_5.predict)=79.25%\n",
      "[ 2019-01-12 10:39:17,468][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_6.predict)=73.58%\n",
      "[ 2019-01-12 10:39:18,254][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_7.predict)=67.92%\n",
      "[ 2019-01-12 10:39:19,045][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_8.predict)=73.58%\n",
      "[ 2019-01-12 10:39:19,831][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_9.predict)=71.70%\n",
      "[ 2019-01-12 10:39:19,958][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_cv.predict)=73.93%\n",
      "[ 2019-01-12 10:39:19,963][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.test.predict)=74.89%\n",
      "[ 2019-01-12 10:39:20,568][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_0.predict)=85.45%\n",
      "[ 2019-01-12 10:39:21,355][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_1.predict)=76.36%\n",
      "[ 2019-01-12 10:39:22,116][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_2.predict)=81.82%\n",
      "[ 2019-01-12 10:39:22,923][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_3.predict)=83.33%\n",
      "[ 2019-01-12 10:39:23,673][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_4.predict)=64.15%\n",
      "[ 2019-01-12 10:39:24,425][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_5.predict)=67.92%\n",
      "[ 2019-01-12 10:39:25,179][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_6.predict)=83.02%\n",
      "[ 2019-01-12 10:39:25,929][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_7.predict)=75.47%\n",
      "[ 2019-01-12 10:39:26,694][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_8.predict)=69.81%\n",
      "[ 2019-01-12 10:39:27,444][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_9.predict)=73.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2019-01-12 10:39:27,571][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_cv.predict)=76.16%\n",
      "[ 2019-01-12 10:39:27,572][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.test.predict)=75.76%\n",
      "[ 2019-01-12 10:39:27,588][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_0.predict)=72.73%\n",
      "[ 2019-01-12 10:39:27,600][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_1.predict)=78.18%\n",
      "[ 2019-01-12 10:39:27,611][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_2.predict)=81.82%\n",
      "[ 2019-01-12 10:39:27,624][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_3.predict)=72.22%\n",
      "[ 2019-01-12 10:39:27,637][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_4.predict)=86.79%\n",
      "[ 2019-01-12 10:39:27,648][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_5.predict)=73.58%\n",
      "[ 2019-01-12 10:39:27,658][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_6.predict)=77.36%\n",
      "[ 2019-01-12 10:39:27,669][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_7.predict)=64.15%\n",
      "[ 2019-01-12 10:39:27,680][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_8.predict)=71.70%\n",
      "[ 2019-01-12 10:39:27,691][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_9.predict)=67.92%\n",
      "[ 2019-01-12 10:39:27,692][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_cv.predict)=74.67%\n",
      "[ 2019-01-12 10:39:27,694][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.test.predict)=78.35%\n",
      "[ 2019-01-12 10:39:27,695][cascade_classifier.calc_accuracy] Accuracy(layer_1 - train.classifier_average)=75.42%\n",
      "[ 2019-01-12 10:39:27,697][cascade_classifier.calc_accuracy] Accuracy(layer_1 - test.classifier_average)=76.62%\n",
      "[ 2019-01-12 10:39:27,710][cascade_classifier.fit_transform] [layer=2] look_indexs=[0], X_cur_train.shape=(537, 14), X_cur_test.shape=(231, 14)\n",
      "[ 2019-01-12 10:39:28,416][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_0.predict)=80.00%\n",
      "[ 2019-01-12 10:39:29,198][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_1.predict)=72.73%\n",
      "[ 2019-01-12 10:39:29,947][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_2.predict)=69.09%\n",
      "[ 2019-01-12 10:39:30,746][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_3.predict)=61.11%\n",
      "[ 2019-01-12 10:39:31,521][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_4.predict)=88.68%\n",
      "[ 2019-01-12 10:39:32,312][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_5.predict)=77.36%\n",
      "[ 2019-01-12 10:39:33,097][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_6.predict)=83.02%\n",
      "[ 2019-01-12 10:39:33,908][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_7.predict)=69.81%\n",
      "[ 2019-01-12 10:39:34,729][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_8.predict)=83.02%\n",
      "[ 2019-01-12 10:39:35,548][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_9.predict)=62.26%\n",
      "[ 2019-01-12 10:39:35,681][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_cv.predict)=74.67%\n",
      "[ 2019-01-12 10:39:35,683][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.test.predict)=75.76%\n",
      "[ 2019-01-12 10:39:36,316][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_0.predict)=63.64%\n",
      "[ 2019-01-12 10:39:37,070][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_1.predict)=74.55%\n",
      "[ 2019-01-12 10:39:37,848][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_2.predict)=74.55%\n",
      "[ 2019-01-12 10:39:38,603][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_3.predict)=81.48%\n",
      "[ 2019-01-12 10:39:39,380][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_4.predict)=84.91%\n",
      "[ 2019-01-12 10:39:40,165][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_5.predict)=73.58%\n",
      "[ 2019-01-12 10:39:40,919][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_6.predict)=73.58%\n",
      "[ 2019-01-12 10:39:41,679][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_7.predict)=77.36%\n",
      "[ 2019-01-12 10:39:42,438][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_8.predict)=71.70%\n",
      "[ 2019-01-12 10:39:43,201][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_9.predict)=77.36%\n",
      "[ 2019-01-12 10:39:43,322][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_cv.predict)=75.23%\n",
      "[ 2019-01-12 10:39:43,325][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.test.predict)=77.49%\n",
      "[ 2019-01-12 10:39:43,337][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_0.predict)=78.18%\n",
      "[ 2019-01-12 10:39:43,346][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_1.predict)=69.09%\n",
      "[ 2019-01-12 10:39:43,357][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_2.predict)=72.73%\n",
      "[ 2019-01-12 10:39:43,369][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_3.predict)=70.37%\n",
      "[ 2019-01-12 10:39:43,376][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_4.predict)=77.36%\n",
      "[ 2019-01-12 10:39:43,386][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_5.predict)=77.36%\n",
      "[ 2019-01-12 10:39:43,397][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_6.predict)=79.25%\n",
      "[ 2019-01-12 10:39:43,406][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_7.predict)=75.47%\n",
      "[ 2019-01-12 10:39:43,415][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_8.predict)=75.47%\n",
      "[ 2019-01-12 10:39:43,427][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_9.predict)=79.25%\n",
      "[ 2019-01-12 10:39:43,428][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_cv.predict)=75.42%\n",
      "[ 2019-01-12 10:39:43,430][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.test.predict)=78.79%\n",
      "[ 2019-01-12 10:39:43,432][cascade_classifier.calc_accuracy] Accuracy(layer_2 - train.classifier_average)=74.86%\n",
      "[ 2019-01-12 10:39:43,434][cascade_classifier.calc_accuracy] Accuracy(layer_2 - test.classifier_average)=76.19%\n",
      "[ 2019-01-12 10:39:43,438][cascade_classifier.fit_transform] [layer=3] look_indexs=[0], X_cur_train.shape=(537, 14), X_cur_test.shape=(231, 14)\n",
      "[ 2019-01-12 10:39:44,124][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_0.predict)=72.73%\n",
      "[ 2019-01-12 10:39:44,924][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_1.predict)=81.82%\n",
      "[ 2019-01-12 10:39:45,707][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_2.predict)=72.73%\n",
      "[ 2019-01-12 10:39:46,490][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_3.predict)=75.93%\n",
      "[ 2019-01-12 10:39:47,278][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_4.predict)=83.02%\n",
      "[ 2019-01-12 10:39:48,120][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_5.predict)=73.58%\n",
      "[ 2019-01-12 10:39:48,934][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_6.predict)=71.70%\n",
      "[ 2019-01-12 10:39:49,728][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_7.predict)=69.81%\n",
      "[ 2019-01-12 10:39:50,489][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_8.predict)=79.25%\n",
      "[ 2019-01-12 10:39:51,329][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_9.predict)=69.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2019-01-12 10:39:51,454][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_cv.predict)=75.05%\n",
      "[ 2019-01-12 10:39:51,456][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.test.predict)=77.49%\n",
      "[ 2019-01-12 10:39:52,108][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_0.predict)=58.18%\n",
      "[ 2019-01-12 10:39:52,842][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_1.predict)=80.00%\n",
      "[ 2019-01-12 10:39:53,616][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_2.predict)=63.64%\n",
      "[ 2019-01-12 10:39:54,405][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_3.predict)=79.63%\n",
      "[ 2019-01-12 10:39:55,184][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_4.predict)=77.36%\n",
      "[ 2019-01-12 10:39:55,962][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_5.predict)=81.13%\n",
      "[ 2019-01-12 10:39:56,731][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_6.predict)=79.25%\n",
      "[ 2019-01-12 10:39:57,496][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_7.predict)=67.92%\n",
      "[ 2019-01-12 10:39:58,259][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_8.predict)=79.25%\n",
      "[ 2019-01-12 10:39:59,047][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_9.predict)=64.15%\n",
      "[ 2019-01-12 10:39:59,183][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_cv.predict)=73.00%\n",
      "[ 2019-01-12 10:39:59,187][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.test.predict)=75.32%\n",
      "[ 2019-01-12 10:39:59,204][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_0.predict)=65.45%\n",
      "[ 2019-01-12 10:39:59,214][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_1.predict)=83.64%\n",
      "[ 2019-01-12 10:39:59,223][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_2.predict)=69.09%\n",
      "[ 2019-01-12 10:39:59,233][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_3.predict)=83.33%\n",
      "[ 2019-01-12 10:39:59,242][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_4.predict)=71.70%\n",
      "[ 2019-01-12 10:39:59,253][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_5.predict)=81.13%\n",
      "[ 2019-01-12 10:39:59,262][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_6.predict)=67.92%\n",
      "[ 2019-01-12 10:39:59,271][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_7.predict)=73.58%\n",
      "[ 2019-01-12 10:39:59,286][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_8.predict)=79.25%\n",
      "[ 2019-01-12 10:39:59,298][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_9.predict)=71.70%\n",
      "[ 2019-01-12 10:39:59,300][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_cv.predict)=74.67%\n",
      "[ 2019-01-12 10:39:59,301][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.test.predict)=76.19%\n",
      "[ 2019-01-12 10:39:59,305][cascade_classifier.calc_accuracy] Accuracy(layer_3 - train.classifier_average)=74.49%\n",
      "[ 2019-01-12 10:39:59,307][cascade_classifier.calc_accuracy] Accuracy(layer_3 - test.classifier_average)=77.49%\n",
      "[ 2019-01-12 10:39:59,309][cascade_classifier.fit_transform] [layer=4] look_indexs=[0], X_cur_train.shape=(537, 14), X_cur_test.shape=(231, 14)\n",
      "[ 2019-01-12 10:39:59,974][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_0.predict)=69.09%\n",
      "[ 2019-01-12 10:40:00,737][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_1.predict)=80.00%\n",
      "[ 2019-01-12 10:40:01,519][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_2.predict)=61.82%\n",
      "[ 2019-01-12 10:40:02,283][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_3.predict)=74.07%\n",
      "[ 2019-01-12 10:40:03,060][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_4.predict)=75.47%\n",
      "[ 2019-01-12 10:40:03,895][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_5.predict)=77.36%\n",
      "[ 2019-01-12 10:40:04,675][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_6.predict)=71.70%\n",
      "[ 2019-01-12 10:40:05,501][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_7.predict)=71.70%\n",
      "[ 2019-01-12 10:40:06,269][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_8.predict)=81.13%\n",
      "[ 2019-01-12 10:40:07,056][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_9.predict)=75.47%\n",
      "[ 2019-01-12 10:40:07,180][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_cv.predict)=73.74%\n",
      "[ 2019-01-12 10:40:07,184][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.test.predict)=74.89%\n",
      "[ 2019-01-12 10:40:07,816][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_0.predict)=83.64%\n",
      "[ 2019-01-12 10:40:08,553][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_1.predict)=69.09%\n",
      "[ 2019-01-12 10:40:09,298][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_2.predict)=78.18%\n",
      "[ 2019-01-12 10:40:10,055][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_3.predict)=66.67%\n",
      "[ 2019-01-12 10:40:10,941][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_4.predict)=67.92%\n",
      "[ 2019-01-12 10:40:11,692][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_5.predict)=69.81%\n",
      "[ 2019-01-12 10:40:12,474][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_6.predict)=77.36%\n",
      "[ 2019-01-12 10:40:13,276][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_7.predict)=73.58%\n",
      "[ 2019-01-12 10:40:14,150][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_8.predict)=69.81%\n",
      "[ 2019-01-12 10:40:15,062][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_9.predict)=71.70%\n",
      "[ 2019-01-12 10:40:15,180][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_cv.predict)=72.81%\n",
      "[ 2019-01-12 10:40:15,181][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.test.predict)=76.62%\n",
      "[ 2019-01-12 10:40:15,196][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_0.predict)=72.73%\n",
      "[ 2019-01-12 10:40:15,208][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_1.predict)=74.55%\n",
      "[ 2019-01-12 10:40:15,222][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_2.predict)=80.00%\n",
      "[ 2019-01-12 10:40:15,239][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_3.predict)=72.22%\n",
      "[ 2019-01-12 10:40:15,256][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_4.predict)=75.47%\n",
      "[ 2019-01-12 10:40:15,272][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_5.predict)=73.58%\n",
      "[ 2019-01-12 10:40:15,287][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_6.predict)=79.25%\n",
      "[ 2019-01-12 10:40:15,302][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_7.predict)=69.81%\n",
      "[ 2019-01-12 10:40:15,316][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_8.predict)=64.15%\n",
      "[ 2019-01-12 10:40:15,330][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_9.predict)=73.58%\n",
      "[ 2019-01-12 10:40:15,332][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_cv.predict)=73.56%\n",
      "[ 2019-01-12 10:40:15,341][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.test.predict)=77.92%\n",
      "[ 2019-01-12 10:40:15,343][cascade_classifier.calc_accuracy] Accuracy(layer_4 - train.classifier_average)=74.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2019-01-12 10:40:15,344][cascade_classifier.calc_accuracy] Accuracy(layer_4 - test.classifier_average)=77.92%\n",
      "[ 2019-01-12 10:40:15,347][cascade_classifier.fit_transform] [Result][Optimal Level Detected] opt_layer_num=2, accuracy_train=75.42%, accuracy_test=76.62%\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "# X_enc is the concatenated predict_proba result of each estimators of the last layer of the GCForest model\n",
    "    # X_enc.shape =\n",
    "    #   (n_datas, n_estimators * n_classes): If cascade is provided\n",
    "    #   (n_datas, n_estimators * n_classes, dimX, dimY): If only finegrained part is provided\n",
    "    # You can also pass X_test, y_test to fit_transform method, then the accracy on test data will be logged when training.\n",
    "X_train_enc, X_test_enc = gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test)\n",
    "    # WARNING: if you set gc.set_keep_model_in_mem(True), you would have to use\n",
    "    # gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test) to evaluate your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2019-01-12 10:40:15,366][cascade_classifier.transform] X_groups_test.shape=[(231, 8)]\n",
      "[ 2019-01-12 10:40:15,369][cascade_classifier.transform] group_dims=[8]\n",
      "[ 2019-01-12 10:40:15,375][cascade_classifier.transform] X_test.shape=(231, 8)\n",
      "[ 2019-01-12 10:40:15,377][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(231, 8)\n",
      "[ 2019-01-12 10:40:17,708][cascade_classifier.transform] [layer=1] look_indexs=[0], X_cur_test.shape=(231, 14)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GCForest = 76.623377 %\n",
      "(' Time ', '84.264', ' seconds')\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "y_pred = gc.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy of GCForest = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[136  21]\n",
      " [ 33  41]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.87      0.83       157\n",
      "        1.0       0.66      0.55      0.60        74\n",
      "\n",
      "avg / total       0.76      0.77      0.76       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "483/483 [==============================] - 2s 4ms/step - loss: 2.1668 - acc: 0.5114\n",
      "Epoch 2/50\n",
      "483/483 [==============================] - 0s 712us/step - loss: 0.7151 - acc: 0.6418\n",
      "Epoch 3/50\n",
      "483/483 [==============================] - 0s 778us/step - loss: 0.6435 - acc: 0.6460\n",
      "Epoch 4/50\n",
      "483/483 [==============================] - 0s 756us/step - loss: 0.6403 - acc: 0.6460\n",
      "Epoch 5/50\n",
      "483/483 [==============================] - 0s 826us/step - loss: 0.6567 - acc: 0.6377\n",
      "Epoch 6/50\n",
      "483/483 [==============================] - 0s 673us/step - loss: 0.6034 - acc: 0.6853\n",
      "Epoch 7/50\n",
      "483/483 [==============================] - 0s 578us/step - loss: 0.6152 - acc: 0.6749\n",
      "Epoch 8/50\n",
      "483/483 [==============================] - 0s 665us/step - loss: 0.6348 - acc: 0.6915\n",
      "Epoch 9/50\n",
      "483/483 [==============================] - 0s 853us/step - loss: 0.6627 - acc: 0.6480\n",
      "Epoch 10/50\n",
      "483/483 [==============================] - 0s 773us/step - loss: 0.6004 - acc: 0.6770\n",
      "Epoch 11/50\n",
      "483/483 [==============================] - 0s 759us/step - loss: 0.5886 - acc: 0.7184\n",
      "Epoch 12/50\n",
      "483/483 [==============================] - 0s 759us/step - loss: 0.5622 - acc: 0.7164\n",
      "Epoch 13/50\n",
      "483/483 [==============================] - 0s 861us/step - loss: 0.6273 - acc: 0.6605\n",
      "Epoch 14/50\n",
      "483/483 [==============================] - 0s 877us/step - loss: 0.5842 - acc: 0.6894\n",
      "Epoch 15/50\n",
      "483/483 [==============================] - 0s 719us/step - loss: 0.5951 - acc: 0.6894\n",
      "Epoch 16/50\n",
      "483/483 [==============================] - 0s 869us/step - loss: 0.5975 - acc: 0.6812\n",
      "Epoch 17/50\n",
      "483/483 [==============================] - 0s 882us/step - loss: 0.5747 - acc: 0.6998\n",
      "Epoch 18/50\n",
      "483/483 [==============================] - 0s 727us/step - loss: 0.5945 - acc: 0.6915\n",
      "Epoch 19/50\n",
      "483/483 [==============================] - 0s 908us/step - loss: 0.5596 - acc: 0.7122\n",
      "Epoch 20/50\n",
      "483/483 [==============================] - 0s 777us/step - loss: 0.5584 - acc: 0.7205\n",
      "Epoch 21/50\n",
      "483/483 [==============================] - 0s 863us/step - loss: 0.5446 - acc: 0.7039\n",
      "Epoch 22/50\n",
      "483/483 [==============================] - 0s 798us/step - loss: 0.5736 - acc: 0.7039\n",
      "Epoch 23/50\n",
      "483/483 [==============================] - 0s 766us/step - loss: 0.5686 - acc: 0.7143\n",
      "Epoch 24/50\n",
      "483/483 [==============================] - 0s 674us/step - loss: 0.5631 - acc: 0.6998\n",
      "Epoch 25/50\n",
      "483/483 [==============================] - 0s 732us/step - loss: 0.5748 - acc: 0.7101\n",
      "Epoch 26/50\n",
      "483/483 [==============================] - 0s 694us/step - loss: 0.5584 - acc: 0.7205\n",
      "Epoch 27/50\n",
      "483/483 [==============================] - 0s 653us/step - loss: 0.5559 - acc: 0.7164\n",
      "Epoch 28/50\n",
      "483/483 [==============================] - 0s 650us/step - loss: 0.5296 - acc: 0.7288\n",
      "Epoch 29/50\n",
      "483/483 [==============================] - 0s 684us/step - loss: 0.5259 - acc: 0.7350\n",
      "Epoch 30/50\n",
      "483/483 [==============================] - 0s 878us/step - loss: 0.5211 - acc: 0.7516\n",
      "Epoch 31/50\n",
      "483/483 [==============================] - 0s 809us/step - loss: 0.5249 - acc: 0.7433\n",
      "Epoch 32/50\n",
      "483/483 [==============================] - 0s 646us/step - loss: 0.5766 - acc: 0.6832\n",
      "Epoch 33/50\n",
      "483/483 [==============================] - 0s 801us/step - loss: 0.5570 - acc: 0.7164\n",
      "Epoch 34/50\n",
      "483/483 [==============================] - 0s 826us/step - loss: 0.5609 - acc: 0.7081\n",
      "Epoch 35/50\n",
      "483/483 [==============================] - 0s 787us/step - loss: 0.5293 - acc: 0.7371\n",
      "Epoch 36/50\n",
      "483/483 [==============================] - 0s 858us/step - loss: 0.5271 - acc: 0.7412\n",
      "Epoch 37/50\n",
      "483/483 [==============================] - 0s 708us/step - loss: 0.5414 - acc: 0.7226\n",
      "Epoch 38/50\n",
      "483/483 [==============================] - 0s 951us/step - loss: 0.5280 - acc: 0.7226\n",
      "Epoch 39/50\n",
      "483/483 [==============================] - 0s 780us/step - loss: 0.5425 - acc: 0.6957\n",
      "Epoch 40/50\n",
      "483/483 [==============================] - 0s 926us/step - loss: 0.5151 - acc: 0.7329\n",
      "Epoch 41/50\n",
      "483/483 [==============================] - 0s 841us/step - loss: 0.5528 - acc: 0.7122\n",
      "Epoch 42/50\n",
      "483/483 [==============================] - 0s 785us/step - loss: 0.5372 - acc: 0.7350\n",
      "Epoch 43/50\n",
      "483/483 [==============================] - 0s 772us/step - loss: 0.5147 - acc: 0.7412\n",
      "Epoch 44/50\n",
      "483/483 [==============================] - 0s 754us/step - loss: 0.5198 - acc: 0.7391\n",
      "Epoch 45/50\n",
      "483/483 [==============================] - 0s 882us/step - loss: 0.5041 - acc: 0.7412\n",
      "Epoch 46/50\n",
      "483/483 [==============================] - 0s 802us/step - loss: 0.5255 - acc: 0.7474\n",
      "Epoch 47/50\n",
      "483/483 [==============================] - 0s 779us/step - loss: 0.5643 - acc: 0.7164\n",
      "Epoch 48/50\n",
      "483/483 [==============================] - 0s 772us/step - loss: 0.5528 - acc: 0.7122\n",
      "Epoch 49/50\n",
      "483/483 [==============================] - 0s 739us/step - loss: 0.5369 - acc: 0.7246\n",
      "Epoch 50/50\n",
      "483/483 [==============================] - 0s 680us/step - loss: 0.5247 - acc: 0.7350\n",
      "54/54 [==============================] - 0s 692us/step\n",
      "Epoch 1/50\n",
      "483/483 [==============================] - 1s 2ms/step - loss: 2.3837 - acc: 0.5052\n",
      "Epoch 2/50\n",
      "483/483 [==============================] - 0s 710us/step - loss: 0.8532 - acc: 0.5983\n",
      "Epoch 3/50\n",
      "483/483 [==============================] - 0s 696us/step - loss: 0.8518 - acc: 0.5569\n",
      "Epoch 4/50\n",
      "483/483 [==============================] - 0s 641us/step - loss: 0.6293 - acc: 0.6667\n",
      "Epoch 5/50\n",
      "483/483 [==============================] - 0s 621us/step - loss: 0.6287 - acc: 0.6812\n",
      "Epoch 6/50\n",
      "483/483 [==============================] - 0s 839us/step - loss: 0.6312 - acc: 0.6874\n",
      "Epoch 7/50\n",
      "483/483 [==============================] - 0s 782us/step - loss: 0.6336 - acc: 0.6749\n",
      "Epoch 8/50\n",
      "483/483 [==============================] - 0s 616us/step - loss: 0.6212 - acc: 0.6832\n",
      "Epoch 9/50\n",
      "483/483 [==============================] - 0s 728us/step - loss: 0.6000 - acc: 0.6977\n",
      "Epoch 10/50\n",
      "483/483 [==============================] - 0s 772us/step - loss: 0.5925 - acc: 0.6791\n",
      "Epoch 11/50\n",
      "483/483 [==============================] - 0s 614us/step - loss: 0.5800 - acc: 0.7143\n",
      "Epoch 12/50\n",
      "483/483 [==============================] - 0s 619us/step - loss: 0.5732 - acc: 0.7350\n",
      "Epoch 13/50\n",
      "483/483 [==============================] - 0s 659us/step - loss: 0.5785 - acc: 0.6977\n",
      "Epoch 14/50\n",
      "483/483 [==============================] - 0s 723us/step - loss: 0.6998 - acc: 0.6687 0s - loss: 0.7163 - acc: 0.\n",
      "Epoch 15/50\n",
      "483/483 [==============================] - 0s 719us/step - loss: 0.6653 - acc: 0.6377\n",
      "Epoch 16/50\n",
      "483/483 [==============================] - 0s 711us/step - loss: 0.6156 - acc: 0.6977\n",
      "Epoch 17/50\n",
      "483/483 [==============================] - 0s 620us/step - loss: 0.5617 - acc: 0.7164\n",
      "Epoch 18/50\n",
      "483/483 [==============================] - 0s 706us/step - loss: 0.5690 - acc: 0.7143\n",
      "Epoch 19/50\n",
      "483/483 [==============================] - 0s 791us/step - loss: 0.5746 - acc: 0.7039\n",
      "Epoch 20/50\n",
      "483/483 [==============================] - 0s 669us/step - loss: 0.5893 - acc: 0.6998\n",
      "Epoch 21/50\n",
      "483/483 [==============================] - 0s 800us/step - loss: 0.5560 - acc: 0.7101\n",
      "Epoch 22/50\n",
      "483/483 [==============================] - 0s 837us/step - loss: 0.5504 - acc: 0.7246\n",
      "Epoch 23/50\n",
      "483/483 [==============================] - 0s 785us/step - loss: 0.5491 - acc: 0.7246\n",
      "Epoch 24/50\n",
      "483/483 [==============================] - 0s 771us/step - loss: 0.5549 - acc: 0.7122\n",
      "Epoch 25/50\n",
      "483/483 [==============================] - 0s 810us/step - loss: 0.5468 - acc: 0.7246\n",
      "Epoch 26/50\n",
      "483/483 [==============================] - 0s 865us/step - loss: 0.5556 - acc: 0.7143\n",
      "Epoch 27/50\n",
      "483/483 [==============================] - 0s 790us/step - loss: 0.5633 - acc: 0.7412\n",
      "Epoch 28/50\n",
      "483/483 [==============================] - 0s 914us/step - loss: 0.5835 - acc: 0.6915\n",
      "Epoch 29/50\n",
      "483/483 [==============================] - 0s 910us/step - loss: 0.5532 - acc: 0.7412\n",
      "Epoch 30/50\n",
      "483/483 [==============================] - 0s 813us/step - loss: 0.5683 - acc: 0.7308\n",
      "Epoch 31/50\n",
      "483/483 [==============================] - 0s 973us/step - loss: 0.5689 - acc: 0.7019\n",
      "Epoch 32/50\n",
      "483/483 [==============================] - 0s 1ms/step - loss: 0.5583 - acc: 0.7143\n",
      "Epoch 33/50\n",
      "483/483 [==============================] - 0s 928us/step - loss: 0.5534 - acc: 0.7164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "483/483 [==============================] - 0s 890us/step - loss: 0.5219 - acc: 0.7598\n",
      "Epoch 35/50\n",
      "483/483 [==============================] - 0s 967us/step - loss: 0.5368 - acc: 0.7288\n",
      "Epoch 36/50\n",
      "483/483 [==============================] - 0s 970us/step - loss: 0.5253 - acc: 0.7453\n",
      "Epoch 37/50\n",
      "483/483 [==============================] - 0s 904us/step - loss: 0.6157 - acc: 0.6749\n",
      "Epoch 38/50\n",
      "483/483 [==============================] - 0s 828us/step - loss: 0.5315 - acc: 0.7412\n",
      "Epoch 39/50\n",
      "483/483 [==============================] - 0s 929us/step - loss: 0.5331 - acc: 0.7329\n",
      "Epoch 40/50\n",
      "483/483 [==============================] - 0s 667us/step - loss: 0.5396 - acc: 0.7267\n",
      "Epoch 41/50\n",
      "483/483 [==============================] - 0s 876us/step - loss: 0.5407 - acc: 0.7205\n",
      "Epoch 42/50\n",
      "483/483 [==============================] - 0s 775us/step - loss: 0.5464 - acc: 0.7350\n",
      "Epoch 43/50\n",
      "483/483 [==============================] - 0s 779us/step - loss: 0.5363 - acc: 0.7329\n",
      "Epoch 44/50\n",
      "483/483 [==============================] - 0s 868us/step - loss: 0.5310 - acc: 0.7288\n",
      "Epoch 45/50\n",
      "483/483 [==============================] - 0s 768us/step - loss: 0.5270 - acc: 0.7391\n",
      "Epoch 46/50\n",
      "483/483 [==============================] - 0s 872us/step - loss: 0.5310 - acc: 0.7329\n",
      "Epoch 47/50\n",
      "483/483 [==============================] - 0s 883us/step - loss: 0.5431 - acc: 0.7143\n",
      "Epoch 48/50\n",
      "483/483 [==============================] - 0s 871us/step - loss: 0.5226 - acc: 0.7453\n",
      "Epoch 49/50\n",
      "483/483 [==============================] - 0s 901us/step - loss: 0.5259 - acc: 0.7619\n",
      "Epoch 50/50\n",
      "483/483 [==============================] - 0s 910us/step - loss: 0.5110 - acc: 0.7557\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "483/483 [==============================] - 1s 2ms/step - loss: 3.1255 - acc: 0.4969\n",
      "Epoch 2/50\n",
      "483/483 [==============================] - 0s 891us/step - loss: 0.8265 - acc: 0.6522\n",
      "Epoch 3/50\n",
      "483/483 [==============================] - 0s 944us/step - loss: 0.6854 - acc: 0.6190\n",
      "Epoch 4/50\n",
      "483/483 [==============================] - 0s 971us/step - loss: 0.6560 - acc: 0.6563\n",
      "Epoch 5/50\n",
      "483/483 [==============================] - 0s 996us/step - loss: 0.6291 - acc: 0.6542\n",
      "Epoch 6/50\n",
      "483/483 [==============================] - 0s 888us/step - loss: 0.6488 - acc: 0.6356\n",
      "Epoch 7/50\n",
      "483/483 [==============================] - 0s 804us/step - loss: 0.5914 - acc: 0.7081\n",
      "Epoch 8/50\n",
      "483/483 [==============================] - 0s 730us/step - loss: 0.5922 - acc: 0.6853\n",
      "Epoch 9/50\n",
      "483/483 [==============================] - 0s 783us/step - loss: 0.6302 - acc: 0.6563\n",
      "Epoch 10/50\n",
      "483/483 [==============================] - 0s 831us/step - loss: 0.6096 - acc: 0.6894\n",
      "Epoch 11/50\n",
      "483/483 [==============================] - 0s 966us/step - loss: 0.6048 - acc: 0.6708\n",
      "Epoch 12/50\n",
      "483/483 [==============================] - 0s 958us/step - loss: 0.5812 - acc: 0.6874\n",
      "Epoch 13/50\n",
      "483/483 [==============================] - 0s 931us/step - loss: 0.5750 - acc: 0.6998\n",
      "Epoch 14/50\n",
      "483/483 [==============================] - 0s 953us/step - loss: 0.5604 - acc: 0.7101\n",
      "Epoch 15/50\n",
      "483/483 [==============================] - 0s 802us/step - loss: 0.5789 - acc: 0.7039\n",
      "Epoch 16/50\n",
      "483/483 [==============================] - 0s 849us/step - loss: 0.5655 - acc: 0.7267\n",
      "Epoch 17/50\n",
      "483/483 [==============================] - 0s 842us/step - loss: 0.5599 - acc: 0.7019\n",
      "Epoch 18/50\n",
      "483/483 [==============================] - 0s 841us/step - loss: 0.5545 - acc: 0.7122\n",
      "Epoch 19/50\n",
      "483/483 [==============================] - 0s 834us/step - loss: 0.5466 - acc: 0.7267\n",
      "Epoch 20/50\n",
      "483/483 [==============================] - 0s 814us/step - loss: 0.6053 - acc: 0.6687\n",
      "Epoch 21/50\n",
      "483/483 [==============================] - 0s 879us/step - loss: 0.5660 - acc: 0.7101\n",
      "Epoch 22/50\n",
      "483/483 [==============================] - 0s 760us/step - loss: 0.5735 - acc: 0.7101\n",
      "Epoch 23/50\n",
      "483/483 [==============================] - 0s 847us/step - loss: 0.5481 - acc: 0.7329\n",
      "Epoch 24/50\n",
      "483/483 [==============================] - 0s 842us/step - loss: 0.5483 - acc: 0.7329\n",
      "Epoch 25/50\n",
      "483/483 [==============================] - 0s 745us/step - loss: 0.5721 - acc: 0.7081\n",
      "Epoch 26/50\n",
      "483/483 [==============================] - 0s 826us/step - loss: 0.5862 - acc: 0.6936\n",
      "Epoch 27/50\n",
      "483/483 [==============================] - 0s 828us/step - loss: 0.5403 - acc: 0.7516\n",
      "Epoch 28/50\n",
      "483/483 [==============================] - 0s 833us/step - loss: 0.5370 - acc: 0.7329\n",
      "Epoch 29/50\n",
      "483/483 [==============================] - 0s 903us/step - loss: 0.5446 - acc: 0.7350\n",
      "Epoch 30/50\n",
      "483/483 [==============================] - 0s 861us/step - loss: 0.5379 - acc: 0.7474\n",
      "Epoch 31/50\n",
      "483/483 [==============================] - 0s 890us/step - loss: 0.5194 - acc: 0.7474\n",
      "Epoch 32/50\n",
      "483/483 [==============================] - 0s 807us/step - loss: 0.5528 - acc: 0.7329\n",
      "Epoch 33/50\n",
      "483/483 [==============================] - 0s 985us/step - loss: 0.5588 - acc: 0.7329 0s - loss: 0.5581 - acc: 0.738\n",
      "Epoch 34/50\n",
      "483/483 [==============================] - 0s 901us/step - loss: 0.5472 - acc: 0.7267\n",
      "Epoch 35/50\n",
      "483/483 [==============================] - 0s 783us/step - loss: 0.5260 - acc: 0.7412\n",
      "Epoch 36/50\n",
      "483/483 [==============================] - 0s 740us/step - loss: 0.5565 - acc: 0.7164\n",
      "Epoch 37/50\n",
      "483/483 [==============================] - 0s 690us/step - loss: 0.5279 - acc: 0.7412\n",
      "Epoch 38/50\n",
      "483/483 [==============================] - 0s 915us/step - loss: 0.5266 - acc: 0.7453\n",
      "Epoch 39/50\n",
      "483/483 [==============================] - 0s 928us/step - loss: 0.5236 - acc: 0.7536\n",
      "Epoch 40/50\n",
      "483/483 [==============================] - 0s 719us/step - loss: 0.5323 - acc: 0.7329\n",
      "Epoch 41/50\n",
      "483/483 [==============================] - 0s 798us/step - loss: 0.5748 - acc: 0.7205\n",
      "Epoch 42/50\n",
      "483/483 [==============================] - 0s 877us/step - loss: 0.5491 - acc: 0.7288\n",
      "Epoch 43/50\n",
      "483/483 [==============================] - 0s 715us/step - loss: 0.5255 - acc: 0.7288\n",
      "Epoch 44/50\n",
      "483/483 [==============================] - 0s 769us/step - loss: 0.5253 - acc: 0.7557\n",
      "Epoch 45/50\n",
      "483/483 [==============================] - 0s 712us/step - loss: 0.5192 - acc: 0.7474\n",
      "Epoch 46/50\n",
      "483/483 [==============================] - 0s 706us/step - loss: 0.5863 - acc: 0.7143\n",
      "Epoch 47/50\n",
      "483/483 [==============================] - 0s 697us/step - loss: 0.5298 - acc: 0.7578\n",
      "Epoch 48/50\n",
      "483/483 [==============================] - 0s 593us/step - loss: 0.5314 - acc: 0.7391\n",
      "Epoch 49/50\n",
      "483/483 [==============================] - 0s 582us/step - loss: 0.5116 - acc: 0.7578\n",
      "Epoch 50/50\n",
      "483/483 [==============================] - 0s 675us/step - loss: 0.5157 - acc: 0.7495\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 1.7739 - acc: 0.5487\n",
      "Epoch 2/50\n",
      "483/483 [==============================] - 0s 650us/step - loss: 0.7485 - acc: 0.6170\n",
      "Epoch 3/50\n",
      "483/483 [==============================] - 0s 665us/step - loss: 0.6925 - acc: 0.6335\n",
      "Epoch 4/50\n",
      "483/483 [==============================] - 0s 563us/step - loss: 0.6516 - acc: 0.6729\n",
      "Epoch 5/50\n",
      "483/483 [==============================] - 0s 596us/step - loss: 0.6790 - acc: 0.6460\n",
      "Epoch 6/50\n",
      "483/483 [==============================] - 0s 632us/step - loss: 0.6305 - acc: 0.6646\n",
      "Epoch 7/50\n",
      "483/483 [==============================] - 0s 562us/step - loss: 0.5954 - acc: 0.6832\n",
      "Epoch 8/50\n",
      "483/483 [==============================] - 0s 573us/step - loss: 0.6153 - acc: 0.6749\n",
      "Epoch 9/50\n",
      "483/483 [==============================] - 0s 619us/step - loss: 0.6145 - acc: 0.6874\n",
      "Epoch 10/50\n",
      "483/483 [==============================] - 0s 592us/step - loss: 0.5968 - acc: 0.6874\n",
      "Epoch 11/50\n",
      "483/483 [==============================] - 0s 575us/step - loss: 0.6730 - acc: 0.6770\n",
      "Epoch 12/50\n",
      "483/483 [==============================] - 0s 592us/step - loss: 0.6232 - acc: 0.6646\n",
      "Epoch 13/50\n",
      "483/483 [==============================] - 0s 600us/step - loss: 0.5851 - acc: 0.6998\n",
      "Epoch 14/50\n",
      "483/483 [==============================] - 0s 558us/step - loss: 0.5904 - acc: 0.7164\n",
      "Epoch 15/50\n",
      "483/483 [==============================] - 0s 609us/step - loss: 0.5833 - acc: 0.7101\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483/483 [==============================] - 0s 576us/step - loss: 0.5763 - acc: 0.7039\n",
      "Epoch 17/50\n",
      "483/483 [==============================] - 0s 538us/step - loss: 0.6157 - acc: 0.6687\n",
      "Epoch 18/50\n",
      "483/483 [==============================] - 0s 600us/step - loss: 0.6330 - acc: 0.6480\n",
      "Epoch 19/50\n",
      "483/483 [==============================] - 0s 658us/step - loss: 0.5784 - acc: 0.6894\n",
      "Epoch 20/50\n",
      "483/483 [==============================] - 0s 811us/step - loss: 0.6473 - acc: 0.6398\n",
      "Epoch 21/50\n",
      "483/483 [==============================] - 0s 642us/step - loss: 0.5903 - acc: 0.6936\n",
      "Epoch 22/50\n",
      "483/483 [==============================] - 0s 569us/step - loss: 0.5901 - acc: 0.7081\n",
      "Epoch 23/50\n",
      "483/483 [==============================] - 0s 783us/step - loss: 0.5732 - acc: 0.6936\n",
      "Epoch 24/50\n",
      "483/483 [==============================] - 0s 645us/step - loss: 0.5734 - acc: 0.6749\n",
      "Epoch 25/50\n",
      "483/483 [==============================] - 0s 696us/step - loss: 0.5604 - acc: 0.7019\n",
      "Epoch 26/50\n",
      "483/483 [==============================] - 0s 945us/step - loss: 0.5541 - acc: 0.7081\n",
      "Epoch 27/50\n",
      "483/483 [==============================] - 0s 787us/step - loss: 0.6121 - acc: 0.6749\n",
      "Epoch 28/50\n",
      "483/483 [==============================] - 0s 832us/step - loss: 0.5826 - acc: 0.6936\n",
      "Epoch 29/50\n",
      "483/483 [==============================] - 0s 658us/step - loss: 0.5718 - acc: 0.7039\n",
      "Epoch 30/50\n",
      "483/483 [==============================] - 0s 684us/step - loss: 0.5568 - acc: 0.7019\n",
      "Epoch 31/50\n",
      "483/483 [==============================] - 0s 673us/step - loss: 0.5518 - acc: 0.7329\n",
      "Epoch 32/50\n",
      "483/483 [==============================] - 0s 749us/step - loss: 0.5537 - acc: 0.7081\n",
      "Epoch 33/50\n",
      "483/483 [==============================] - 0s 755us/step - loss: 0.5449 - acc: 0.7226\n",
      "Epoch 34/50\n",
      "483/483 [==============================] - 0s 675us/step - loss: 0.5496 - acc: 0.7143\n",
      "Epoch 35/50\n",
      "483/483 [==============================] - 0s 664us/step - loss: 0.5407 - acc: 0.7371\n",
      "Epoch 36/50\n",
      "483/483 [==============================] - 0s 761us/step - loss: 0.5409 - acc: 0.7246\n",
      "Epoch 37/50\n",
      "483/483 [==============================] - 0s 762us/step - loss: 0.5531 - acc: 0.7267\n",
      "Epoch 38/50\n",
      "483/483 [==============================] - 0s 781us/step - loss: 0.5669 - acc: 0.6998\n",
      "Epoch 39/50\n",
      "483/483 [==============================] - 0s 868us/step - loss: 0.5588 - acc: 0.7122\n",
      "Epoch 40/50\n",
      "483/483 [==============================] - 0s 946us/step - loss: 0.5333 - acc: 0.7246\n",
      "Epoch 41/50\n",
      "483/483 [==============================] - 0s 728us/step - loss: 0.5606 - acc: 0.7101\n",
      "Epoch 42/50\n",
      "483/483 [==============================] - 0s 922us/step - loss: 0.5639 - acc: 0.7019\n",
      "Epoch 43/50\n",
      "483/483 [==============================] - 0s 870us/step - loss: 0.5568 - acc: 0.7184\n",
      "Epoch 44/50\n",
      "483/483 [==============================] - 0s 685us/step - loss: 0.5690 - acc: 0.7122\n",
      "Epoch 45/50\n",
      "483/483 [==============================] - 0s 684us/step - loss: 0.5774 - acc: 0.6874\n",
      "Epoch 46/50\n",
      "483/483 [==============================] - 0s 577us/step - loss: 0.5514 - acc: 0.7205\n",
      "Epoch 47/50\n",
      "483/483 [==============================] - 0s 483us/step - loss: 0.5244 - acc: 0.7371\n",
      "Epoch 48/50\n",
      "483/483 [==============================] - 0s 559us/step - loss: 0.5334 - acc: 0.7329\n",
      "Epoch 49/50\n",
      "483/483 [==============================] - 0s 541us/step - loss: 0.5332 - acc: 0.7350\n",
      "Epoch 50/50\n",
      "483/483 [==============================] - 0s 638us/step - loss: 0.5381 - acc: 0.7246\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "483/483 [==============================] - 1s 2ms/step - loss: 3.1953 - acc: 0.5383\n",
      "Epoch 2/50\n",
      "483/483 [==============================] - 0s 746us/step - loss: 0.7586 - acc: 0.6108\n",
      "Epoch 3/50\n",
      "483/483 [==============================] - 0s 858us/step - loss: 0.7621 - acc: 0.6190\n",
      "Epoch 4/50\n",
      "483/483 [==============================] - 0s 932us/step - loss: 0.6497 - acc: 0.6584\n",
      "Epoch 5/50\n",
      "483/483 [==============================] - 0s 591us/step - loss: 0.6319 - acc: 0.6832\n",
      "Epoch 6/50\n",
      "483/483 [==============================] - 0s 550us/step - loss: 0.6145 - acc: 0.6853\n",
      "Epoch 7/50\n",
      "483/483 [==============================] - 0s 549us/step - loss: 0.7766 - acc: 0.5901\n",
      "Epoch 8/50\n",
      "483/483 [==============================] - 0s 600us/step - loss: 0.5999 - acc: 0.6812\n",
      "Epoch 9/50\n",
      "483/483 [==============================] - 0s 509us/step - loss: 0.5799 - acc: 0.7019\n",
      "Epoch 10/50\n",
      "483/483 [==============================] - 0s 552us/step - loss: 0.5793 - acc: 0.7184\n",
      "Epoch 11/50\n",
      "483/483 [==============================] - 0s 539us/step - loss: 0.5935 - acc: 0.6977\n",
      "Epoch 12/50\n",
      "483/483 [==============================] - 0s 532us/step - loss: 0.5772 - acc: 0.6957\n",
      "Epoch 13/50\n",
      "483/483 [==============================] - 0s 533us/step - loss: 0.6004 - acc: 0.6915\n",
      "Epoch 14/50\n",
      "483/483 [==============================] - 0s 561us/step - loss: 0.6106 - acc: 0.6749\n",
      "Epoch 15/50\n",
      "483/483 [==============================] - 0s 673us/step - loss: 0.6004 - acc: 0.6853\n",
      "Epoch 16/50\n",
      "483/483 [==============================] - 0s 627us/step - loss: 0.5597 - acc: 0.7122\n",
      "Epoch 17/50\n",
      "483/483 [==============================] - 0s 528us/step - loss: 0.5612 - acc: 0.7267\n",
      "Epoch 18/50\n",
      "483/483 [==============================] - 0s 576us/step - loss: 0.5633 - acc: 0.7267\n",
      "Epoch 19/50\n",
      "483/483 [==============================] - 0s 540us/step - loss: 0.6095 - acc: 0.6812\n",
      "Epoch 20/50\n",
      "483/483 [==============================] - 0s 519us/step - loss: 0.5757 - acc: 0.6998\n",
      "Epoch 21/50\n",
      "483/483 [==============================] - 0s 546us/step - loss: 0.5809 - acc: 0.6894\n",
      "Epoch 22/50\n",
      "483/483 [==============================] - 0s 555us/step - loss: 0.5865 - acc: 0.7164\n",
      "Epoch 23/50\n",
      "483/483 [==============================] - 0s 538us/step - loss: 0.5496 - acc: 0.7391\n",
      "Epoch 24/50\n",
      "483/483 [==============================] - 0s 518us/step - loss: 0.5518 - acc: 0.7226\n",
      "Epoch 25/50\n",
      "483/483 [==============================] - 0s 555us/step - loss: 0.5438 - acc: 0.7557\n",
      "Epoch 26/50\n",
      "483/483 [==============================] - 0s 658us/step - loss: 0.5652 - acc: 0.7122\n",
      "Epoch 27/50\n",
      "483/483 [==============================] - 0s 731us/step - loss: 0.5527 - acc: 0.7143\n",
      "Epoch 28/50\n",
      "483/483 [==============================] - 0s 942us/step - loss: 0.5480 - acc: 0.7391\n",
      "Epoch 29/50\n",
      "483/483 [==============================] - 0s 883us/step - loss: 0.5777 - acc: 0.7143\n",
      "Epoch 30/50\n",
      "483/483 [==============================] - 0s 814us/step - loss: 0.5527 - acc: 0.7308\n",
      "Epoch 31/50\n",
      "483/483 [==============================] - 0s 903us/step - loss: 0.5362 - acc: 0.7474\n",
      "Epoch 32/50\n",
      "483/483 [==============================] - 0s 889us/step - loss: 0.5424 - acc: 0.7267\n",
      "Epoch 33/50\n",
      "483/483 [==============================] - 0s 918us/step - loss: 0.5466 - acc: 0.7453\n",
      "Epoch 34/50\n",
      "483/483 [==============================] - 0s 982us/step - loss: 0.5439 - acc: 0.7474\n",
      "Epoch 35/50\n",
      "483/483 [==============================] - 0s 921us/step - loss: 0.5880 - acc: 0.6957\n",
      "Epoch 36/50\n",
      "483/483 [==============================] - 0s 861us/step - loss: 0.5361 - acc: 0.7371\n",
      "Epoch 37/50\n",
      "483/483 [==============================] - 0s 951us/step - loss: 0.5439 - acc: 0.7267\n",
      "Epoch 38/50\n",
      "483/483 [==============================] - 0s 846us/step - loss: 0.5499 - acc: 0.7143\n",
      "Epoch 39/50\n",
      "483/483 [==============================] - 0s 900us/step - loss: 0.5432 - acc: 0.7371\n",
      "Epoch 40/50\n",
      "483/483 [==============================] - 0s 663us/step - loss: 0.5544 - acc: 0.7184\n",
      "Epoch 41/50\n",
      "483/483 [==============================] - 0s 663us/step - loss: 0.5600 - acc: 0.7060\n",
      "Epoch 42/50\n",
      "483/483 [==============================] - 0s 683us/step - loss: 0.5310 - acc: 0.7557\n",
      "Epoch 43/50\n",
      "483/483 [==============================] - 0s 575us/step - loss: 0.5485 - acc: 0.7391\n",
      "Epoch 44/50\n",
      "483/483 [==============================] - 0s 592us/step - loss: 0.5145 - acc: 0.7578\n",
      "Epoch 45/50\n",
      "483/483 [==============================] - 0s 568us/step - loss: 0.5279 - acc: 0.7350\n",
      "Epoch 46/50\n",
      "483/483 [==============================] - 0s 562us/step - loss: 0.5278 - acc: 0.7391\n",
      "Epoch 47/50\n",
      "483/483 [==============================] - 0s 601us/step - loss: 0.5145 - acc: 0.7578\n",
      "Epoch 48/50\n",
      "483/483 [==============================] - 0s 521us/step - loss: 0.5059 - acc: 0.7640\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483/483 [==============================] - 0s 639us/step - loss: 0.5035 - acc: 0.7619\n",
      "Epoch 50/50\n",
      "483/483 [==============================] - 0s 594us/step - loss: 0.5195 - acc: 0.7474\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "483/483 [==============================] - 1s 1ms/step - loss: 4.1753 - acc: 0.5797\n",
      "Epoch 2/50\n",
      "483/483 [==============================] - 0s 622us/step - loss: 1.4756 - acc: 0.5487\n",
      "Epoch 3/50\n",
      "483/483 [==============================] - 0s 693us/step - loss: 0.6983 - acc: 0.6128\n",
      "Epoch 4/50\n",
      "483/483 [==============================] - 0s 688us/step - loss: 0.6564 - acc: 0.6439\n",
      "Epoch 5/50\n",
      "483/483 [==============================] - 0s 608us/step - loss: 0.7419 - acc: 0.5818\n",
      "Epoch 6/50\n",
      "483/483 [==============================] - 0s 545us/step - loss: 0.6904 - acc: 0.5983\n",
      "Epoch 7/50\n",
      "483/483 [==============================] - 0s 593us/step - loss: 0.6144 - acc: 0.6791\n",
      "Epoch 8/50\n",
      "483/483 [==============================] - 0s 538us/step - loss: 0.7287 - acc: 0.6149\n",
      "Epoch 9/50\n",
      "483/483 [==============================] - 0s 553us/step - loss: 0.6366 - acc: 0.6542\n",
      "Epoch 10/50\n",
      "483/483 [==============================] - 0s 508us/step - loss: 0.6124 - acc: 0.6832 0s - loss: 0.5935 - acc: 0.699\n",
      "Epoch 11/50\n",
      "483/483 [==============================] - 0s 528us/step - loss: 0.5811 - acc: 0.7143\n",
      "Epoch 12/50\n",
      "483/483 [==============================] - 0s 512us/step - loss: 0.6041 - acc: 0.6957\n",
      "Epoch 13/50\n",
      "483/483 [==============================] - 0s 557us/step - loss: 0.5768 - acc: 0.7164\n",
      "Epoch 14/50\n",
      "483/483 [==============================] - 0s 737us/step - loss: 0.5742 - acc: 0.7039\n",
      "Epoch 15/50\n",
      "483/483 [==============================] - 0s 556us/step - loss: 0.5961 - acc: 0.6998\n",
      "Epoch 16/50\n",
      "483/483 [==============================] - 0s 557us/step - loss: 0.5809 - acc: 0.7081\n",
      "Epoch 17/50\n",
      "483/483 [==============================] - 0s 511us/step - loss: 0.5829 - acc: 0.7081\n",
      "Epoch 18/50\n",
      "483/483 [==============================] - 0s 581us/step - loss: 0.5635 - acc: 0.7039\n",
      "Epoch 19/50\n",
      "483/483 [==============================] - 0s 542us/step - loss: 0.5688 - acc: 0.7122\n",
      "Epoch 20/50\n",
      "483/483 [==============================] - 0s 524us/step - loss: 0.6112 - acc: 0.6646\n",
      "Epoch 21/50\n",
      "483/483 [==============================] - 0s 646us/step - loss: 0.5819 - acc: 0.7101\n",
      "Epoch 22/50\n",
      "483/483 [==============================] - 0s 666us/step - loss: 0.5658 - acc: 0.7288\n",
      "Epoch 23/50\n",
      "483/483 [==============================] - 0s 504us/step - loss: 0.5528 - acc: 0.7288\n",
      "Epoch 24/50\n",
      "483/483 [==============================] - 0s 650us/step - loss: 0.5736 - acc: 0.7039\n",
      "Epoch 25/50\n",
      "483/483 [==============================] - 0s 799us/step - loss: 0.5793 - acc: 0.7060\n",
      "Epoch 26/50\n",
      "483/483 [==============================] - 0s 708us/step - loss: 0.5571 - acc: 0.7101\n",
      "Epoch 27/50\n",
      "483/483 [==============================] - 0s 779us/step - loss: 0.5979 - acc: 0.6957\n",
      "Epoch 28/50\n",
      "483/483 [==============================] - 0s 786us/step - loss: 0.5914 - acc: 0.7039\n",
      "Epoch 29/50\n",
      "483/483 [==============================] - 0s 853us/step - loss: 0.5762 - acc: 0.7101\n",
      "Epoch 30/50\n",
      "483/483 [==============================] - 0s 884us/step - loss: 0.5518 - acc: 0.7246\n",
      "Epoch 31/50\n",
      "483/483 [==============================] - 0s 784us/step - loss: 0.5584 - acc: 0.7226\n",
      "Epoch 32/50\n",
      "483/483 [==============================] - 0s 968us/step - loss: 0.5356 - acc: 0.7412\n",
      "Epoch 33/50\n",
      "483/483 [==============================] - 0s 748us/step - loss: 0.5572 - acc: 0.6915\n",
      "Epoch 34/50\n",
      "483/483 [==============================] - 0s 616us/step - loss: 0.5463 - acc: 0.7308\n",
      "Epoch 35/50\n",
      "483/483 [==============================] - 0s 748us/step - loss: 0.5333 - acc: 0.7433\n",
      "Epoch 36/50\n",
      "483/483 [==============================] - 0s 745us/step - loss: 0.5462 - acc: 0.7391\n",
      "Epoch 37/50\n",
      "483/483 [==============================] - 0s 949us/step - loss: 0.5372 - acc: 0.7205\n",
      "Epoch 38/50\n",
      "483/483 [==============================] - 0s 777us/step - loss: 0.5638 - acc: 0.7308\n",
      "Epoch 39/50\n",
      "483/483 [==============================] - 0s 824us/step - loss: 0.5386 - acc: 0.7329\n",
      "Epoch 40/50\n",
      "483/483 [==============================] - 0s 854us/step - loss: 0.5419 - acc: 0.7329\n",
      "Epoch 41/50\n",
      "483/483 [==============================] - 0s 804us/step - loss: 0.5384 - acc: 0.7308\n",
      "Epoch 42/50\n",
      "483/483 [==============================] - 0s 700us/step - loss: 0.5332 - acc: 0.7329\n",
      "Epoch 43/50\n",
      "483/483 [==============================] - 0s 734us/step - loss: 0.5538 - acc: 0.7164\n",
      "Epoch 44/50\n",
      "483/483 [==============================] - 0s 662us/step - loss: 0.5435 - acc: 0.7350\n",
      "Epoch 45/50\n",
      "483/483 [==============================] - 0s 840us/step - loss: 0.5733 - acc: 0.7164\n",
      "Epoch 46/50\n",
      "483/483 [==============================] - 0s 844us/step - loss: 0.5607 - acc: 0.7081\n",
      "Epoch 47/50\n",
      "483/483 [==============================] - 0s 645us/step - loss: 0.5489 - acc: 0.7308\n",
      "Epoch 48/50\n",
      "483/483 [==============================] - 0s 632us/step - loss: 0.5427 - acc: 0.7226\n",
      "Epoch 49/50\n",
      "483/483 [==============================] - 0s 646us/step - loss: 0.5330 - acc: 0.7391\n",
      "Epoch 50/50\n",
      "483/483 [==============================] - 0s 619us/step - loss: 0.5339 - acc: 0.7350\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "483/483 [==============================] - 1s 2ms/step - loss: 2.1462 - acc: 0.5549\n",
      "Epoch 2/50\n",
      "483/483 [==============================] - 0s 591us/step - loss: 1.0892 - acc: 0.5776\n",
      "Epoch 3/50\n",
      "483/483 [==============================] - 0s 575us/step - loss: 0.8680 - acc: 0.5859\n",
      "Epoch 4/50\n",
      "483/483 [==============================] - 0s 669us/step - loss: 0.7014 - acc: 0.6004\n",
      "Epoch 5/50\n",
      "483/483 [==============================] - 0s 609us/step - loss: 0.6583 - acc: 0.6687\n",
      "Epoch 6/50\n",
      "483/483 [==============================] - 0s 821us/step - loss: 0.6256 - acc: 0.6853\n",
      "Epoch 7/50\n",
      "483/483 [==============================] - 0s 782us/step - loss: 0.5928 - acc: 0.6957\n",
      "Epoch 8/50\n",
      "483/483 [==============================] - 0s 685us/step - loss: 0.5933 - acc: 0.7019\n",
      "Epoch 9/50\n",
      "483/483 [==============================] - 0s 632us/step - loss: 0.6438 - acc: 0.6522\n",
      "Epoch 10/50\n",
      "483/483 [==============================] - 0s 559us/step - loss: 0.5871 - acc: 0.6998\n",
      "Epoch 11/50\n",
      "483/483 [==============================] - 0s 572us/step - loss: 0.5562 - acc: 0.7081\n",
      "Epoch 12/50\n",
      "483/483 [==============================] - 0s 832us/step - loss: 0.5656 - acc: 0.7060\n",
      "Epoch 13/50\n",
      "483/483 [==============================] - 0s 832us/step - loss: 0.5848 - acc: 0.6957\n",
      "Epoch 14/50\n",
      "483/483 [==============================] - 0s 778us/step - loss: 0.5716 - acc: 0.6915\n",
      "Epoch 15/50\n",
      "483/483 [==============================] - 0s 813us/step - loss: 0.5737 - acc: 0.7060\n",
      "Epoch 16/50\n",
      "483/483 [==============================] - 0s 827us/step - loss: 0.5720 - acc: 0.6853\n",
      "Epoch 17/50\n",
      "483/483 [==============================] - 0s 824us/step - loss: 0.5560 - acc: 0.7226\n",
      "Epoch 18/50\n",
      "483/483 [==============================] - 0s 784us/step - loss: 0.5461 - acc: 0.7329\n",
      "Epoch 19/50\n",
      "483/483 [==============================] - 0s 760us/step - loss: 0.5367 - acc: 0.7288\n",
      "Epoch 20/50\n",
      "483/483 [==============================] - 0s 826us/step - loss: 0.5422 - acc: 0.7329\n",
      "Epoch 21/50\n",
      "483/483 [==============================] - 0s 743us/step - loss: 0.5597 - acc: 0.7412\n",
      "Epoch 22/50\n",
      "483/483 [==============================] - 0s 637us/step - loss: 0.5414 - acc: 0.7205\n",
      "Epoch 23/50\n",
      "483/483 [==============================] - 0s 604us/step - loss: 0.5454 - acc: 0.7246\n",
      "Epoch 24/50\n",
      "483/483 [==============================] - 0s 621us/step - loss: 0.5471 - acc: 0.7433\n",
      "Epoch 25/50\n",
      "483/483 [==============================] - 0s 609us/step - loss: 0.5383 - acc: 0.7371\n",
      "Epoch 26/50\n",
      "483/483 [==============================] - 0s 572us/step - loss: 0.5628 - acc: 0.7122\n",
      "Epoch 27/50\n",
      "483/483 [==============================] - 0s 589us/step - loss: 0.5443 - acc: 0.7164\n",
      "Epoch 28/50\n",
      "483/483 [==============================] - 0s 700us/step - loss: 0.5287 - acc: 0.7495\n",
      "Epoch 29/50\n",
      "483/483 [==============================] - 0s 577us/step - loss: 0.5310 - acc: 0.7184\n",
      "Epoch 30/50\n",
      "483/483 [==============================] - 0s 569us/step - loss: 0.5181 - acc: 0.7516\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483/483 [==============================] - 0s 579us/step - loss: 0.5159 - acc: 0.7536\n",
      "Epoch 32/50\n",
      "483/483 [==============================] - 0s 551us/step - loss: 0.5259 - acc: 0.7226\n",
      "Epoch 33/50\n",
      "483/483 [==============================] - 0s 857us/step - loss: 0.5205 - acc: 0.7391\n",
      "Epoch 34/50\n",
      "483/483 [==============================] - 0s 830us/step - loss: 0.5388 - acc: 0.7329\n",
      "Epoch 35/50\n",
      "483/483 [==============================] - 0s 797us/step - loss: 0.5935 - acc: 0.7039\n",
      "Epoch 36/50\n",
      "483/483 [==============================] - 0s 731us/step - loss: 0.5370 - acc: 0.7081\n",
      "Epoch 37/50\n",
      "483/483 [==============================] - 0s 675us/step - loss: 0.5445 - acc: 0.7371\n",
      "Epoch 38/50\n",
      "483/483 [==============================] - 0s 739us/step - loss: 0.5096 - acc: 0.7495\n",
      "Epoch 39/50\n",
      "483/483 [==============================] - 0s 854us/step - loss: 0.5561 - acc: 0.7288\n",
      "Epoch 40/50\n",
      "483/483 [==============================] - 0s 791us/step - loss: 0.5210 - acc: 0.7453\n",
      "Epoch 41/50\n",
      "483/483 [==============================] - 0s 913us/step - loss: 0.5100 - acc: 0.7516\n",
      "Epoch 42/50\n",
      "483/483 [==============================] - 0s 811us/step - loss: 0.4973 - acc: 0.7557\n",
      "Epoch 43/50\n",
      "483/483 [==============================] - 0s 852us/step - loss: 0.4925 - acc: 0.7660\n",
      "Epoch 44/50\n",
      "483/483 [==============================] - 0s 844us/step - loss: 0.5719 - acc: 0.7308\n",
      "Epoch 45/50\n",
      "483/483 [==============================] - 0s 839us/step - loss: 0.5343 - acc: 0.7433 0s - loss: 0.5472 - acc: 0.7\n",
      "Epoch 46/50\n",
      "483/483 [==============================] - 0s 891us/step - loss: 0.5153 - acc: 0.7474\n",
      "Epoch 47/50\n",
      "483/483 [==============================] - 0s 801us/step - loss: 0.5321 - acc: 0.7329\n",
      "Epoch 48/50\n",
      "483/483 [==============================] - 0s 724us/step - loss: 0.5269 - acc: 0.7267\n",
      "Epoch 49/50\n",
      "483/483 [==============================] - 0s 722us/step - loss: 0.5226 - acc: 0.7143\n",
      "Epoch 50/50\n",
      "483/483 [==============================] - 0s 586us/step - loss: 0.5158 - acc: 0.7557\n",
      "54/54 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "484/484 [==============================] - 1s 2ms/step - loss: 2.2728 - acc: 0.5186\n",
      "Epoch 2/50\n",
      "484/484 [==============================] - 0s 741us/step - loss: 0.9716 - acc: 0.5599\n",
      "Epoch 3/50\n",
      "484/484 [==============================] - 0s 546us/step - loss: 0.6548 - acc: 0.6281\n",
      "Epoch 4/50\n",
      "484/484 [==============================] - 0s 640us/step - loss: 0.6527 - acc: 0.6384\n",
      "Epoch 5/50\n",
      "484/484 [==============================] - 0s 642us/step - loss: 0.6100 - acc: 0.6591\n",
      "Epoch 6/50\n",
      "484/484 [==============================] - 0s 711us/step - loss: 0.6047 - acc: 0.6921\n",
      "Epoch 7/50\n",
      "484/484 [==============================] - 0s 887us/step - loss: 0.5831 - acc: 0.7004\n",
      "Epoch 8/50\n",
      "484/484 [==============================] - 0s 720us/step - loss: 0.6205 - acc: 0.6715\n",
      "Epoch 9/50\n",
      "484/484 [==============================] - 0s 811us/step - loss: 0.5725 - acc: 0.7107\n",
      "Epoch 10/50\n",
      "484/484 [==============================] - 0s 856us/step - loss: 0.5583 - acc: 0.7190\n",
      "Epoch 11/50\n",
      "484/484 [==============================] - 0s 838us/step - loss: 0.6044 - acc: 0.6983\n",
      "Epoch 12/50\n",
      "484/484 [==============================] - 0s 913us/step - loss: 0.5856 - acc: 0.6880\n",
      "Epoch 13/50\n",
      "484/484 [==============================] - 0s 732us/step - loss: 0.5955 - acc: 0.6963 0s - loss: 0.6101 - acc: 0.\n",
      "Epoch 14/50\n",
      "484/484 [==============================] - 0s 926us/step - loss: 0.5852 - acc: 0.7128\n",
      "Epoch 15/50\n",
      "484/484 [==============================] - 0s 822us/step - loss: 0.5859 - acc: 0.6880\n",
      "Epoch 16/50\n",
      "484/484 [==============================] - 0s 729us/step - loss: 0.5606 - acc: 0.7231\n",
      "Epoch 17/50\n",
      "484/484 [==============================] - 0s 826us/step - loss: 0.5653 - acc: 0.7169\n",
      "Epoch 18/50\n",
      "484/484 [==============================] - 0s 683us/step - loss: 0.5506 - acc: 0.7045\n",
      "Epoch 19/50\n",
      "484/484 [==============================] - 0s 690us/step - loss: 0.5524 - acc: 0.7252 0s - loss: 0.5515 - acc: 0.73\n",
      "Epoch 20/50\n",
      "484/484 [==============================] - 0s 704us/step - loss: 0.5458 - acc: 0.7087\n",
      "Epoch 21/50\n",
      "484/484 [==============================] - 0s 645us/step - loss: 0.5373 - acc: 0.7417\n",
      "Epoch 22/50\n",
      "484/484 [==============================] - 0s 570us/step - loss: 0.5476 - acc: 0.7252\n",
      "Epoch 23/50\n",
      "484/484 [==============================] - 0s 797us/step - loss: 0.5415 - acc: 0.7190\n",
      "Epoch 24/50\n",
      "484/484 [==============================] - 0s 562us/step - loss: 0.5332 - acc: 0.7397\n",
      "Epoch 25/50\n",
      "484/484 [==============================] - 0s 624us/step - loss: 0.5298 - acc: 0.7397\n",
      "Epoch 26/50\n",
      "484/484 [==============================] - 0s 672us/step - loss: 0.5310 - acc: 0.7376\n",
      "Epoch 27/50\n",
      "484/484 [==============================] - 0s 727us/step - loss: 0.5532 - acc: 0.7087\n",
      "Epoch 28/50\n",
      "484/484 [==============================] - 0s 726us/step - loss: 0.5723 - acc: 0.7045\n",
      "Epoch 29/50\n",
      "484/484 [==============================] - 0s 727us/step - loss: 0.5403 - acc: 0.7231\n",
      "Epoch 30/50\n",
      "484/484 [==============================] - 0s 753us/step - loss: 0.5170 - acc: 0.7521\n",
      "Epoch 31/50\n",
      "484/484 [==============================] - 0s 867us/step - loss: 0.5294 - acc: 0.7459\n",
      "Epoch 32/50\n",
      "484/484 [==============================] - 0s 853us/step - loss: 0.5278 - acc: 0.7314\n",
      "Epoch 33/50\n",
      "484/484 [==============================] - 0s 737us/step - loss: 0.5160 - acc: 0.7521\n",
      "Epoch 34/50\n",
      "484/484 [==============================] - 0s 925us/step - loss: 0.5052 - acc: 0.7624\n",
      "Epoch 35/50\n",
      "484/484 [==============================] - 0s 872us/step - loss: 0.5420 - acc: 0.7335\n",
      "Epoch 36/50\n",
      "484/484 [==============================] - 0s 718us/step - loss: 0.5237 - acc: 0.7355\n",
      "Epoch 37/50\n",
      "484/484 [==============================] - 0s 618us/step - loss: 0.5398 - acc: 0.7066\n",
      "Epoch 38/50\n",
      "484/484 [==============================] - 0s 568us/step - loss: 0.5294 - acc: 0.7479\n",
      "Epoch 39/50\n",
      "484/484 [==============================] - 0s 664us/step - loss: 0.5705 - acc: 0.7107\n",
      "Epoch 40/50\n",
      "484/484 [==============================] - 0s 572us/step - loss: 0.5215 - acc: 0.7335\n",
      "Epoch 41/50\n",
      "484/484 [==============================] - 0s 690us/step - loss: 0.5351 - acc: 0.7376\n",
      "Epoch 42/50\n",
      "484/484 [==============================] - 0s 694us/step - loss: 0.5252 - acc: 0.7376\n",
      "Epoch 43/50\n",
      "484/484 [==============================] - 0s 712us/step - loss: 0.5063 - acc: 0.7438\n",
      "Epoch 44/50\n",
      "484/484 [==============================] - 0s 579us/step - loss: 0.5024 - acc: 0.7583\n",
      "Epoch 45/50\n",
      "484/484 [==============================] - 0s 689us/step - loss: 0.4989 - acc: 0.7624\n",
      "Epoch 46/50\n",
      "484/484 [==============================] - 0s 652us/step - loss: 0.5008 - acc: 0.7541\n",
      "Epoch 47/50\n",
      "484/484 [==============================] - 0s 686us/step - loss: 0.5095 - acc: 0.7479\n",
      "Epoch 48/50\n",
      "484/484 [==============================] - 0s 738us/step - loss: 0.4966 - acc: 0.7707\n",
      "Epoch 49/50\n",
      "484/484 [==============================] - 0s 756us/step - loss: 0.5027 - acc: 0.7521\n",
      "Epoch 50/50\n",
      "484/484 [==============================] - 0s 733us/step - loss: 0.4972 - acc: 0.7583\n",
      "53/53 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "484/484 [==============================] - 1s 2ms/step - loss: 2.1291 - acc: 0.5744\n",
      "Epoch 2/50\n",
      "484/484 [==============================] - 0s 613us/step - loss: 0.7800 - acc: 0.5992\n",
      "Epoch 3/50\n",
      "484/484 [==============================] - 0s 564us/step - loss: 0.6824 - acc: 0.6384\n",
      "Epoch 4/50\n",
      "484/484 [==============================] - 0s 525us/step - loss: 0.6726 - acc: 0.6467\n",
      "Epoch 5/50\n",
      "484/484 [==============================] - 0s 554us/step - loss: 0.6325 - acc: 0.6674\n",
      "Epoch 6/50\n",
      "484/484 [==============================] - 0s 522us/step - loss: 0.6580 - acc: 0.6508\n",
      "Epoch 7/50\n",
      "484/484 [==============================] - 0s 519us/step - loss: 0.7387 - acc: 0.6756\n",
      "Epoch 8/50\n",
      "484/484 [==============================] - 0s 546us/step - loss: 0.5888 - acc: 0.6880\n",
      "Epoch 9/50\n",
      "484/484 [==============================] - 0s 538us/step - loss: 0.5744 - acc: 0.6963\n",
      "Epoch 10/50\n",
      "484/484 [==============================] - 0s 654us/step - loss: 0.6227 - acc: 0.6364\n",
      "Epoch 11/50\n",
      "484/484 [==============================] - 0s 615us/step - loss: 0.5934 - acc: 0.6880\n",
      "Epoch 12/50\n",
      "484/484 [==============================] - 0s 604us/step - loss: 0.5569 - acc: 0.7293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "484/484 [==============================] - 0s 527us/step - loss: 0.5593 - acc: 0.7252\n",
      "Epoch 14/50\n",
      "484/484 [==============================] - 0s 594us/step - loss: 0.5970 - acc: 0.6839\n",
      "Epoch 15/50\n",
      "484/484 [==============================] - 0s 902us/step - loss: 0.5494 - acc: 0.7149\n",
      "Epoch 16/50\n",
      "484/484 [==============================] - 0s 819us/step - loss: 0.5428 - acc: 0.7231\n",
      "Epoch 17/50\n",
      "484/484 [==============================] - 0s 876us/step - loss: 0.5628 - acc: 0.7149\n",
      "Epoch 18/50\n",
      "484/484 [==============================] - 0s 646us/step - loss: 0.5627 - acc: 0.7128\n",
      "Epoch 19/50\n",
      "484/484 [==============================] - 0s 705us/step - loss: 0.5632 - acc: 0.7128\n",
      "Epoch 20/50\n",
      "484/484 [==============================] - 0s 837us/step - loss: 0.5572 - acc: 0.7211\n",
      "Epoch 21/50\n",
      "484/484 [==============================] - 0s 767us/step - loss: 0.5374 - acc: 0.7273\n",
      "Epoch 22/50\n",
      "484/484 [==============================] - 0s 714us/step - loss: 0.5239 - acc: 0.7376\n",
      "Epoch 23/50\n",
      "484/484 [==============================] - 0s 890us/step - loss: 0.5292 - acc: 0.7479\n",
      "Epoch 24/50\n",
      "484/484 [==============================] - 0s 856us/step - loss: 0.5658 - acc: 0.7190\n",
      "Epoch 25/50\n",
      "484/484 [==============================] - 0s 761us/step - loss: 0.5387 - acc: 0.7252\n",
      "Epoch 26/50\n",
      "484/484 [==============================] - 0s 619us/step - loss: 0.5406 - acc: 0.7376\n",
      "Epoch 27/50\n",
      "484/484 [==============================] - 0s 646us/step - loss: 0.5390 - acc: 0.7541\n",
      "Epoch 28/50\n",
      "484/484 [==============================] - 0s 651us/step - loss: 0.5188 - acc: 0.7459\n",
      "Epoch 29/50\n",
      "484/484 [==============================] - 0s 561us/step - loss: 0.5556 - acc: 0.7149\n",
      "Epoch 30/50\n",
      "484/484 [==============================] - 0s 636us/step - loss: 0.5603 - acc: 0.7025\n",
      "Epoch 31/50\n",
      "484/484 [==============================] - 0s 834us/step - loss: 0.5517 - acc: 0.7128\n",
      "Epoch 32/50\n",
      "484/484 [==============================] - 0s 681us/step - loss: 0.5645 - acc: 0.7397\n",
      "Epoch 33/50\n",
      "484/484 [==============================] - 0s 579us/step - loss: 0.5677 - acc: 0.7128\n",
      "Epoch 34/50\n",
      "484/484 [==============================] - 0s 635us/step - loss: 0.5556 - acc: 0.7128\n",
      "Epoch 35/50\n",
      "484/484 [==============================] - 0s 743us/step - loss: 0.5244 - acc: 0.7376\n",
      "Epoch 36/50\n",
      "484/484 [==============================] - 0s 668us/step - loss: 0.5196 - acc: 0.7583\n",
      "Epoch 37/50\n",
      "484/484 [==============================] - 0s 811us/step - loss: 0.5742 - acc: 0.7128\n",
      "Epoch 38/50\n",
      "484/484 [==============================] - 0s 749us/step - loss: 0.5549 - acc: 0.7231\n",
      "Epoch 39/50\n",
      "484/484 [==============================] - 0s 783us/step - loss: 0.5421 - acc: 0.7252\n",
      "Epoch 40/50\n",
      "484/484 [==============================] - 0s 744us/step - loss: 0.5252 - acc: 0.7500\n",
      "Epoch 41/50\n",
      "484/484 [==============================] - 0s 745us/step - loss: 0.5332 - acc: 0.7355\n",
      "Epoch 42/50\n",
      "484/484 [==============================] - 0s 673us/step - loss: 0.5133 - acc: 0.7459\n",
      "Epoch 43/50\n",
      "484/484 [==============================] - 0s 720us/step - loss: 0.5146 - acc: 0.7459\n",
      "Epoch 44/50\n",
      "484/484 [==============================] - 0s 560us/step - loss: 0.5237 - acc: 0.7376\n",
      "Epoch 45/50\n",
      "484/484 [==============================] - 0s 526us/step - loss: 0.5137 - acc: 0.7459\n",
      "Epoch 46/50\n",
      "484/484 [==============================] - 0s 564us/step - loss: 0.5096 - acc: 0.7583\n",
      "Epoch 47/50\n",
      "484/484 [==============================] - 0s 560us/step - loss: 0.4999 - acc: 0.7500\n",
      "Epoch 48/50\n",
      "484/484 [==============================] - 0s 550us/step - loss: 0.4902 - acc: 0.7645\n",
      "Epoch 49/50\n",
      "484/484 [==============================] - 0s 539us/step - loss: 0.5005 - acc: 0.7521\n",
      "Epoch 50/50\n",
      "484/484 [==============================] - 0s 629us/step - loss: 0.5021 - acc: 0.7438\n",
      "53/53 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "484/484 [==============================] - 1s 2ms/step - loss: 2.0125 - acc: 0.5393\n",
      "Epoch 2/50\n",
      "484/484 [==============================] - 0s 629us/step - loss: 0.8291 - acc: 0.5579\n",
      "Epoch 3/50\n",
      "484/484 [==============================] - 0s 696us/step - loss: 0.6550 - acc: 0.6467 0s - loss: 0.6920 - acc: 0.6\n",
      "Epoch 4/50\n",
      "484/484 [==============================] - 0s 744us/step - loss: 0.6309 - acc: 0.6839\n",
      "Epoch 5/50\n",
      "484/484 [==============================] - 0s 620us/step - loss: 0.6002 - acc: 0.6632\n",
      "Epoch 6/50\n",
      "484/484 [==============================] - 0s 523us/step - loss: 0.5679 - acc: 0.7004\n",
      "Epoch 7/50\n",
      "484/484 [==============================] - 0s 627us/step - loss: 0.5659 - acc: 0.7066\n",
      "Epoch 8/50\n",
      "484/484 [==============================] - 0s 621us/step - loss: 0.5719 - acc: 0.6942\n",
      "Epoch 9/50\n",
      "484/484 [==============================] - 0s 626us/step - loss: 0.5914 - acc: 0.6983\n",
      "Epoch 10/50\n",
      "484/484 [==============================] - 0s 768us/step - loss: 0.6016 - acc: 0.6839\n",
      "Epoch 11/50\n",
      "484/484 [==============================] - 0s 648us/step - loss: 0.5708 - acc: 0.6983\n",
      "Epoch 12/50\n",
      "484/484 [==============================] - 0s 538us/step - loss: 0.5511 - acc: 0.7190\n",
      "Epoch 13/50\n",
      "484/484 [==============================] - 0s 587us/step - loss: 0.5517 - acc: 0.7355\n",
      "Epoch 14/50\n",
      "484/484 [==============================] - 0s 654us/step - loss: 0.5535 - acc: 0.7045\n",
      "Epoch 15/50\n",
      "484/484 [==============================] - 0s 622us/step - loss: 0.5372 - acc: 0.7231\n",
      "Epoch 16/50\n",
      "484/484 [==============================] - 0s 654us/step - loss: 0.5455 - acc: 0.7397\n",
      "Epoch 17/50\n",
      "484/484 [==============================] - 0s 595us/step - loss: 0.5305 - acc: 0.7376\n",
      "Epoch 18/50\n",
      "484/484 [==============================] - 0s 573us/step - loss: 0.5986 - acc: 0.7066\n",
      "Epoch 19/50\n",
      "484/484 [==============================] - 0s 613us/step - loss: 0.5724 - acc: 0.7025\n",
      "Epoch 20/50\n",
      "484/484 [==============================] - 0s 549us/step - loss: 0.5396 - acc: 0.7128\n",
      "Epoch 21/50\n",
      "484/484 [==============================] - 0s 624us/step - loss: 0.5249 - acc: 0.7355\n",
      "Epoch 22/50\n",
      "484/484 [==============================] - 0s 541us/step - loss: 0.5222 - acc: 0.7252\n",
      "Epoch 23/50\n",
      "484/484 [==============================] - 0s 694us/step - loss: 0.5256 - acc: 0.7459\n",
      "Epoch 24/50\n",
      "484/484 [==============================] - 0s 642us/step - loss: 0.5310 - acc: 0.7149\n",
      "Epoch 25/50\n",
      "484/484 [==============================] - 0s 658us/step - loss: 0.5135 - acc: 0.7376\n",
      "Epoch 26/50\n",
      "484/484 [==============================] - 0s 646us/step - loss: 0.5366 - acc: 0.7376\n",
      "Epoch 27/50\n",
      "484/484 [==============================] - 0s 648us/step - loss: 0.5344 - acc: 0.7273\n",
      "Epoch 28/50\n",
      "484/484 [==============================] - 0s 586us/step - loss: 0.5214 - acc: 0.7335\n",
      "Epoch 29/50\n",
      "484/484 [==============================] - 0s 656us/step - loss: 0.5072 - acc: 0.7583\n",
      "Epoch 30/50\n",
      "484/484 [==============================] - 0s 744us/step - loss: 0.5130 - acc: 0.7293\n",
      "Epoch 31/50\n",
      "484/484 [==============================] - 0s 657us/step - loss: 0.5194 - acc: 0.7417\n",
      "Epoch 32/50\n",
      "484/484 [==============================] - 0s 684us/step - loss: 0.5043 - acc: 0.7417\n",
      "Epoch 33/50\n",
      "484/484 [==============================] - 0s 712us/step - loss: 0.5168 - acc: 0.7438\n",
      "Epoch 34/50\n",
      "484/484 [==============================] - 0s 662us/step - loss: 0.5601 - acc: 0.7087\n",
      "Epoch 35/50\n",
      "484/484 [==============================] - 0s 563us/step - loss: 0.5096 - acc: 0.7624\n",
      "Epoch 36/50\n",
      "484/484 [==============================] - 0s 538us/step - loss: 0.5216 - acc: 0.7376\n",
      "Epoch 37/50\n",
      "484/484 [==============================] - 0s 563us/step - loss: 0.5483 - acc: 0.7128\n",
      "Epoch 38/50\n",
      "484/484 [==============================] - 0s 714us/step - loss: 0.5298 - acc: 0.7314\n",
      "Epoch 39/50\n",
      "484/484 [==============================] - 0s 776us/step - loss: 0.5331 - acc: 0.7293\n",
      "Epoch 40/50\n",
      "484/484 [==============================] - 0s 704us/step - loss: 0.5155 - acc: 0.7686\n",
      "Epoch 41/50\n",
      "484/484 [==============================] - 0s 823us/step - loss: 0.5141 - acc: 0.7438\n",
      "Epoch 42/50\n",
      "484/484 [==============================] - 0s 795us/step - loss: 0.5099 - acc: 0.7603\n",
      "Epoch 43/50\n",
      "484/484 [==============================] - 0s 777us/step - loss: 0.5014 - acc: 0.7521\n",
      "Epoch 44/50\n",
      "484/484 [==============================] - 0s 933us/step - loss: 0.5028 - acc: 0.7603\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484/484 [==============================] - 0s 621us/step - loss: 0.4939 - acc: 0.7686\n",
      "Epoch 46/50\n",
      "484/484 [==============================] - 0s 546us/step - loss: 0.5415 - acc: 0.7004\n",
      "Epoch 47/50\n",
      "484/484 [==============================] - 0s 586us/step - loss: 0.5131 - acc: 0.7417\n",
      "Epoch 48/50\n",
      "484/484 [==============================] - 0s 564us/step - loss: 0.4961 - acc: 0.7603\n",
      "Epoch 49/50\n",
      "484/484 [==============================] - 0s 558us/step - loss: 0.5093 - acc: 0.7438\n",
      "Epoch 50/50\n",
      "484/484 [==============================] - 0s 669us/step - loss: 0.5173 - acc: 0.7293\n",
      "53/53 [==============================] - 0s 3ms/step\n",
      "Accuracy mean: 0.698008388543\n",
      "Accuracy variance: 0.0663048925269\n"
     ]
    }
   ],
   "source": [
    "# estimators \n",
    "# Evaluating the ANN\n",
    "t0 = time()\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 1024, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n",
    "    classifier.add(Dense(units = 512, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 50)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' Time ', '197.394', ' seconds')\n",
      "[[136  21]\n",
      " [ 33  41]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.87      0.83       157\n",
      "        1.0       0.66      0.55      0.60        74\n",
      "\n",
      "avg / total       0.76      0.77      0.76       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of DecisionTreeClassifier = 71.428571 %\n",
      "[[120  37]\n",
      " [ 29  45]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.76      0.78       157\n",
      "        1.0       0.55      0.61      0.58        74\n",
      "\n",
      "avg / total       0.72      0.71      0.72       231\n",
      "\n",
      "(' Time ', '0.009', ' seconds')\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of DecisionTreeClassifier = {:.6f} %\".format(acc * 100))\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of RandomForestClassifier = 77.922078 %\n",
      "[[139  18]\n",
      " [ 33  41]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.89      0.84       157\n",
      "        1.0       0.69      0.55      0.62        74\n",
      "\n",
      "avg / total       0.77      0.78      0.77       231\n",
      "\n",
      "(' Time ', '0.651', ' seconds')\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of RandomForestClassifier = {:.6f} %\".format(acc * 100))\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of ExtraTreesClassifier = 77.056277 %\n",
      "[[136  21]\n",
      " [ 32  42]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.81      0.87      0.84       157\n",
      "        1.0       0.67      0.57      0.61        74\n",
      "\n",
      "avg / total       0.76      0.77      0.77       231\n",
      "\n",
      "(' Time ', '0.521', ' seconds')\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of ExtraTreesClassifier = {:.6f} %\".format(acc * 100))\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of AdaBoostClassifier = 75.324675 %\n",
      "[[136  21]\n",
      " [ 36  38]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.87      0.83       157\n",
      "        1.0       0.64      0.51      0.57        74\n",
      "\n",
      "avg / total       0.74      0.75      0.74       231\n",
      "\n",
      "(' Time ', '0.436', ' seconds')\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of AdaBoostClassifier = {:.6f} %\".format(acc * 100))\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Naive_bayes  GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GaussianNB = 76.190476 %\n",
      "[[138  19]\n",
      " [ 36  38]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.88      0.83       157\n",
      "        1.0       0.67      0.51      0.58        74\n",
      "\n",
      "avg / total       0.75      0.76      0.75       231\n",
      "\n",
      "(' Time ', '0.039', ' seconds')\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred= gnb.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of GaussianNB = {:.6f} %\".format(acc * 100))\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
