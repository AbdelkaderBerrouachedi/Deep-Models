{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt \n",
    "from pprint import pprint\n",
    "from numpy import array\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>att1</th>\n",
       "      <th>att2</th>\n",
       "      <th>att3</th>\n",
       "      <th>att4</th>\n",
       "      <th>att5</th>\n",
       "      <th>att6</th>\n",
       "      <th>att7</th>\n",
       "      <th>att8</th>\n",
       "      <th>att9</th>\n",
       "      <th>att10</th>\n",
       "      <th>...</th>\n",
       "      <th>att19</th>\n",
       "      <th>att20</th>\n",
       "      <th>att21</th>\n",
       "      <th>att22</th>\n",
       "      <th>att23</th>\n",
       "      <th>att24</th>\n",
       "      <th>att25</th>\n",
       "      <th>att26</th>\n",
       "      <th>att27</th>\n",
       "      <th>outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.784999</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048171</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115728</td>\n",
       "      <td>0.023449</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.034952</td>\n",
       "      <td>0.046914</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.958088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022035</td>\n",
       "      <td>0.007516</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.938768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035542</td>\n",
       "      <td>0.011982</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.019520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.954775</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019941</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.933601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046759</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       att1      att2  att3      att4  att5  att6  att7  att8  att9     att10  \\\n",
       "0  0.784999  0.000018   0.0  0.000093   0.0   0.0   0.0   0.0   0.0  0.139811   \n",
       "1  0.958088  0.000000   0.0  0.001671   0.0   0.0   0.0   0.0   0.0  0.019556   \n",
       "2  0.938768  0.000000   0.0  0.005146   0.0   0.0   0.0   0.0   0.0  0.018451   \n",
       "3  0.954775  0.000000   0.0  0.001427   0.0   0.0   0.0   0.0   0.0  0.024944   \n",
       "4  0.933601  0.000000   0.0  0.001682   0.0   0.0   0.0   0.0   0.0  0.037002   \n",
       "\n",
       "    ...        att19     att20  att21     att22     att23   att24     att25  \\\n",
       "0   ...     0.048171  0.001189    0.0  0.115728  0.023449  0.0002  0.000220   \n",
       "1   ...     0.000000  0.000000    0.0  0.022035  0.007516  0.0000  0.000000   \n",
       "2   ...     0.000000  0.000000    0.0  0.035542  0.011982  0.0000  0.001595   \n",
       "3   ...     0.000000  0.000000    0.0  0.019941  0.000805  0.0000  0.000000   \n",
       "4   ...     0.000000  0.000000    0.0  0.046759  0.002663  0.0000  0.000339   \n",
       "\n",
       "      att26     att27  outlier  \n",
       "0  0.034952  0.046914        1  \n",
       "1  0.001033  0.000000        1  \n",
       "2  0.019520  0.000000        1  \n",
       "3  0.000035  0.000000        1  \n",
       "4  0.001359  0.000000        1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df=pd.read_csv('ALOI_norm.csv')  \n",
    "\n",
    "del df['id']\n",
    "del df['Unnamed: 0']\n",
    "df['outlier'] = df.outlier.apply(lambda label: 1 if label == \"'yes'\" else 0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df to values\n",
    "df = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GC Forest\n",
    "import argparse\n",
    "import sys\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "sys.path.insert(0, \"lib\")\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.utils.config_utils import load_json\n",
    "config = load_json(\"./examples/aloi.json\")   \n",
    "gc = GCForest(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# train test \n",
    "from sklearn.cross_validation import train_test_split\n",
    "y = df[:,27]\n",
    "X = df[:,0:27]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of class\n",
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 15:40:50,733][cascade_classifier.fit_transform] X_groups_train.shape=[(35000, 27)],y_train.shape=(35000,),X_groups_test.shape=[(15000, 27)],y_test.shape=(15000,)\n",
      "[ 2018-07-31 15:40:50,738][cascade_classifier.fit_transform] group_dims=[27]\n",
      "[ 2018-07-31 15:40:50,739][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-31 15:40:50,740][cascade_classifier.fit_transform] group_ends=[27]\n",
      "[ 2018-07-31 15:40:50,741][cascade_classifier.fit_transform] X_train.shape=(35000, 27),X_test.shape=(15000, 27)\n",
      "[ 2018-07-31 15:40:50,749][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(35000, 27), X_cur_test.shape=(15000, 27)\n",
      "[ 2018-07-31 15:40:54,294][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=97.12%\n",
      "[ 2018-07-31 15:40:57,380][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=97.17%\n",
      "[ 2018-07-31 15:41:00,365][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=97.23%\n",
      "[ 2018-07-31 15:41:03,462][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=97.09%\n",
      "[ 2018-07-31 15:41:06,601][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=97.29%\n",
      "[ 2018-07-31 15:41:09,990][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=97.26%\n",
      "[ 2018-07-31 15:41:14,312][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=97.03%\n",
      "[ 2018-07-31 15:41:17,306][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=97.11%\n",
      "[ 2018-07-31 15:41:20,300][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=97.20%\n",
      "[ 2018-07-31 15:41:23,314][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=97.23%\n",
      "[ 2018-07-31 15:41:23,562][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=97.17%\n",
      "[ 2018-07-31 15:41:23,563][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=97.15%\n",
      "[ 2018-07-31 15:41:25,106][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_0.predict)=97.40%\n",
      "[ 2018-07-31 15:41:26,860][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_1.predict)=97.49%\n",
      "[ 2018-07-31 15:41:28,649][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_2.predict)=97.20%\n",
      "[ 2018-07-31 15:41:30,546][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_3.predict)=97.23%\n",
      "[ 2018-07-31 15:41:32,706][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_4.predict)=97.34%\n",
      "[ 2018-07-31 15:41:35,206][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_5.predict)=97.40%\n",
      "[ 2018-07-31 15:41:37,371][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_6.predict)=97.37%\n",
      "[ 2018-07-31 15:41:39,108][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_7.predict)=97.17%\n",
      "[ 2018-07-31 15:41:40,858][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_8.predict)=97.26%\n",
      "[ 2018-07-31 15:41:42,749][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_9.predict)=97.23%\n",
      "[ 2018-07-31 15:41:42,987][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_cv.predict)=97.31%\n",
      "[ 2018-07-31 15:41:42,989][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.test.predict)=97.29%\n",
      "[ 2018-07-31 15:41:43,211][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_0.predict)=96.97%\n",
      "[ 2018-07-31 15:41:43,318][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_1.predict)=96.97%\n",
      "[ 2018-07-31 15:41:43,421][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_2.predict)=96.97%\n",
      "[ 2018-07-31 15:41:43,522][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_3.predict)=96.97%\n",
      "[ 2018-07-31 15:41:43,638][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_4.predict)=96.97%\n",
      "[ 2018-07-31 15:41:43,750][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_5.predict)=96.97%\n",
      "[ 2018-07-31 15:41:43,863][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_6.predict)=96.97%\n",
      "[ 2018-07-31 15:41:43,979][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_7.predict)=96.97%\n",
      "[ 2018-07-31 15:41:44,080][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_8.predict)=97.00%\n",
      "[ 2018-07-31 15:41:44,200][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_9.predict)=97.00%\n",
      "[ 2018-07-31 15:41:44,203][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_cv.predict)=96.98%\n",
      "[ 2018-07-31 15:41:44,205][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.test.predict)=97.00%\n",
      "[ 2018-07-31 15:41:44,207][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=97.03%\n",
      "[ 2018-07-31 15:41:44,209][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=97.03%\n",
      "[ 2018-07-31 15:41:44,218][cascade_classifier.fit_transform] [layer=1] look_indexs=[0], X_cur_train.shape=(35000, 33), X_cur_test.shape=(15000, 33)\n",
      "[ 2018-07-31 15:41:46,303][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_0.predict)=98.09%\n",
      "[ 2018-07-31 15:41:48,477][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_1.predict)=97.97%\n",
      "[ 2018-07-31 15:41:50,809][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_2.predict)=97.97%\n",
      "[ 2018-07-31 15:41:53,636][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_3.predict)=98.20%\n",
      "[ 2018-07-31 15:41:57,133][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_4.predict)=97.74%\n",
      "[ 2018-07-31 15:41:59,525][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_5.predict)=97.80%\n",
      "[ 2018-07-31 15:42:02,413][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_6.predict)=98.03%\n",
      "[ 2018-07-31 15:42:05,302][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_7.predict)=97.83%\n",
      "[ 2018-07-31 15:42:08,696][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_8.predict)=98.23%\n",
      "[ 2018-07-31 15:42:12,385][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_9.predict)=97.94%\n",
      "[ 2018-07-31 15:42:12,738][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_cv.predict)=97.98%\n",
      "[ 2018-07-31 15:42:12,743][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.test.predict)=98.09%\n",
      "[ 2018-07-31 15:42:14,382][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_0.predict)=98.23%\n",
      "[ 2018-07-31 15:42:15,760][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_1.predict)=97.97%\n",
      "[ 2018-07-31 15:42:17,218][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_2.predict)=97.89%\n",
      "[ 2018-07-31 15:42:18,599][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_3.predict)=98.09%\n",
      "[ 2018-07-31 15:42:19,974][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_4.predict)=97.71%\n",
      "[ 2018-07-31 15:42:21,378][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_5.predict)=97.94%\n",
      "[ 2018-07-31 15:42:22,790][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_6.predict)=98.00%\n",
      "[ 2018-07-31 15:42:24,164][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_7.predict)=97.91%\n",
      "[ 2018-07-31 15:42:25,579][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_8.predict)=97.69%\n",
      "[ 2018-07-31 15:42:26,991][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_9.predict)=97.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 15:42:27,242][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_cv.predict)=97.93%\n",
      "[ 2018-07-31 15:42:27,244][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.test.predict)=98.01%\n",
      "[ 2018-07-31 15:42:27,407][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_0.predict)=97.83%\n",
      "[ 2018-07-31 15:42:27,583][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_1.predict)=97.69%\n",
      "[ 2018-07-31 15:42:27,715][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_2.predict)=98.00%\n",
      "[ 2018-07-31 15:42:27,855][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_3.predict)=97.74%\n",
      "[ 2018-07-31 15:42:27,985][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_4.predict)=97.97%\n",
      "[ 2018-07-31 15:42:28,120][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_5.predict)=97.74%\n",
      "[ 2018-07-31 15:42:28,253][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_6.predict)=98.09%\n",
      "[ 2018-07-31 15:42:28,381][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_7.predict)=98.00%\n",
      "[ 2018-07-31 15:42:28,515][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_8.predict)=97.80%\n",
      "[ 2018-07-31 15:42:28,648][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_9.predict)=98.00%\n",
      "[ 2018-07-31 15:42:28,651][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_cv.predict)=97.89%\n",
      "[ 2018-07-31 15:42:28,652][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.test.predict)=97.86%\n",
      "[ 2018-07-31 15:42:28,654][cascade_classifier.calc_accuracy] Accuracy(layer_1 - train.classifier_average)=97.96%\n",
      "[ 2018-07-31 15:42:28,656][cascade_classifier.calc_accuracy] Accuracy(layer_1 - test.classifier_average)=97.97%\n",
      "[ 2018-07-31 15:42:28,664][cascade_classifier.fit_transform] [layer=2] look_indexs=[0], X_cur_train.shape=(35000, 33), X_cur_test.shape=(15000, 33)\n",
      "[ 2018-07-31 15:42:30,645][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_0.predict)=97.97%\n",
      "[ 2018-07-31 15:42:32,824][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_1.predict)=97.69%\n",
      "[ 2018-07-31 15:42:35,030][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_2.predict)=97.69%\n",
      "[ 2018-07-31 15:42:37,241][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_3.predict)=98.11%\n",
      "[ 2018-07-31 15:42:39,420][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_4.predict)=98.03%\n",
      "[ 2018-07-31 15:42:41,828][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_5.predict)=98.09%\n",
      "[ 2018-07-31 15:42:44,140][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_6.predict)=98.00%\n",
      "[ 2018-07-31 15:42:46,655][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_7.predict)=98.20%\n",
      "[ 2018-07-31 15:42:49,154][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_8.predict)=98.34%\n",
      "[ 2018-07-31 15:42:51,363][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_9.predict)=97.94%\n",
      "[ 2018-07-31 15:42:51,614][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_cv.predict)=98.01%\n",
      "[ 2018-07-31 15:42:51,615][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.test.predict)=98.09%\n",
      "[ 2018-07-31 15:42:52,751][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_0.predict)=98.06%\n",
      "[ 2018-07-31 15:42:54,123][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_1.predict)=98.06%\n",
      "[ 2018-07-31 15:42:55,503][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_2.predict)=98.14%\n",
      "[ 2018-07-31 15:42:56,872][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_3.predict)=97.83%\n",
      "[ 2018-07-31 15:42:58,264][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_4.predict)=98.00%\n",
      "[ 2018-07-31 15:42:59,643][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_5.predict)=97.86%\n",
      "[ 2018-07-31 15:43:01,038][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_6.predict)=98.09%\n",
      "[ 2018-07-31 15:43:02,416][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_7.predict)=97.91%\n",
      "[ 2018-07-31 15:43:03,813][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_8.predict)=98.09%\n",
      "[ 2018-07-31 15:43:05,183][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_9.predict)=97.71%\n",
      "[ 2018-07-31 15:43:05,439][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_cv.predict)=97.97%\n",
      "[ 2018-07-31 15:43:05,441][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.test.predict)=98.01%\n",
      "[ 2018-07-31 15:43:05,594][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_0.predict)=98.17%\n",
      "[ 2018-07-31 15:43:05,728][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_1.predict)=97.91%\n",
      "[ 2018-07-31 15:43:05,864][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_2.predict)=98.00%\n",
      "[ 2018-07-31 15:43:05,994][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_3.predict)=97.80%\n",
      "[ 2018-07-31 15:43:06,125][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_4.predict)=97.97%\n",
      "[ 2018-07-31 15:43:06,257][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_5.predict)=98.11%\n",
      "[ 2018-07-31 15:43:06,398][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_6.predict)=97.94%\n",
      "[ 2018-07-31 15:43:06,543][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_7.predict)=97.86%\n",
      "[ 2018-07-31 15:43:06,684][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_8.predict)=97.69%\n",
      "[ 2018-07-31 15:43:06,828][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_9.predict)=98.20%\n",
      "[ 2018-07-31 15:43:06,831][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_cv.predict)=97.97%\n",
      "[ 2018-07-31 15:43:06,832][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.test.predict)=98.12%\n",
      "[ 2018-07-31 15:43:06,834][cascade_classifier.calc_accuracy] Accuracy(layer_2 - train.classifier_average)=97.97%\n",
      "[ 2018-07-31 15:43:06,835][cascade_classifier.calc_accuracy] Accuracy(layer_2 - test.classifier_average)=98.07%\n",
      "[ 2018-07-31 15:43:06,844][cascade_classifier.fit_transform] [layer=3] look_indexs=[0], X_cur_train.shape=(35000, 33), X_cur_test.shape=(15000, 33)\n",
      "[ 2018-07-31 15:43:08,908][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_0.predict)=98.00%\n",
      "[ 2018-07-31 15:43:11,204][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_1.predict)=98.00%\n",
      "[ 2018-07-31 15:43:13,516][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_2.predict)=98.03%\n",
      "[ 2018-07-31 15:43:15,699][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_3.predict)=97.94%\n",
      "[ 2018-07-31 15:43:17,898][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_4.predict)=97.77%\n",
      "[ 2018-07-31 15:43:20,131][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_5.predict)=97.71%\n",
      "[ 2018-07-31 15:43:22,471][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_6.predict)=97.94%\n",
      "[ 2018-07-31 15:43:24,652][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_7.predict)=98.17%\n",
      "[ 2018-07-31 15:43:26,852][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_8.predict)=98.14%\n",
      "[ 2018-07-31 15:43:29,034][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_9.predict)=97.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 15:43:29,281][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_cv.predict)=97.97%\n",
      "[ 2018-07-31 15:43:29,283][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.test.predict)=98.14%\n",
      "[ 2018-07-31 15:43:30,431][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_0.predict)=97.86%\n",
      "[ 2018-07-31 15:43:31,818][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_1.predict)=97.57%\n",
      "[ 2018-07-31 15:43:33,191][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_2.predict)=97.86%\n",
      "[ 2018-07-31 15:43:34,591][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_3.predict)=98.03%\n",
      "[ 2018-07-31 15:43:35,991][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_4.predict)=98.14%\n",
      "[ 2018-07-31 15:43:37,382][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_5.predict)=97.89%\n",
      "[ 2018-07-31 15:43:38,773][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_6.predict)=98.11%\n",
      "[ 2018-07-31 15:43:40,153][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_7.predict)=98.00%\n",
      "[ 2018-07-31 15:43:41,639][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_8.predict)=98.29%\n",
      "[ 2018-07-31 15:43:43,069][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_9.predict)=97.69%\n",
      "[ 2018-07-31 15:43:43,289][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_cv.predict)=97.94%\n",
      "[ 2018-07-31 15:43:43,291][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.test.predict)=98.05%\n",
      "[ 2018-07-31 15:43:43,434][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_0.predict)=97.91%\n",
      "[ 2018-07-31 15:43:43,570][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_1.predict)=98.20%\n",
      "[ 2018-07-31 15:43:43,699][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_2.predict)=97.69%\n",
      "[ 2018-07-31 15:43:43,895][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_3.predict)=97.91%\n",
      "[ 2018-07-31 15:43:44,093][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_4.predict)=98.03%\n",
      "[ 2018-07-31 15:43:44,283][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_5.predict)=97.71%\n",
      "[ 2018-07-31 15:43:44,483][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_6.predict)=97.94%\n",
      "[ 2018-07-31 15:43:44,694][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_7.predict)=98.03%\n",
      "[ 2018-07-31 15:43:44,909][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_8.predict)=98.06%\n",
      "[ 2018-07-31 15:43:45,098][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_9.predict)=98.03%\n",
      "[ 2018-07-31 15:43:45,101][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_cv.predict)=97.95%\n",
      "[ 2018-07-31 15:43:45,103][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.test.predict)=98.00%\n",
      "[ 2018-07-31 15:43:45,107][cascade_classifier.calc_accuracy] Accuracy(layer_3 - train.classifier_average)=97.97%\n",
      "[ 2018-07-31 15:43:45,108][cascade_classifier.calc_accuracy] Accuracy(layer_3 - test.classifier_average)=98.07%\n",
      "[ 2018-07-31 15:43:45,121][cascade_classifier.fit_transform] [layer=4] look_indexs=[0], X_cur_train.shape=(35000, 33), X_cur_test.shape=(15000, 33)\n",
      "[ 2018-07-31 15:43:47,454][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_0.predict)=97.77%\n",
      "[ 2018-07-31 15:43:49,815][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_1.predict)=98.26%\n",
      "[ 2018-07-31 15:43:52,073][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_2.predict)=97.83%\n",
      "[ 2018-07-31 15:43:54,489][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_3.predict)=97.66%\n",
      "[ 2018-07-31 15:43:56,782][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_4.predict)=98.00%\n",
      "[ 2018-07-31 15:43:59,093][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_5.predict)=98.17%\n",
      "[ 2018-07-31 15:44:01,403][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_6.predict)=97.63%\n",
      "[ 2018-07-31 15:44:03,802][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_7.predict)=98.20%\n",
      "[ 2018-07-31 15:44:06,090][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_8.predict)=97.89%\n",
      "[ 2018-07-31 15:44:08,370][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_9.predict)=97.91%\n",
      "[ 2018-07-31 15:44:08,619][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_cv.predict)=97.93%\n",
      "[ 2018-07-31 15:44:08,620][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.test.predict)=98.11%\n",
      "[ 2018-07-31 15:44:09,866][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_0.predict)=97.77%\n",
      "[ 2018-07-31 15:44:11,239][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_1.predict)=97.54%\n",
      "[ 2018-07-31 15:44:12,726][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_2.predict)=98.31%\n",
      "[ 2018-07-31 15:44:14,220][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_3.predict)=98.20%\n",
      "[ 2018-07-31 15:44:15,721][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_4.predict)=97.91%\n",
      "[ 2018-07-31 15:44:17,209][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_5.predict)=97.80%\n",
      "[ 2018-07-31 15:44:18,700][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_6.predict)=97.94%\n",
      "[ 2018-07-31 15:44:20,156][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_7.predict)=97.71%\n",
      "[ 2018-07-31 15:44:21,604][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_8.predict)=97.86%\n",
      "[ 2018-07-31 15:44:23,109][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_9.predict)=97.83%\n",
      "[ 2018-07-31 15:44:23,367][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_cv.predict)=97.89%\n",
      "[ 2018-07-31 15:44:23,368][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.test.predict)=98.09%\n",
      "[ 2018-07-31 15:44:23,519][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_0.predict)=97.91%\n",
      "[ 2018-07-31 15:44:23,656][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_1.predict)=98.00%\n",
      "[ 2018-07-31 15:44:23,793][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_2.predict)=97.97%\n",
      "[ 2018-07-31 15:44:23,932][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_3.predict)=98.34%\n",
      "[ 2018-07-31 15:44:24,074][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_4.predict)=97.86%\n",
      "[ 2018-07-31 15:44:24,220][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_5.predict)=97.89%\n",
      "[ 2018-07-31 15:44:24,362][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_6.predict)=97.86%\n",
      "[ 2018-07-31 15:44:24,503][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_7.predict)=97.77%\n",
      "[ 2018-07-31 15:44:24,644][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_8.predict)=97.97%\n",
      "[ 2018-07-31 15:44:24,784][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_9.predict)=97.77%\n",
      "[ 2018-07-31 15:44:24,787][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_cv.predict)=97.93%\n",
      "[ 2018-07-31 15:44:24,788][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.test.predict)=98.06%\n",
      "[ 2018-07-31 15:44:24,790][cascade_classifier.calc_accuracy] Accuracy(layer_4 - train.classifier_average)=97.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 15:44:24,791][cascade_classifier.calc_accuracy] Accuracy(layer_4 - test.classifier_average)=98.11%\n",
      "[ 2018-07-31 15:44:24,800][cascade_classifier.fit_transform] [layer=5] look_indexs=[0], X_cur_train.shape=(35000, 33), X_cur_test.shape=(15000, 33)\n",
      "[ 2018-07-31 15:44:26,848][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_0.predict)=97.89%\n",
      "[ 2018-07-31 15:44:29,194][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_1.predict)=97.66%\n",
      "[ 2018-07-31 15:44:31,466][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_2.predict)=97.71%\n",
      "[ 2018-07-31 15:44:33,743][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_3.predict)=97.80%\n",
      "[ 2018-07-31 15:44:36,140][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_4.predict)=98.03%\n",
      "[ 2018-07-31 15:44:38,410][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_5.predict)=97.89%\n",
      "[ 2018-07-31 15:44:40,661][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_6.predict)=97.94%\n",
      "[ 2018-07-31 15:44:43,432][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_7.predict)=98.03%\n",
      "[ 2018-07-31 15:44:46,039][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_8.predict)=98.20%\n",
      "[ 2018-07-31 15:44:48,655][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_9.predict)=97.74%\n",
      "[ 2018-07-31 15:44:48,909][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_cv.predict)=97.89%\n",
      "[ 2018-07-31 15:44:48,911][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.test.predict)=98.11%\n",
      "[ 2018-07-31 15:44:50,264][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_0.predict)=97.80%\n",
      "[ 2018-07-31 15:44:51,805][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_1.predict)=97.83%\n",
      "[ 2018-07-31 15:44:53,282][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_2.predict)=97.66%\n",
      "[ 2018-07-31 15:44:54,739][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_3.predict)=98.06%\n",
      "[ 2018-07-31 15:44:56,244][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_4.predict)=97.80%\n",
      "[ 2018-07-31 15:44:57,690][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_5.predict)=97.74%\n",
      "[ 2018-07-31 15:44:59,203][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_6.predict)=98.09%\n",
      "[ 2018-07-31 15:45:00,721][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_7.predict)=98.29%\n",
      "[ 2018-07-31 15:45:02,579][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_8.predict)=97.60%\n",
      "[ 2018-07-31 15:45:05,226][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_9.predict)=97.74%\n",
      "[ 2018-07-31 15:45:05,741][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_cv.predict)=97.86%\n",
      "[ 2018-07-31 15:45:05,743][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.test.predict)=98.07%\n",
      "[ 2018-07-31 15:45:06,044][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_0.predict)=97.80%\n",
      "[ 2018-07-31 15:45:06,518][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_1.predict)=97.86%\n",
      "[ 2018-07-31 15:45:06,949][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_2.predict)=98.03%\n",
      "[ 2018-07-31 15:45:07,307][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_3.predict)=97.83%\n",
      "[ 2018-07-31 15:45:07,720][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_4.predict)=97.86%\n",
      "[ 2018-07-31 15:45:08,209][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_5.predict)=97.86%\n",
      "[ 2018-07-31 15:45:08,555][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_6.predict)=97.94%\n",
      "[ 2018-07-31 15:45:08,922][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_7.predict)=97.97%\n",
      "[ 2018-07-31 15:45:09,189][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_8.predict)=97.89%\n",
      "[ 2018-07-31 15:45:09,512][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_9.predict)=97.71%\n",
      "[ 2018-07-31 15:45:09,527][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_cv.predict)=97.87%\n",
      "[ 2018-07-31 15:45:09,529][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.test.predict)=98.05%\n",
      "[ 2018-07-31 15:45:09,532][cascade_classifier.calc_accuracy] Accuracy(layer_5 - train.classifier_average)=97.90%\n",
      "[ 2018-07-31 15:45:09,534][cascade_classifier.calc_accuracy] Accuracy(layer_5 - test.classifier_average)=98.10%\n",
      "[ 2018-07-31 15:45:09,535][cascade_classifier.fit_transform] [Result][Optimal Level Detected] opt_layer_num=3, accuracy_train=97.97%, accuracy_test=98.07%\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "# X_enc is the concatenated predict_proba result of each estimators of the last layer of the GCForest model\n",
    "    # X_enc.shape =\n",
    "    #   (n_datas, n_estimators * n_classes): If cascade is provided\n",
    "    #   (n_datas, n_estimators * n_classes, dimX, dimY): If only finegrained part is provided\n",
    "    # You can also pass X_test, y_test to fit_transform method, then the accracy on test data will be logged when training.\n",
    "X_train_enc, X_test_enc = gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test)\n",
    "    # WARNING: if you set gc.set_keep_model_in_mem(True), you would have to use\n",
    "    # gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test) to evaluate your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 15:45:09,628][cascade_classifier.transform] X_groups_test.shape=[(15000, 27)]\n",
      "[ 2018-07-31 15:45:09,634][cascade_classifier.transform] group_dims=[27]\n",
      "[ 2018-07-31 15:45:09,638][cascade_classifier.transform] X_test.shape=(15000, 27)\n",
      "[ 2018-07-31 15:45:09,642][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(15000, 27)\n",
      "[ 2018-07-31 15:45:15,047][cascade_classifier.transform] [layer=1] look_indexs=[0], X_cur_test.shape=(15000, 33)\n",
      "[ 2018-07-31 15:45:19,918][cascade_classifier.transform] [layer=2] look_indexs=[0], X_cur_test.shape=(15000, 33)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GCForest = 98.066667 %\n",
      "(' Time ', '274.127', ' seconds')\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "y_pred = gc.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy of GCForest = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14505    45]\n",
      " [  245   205]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99     14550\n",
      "        1.0       0.82      0.46      0.59       450\n",
      "\n",
      "avg / total       0.98      0.98      0.98     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "31500/31500 [==============================] - 7s 236us/step - loss: 0.1411 - acc: 0.9689\n",
      "Epoch 2/50\n",
      "31500/31500 [==============================] - 5s 171us/step - loss: 0.1343 - acc: 0.9700\n",
      "Epoch 3/50\n",
      "31500/31500 [==============================] - 6s 191us/step - loss: 0.1332 - acc: 0.9702\n",
      "Epoch 4/50\n",
      "31500/31500 [==============================] - 7s 227us/step - loss: 0.1326 - acc: 0.9704\n",
      "Epoch 5/50\n",
      "31500/31500 [==============================] - 5s 171us/step - loss: 0.1309 - acc: 0.9705\n",
      "Epoch 6/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.1294 - acc: 0.9706\n",
      "Epoch 7/50\n",
      "31500/31500 [==============================] - 7s 212us/step - loss: 0.1286 - acc: 0.9706\n",
      "Epoch 8/50\n",
      "31500/31500 [==============================] - 6s 186us/step - loss: 0.1275 - acc: 0.9708\n",
      "Epoch 9/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.1261 - acc: 0.9709\n",
      "Epoch 10/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.1253 - acc: 0.9710\n",
      "Epoch 11/50\n",
      "31500/31500 [==============================] - 7s 218us/step - loss: 0.1239 - acc: 0.9710\n",
      "Epoch 12/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.1225 - acc: 0.9714\n",
      "Epoch 13/50\n",
      "31500/31500 [==============================] - 6s 180us/step - loss: 0.1218 - acc: 0.9713\n",
      "Epoch 14/50\n",
      "31500/31500 [==============================] - 7s 225us/step - loss: 0.1205 - acc: 0.9717\n",
      "Epoch 15/50\n",
      "31500/31500 [==============================] - 5s 173us/step - loss: 0.1189 - acc: 0.9718\n",
      "Epoch 16/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.1182 - acc: 0.9717\n",
      "Epoch 17/50\n",
      "31500/31500 [==============================] - 6s 205us/step - loss: 0.1160 - acc: 0.9722\n",
      "Epoch 18/50\n",
      "31500/31500 [==============================] - 8s 260us/step - loss: 0.1160 - acc: 0.9722\n",
      "Epoch 19/50\n",
      "31500/31500 [==============================] - 7s 213us/step - loss: 0.1149 - acc: 0.9723\n",
      "Epoch 20/50\n",
      "31500/31500 [==============================] - 6s 177us/step - loss: 0.1130 - acc: 0.9726\n",
      "Epoch 21/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.1126 - acc: 0.9726\n",
      "Epoch 22/50\n",
      "31500/31500 [==============================] - 6s 177us/step - loss: 0.1120 - acc: 0.9724\n",
      "Epoch 23/50\n",
      "31500/31500 [==============================] - 6s 194us/step - loss: 0.1107 - acc: 0.9730\n",
      "Epoch 24/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.1102 - acc: 0.9730\n",
      "Epoch 25/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.1091 - acc: 0.9727\n",
      "Epoch 26/50\n",
      "31500/31500 [==============================] - 7s 217us/step - loss: 0.1082 - acc: 0.9730\n",
      "Epoch 27/50\n",
      "31500/31500 [==============================] - 6s 203us/step - loss: 0.1083 - acc: 0.9733\n",
      "Epoch 28/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.1064 - acc: 0.9732\n",
      "Epoch 29/50\n",
      "31500/31500 [==============================] - 6s 180us/step - loss: 0.1064 - acc: 0.9732\n",
      "Epoch 30/50\n",
      "31500/31500 [==============================] - 5s 174us/step - loss: 0.1054 - acc: 0.9737\n",
      "Epoch 31/50\n",
      "31500/31500 [==============================] - 6s 175us/step - loss: 0.1040 - acc: 0.9737\n",
      "Epoch 32/50\n",
      "31500/31500 [==============================] - 5s 173us/step - loss: 0.1039 - acc: 0.9735\n",
      "Epoch 33/50\n",
      "31500/31500 [==============================] - 6s 186us/step - loss: 0.1029 - acc: 0.9740\n",
      "Epoch 34/50\n",
      "31500/31500 [==============================] - 6s 179us/step - loss: 0.1027 - acc: 0.9739\n",
      "Epoch 35/50\n",
      "31500/31500 [==============================] - 5s 170us/step - loss: 0.1019 - acc: 0.9740\n",
      "Epoch 36/50\n",
      "31500/31500 [==============================] - 5s 170us/step - loss: 0.1012 - acc: 0.9741\n",
      "Epoch 37/50\n",
      "31500/31500 [==============================] - 6s 177us/step - loss: 0.0999 - acc: 0.9745\n",
      "Epoch 38/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.1006 - acc: 0.9737\n",
      "Epoch 39/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.0982 - acc: 0.9747\n",
      "Epoch 40/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.0976 - acc: 0.9751\n",
      "Epoch 41/50\n",
      "31500/31500 [==============================] - 5s 174us/step - loss: 0.0978 - acc: 0.9746\n",
      "Epoch 42/50\n",
      "31500/31500 [==============================] - 5s 173us/step - loss: 0.0964 - acc: 0.9749\n",
      "Epoch 43/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.0971 - acc: 0.9749\n",
      "Epoch 44/50\n",
      "31500/31500 [==============================] - 6s 185us/step - loss: 0.0962 - acc: 0.9748\n",
      "Epoch 45/50\n",
      "31500/31500 [==============================] - 6s 189us/step - loss: 0.0945 - acc: 0.9756\n",
      "Epoch 46/50\n",
      "31500/31500 [==============================] - 6s 179us/step - loss: 0.0943 - acc: 0.9757\n",
      "Epoch 47/50\n",
      "31500/31500 [==============================] - 6s 181us/step - loss: 0.0937 - acc: 0.9756\n",
      "Epoch 48/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.0927 - acc: 0.9759\n",
      "Epoch 49/50\n",
      "31500/31500 [==============================] - 7s 221us/step - loss: 0.0920 - acc: 0.9762\n",
      "Epoch 50/50\n",
      "31500/31500 [==============================] - 8s 259us/step - loss: 0.0920 - acc: 0.9761\n",
      "3500/3500 [==============================] - 0s 51us/step\n",
      "Epoch 1/50\n",
      "31500/31500 [==============================] - 6s 188us/step - loss: 0.1434 - acc: 0.9684\n",
      "Epoch 2/50\n",
      "31500/31500 [==============================] - 6s 177us/step - loss: 0.1367 - acc: 0.9696\n",
      "Epoch 3/50\n",
      "31500/31500 [==============================] - 7s 232us/step - loss: 0.1347 - acc: 0.9698\n",
      "Epoch 4/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.1333 - acc: 0.9699\n",
      "Epoch 5/50\n",
      "31500/31500 [==============================] - 5s 171us/step - loss: 0.1328 - acc: 0.9701\n",
      "Epoch 6/50\n",
      "31500/31500 [==============================] - 6s 205us/step - loss: 0.1312 - acc: 0.9702\n",
      "Epoch 7/50\n",
      "31500/31500 [==============================] - 8s 256us/step - loss: 0.1309 - acc: 0.9704\n",
      "Epoch 8/50\n",
      "31500/31500 [==============================] - 5s 170us/step - loss: 0.1296 - acc: 0.9704\n",
      "Epoch 9/50\n",
      "31500/31500 [==============================] - 6s 195us/step - loss: 0.1282 - acc: 0.9704\n",
      "Epoch 10/50\n",
      "31500/31500 [==============================] - 6s 203us/step - loss: 0.1277 - acc: 0.9703\n",
      "Epoch 11/50\n",
      "31500/31500 [==============================] - 5s 169us/step - loss: 0.1268 - acc: 0.9705\n",
      "Epoch 12/50\n",
      "31500/31500 [==============================] - 5s 171us/step - loss: 0.1259 - acc: 0.9707\n",
      "Epoch 13/50\n",
      "31500/31500 [==============================] - 7s 230us/step - loss: 0.1248 - acc: 0.9708\n",
      "Epoch 14/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.1232 - acc: 0.9711\n",
      "Epoch 15/50\n",
      "31500/31500 [==============================] - 5s 171us/step - loss: 0.1231 - acc: 0.9710\n",
      "Epoch 16/50\n",
      "31500/31500 [==============================] - 6s 203us/step - loss: 0.1211 - acc: 0.9713\n",
      "Epoch 17/50\n",
      "31500/31500 [==============================] - 6s 193us/step - loss: 0.1201 - acc: 0.9713\n",
      "Epoch 18/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.1198 - acc: 0.9715\n",
      "Epoch 19/50\n",
      "31500/31500 [==============================] - 6s 181us/step - loss: 0.1180 - acc: 0.9716\n",
      "Epoch 20/50\n",
      "31500/31500 [==============================] - 8s 266us/step - loss: 0.1167 - acc: 0.9717\n",
      "Epoch 21/50\n",
      "31500/31500 [==============================] - 6s 199us/step - loss: 0.1161 - acc: 0.9720\n",
      "Epoch 22/50\n",
      "31500/31500 [==============================] - 6s 188us/step - loss: 0.1148 - acc: 0.9718\n",
      "Epoch 23/50\n",
      "31500/31500 [==============================] - 6s 183us/step - loss: 0.1144 - acc: 0.9722\n",
      "Epoch 24/50\n",
      "31500/31500 [==============================] - 6s 187us/step - loss: 0.1129 - acc: 0.9719\n",
      "Epoch 25/50\n",
      "31500/31500 [==============================] - 5s 170us/step - loss: 0.1122 - acc: 0.9726\n",
      "Epoch 26/50\n",
      "31500/31500 [==============================] - 6s 175us/step - loss: 0.1122 - acc: 0.9721\n",
      "Epoch 27/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.1100 - acc: 0.9727\n",
      "Epoch 28/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.1096 - acc: 0.9728\n",
      "Epoch 29/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.1083 - acc: 0.9728\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.1075 - acc: 0.9727\n",
      "Epoch 31/50\n",
      "31500/31500 [==============================] - 5s 169us/step - loss: 0.1068 - acc: 0.9732\n",
      "Epoch 32/50\n",
      "31500/31500 [==============================] - 5s 170us/step - loss: 0.1069 - acc: 0.9730\n",
      "Epoch 33/50\n",
      "31500/31500 [==============================] - 5s 169us/step - loss: 0.1053 - acc: 0.9731\n",
      "Epoch 34/50\n",
      "31500/31500 [==============================] - 6s 183us/step - loss: 0.1041 - acc: 0.9736\n",
      "Epoch 35/50\n",
      "31500/31500 [==============================] - 6s 184us/step - loss: 0.1044 - acc: 0.9731\n",
      "Epoch 36/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.1027 - acc: 0.9733\n",
      "Epoch 37/50\n",
      "31500/31500 [==============================] - 6s 178us/step - loss: 0.1029 - acc: 0.9735\n",
      "Epoch 38/50\n",
      "31500/31500 [==============================] - 7s 229us/step - loss: 0.1032 - acc: 0.9737\n",
      "Epoch 39/50\n",
      "31500/31500 [==============================] - 5s 171us/step - loss: 0.1009 - acc: 0.9740\n",
      "Epoch 40/50\n",
      "31500/31500 [==============================] - 5s 171us/step - loss: 0.1008 - acc: 0.9741\n",
      "Epoch 41/50\n",
      "31500/31500 [==============================] - 5s 173us/step - loss: 0.0992 - acc: 0.9743\n",
      "Epoch 42/50\n",
      "31500/31500 [==============================] - 5s 169us/step - loss: 0.0995 - acc: 0.9743\n",
      "Epoch 43/50\n",
      "31500/31500 [==============================] - 5s 170us/step - loss: 0.0985 - acc: 0.9744\n",
      "Epoch 44/50\n",
      "31500/31500 [==============================] - 5s 171us/step - loss: 0.0998 - acc: 0.9740\n",
      "Epoch 45/50\n",
      "31500/31500 [==============================] - 6s 189us/step - loss: 0.0975 - acc: 0.9745\n",
      "Epoch 46/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.0963 - acc: 0.9747\n",
      "Epoch 47/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.0962 - acc: 0.9747\n",
      "Epoch 48/50\n",
      "31500/31500 [==============================] - 6s 178us/step - loss: 0.0963 - acc: 0.9747\n",
      "Epoch 49/50\n",
      "31500/31500 [==============================] - 5s 169us/step - loss: 0.0951 - acc: 0.9750\n",
      "Epoch 50/50\n",
      "31500/31500 [==============================] - 6s 187us/step - loss: 0.0951 - acc: 0.9750\n",
      "3500/3500 [==============================] - 0s 82us/step\n",
      "Epoch 1/50\n",
      "31500/31500 [==============================] - 8s 266us/step - loss: 0.1415 - acc: 0.9690\n",
      "Epoch 2/50\n",
      "31500/31500 [==============================] - 5s 169us/step - loss: 0.1347 - acc: 0.9698\n",
      "Epoch 3/50\n",
      "31500/31500 [==============================] - 5s 169us/step - loss: 0.1332 - acc: 0.9702\n",
      "Epoch 4/50\n",
      "31500/31500 [==============================] - 7s 212us/step - loss: 0.1320 - acc: 0.9705\n",
      "Epoch 5/50\n",
      "31500/31500 [==============================] - 6s 187us/step - loss: 0.1300 - acc: 0.9707\n",
      "Epoch 6/50\n",
      "31500/31500 [==============================] - 5s 171us/step - loss: 0.1286 - acc: 0.9708\n",
      "Epoch 7/50\n",
      "31500/31500 [==============================] - 6s 175us/step - loss: 0.1276 - acc: 0.9708\n",
      "Epoch 8/50\n",
      "31500/31500 [==============================] - 7s 231us/step - loss: 0.1263 - acc: 0.9708\n",
      "Epoch 9/50\n",
      "31500/31500 [==============================] - 5s 170us/step - loss: 0.1258 - acc: 0.9710\n",
      "Epoch 10/50\n",
      "31500/31500 [==============================] - 5s 173us/step - loss: 0.1245 - acc: 0.9712\n",
      "Epoch 11/50\n",
      "31500/31500 [==============================] - 7s 221us/step - loss: 0.1237 - acc: 0.9711\n",
      "Epoch 12/50\n",
      "31500/31500 [==============================] - 6s 175us/step - loss: 0.1221 - acc: 0.9713\n",
      "Epoch 13/50\n",
      "31500/31500 [==============================] - 5s 171us/step - loss: 0.1209 - acc: 0.9717\n",
      "Epoch 14/50\n",
      "31500/31500 [==============================] - 6s 175us/step - loss: 0.1202 - acc: 0.9717\n",
      "Epoch 15/50\n",
      "31500/31500 [==============================] - 7s 223us/step - loss: 0.1195 - acc: 0.9717\n",
      "Epoch 16/50\n",
      "31500/31500 [==============================] - 5s 170us/step - loss: 0.1182 - acc: 0.9719\n",
      "Epoch 17/50\n",
      "31500/31500 [==============================] - 5s 171us/step - loss: 0.1173 - acc: 0.9720\n",
      "Epoch 18/50\n",
      "31500/31500 [==============================] - 8s 263us/step - loss: 0.1164 - acc: 0.9722\n",
      "Epoch 19/50\n",
      "31500/31500 [==============================] - 6s 202us/step - loss: 0.1148 - acc: 0.9725\n",
      "Epoch 20/50\n",
      "31500/31500 [==============================] - 6s 177us/step - loss: 0.1140 - acc: 0.9725\n",
      "Epoch 21/50\n",
      "31500/31500 [==============================] - 7s 226us/step - loss: 0.1131 - acc: 0.9727\n",
      "Epoch 22/50\n",
      "31500/31500 [==============================] - 7s 229us/step - loss: 0.1121 - acc: 0.9725\n",
      "Epoch 23/50\n",
      "31500/31500 [==============================] - 7s 207us/step - loss: 0.1109 - acc: 0.9728\n",
      "Epoch 24/50\n",
      "31500/31500 [==============================] - 6s 175us/step - loss: 0.1104 - acc: 0.9729\n",
      "Epoch 25/50\n",
      "31500/31500 [==============================] - 6s 187us/step - loss: 0.1093 - acc: 0.9732\n",
      "Epoch 26/50\n",
      "31500/31500 [==============================] - 5s 170us/step - loss: 0.1095 - acc: 0.9731\n",
      "Epoch 27/50\n",
      "31500/31500 [==============================] - 5s 171us/step - loss: 0.1079 - acc: 0.9737\n",
      "Epoch 28/50\n",
      "31500/31500 [==============================] - 6s 175us/step - loss: 0.1076 - acc: 0.9737\n",
      "Epoch 29/50\n",
      "31500/31500 [==============================] - 5s 171us/step - loss: 0.1058 - acc: 0.9738\n",
      "Epoch 30/50\n",
      "31500/31500 [==============================] - 5s 173us/step - loss: 0.1056 - acc: 0.9738\n",
      "Epoch 31/50\n",
      "31500/31500 [==============================] - 5s 170us/step - loss: 0.1058 - acc: 0.9738\n",
      "Epoch 32/50\n",
      "31500/31500 [==============================] - 5s 174us/step - loss: 0.1042 - acc: 0.9740\n",
      "Epoch 33/50\n",
      "31500/31500 [==============================] - 5s 171us/step - loss: 0.1031 - acc: 0.9741\n",
      "Epoch 34/50\n",
      "31500/31500 [==============================] - 5s 169us/step - loss: 0.1028 - acc: 0.9744\n",
      "Epoch 35/50\n",
      "31500/31500 [==============================] - 5s 174us/step - loss: 0.1021 - acc: 0.9742\n",
      "Epoch 36/50\n",
      "31500/31500 [==============================] - 6s 188us/step - loss: 0.1022 - acc: 0.9741\n",
      "Epoch 37/50\n",
      "31500/31500 [==============================] - 5s 171us/step - loss: 0.1006 - acc: 0.9747\n",
      "Epoch 38/50\n",
      "31500/31500 [==============================] - 5s 171us/step - loss: 0.1001 - acc: 0.9746\n",
      "Epoch 39/50\n",
      "31500/31500 [==============================] - 6s 177us/step - loss: 0.0999 - acc: 0.9746\n",
      "Epoch 40/50\n",
      "31500/31500 [==============================] - 5s 171us/step - loss: 0.0998 - acc: 0.9743\n",
      "Epoch 41/50\n",
      "31500/31500 [==============================] - 5s 173us/step - loss: 0.0991 - acc: 0.9749\n",
      "Epoch 42/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.0972 - acc: 0.9748\n",
      "Epoch 43/50\n",
      "31500/31500 [==============================] - 5s 173us/step - loss: 0.0969 - acc: 0.9752\n",
      "Epoch 44/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.0977 - acc: 0.9749\n",
      "Epoch 45/50\n",
      "31500/31500 [==============================] - 5s 173us/step - loss: 0.0964 - acc: 0.9754\n",
      "Epoch 46/50\n",
      "31500/31500 [==============================] - 6s 189us/step - loss: 0.0950 - acc: 0.9757\n",
      "Epoch 47/50\n",
      "31500/31500 [==============================] - 6s 188us/step - loss: 0.0955 - acc: 0.9757\n",
      "Epoch 48/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.0950 - acc: 0.9754\n",
      "Epoch 49/50\n",
      "31500/31500 [==============================] - 6s 190us/step - loss: 0.0935 - acc: 0.9756\n",
      "Epoch 50/50\n",
      "31500/31500 [==============================] - 7s 227us/step - loss: 0.0937 - acc: 0.9757\n",
      "3500/3500 [==============================] - 0s 57us/step\n",
      "Epoch 1/50\n",
      "31500/31500 [==============================] - 8s 267us/step - loss: 0.1421 - acc: 0.9688\n",
      "Epoch 2/50\n",
      "31500/31500 [==============================] - 7s 213us/step - loss: 0.1350 - acc: 0.9698\n",
      "Epoch 3/50\n",
      "31500/31500 [==============================] - 5s 171us/step - loss: 0.1338 - acc: 0.9700\n",
      "Epoch 4/50\n",
      "31500/31500 [==============================] - 5s 170us/step - loss: 0.1323 - acc: 0.9702\n",
      "Epoch 5/50\n",
      "31500/31500 [==============================] - 7s 228us/step - loss: 0.1320 - acc: 0.9703\n",
      "Epoch 6/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.1302 - acc: 0.9707\n",
      "Epoch 7/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.1284 - acc: 0.9709\n",
      "Epoch 8/50\n",
      "31500/31500 [==============================] - 6s 203us/step - loss: 0.1280 - acc: 0.9708\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31500/31500 [==============================] - 6s 199us/step - loss: 0.1270 - acc: 0.9709\n",
      "Epoch 10/50\n",
      "31500/31500 [==============================] - 5s 173us/step - loss: 0.1261 - acc: 0.9709\n",
      "Epoch 11/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.1248 - acc: 0.9709\n",
      "Epoch 12/50\n",
      "31500/31500 [==============================] - 7s 221us/step - loss: 0.1237 - acc: 0.9710\n",
      "Epoch 13/50\n",
      "31500/31500 [==============================] - 6s 175us/step - loss: 0.1223 - acc: 0.9709\n",
      "Epoch 14/50\n",
      "31500/31500 [==============================] - 5s 174us/step - loss: 0.1215 - acc: 0.9714\n",
      "Epoch 15/50\n",
      "31500/31500 [==============================] - 7s 228us/step - loss: 0.1200 - acc: 0.9716\n",
      "Epoch 16/50\n",
      "31500/31500 [==============================] - 6s 180us/step - loss: 0.1192 - acc: 0.9717\n",
      "Epoch 17/50\n",
      "31500/31500 [==============================] - 5s 174us/step - loss: 0.1181 - acc: 0.9719\n",
      "Epoch 18/50\n",
      "31500/31500 [==============================] - 6s 193us/step - loss: 0.1177 - acc: 0.9719\n",
      "Epoch 19/50\n",
      "31500/31500 [==============================] - 7s 216us/step - loss: 0.1162 - acc: 0.9722\n",
      "Epoch 20/50\n",
      "31500/31500 [==============================] - 5s 175us/step - loss: 0.1150 - acc: 0.9726\n",
      "Epoch 21/50\n",
      "31500/31500 [==============================] - 6s 183us/step - loss: 0.1144 - acc: 0.9725\n",
      "Epoch 22/50\n",
      "31500/31500 [==============================] - 9s 273us/step - loss: 0.1129 - acc: 0.9726\n",
      "Epoch 23/50\n",
      "31500/31500 [==============================] - 6s 200us/step - loss: 0.1131 - acc: 0.9724\n",
      "Epoch 24/50\n",
      "31500/31500 [==============================] - 6s 192us/step - loss: 0.1120 - acc: 0.9728\n",
      "Epoch 25/50\n",
      "31500/31500 [==============================] - 6s 189us/step - loss: 0.1106 - acc: 0.9727\n",
      "Epoch 26/50\n",
      "31500/31500 [==============================] - 6s 188us/step - loss: 0.1106 - acc: 0.9725\n",
      "Epoch 27/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.1103 - acc: 0.9726\n",
      "Epoch 28/50\n",
      "31500/31500 [==============================] - 6s 202us/step - loss: 0.1080 - acc: 0.9731\n",
      "Epoch 29/50\n",
      "31500/31500 [==============================] - 7s 218us/step - loss: 0.1077 - acc: 0.9738\n",
      "Epoch 30/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.1071 - acc: 0.9734\n",
      "Epoch 31/50\n",
      "31500/31500 [==============================] - 5s 173us/step - loss: 0.1066 - acc: 0.9733\n",
      "Epoch 32/50\n",
      "31500/31500 [==============================] - 5s 174us/step - loss: 0.1061 - acc: 0.9736\n",
      "Epoch 33/50\n",
      "31500/31500 [==============================] - 5s 175us/step - loss: 0.1064 - acc: 0.9732\n",
      "Epoch 34/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.1040 - acc: 0.9739\n",
      "Epoch 35/50\n",
      "31500/31500 [==============================] - 5s 173us/step - loss: 0.1032 - acc: 0.9738\n",
      "Epoch 36/50\n",
      "31500/31500 [==============================] - 6s 188us/step - loss: 0.1027 - acc: 0.9741\n",
      "Epoch 37/50\n",
      "31500/31500 [==============================] - 6s 184us/step - loss: 0.1029 - acc: 0.9742\n",
      "Epoch 38/50\n",
      "31500/31500 [==============================] - 5s 171us/step - loss: 0.1014 - acc: 0.9740\n",
      "Epoch 39/50\n",
      "31500/31500 [==============================] - 6s 175us/step - loss: 0.1009 - acc: 0.9741\n",
      "Epoch 40/50\n",
      "31500/31500 [==============================] - 5s 173us/step - loss: 0.0999 - acc: 0.9746\n",
      "Epoch 41/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.0998 - acc: 0.9743\n",
      "Epoch 42/50\n",
      "31500/31500 [==============================] - 5s 170us/step - loss: 0.0999 - acc: 0.9745\n",
      "Epoch 43/50\n",
      "31500/31500 [==============================] - 5s 173us/step - loss: 0.0984 - acc: 0.9747\n",
      "Epoch 44/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.0992 - acc: 0.9742\n",
      "Epoch 45/50\n",
      "31500/31500 [==============================] - 6s 175us/step - loss: 0.0975 - acc: 0.9745\n",
      "Epoch 46/50\n",
      "31500/31500 [==============================] - 6s 180us/step - loss: 0.0964 - acc: 0.9750\n",
      "Epoch 47/50\n",
      "31500/31500 [==============================] - 6s 194us/step - loss: 0.0962 - acc: 0.9746\n",
      "Epoch 48/50\n",
      "31500/31500 [==============================] - 6s 175us/step - loss: 0.0982 - acc: 0.9742\n",
      "Epoch 49/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.0946 - acc: 0.9747\n",
      "Epoch 50/50\n",
      "31500/31500 [==============================] - 6s 177us/step - loss: 0.0944 - acc: 0.9751\n",
      "3500/3500 [==============================] - 0s 66us/step\n",
      "Epoch 1/50\n",
      "31500/31500 [==============================] - 6s 194us/step - loss: 0.1400 - acc: 0.9694\n",
      "Epoch 2/50\n",
      "31500/31500 [==============================] - 5s 174us/step - loss: 0.1337 - acc: 0.9704\n",
      "Epoch 3/50\n",
      "31500/31500 [==============================] - 7s 220us/step - loss: 0.1320 - acc: 0.9706\n",
      "Epoch 4/50\n",
      "31500/31500 [==============================] - 8s 254us/step - loss: 0.1304 - acc: 0.9708\n",
      "Epoch 5/50\n",
      "31500/31500 [==============================] - 6s 175us/step - loss: 0.1290 - acc: 0.9711\n",
      "Epoch 6/50\n",
      "31500/31500 [==============================] - 6s 182us/step - loss: 0.1273 - acc: 0.9712\n",
      "Epoch 7/50\n",
      "31500/31500 [==============================] - 7s 227us/step - loss: 0.1262 - acc: 0.9714\n",
      "Epoch 8/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.1251 - acc: 0.9713\n",
      "Epoch 9/50\n",
      "31500/31500 [==============================] - 7s 221us/step - loss: 0.1235 - acc: 0.9714\n",
      "Epoch 10/50\n",
      "31500/31500 [==============================] - 8s 244us/step - loss: 0.1229 - acc: 0.9717\n",
      "Epoch 11/50\n",
      "31500/31500 [==============================] - 6s 175us/step - loss: 0.1214 - acc: 0.9717\n",
      "Epoch 12/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.1204 - acc: 0.9718\n",
      "Epoch 13/50\n",
      "31500/31500 [==============================] - 6s 200us/step - loss: 0.1194 - acc: 0.9723\n",
      "Epoch 14/50\n",
      "31500/31500 [==============================] - 6s 205us/step - loss: 0.1180 - acc: 0.9723\n",
      "Epoch 15/50\n",
      "31500/31500 [==============================] - 5s 174us/step - loss: 0.1171 - acc: 0.9723\n",
      "Epoch 16/50\n",
      "31500/31500 [==============================] - 6s 182us/step - loss: 0.1155 - acc: 0.9727\n",
      "Epoch 17/50\n",
      "31500/31500 [==============================] - 7s 223us/step - loss: 0.1152 - acc: 0.9726\n",
      "Epoch 18/50\n",
      "31500/31500 [==============================] - 5s 173us/step - loss: 0.1140 - acc: 0.9728\n",
      "Epoch 19/50\n",
      "31500/31500 [==============================] - 6s 181us/step - loss: 0.1128 - acc: 0.9730\n",
      "Epoch 20/50\n",
      "31500/31500 [==============================] - 7s 218us/step - loss: 0.1119 - acc: 0.9734\n",
      "Epoch 21/50\n",
      "31500/31500 [==============================] - 6s 178us/step - loss: 0.1112 - acc: 0.9733\n",
      "Epoch 22/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.1103 - acc: 0.9733\n",
      "Epoch 23/50\n",
      "31500/31500 [==============================] - 6s 194us/step - loss: 0.1090 - acc: 0.9737\n",
      "Epoch 24/50\n",
      "31500/31500 [==============================] - 8s 248us/step - loss: 0.1089 - acc: 0.9735\n",
      "Epoch 25/50\n",
      "31500/31500 [==============================] - 6s 201us/step - loss: 0.1079 - acc: 0.9736\n",
      "Epoch 26/50\n",
      "31500/31500 [==============================] - 7s 222us/step - loss: 0.1078 - acc: 0.9736\n",
      "Epoch 27/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.1064 - acc: 0.9737\n",
      "Epoch 28/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.1056 - acc: 0.9743\n",
      "Epoch 29/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.1052 - acc: 0.9739\n",
      "Epoch 30/50\n",
      "31500/31500 [==============================] - 5s 171us/step - loss: 0.1046 - acc: 0.9741\n",
      "Epoch 31/50\n",
      "31500/31500 [==============================] - 5s 171us/step - loss: 0.1035 - acc: 0.9742\n",
      "Epoch 32/50\n",
      "31500/31500 [==============================] - 5s 169us/step - loss: 0.1041 - acc: 0.9742\n",
      "Epoch 33/50\n",
      "31500/31500 [==============================] - 5s 168us/step - loss: 0.1032 - acc: 0.9745\n",
      "Epoch 34/50\n",
      "31500/31500 [==============================] - 5s 173us/step - loss: 0.1017 - acc: 0.9745\n",
      "Epoch 35/50\n",
      "31500/31500 [==============================] - 5s 170us/step - loss: 0.1036 - acc: 0.9741\n",
      "Epoch 36/50\n",
      "31500/31500 [==============================] - 6s 177us/step - loss: 0.1006 - acc: 0.9748\n",
      "Epoch 37/50\n",
      "31500/31500 [==============================] - 6s 188us/step - loss: 0.1001 - acc: 0.9750\n",
      "Epoch 38/50\n",
      "31500/31500 [==============================] - 6s 177us/step - loss: 0.0994 - acc: 0.9755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "31500/31500 [==============================] - 6s 194us/step - loss: 0.0996 - acc: 0.9746\n",
      "Epoch 40/50\n",
      "31500/31500 [==============================] - 7s 215us/step - loss: 0.0982 - acc: 0.9755\n",
      "Epoch 41/50\n",
      "31500/31500 [==============================] - 5s 171us/step - loss: 0.0973 - acc: 0.9754\n",
      "Epoch 42/50\n",
      "31500/31500 [==============================] - 5s 171us/step - loss: 0.0993 - acc: 0.9750\n",
      "Epoch 43/50\n",
      "31500/31500 [==============================] - 5s 170us/step - loss: 0.0963 - acc: 0.9758\n",
      "Epoch 44/50\n",
      "31500/31500 [==============================] - 5s 174us/step - loss: 0.0963 - acc: 0.9756\n",
      "Epoch 45/50\n",
      "31500/31500 [==============================] - 6s 175us/step - loss: 0.0966 - acc: 0.9757\n",
      "Epoch 46/50\n",
      "31500/31500 [==============================] - 5s 174us/step - loss: 0.0970 - acc: 0.9754\n",
      "Epoch 47/50\n",
      "31500/31500 [==============================] - 6s 186us/step - loss: 0.0944 - acc: 0.9760\n",
      "Epoch 48/50\n",
      "31500/31500 [==============================] - 6s 188us/step - loss: 0.0939 - acc: 0.9761\n",
      "Epoch 49/50\n",
      "31500/31500 [==============================] - 5s 173us/step - loss: 0.0945 - acc: 0.9759\n",
      "Epoch 50/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.0934 - acc: 0.9759\n",
      "3500/3500 [==============================] - 0s 63us/step\n",
      "Epoch 1/50\n",
      "31500/31500 [==============================] - 6s 193us/step - loss: 0.1424 - acc: 0.9692\n",
      "Epoch 2/50\n",
      "31500/31500 [==============================] - 6s 175us/step - loss: 0.1357 - acc: 0.9697\n",
      "Epoch 3/50\n",
      "31500/31500 [==============================] - 5s 173us/step - loss: 0.1338 - acc: 0.9697\n",
      "Epoch 4/50\n",
      "31500/31500 [==============================] - 6s 175us/step - loss: 0.1330 - acc: 0.9701\n",
      "Epoch 5/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.1317 - acc: 0.9702\n",
      "Epoch 6/50\n",
      "31500/31500 [==============================] - 6s 175us/step - loss: 0.1313 - acc: 0.9706\n",
      "Epoch 7/50\n",
      "31500/31500 [==============================] - 6s 178us/step - loss: 0.1293 - acc: 0.9705\n",
      "Epoch 8/50\n",
      "31500/31500 [==============================] - 6s 188us/step - loss: 0.1277 - acc: 0.9709\n",
      "Epoch 9/50\n",
      "31500/31500 [==============================] - 6s 175us/step - loss: 0.1265 - acc: 0.9710\n",
      "Epoch 10/50\n",
      "31500/31500 [==============================] - 6s 175us/step - loss: 0.1252 - acc: 0.9708\n",
      "Epoch 11/50\n",
      "31500/31500 [==============================] - 5s 171us/step - loss: 0.1245 - acc: 0.9712\n",
      "Epoch 12/50\n",
      "31500/31500 [==============================] - 5s 175us/step - loss: 0.1233 - acc: 0.9711\n",
      "Epoch 13/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.1220 - acc: 0.9711\n",
      "Epoch 14/50\n",
      "31500/31500 [==============================] - 5s 173us/step - loss: 0.1206 - acc: 0.9713\n",
      "Epoch 15/50\n",
      "31500/31500 [==============================] - 5s 174us/step - loss: 0.1197 - acc: 0.9714\n",
      "Epoch 16/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.1193 - acc: 0.9717\n",
      "Epoch 17/50\n",
      "31500/31500 [==============================] - 6s 175us/step - loss: 0.1183 - acc: 0.9720\n",
      "Epoch 18/50\n",
      "31500/31500 [==============================] - 6s 179us/step - loss: 0.1170 - acc: 0.9719\n",
      "Epoch 19/50\n",
      "31500/31500 [==============================] - 6s 192us/step - loss: 0.1162 - acc: 0.9721\n",
      "Epoch 20/50\n",
      "31500/31500 [==============================] - 5s 173us/step - loss: 0.1154 - acc: 0.9721\n",
      "Epoch 21/50\n",
      "31500/31500 [==============================] - 7s 208us/step - loss: 0.1143 - acc: 0.9722\n",
      "Epoch 22/50\n",
      "31500/31500 [==============================] - 6s 200us/step - loss: 0.1133 - acc: 0.9724\n",
      "Epoch 23/50\n",
      "31500/31500 [==============================] - 5s 171us/step - loss: 0.1120 - acc: 0.9724\n",
      "Epoch 24/50\n",
      "31500/31500 [==============================] - 5s 170us/step - loss: 0.1118 - acc: 0.9725\n",
      "Epoch 25/50\n",
      "31500/31500 [==============================] - 5s 170us/step - loss: 0.1111 - acc: 0.9727\n",
      "Epoch 26/50\n",
      "31500/31500 [==============================] - 5s 170us/step - loss: 0.1097 - acc: 0.9730\n",
      "Epoch 27/50\n",
      "31500/31500 [==============================] - 5s 173us/step - loss: 0.1089 - acc: 0.9726\n",
      "Epoch 28/50\n",
      "31500/31500 [==============================] - 5s 174us/step - loss: 0.1089 - acc: 0.9729\n",
      "Epoch 29/50\n",
      "31500/31500 [==============================] - 6s 187us/step - loss: 0.1083 - acc: 0.9730\n",
      "Epoch 30/50\n",
      "31500/31500 [==============================] - 6s 179us/step - loss: 0.1068 - acc: 0.9729\n",
      "Epoch 31/50\n",
      "31500/31500 [==============================] - 5s 170us/step - loss: 0.1063 - acc: 0.9733\n",
      "Epoch 32/50\n",
      "31500/31500 [==============================] - 6s 175us/step - loss: 0.1059 - acc: 0.9731\n",
      "Epoch 33/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.1050 - acc: 0.9730\n",
      "Epoch 34/50\n",
      "31500/31500 [==============================] - 5s 171us/step - loss: 0.1034 - acc: 0.9735\n",
      "Epoch 35/50\n",
      "31500/31500 [==============================] - 5s 170us/step - loss: 0.1028 - acc: 0.9737\n",
      "Epoch 36/50\n",
      "31500/31500 [==============================] - 5s 170us/step - loss: 0.1039 - acc: 0.9735\n",
      "Epoch 37/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.1017 - acc: 0.9736\n",
      "Epoch 38/50\n",
      "31500/31500 [==============================] - 5s 173us/step - loss: 0.1011 - acc: 0.9742\n",
      "Epoch 39/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.1003 - acc: 0.9740\n",
      "Epoch 40/50\n",
      "31500/31500 [==============================] - 6s 183us/step - loss: 0.0994 - acc: 0.9742\n",
      "Epoch 41/50\n",
      "31500/31500 [==============================] - 6s 186us/step - loss: 0.0987 - acc: 0.9743\n",
      "Epoch 42/50\n",
      "31500/31500 [==============================] - 5s 174us/step - loss: 0.0979 - acc: 0.9746\n",
      "Epoch 43/50\n",
      "31500/31500 [==============================] - 5s 173us/step - loss: 0.0962 - acc: 0.9747\n",
      "Epoch 44/50\n",
      "31500/31500 [==============================] - 6s 175us/step - loss: 0.0974 - acc: 0.9748\n",
      "Epoch 45/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.0958 - acc: 0.9747\n",
      "Epoch 46/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.0946 - acc: 0.9747\n",
      "Epoch 47/50\n",
      "31500/31500 [==============================] - 5s 169us/step - loss: 0.0946 - acc: 0.9751\n",
      "Epoch 48/50\n",
      "31500/31500 [==============================] - 5s 171us/step - loss: 0.0933 - acc: 0.9753\n",
      "Epoch 49/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.0946 - acc: 0.9746\n",
      "Epoch 50/50\n",
      "31500/31500 [==============================] - 5s 171us/step - loss: 0.0929 - acc: 0.9753\n",
      "3500/3500 [==============================] - 0s 71us/step\n",
      "Epoch 1/50\n",
      "31500/31500 [==============================] - 7s 210us/step - loss: 0.1418 - acc: 0.9700\n",
      "Epoch 2/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.1345 - acc: 0.9700\n",
      "Epoch 3/50\n",
      "31500/31500 [==============================] - 6s 191us/step - loss: 0.1326 - acc: 0.9700\n",
      "Epoch 4/50\n",
      "31500/31500 [==============================] - 7s 226us/step - loss: 0.1314 - acc: 0.9705\n",
      "Epoch 5/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.1307 - acc: 0.9707\n",
      "Epoch 6/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.1290 - acc: 0.9707\n",
      "Epoch 7/50\n",
      "31500/31500 [==============================] - 5s 174us/step - loss: 0.1279 - acc: 0.9710\n",
      "Epoch 8/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.1269 - acc: 0.9711\n",
      "Epoch 9/50\n",
      "31500/31500 [==============================] - 6s 180us/step - loss: 0.1258 - acc: 0.9711\n",
      "Epoch 10/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.1246 - acc: 0.9713\n",
      "Epoch 11/50\n",
      "31500/31500 [==============================] - 6s 188us/step - loss: 0.1229 - acc: 0.9714\n",
      "Epoch 12/50\n",
      "31500/31500 [==============================] - 6s 190us/step - loss: 0.1220 - acc: 0.9715\n",
      "Epoch 13/50\n",
      "31500/31500 [==============================] - 6s 178us/step - loss: 0.1208 - acc: 0.9716\n",
      "Epoch 14/50\n",
      "31500/31500 [==============================] - 6s 177us/step - loss: 0.1200 - acc: 0.9718\n",
      "Epoch 15/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.1181 - acc: 0.9720\n",
      "Epoch 16/50\n",
      "31500/31500 [==============================] - 6s 175us/step - loss: 0.1173 - acc: 0.9721\n",
      "Epoch 17/50\n",
      "31500/31500 [==============================] - 6s 177us/step - loss: 0.1166 - acc: 0.9724\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31500/31500 [==============================] - 6s 175us/step - loss: 0.1149 - acc: 0.9724\n",
      "Epoch 19/50\n",
      "31500/31500 [==============================] - 5s 174us/step - loss: 0.1141 - acc: 0.9727\n",
      "Epoch 20/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.1132 - acc: 0.9726\n",
      "Epoch 21/50\n",
      "31500/31500 [==============================] - 6s 179us/step - loss: 0.1132 - acc: 0.9725\n",
      "Epoch 22/50\n",
      "31500/31500 [==============================] - 6s 192us/step - loss: 0.1113 - acc: 0.9728\n",
      "Epoch 23/50\n",
      "31500/31500 [==============================] - 6s 180us/step - loss: 0.1103 - acc: 0.9731\n",
      "Epoch 24/50\n",
      "31500/31500 [==============================] - 6s 178us/step - loss: 0.1097 - acc: 0.9735\n",
      "Epoch 25/50\n",
      "31500/31500 [==============================] - 6s 179us/step - loss: 0.1099 - acc: 0.9727\n",
      "Epoch 26/50\n",
      "31500/31500 [==============================] - 6s 177us/step - loss: 0.1089 - acc: 0.9735\n",
      "Epoch 27/50\n",
      "31500/31500 [==============================] - 6s 177us/step - loss: 0.1082 - acc: 0.9730\n",
      "Epoch 28/50\n",
      "31500/31500 [==============================] - 6s 175us/step - loss: 0.1077 - acc: 0.9735\n",
      "Epoch 29/50\n",
      "31500/31500 [==============================] - 6s 177us/step - loss: 0.1069 - acc: 0.9735\n",
      "Epoch 30/50\n",
      "31500/31500 [==============================] - 6s 181us/step - loss: 0.1058 - acc: 0.9739\n",
      "Epoch 31/50\n",
      "31500/31500 [==============================] - 6s 178us/step - loss: 0.1058 - acc: 0.9737\n",
      "Epoch 32/50\n",
      "31500/31500 [==============================] - 6s 181us/step - loss: 0.1058 - acc: 0.9736\n",
      "Epoch 33/50\n",
      "31500/31500 [==============================] - 6s 194us/step - loss: 0.1040 - acc: 0.9741\n",
      "Epoch 34/50\n",
      "31500/31500 [==============================] - 6s 179us/step - loss: 0.1038 - acc: 0.9741\n",
      "Epoch 35/50\n",
      "31500/31500 [==============================] - 7s 231us/step - loss: 0.1032 - acc: 0.9739\n",
      "Epoch 36/50\n",
      "31500/31500 [==============================] - 6s 184us/step - loss: 0.1018 - acc: 0.9742\n",
      "Epoch 37/50\n",
      "31500/31500 [==============================] - 6s 178us/step - loss: 0.1035 - acc: 0.9741\n",
      "Epoch 38/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.1012 - acc: 0.9741\n",
      "Epoch 39/50\n",
      "31500/31500 [==============================] - 6s 178us/step - loss: 0.0993 - acc: 0.9747\n",
      "Epoch 40/50\n",
      "31500/31500 [==============================] - 6s 179us/step - loss: 0.1001 - acc: 0.9744\n",
      "Epoch 41/50\n",
      "31500/31500 [==============================] - 6s 179us/step - loss: 0.0982 - acc: 0.9747\n",
      "Epoch 42/50\n",
      "31500/31500 [==============================] - 6s 179us/step - loss: 0.0991 - acc: 0.9749\n",
      "Epoch 43/50\n",
      "31500/31500 [==============================] - 6s 194us/step - loss: 0.0979 - acc: 0.9750\n",
      "Epoch 44/50\n",
      "31500/31500 [==============================] - 6s 181us/step - loss: 0.0977 - acc: 0.9754\n",
      "Epoch 45/50\n",
      "31500/31500 [==============================] - 6s 180us/step - loss: 0.0968 - acc: 0.9754\n",
      "Epoch 46/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.0949 - acc: 0.9756\n",
      "Epoch 47/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.0958 - acc: 0.9750\n",
      "Epoch 48/50\n",
      "31500/31500 [==============================] - 6s 175us/step - loss: 0.0942 - acc: 0.9752\n",
      "Epoch 49/50\n",
      "31500/31500 [==============================] - 5s 172us/step - loss: 0.0944 - acc: 0.9755\n",
      "Epoch 50/50\n",
      "31500/31500 [==============================] - 5s 174us/step - loss: 0.0953 - acc: 0.9753\n",
      "3500/3500 [==============================] - 0s 70us/step\n",
      "Epoch 1/50\n",
      "31500/31500 [==============================] - 6s 199us/step - loss: 0.1442 - acc: 0.9688\n",
      "Epoch 2/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.1372 - acc: 0.9692\n",
      "Epoch 3/50\n",
      "31500/31500 [==============================] - 6s 184us/step - loss: 0.1352 - acc: 0.9697\n",
      "Epoch 4/50\n",
      "31500/31500 [==============================] - 6s 196us/step - loss: 0.1345 - acc: 0.9698\n",
      "Epoch 5/50\n",
      "31500/31500 [==============================] - 6s 178us/step - loss: 0.1326 - acc: 0.9701\n",
      "Epoch 6/50\n",
      "31500/31500 [==============================] - 6s 179us/step - loss: 0.1315 - acc: 0.9703\n",
      "Epoch 7/50\n",
      "31500/31500 [==============================] - 6s 177us/step - loss: 0.1301 - acc: 0.9703\n",
      "Epoch 8/50\n",
      "31500/31500 [==============================] - 6s 180us/step - loss: 0.1289 - acc: 0.9703\n",
      "Epoch 9/50\n",
      "31500/31500 [==============================] - 6s 177us/step - loss: 0.1280 - acc: 0.9706\n",
      "Epoch 10/50\n",
      "31500/31500 [==============================] - 6s 179us/step - loss: 0.1271 - acc: 0.9708\n",
      "Epoch 11/50\n",
      "31500/31500 [==============================] - 6s 178us/step - loss: 0.1260 - acc: 0.9707\n",
      "Epoch 12/50\n",
      "31500/31500 [==============================] - 6s 181us/step - loss: 0.1252 - acc: 0.9709\n",
      "Epoch 13/50\n",
      "31500/31500 [==============================] - 6s 185us/step - loss: 0.1240 - acc: 0.9710\n",
      "Epoch 14/50\n",
      "31500/31500 [==============================] - 6s 194us/step - loss: 0.1222 - acc: 0.9714\n",
      "Epoch 15/50\n",
      "31500/31500 [==============================] - 6s 184us/step - loss: 0.1216 - acc: 0.9714\n",
      "Epoch 16/50\n",
      "31500/31500 [==============================] - 7s 219us/step - loss: 0.1206 - acc: 0.9716\n",
      "Epoch 17/50\n",
      "31500/31500 [==============================] - 6s 203us/step - loss: 0.1201 - acc: 0.9716\n",
      "Epoch 18/50\n",
      "31500/31500 [==============================] - 6s 180us/step - loss: 0.1188 - acc: 0.9717\n",
      "Epoch 19/50\n",
      "31500/31500 [==============================] - 6s 179us/step - loss: 0.1176 - acc: 0.9720\n",
      "Epoch 20/50\n",
      "31500/31500 [==============================] - 6s 177us/step - loss: 0.1166 - acc: 0.9719\n",
      "Epoch 21/50\n",
      "31500/31500 [==============================] - 6s 178us/step - loss: 0.1165 - acc: 0.9717\n",
      "Epoch 22/50\n",
      "31500/31500 [==============================] - 6s 180us/step - loss: 0.1156 - acc: 0.9722\n",
      "Epoch 23/50\n",
      "31500/31500 [==============================] - 6s 181us/step - loss: 0.1144 - acc: 0.9725\n",
      "Epoch 24/50\n",
      "31500/31500 [==============================] - 6s 192us/step - loss: 0.1135 - acc: 0.9723\n",
      "Epoch 25/50\n",
      "31500/31500 [==============================] - 6s 184us/step - loss: 0.1126 - acc: 0.9722\n",
      "Epoch 26/50\n",
      "31500/31500 [==============================] - 6s 183us/step - loss: 0.1120 - acc: 0.9727\n",
      "Epoch 27/50\n",
      "31500/31500 [==============================] - 6s 177us/step - loss: 0.1107 - acc: 0.9724\n",
      "Epoch 28/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.1105 - acc: 0.9728\n",
      "Epoch 29/50\n",
      "31500/31500 [==============================] - 6s 179us/step - loss: 0.1095 - acc: 0.9730\n",
      "Epoch 30/50\n",
      "31500/31500 [==============================] - 6s 177us/step - loss: 0.1082 - acc: 0.9732\n",
      "Epoch 31/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.1076 - acc: 0.9731\n",
      "Epoch 32/50\n",
      "31500/31500 [==============================] - 5s 174us/step - loss: 0.1076 - acc: 0.9729\n",
      "Epoch 33/50\n",
      "31500/31500 [==============================] - 6s 176us/step - loss: 0.1066 - acc: 0.9734\n",
      "Epoch 34/50\n",
      "31500/31500 [==============================] - 6s 184us/step - loss: 0.1050 - acc: 0.9737\n",
      "Epoch 35/50\n",
      "31500/31500 [==============================] - 6s 195us/step - loss: 0.1049 - acc: 0.9733\n",
      "Epoch 36/50\n",
      "31500/31500 [==============================] - 6s 180us/step - loss: 0.1044 - acc: 0.9737\n",
      "Epoch 37/50\n",
      "31500/31500 [==============================] - 6s 184us/step - loss: 0.1024 - acc: 0.9737\n",
      "Epoch 38/50\n",
      "31500/31500 [==============================] - 6s 179us/step - loss: 0.1025 - acc: 0.9737\n",
      "Epoch 39/50\n",
      "31500/31500 [==============================] - 6s 180us/step - loss: 0.1021 - acc: 0.9740\n",
      "Epoch 40/50\n",
      "31500/31500 [==============================] - 6s 178us/step - loss: 0.0999 - acc: 0.9745\n",
      "Epoch 41/50\n",
      "31500/31500 [==============================] - 6s 178us/step - loss: 0.1006 - acc: 0.9743\n",
      "Epoch 42/50\n",
      "31500/31500 [==============================] - 6s 185us/step - loss: 0.0993 - acc: 0.9746\n",
      "Epoch 43/50\n",
      "31500/31500 [==============================] - 6s 186us/step - loss: 0.0994 - acc: 0.9745\n",
      "Epoch 44/50\n",
      "31500/31500 [==============================] - 6s 181us/step - loss: 0.0972 - acc: 0.9752\n",
      "Epoch 45/50\n",
      "31500/31500 [==============================] - 6s 191us/step - loss: 0.0977 - acc: 0.9747\n",
      "Epoch 46/50\n",
      "31500/31500 [==============================] - 6s 191us/step - loss: 0.0972 - acc: 0.9748\n",
      "Epoch 47/50\n",
      "31500/31500 [==============================] - 6s 205us/step - loss: 0.0963 - acc: 0.9751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50\n",
      "31500/31500 [==============================] - 7s 219us/step - loss: 0.0958 - acc: 0.9753\n",
      "Epoch 49/50\n",
      "31500/31500 [==============================] - 6s 179us/step - loss: 0.0948 - acc: 0.9755\n",
      "Epoch 50/50\n",
      "31500/31500 [==============================] - 6s 181us/step - loss: 0.0943 - acc: 0.9758\n",
      "3500/3500 [==============================] - 0s 76us/step\n",
      "Epoch 1/50\n",
      "31500/31500 [==============================] - 6s 202us/step - loss: 0.1415 - acc: 0.9690\n",
      "Epoch 2/50\n",
      "31500/31500 [==============================] - 6s 183us/step - loss: 0.1343 - acc: 0.9700\n",
      "Epoch 3/50\n",
      "31500/31500 [==============================] - 6s 183us/step - loss: 0.1331 - acc: 0.9702\n",
      "Epoch 4/50\n",
      "31500/31500 [==============================] - 6s 183us/step - loss: 0.1316 - acc: 0.9706\n",
      "Epoch 5/50\n",
      "31500/31500 [==============================] - 6s 199us/step - loss: 0.1306 - acc: 0.9705\n",
      "Epoch 6/50\n",
      "31500/31500 [==============================] - 6s 186us/step - loss: 0.1296 - acc: 0.9709\n",
      "Epoch 7/50\n",
      "31500/31500 [==============================] - 6s 184us/step - loss: 0.1288 - acc: 0.9709\n",
      "Epoch 8/50\n",
      "31500/31500 [==============================] - 6s 180us/step - loss: 0.1269 - acc: 0.9710\n",
      "Epoch 9/50\n",
      "31500/31500 [==============================] - 6s 179us/step - loss: 0.1260 - acc: 0.9710\n",
      "Epoch 10/50\n",
      "31500/31500 [==============================] - 6s 181us/step - loss: 0.1246 - acc: 0.9710\n",
      "Epoch 11/50\n",
      "31500/31500 [==============================] - 6s 180us/step - loss: 0.1241 - acc: 0.9709\n",
      "Epoch 12/50\n",
      "31500/31500 [==============================] - 6s 181us/step - loss: 0.1232 - acc: 0.9710\n",
      "Epoch 13/50\n",
      "31500/31500 [==============================] - 6s 179us/step - loss: 0.1211 - acc: 0.9713\n",
      "Epoch 14/50\n",
      "31500/31500 [==============================] - 6s 180us/step - loss: 0.1209 - acc: 0.9716\n",
      "Epoch 15/50\n",
      "31500/31500 [==============================] - 6s 192us/step - loss: 0.1193 - acc: 0.9714\n",
      "Epoch 16/50\n",
      "31500/31500 [==============================] - 6s 194us/step - loss: 0.1182 - acc: 0.9717\n",
      "Epoch 17/50\n",
      "31500/31500 [==============================] - 6s 186us/step - loss: 0.1174 - acc: 0.9719\n",
      "Epoch 18/50\n",
      "31500/31500 [==============================] - 6s 183us/step - loss: 0.1164 - acc: 0.9722\n",
      "Epoch 19/50\n",
      "31500/31500 [==============================] - 6s 182us/step - loss: 0.1155 - acc: 0.9721\n",
      "Epoch 20/50\n",
      "31500/31500 [==============================] - 6s 181us/step - loss: 0.1140 - acc: 0.9722\n",
      "Epoch 21/50\n",
      "31500/31500 [==============================] - 6s 181us/step - loss: 0.1133 - acc: 0.9725\n",
      "Epoch 22/50\n",
      "31500/31500 [==============================] - 6s 183us/step - loss: 0.1121 - acc: 0.9727\n",
      "Epoch 23/50\n",
      "31500/31500 [==============================] - 6s 180us/step - loss: 0.1113 - acc: 0.9727\n",
      "Epoch 24/50\n",
      "31500/31500 [==============================] - 6s 181us/step - loss: 0.1115 - acc: 0.9727\n",
      "Epoch 25/50\n",
      "31500/31500 [==============================] - 6s 186us/step - loss: 0.1092 - acc: 0.9730\n",
      "Epoch 26/50\n",
      "31500/31500 [==============================] - 6s 199us/step - loss: 0.1096 - acc: 0.9730\n",
      "Epoch 27/50\n",
      "31500/31500 [==============================] - 6s 183us/step - loss: 0.1097 - acc: 0.9729\n",
      "Epoch 28/50\n",
      "31500/31500 [==============================] - 8s 248us/step - loss: 0.1077 - acc: 0.9730\n",
      "Epoch 29/50\n",
      "31500/31500 [==============================] - 6s 185us/step - loss: 0.1063 - acc: 0.9736\n",
      "Epoch 30/50\n",
      "31500/31500 [==============================] - 6s 181us/step - loss: 0.1050 - acc: 0.9736\n",
      "Epoch 31/50\n",
      "31500/31500 [==============================] - 6s 181us/step - loss: 0.1054 - acc: 0.9737\n",
      "Epoch 32/50\n",
      "31500/31500 [==============================] - 6s 180us/step - loss: 0.1059 - acc: 0.9735\n",
      "Epoch 33/50\n",
      "31500/31500 [==============================] - 6s 180us/step - loss: 0.1036 - acc: 0.9738\n",
      "Epoch 34/50\n",
      "31500/31500 [==============================] - 6s 183us/step - loss: 0.1033 - acc: 0.9739\n",
      "Epoch 35/50\n",
      "31500/31500 [==============================] - 6s 185us/step - loss: 0.1033 - acc: 0.9739\n",
      "Epoch 36/50\n",
      "31500/31500 [==============================] - 6s 203us/step - loss: 0.1016 - acc: 0.9743\n",
      "Epoch 37/50\n",
      "31500/31500 [==============================] - 6s 180us/step - loss: 0.1006 - acc: 0.9747\n",
      "Epoch 38/50\n",
      "31500/31500 [==============================] - 6s 184us/step - loss: 0.1011 - acc: 0.9745\n",
      "Epoch 39/50\n",
      "31500/31500 [==============================] - 6s 180us/step - loss: 0.0997 - acc: 0.9748\n",
      "Epoch 40/50\n",
      "31500/31500 [==============================] - 6s 179us/step - loss: 0.0995 - acc: 0.9749\n",
      "Epoch 41/50\n",
      "31500/31500 [==============================] - 6s 180us/step - loss: 0.0987 - acc: 0.9750\n",
      "Epoch 42/50\n",
      "31500/31500 [==============================] - 6s 178us/step - loss: 0.0976 - acc: 0.9750\n",
      "Epoch 43/50\n",
      "31500/31500 [==============================] - 6s 181us/step - loss: 0.0975 - acc: 0.9750\n",
      "Epoch 44/50\n",
      "31500/31500 [==============================] - 6s 181us/step - loss: 0.0975 - acc: 0.9748\n",
      "Epoch 45/50\n",
      "31500/31500 [==============================] - 6s 181us/step - loss: 0.0983 - acc: 0.9750\n",
      "Epoch 46/50\n",
      "31500/31500 [==============================] - 6s 198us/step - loss: 0.0959 - acc: 0.9758\n",
      "Epoch 47/50\n",
      "31500/31500 [==============================] - 6s 189us/step - loss: 0.0949 - acc: 0.9760\n",
      "Epoch 48/50\n",
      "31500/31500 [==============================] - 6s 184us/step - loss: 0.0952 - acc: 0.9755\n",
      "Epoch 49/50\n",
      "31500/31500 [==============================] - 6s 181us/step - loss: 0.0950 - acc: 0.9754\n",
      "Epoch 50/50\n",
      "31500/31500 [==============================] - 6s 185us/step - loss: 0.0933 - acc: 0.9762\n",
      "3500/3500 [==============================] - 0s 81us/step\n",
      "Epoch 1/50\n",
      "31500/31500 [==============================] - 6s 197us/step - loss: 0.1406 - acc: 0.9700\n",
      "Epoch 2/50\n",
      "31500/31500 [==============================] - 6s 184us/step - loss: 0.1342 - acc: 0.9701\n",
      "Epoch 3/50\n",
      "31500/31500 [==============================] - 6s 186us/step - loss: 0.1326 - acc: 0.9703\n",
      "Epoch 4/50\n",
      "31500/31500 [==============================] - 6s 182us/step - loss: 0.1308 - acc: 0.9706\n",
      "Epoch 5/50\n",
      "31500/31500 [==============================] - 6s 183us/step - loss: 0.1306 - acc: 0.9706\n",
      "Epoch 6/50\n",
      "31500/31500 [==============================] - 6s 198us/step - loss: 0.1296 - acc: 0.9708\n",
      "Epoch 7/50\n",
      "31500/31500 [==============================] - 6s 191us/step - loss: 0.1282 - acc: 0.9709\n",
      "Epoch 8/50\n",
      "31500/31500 [==============================] - 7s 218us/step - loss: 0.1274 - acc: 0.9710\n",
      "Epoch 9/50\n",
      "31500/31500 [==============================] - 7s 213us/step - loss: 0.1259 - acc: 0.9711\n",
      "Epoch 10/50\n",
      "31500/31500 [==============================] - 6s 181us/step - loss: 0.1248 - acc: 0.9712\n",
      "Epoch 11/50\n",
      "31500/31500 [==============================] - 6s 183us/step - loss: 0.1245 - acc: 0.9714\n",
      "Epoch 12/50\n",
      "31500/31500 [==============================] - 6s 181us/step - loss: 0.1228 - acc: 0.9712\n",
      "Epoch 13/50\n",
      "31500/31500 [==============================] - 6s 182us/step - loss: 0.1219 - acc: 0.9715\n",
      "Epoch 14/50\n",
      "31500/31500 [==============================] - 6s 181us/step - loss: 0.1208 - acc: 0.9717\n",
      "Epoch 15/50\n",
      "31500/31500 [==============================] - 6s 183us/step - loss: 0.1206 - acc: 0.9716\n",
      "Epoch 16/50\n",
      "31500/31500 [==============================] - 6s 201us/step - loss: 0.1192 - acc: 0.9719\n",
      "Epoch 17/50\n",
      "31500/31500 [==============================] - 6s 187us/step - loss: 0.1183 - acc: 0.9721\n",
      "Epoch 18/50\n",
      "31500/31500 [==============================] - 6s 182us/step - loss: 0.1171 - acc: 0.9723\n",
      "Epoch 19/50\n",
      "31500/31500 [==============================] - 6s 181us/step - loss: 0.1162 - acc: 0.9722\n",
      "Epoch 20/50\n",
      "31500/31500 [==============================] - 6s 183us/step - loss: 0.1154 - acc: 0.9725\n",
      "Epoch 21/50\n",
      "31500/31500 [==============================] - 6s 181us/step - loss: 0.1155 - acc: 0.9723\n",
      "Epoch 22/50\n",
      "31500/31500 [==============================] - 6s 179us/step - loss: 0.1141 - acc: 0.9726\n",
      "Epoch 23/50\n",
      "31500/31500 [==============================] - 6s 179us/step - loss: 0.1135 - acc: 0.9728\n",
      "Epoch 24/50\n",
      "31500/31500 [==============================] - 6s 181us/step - loss: 0.1126 - acc: 0.9726\n",
      "Epoch 25/50\n",
      "31500/31500 [==============================] - 6s 184us/step - loss: 0.1113 - acc: 0.9730\n",
      "Epoch 26/50\n",
      "31500/31500 [==============================] - 6s 187us/step - loss: 0.1109 - acc: 0.9729\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31500/31500 [==============================] - 6s 198us/step - loss: 0.1099 - acc: 0.9731\n",
      "Epoch 28/50\n",
      "31500/31500 [==============================] - 6s 182us/step - loss: 0.1092 - acc: 0.9730\n",
      "Epoch 29/50\n",
      "31500/31500 [==============================] - 6s 182us/step - loss: 0.1086 - acc: 0.9729\n",
      "Epoch 30/50\n",
      "31500/31500 [==============================] - 6s 178us/step - loss: 0.1069 - acc: 0.9737\n",
      "Epoch 31/50\n",
      "31500/31500 [==============================] - 6s 179us/step - loss: 0.1071 - acc: 0.9736\n",
      "Epoch 32/50\n",
      "31500/31500 [==============================] - 6s 180us/step - loss: 0.1062 - acc: 0.9734\n",
      "Epoch 33/50\n",
      "31500/31500 [==============================] - 6s 183us/step - loss: 0.1056 - acc: 0.9737\n",
      "Epoch 34/50\n",
      "31500/31500 [==============================] - 6s 183us/step - loss: 0.1049 - acc: 0.9736\n",
      "Epoch 35/50\n",
      "31500/31500 [==============================] - 6s 183us/step - loss: 0.1034 - acc: 0.9737\n",
      "Epoch 36/50\n",
      "31500/31500 [==============================] - 6s 184us/step - loss: 0.1031 - acc: 0.9737\n",
      "Epoch 37/50\n",
      "31500/31500 [==============================] - 6s 197us/step - loss: 0.1015 - acc: 0.9740\n",
      "Epoch 38/50\n",
      "31500/31500 [==============================] - 6s 190us/step - loss: 0.1014 - acc: 0.9743\n",
      "Epoch 39/50\n",
      "31500/31500 [==============================] - 8s 242us/step - loss: 0.1013 - acc: 0.9741\n",
      "Epoch 40/50\n",
      "31500/31500 [==============================] - 6s 186us/step - loss: 0.1008 - acc: 0.9741\n",
      "Epoch 41/50\n",
      "31500/31500 [==============================] - 6s 179us/step - loss: 0.1002 - acc: 0.9743\n",
      "Epoch 42/50\n",
      "31500/31500 [==============================] - 6s 181us/step - loss: 0.0983 - acc: 0.9746\n",
      "Epoch 43/50\n",
      "31500/31500 [==============================] - 6s 180us/step - loss: 0.0976 - acc: 0.9747\n",
      "Epoch 44/50\n",
      "31500/31500 [==============================] - 6s 183us/step - loss: 0.0971 - acc: 0.9748\n",
      "Epoch 45/50\n",
      "31500/31500 [==============================] - 6s 182us/step - loss: 0.0976 - acc: 0.9748\n",
      "Epoch 46/50\n",
      "31500/31500 [==============================] - 6s 184us/step - loss: 0.0958 - acc: 0.9751\n",
      "Epoch 47/50\n",
      "31500/31500 [==============================] - 6s 196us/step - loss: 0.0955 - acc: 0.9757\n",
      "Epoch 48/50\n",
      "31500/31500 [==============================] - 6s 187us/step - loss: 0.0950 - acc: 0.9754\n",
      "Epoch 49/50\n",
      "31500/31500 [==============================] - 6s 187us/step - loss: 0.0940 - acc: 0.9756\n",
      "Epoch 50/50\n",
      "31500/31500 [==============================] - 6s 182us/step - loss: 0.0954 - acc: 0.9750\n",
      "3500/3500 [==============================] - 0s 85us/step\n",
      "Accuracy mean: 0.971914285714\n",
      "Accuracy variance: 0.00264667677648\n"
     ]
    }
   ],
   "source": [
    "# estimators \n",
    "# Evaluating the ANN\n",
    "t0 = time()\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 1024, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n",
    "    classifier.add(Dense(units = 512, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 50)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' Time ', '2927.469', ' seconds')\n",
      "[[14505    45]\n",
      " [  245   205]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99     14550\n",
      "        1.0       0.82      0.46      0.59       450\n",
      "\n",
      "avg / total       0.98      0.98      0.98     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of DecisionTreeClassifier = 95.606667 %\n",
      "[[14237   313]\n",
      " [  346   104]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.98      0.98     14550\n",
      "        1.0       0.25      0.23      0.24       450\n",
      "\n",
      "avg / total       0.95      0.96      0.96     15000\n",
      "\n",
      "(' Time ', '1.328', ' seconds')\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of DecisionTreeClassifier = {:.6f} %\".format(acc * 100))\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of RandomForestClassifier = 97.146667 %\n",
      "[[14549     1]\n",
      " [  427    23]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.99     14550\n",
      "        1.0       0.96      0.05      0.10       450\n",
      "\n",
      "avg / total       0.97      0.97      0.96     15000\n",
      "\n",
      "(' Time ', '13.869', ' seconds')\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of RandomForestClassifier = {:.6f} %\".format(acc * 100))\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of ExtraTreesClassifier = 97.320000 %\n",
      "[[14547     3]\n",
      " [  399    51]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.99     14550\n",
      "        1.0       0.94      0.11      0.20       450\n",
      "\n",
      "avg / total       0.97      0.97      0.96     15000\n",
      "\n",
      "(' Time ', '5.41', ' seconds')\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of ExtraTreesClassifier = {:.6f} %\".format(acc * 100))\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of AdaBoostClassifier = 97.000000 %\n",
      "[[14544     6]\n",
      " [  444     6]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.98     14550\n",
      "        1.0       0.50      0.01      0.03       450\n",
      "\n",
      "avg / total       0.96      0.97      0.96     15000\n",
      "\n",
      "(' Time ', '6.69', ' seconds')\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of AdaBoostClassifier = {:.6f} %\".format(acc * 100))\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Naive_bayes  GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GaussianNB = 76.720000 %\n",
      "[[11349  3201]\n",
      " [  291   159]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.78      0.87     14550\n",
      "        1.0       0.05      0.35      0.08       450\n",
      "\n",
      "avg / total       0.95      0.77      0.84     15000\n",
      "\n",
      "(' Time ', '0.042', ' seconds')\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred= gnb.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of GaussianNB = {:.6f} %\".format(acc * 100))\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
