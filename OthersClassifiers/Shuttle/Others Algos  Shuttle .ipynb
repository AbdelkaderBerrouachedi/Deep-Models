{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt \n",
    "from pprint import pprint\n",
    "from numpy import array\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>att1</th>\n",
       "      <th>att2</th>\n",
       "      <th>att3</th>\n",
       "      <th>att4</th>\n",
       "      <th>att5</th>\n",
       "      <th>att6</th>\n",
       "      <th>att7</th>\n",
       "      <th>att8</th>\n",
       "      <th>att9</th>\n",
       "      <th>outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.607955</td>\n",
       "      <td>0.12766</td>\n",
       "      <td>0.020145</td>\n",
       "      <td>0.207865</td>\n",
       "      <td>0.088428</td>\n",
       "      <td>0.347222</td>\n",
       "      <td>0.746875</td>\n",
       "      <td>0.737113</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.607955</td>\n",
       "      <td>0.12766</td>\n",
       "      <td>0.020145</td>\n",
       "      <td>0.207865</td>\n",
       "      <td>0.088428</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.746875</td>\n",
       "      <td>0.716495</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.607955</td>\n",
       "      <td>0.12766</td>\n",
       "      <td>0.020145</td>\n",
       "      <td>0.067416</td>\n",
       "      <td>0.088428</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.871134</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.602273</td>\n",
       "      <td>0.12766</td>\n",
       "      <td>0.020145</td>\n",
       "      <td>0.207865</td>\n",
       "      <td>0.088428</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.746875</td>\n",
       "      <td>0.716495</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.185714</td>\n",
       "      <td>0.653409</td>\n",
       "      <td>0.12766</td>\n",
       "      <td>0.020145</td>\n",
       "      <td>0.067416</td>\n",
       "      <td>0.088428</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.865979</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       att1      att2     att3      att4      att5      att6      att7  \\\n",
       "0  0.214286  0.607955  0.12766  0.020145  0.207865  0.088428  0.347222   \n",
       "1  0.085714  0.607955  0.12766  0.020145  0.207865  0.088428  0.458333   \n",
       "2  0.200000  0.607955  0.12766  0.020145  0.067416  0.088428  0.361111   \n",
       "3  0.085714  0.602273  0.12766  0.020145  0.207865  0.088428  0.472222   \n",
       "4  0.185714  0.653409  0.12766  0.020145  0.067416  0.088428  0.375000   \n",
       "\n",
       "       att8      att9  outlier  \n",
       "0  0.746875  0.737113        1  \n",
       "1  0.746875  0.716495        1  \n",
       "2  0.912500  0.871134        1  \n",
       "3  0.746875  0.716495        1  \n",
       "4  0.912500  0.865979        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df=pd.read_csv('Shuttle_withoutdupl_norm_v01.csv')\n",
    "\n",
    "del df['id']\n",
    "del df['Unnamed: 0']\n",
    "df['outlier'] = df.outlier.apply(lambda label: 1 if label == \"'yes'\" else 0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df to values\n",
    "df = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GC Forest\n",
    "import argparse\n",
    "import sys\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "sys.path.insert(0, \"lib\")\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.utils.config_utils import load_json\n",
    "config = load_json(\"./examples/Shuttle.json\")   \n",
    "gc = GCForest(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# train test \n",
    "from sklearn.cross_validation import train_test_split\n",
    "y = df[:,9]\n",
    "X = df[:,0:9]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of class\n",
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:11:33,421][cascade_classifier.fit_transform] X_groups_train.shape=[(709, 9)],y_train.shape=(709,),X_groups_test.shape=[(304, 9)],y_test.shape=(304,)\n",
      "[ 2018-07-31 22:11:33,422][cascade_classifier.fit_transform] group_dims=[9]\n",
      "[ 2018-07-31 22:11:33,424][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-31 22:11:33,425][cascade_classifier.fit_transform] group_ends=[9]\n",
      "[ 2018-07-31 22:11:33,427][cascade_classifier.fit_transform] X_train.shape=(709, 9),X_test.shape=(304, 9)\n",
      "[ 2018-07-31 22:11:33,429][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(709, 9), X_cur_test.shape=(304, 9)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 8 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[ 2018-07-31 22:11:34,252][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=100.00%\n",
      "[ 2018-07-31 22:11:35,209][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=98.59%\n",
      "[ 2018-07-31 22:11:36,347][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=100.00%\n",
      "[ 2018-07-31 22:11:37,372][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=100.00%\n",
      "[ 2018-07-31 22:11:38,360][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=100.00%\n",
      "[ 2018-07-31 22:11:39,488][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=100.00%\n",
      "[ 2018-07-31 22:11:40,507][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=100.00%\n",
      "[ 2018-07-31 22:11:41,551][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=100.00%\n",
      "[ 2018-07-31 22:11:42,588][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=100.00%\n",
      "[ 2018-07-31 22:11:43,683][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=98.59%\n",
      "[ 2018-07-31 22:11:43,928][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=99.72%\n",
      "[ 2018-07-31 22:11:43,930][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=100.00%\n",
      "[ 2018-07-31 22:11:44,761][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_0.predict)=100.00%\n",
      "[ 2018-07-31 22:11:45,767][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-31 22:11:46,768][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_2.predict)=100.00%\n",
      "[ 2018-07-31 22:11:47,762][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_3.predict)=100.00%\n",
      "[ 2018-07-31 22:11:48,821][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_4.predict)=98.59%\n",
      "[ 2018-07-31 22:11:49,903][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_5.predict)=100.00%\n",
      "[ 2018-07-31 22:11:50,925][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_6.predict)=98.59%\n",
      "[ 2018-07-31 22:11:51,922][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_7.predict)=100.00%\n",
      "[ 2018-07-31 22:11:53,141][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_8.predict)=98.59%\n",
      "[ 2018-07-31 22:11:54,252][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_9.predict)=100.00%\n",
      "[ 2018-07-31 22:11:54,494][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_cv.predict)=99.58%\n",
      "[ 2018-07-31 22:11:54,496][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.test.predict)=100.00%\n",
      "[ 2018-07-31 22:11:54,562][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_0.predict)=98.61%\n",
      "[ 2018-07-31 22:11:54,572][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_1.predict)=98.59%\n",
      "[ 2018-07-31 22:11:54,580][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_2.predict)=98.59%\n",
      "[ 2018-07-31 22:11:54,590][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_3.predict)=98.59%\n",
      "[ 2018-07-31 22:11:54,595][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_4.predict)=98.59%\n",
      "[ 2018-07-31 22:11:54,611][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_5.predict)=100.00%\n",
      "[ 2018-07-31 22:11:54,633][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_6.predict)=100.00%\n",
      "[ 2018-07-31 22:11:54,640][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_7.predict)=98.59%\n",
      "[ 2018-07-31 22:11:54,645][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_8.predict)=98.59%\n",
      "[ 2018-07-31 22:11:54,657][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_9.predict)=98.59%\n",
      "[ 2018-07-31 22:11:54,661][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_cv.predict)=98.87%\n",
      "[ 2018-07-31 22:11:54,666][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.test.predict)=98.36%\n",
      "[ 2018-07-31 22:11:54,668][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=99.58%\n",
      "[ 2018-07-31 22:11:54,674][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=99.67%\n",
      "[ 2018-07-31 22:11:54,676][cascade_classifier.fit_transform] [layer=1] look_indexs=[0], X_cur_train.shape=(709, 15), X_cur_test.shape=(304, 15)\n",
      "[ 2018-07-31 22:11:55,505][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_0.predict)=100.00%\n",
      "[ 2018-07-31 22:11:56,591][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-31 22:11:57,616][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_2.predict)=100.00%\n",
      "[ 2018-07-31 22:11:58,741][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_3.predict)=100.00%\n",
      "[ 2018-07-31 22:11:59,753][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_4.predict)=98.59%\n",
      "[ 2018-07-31 22:12:00,707][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_5.predict)=100.00%\n",
      "[ 2018-07-31 22:12:01,828][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_6.predict)=100.00%\n",
      "[ 2018-07-31 22:12:02,977][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_7.predict)=100.00%\n",
      "[ 2018-07-31 22:12:04,698][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_8.predict)=100.00%\n",
      "[ 2018-07-31 22:12:05,960][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_9.predict)=100.00%\n",
      "[ 2018-07-31 22:12:06,216][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_cv.predict)=99.86%\n",
      "[ 2018-07-31 22:12:06,218][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.test.predict)=100.00%\n",
      "[ 2018-07-31 22:12:07,368][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_0.predict)=100.00%\n",
      "[ 2018-07-31 22:12:08,650][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_1.predict)=98.57%\n",
      "[ 2018-07-31 22:12:10,400][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_2.predict)=100.00%\n",
      "[ 2018-07-31 22:12:11,890][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_3.predict)=100.00%\n",
      "[ 2018-07-31 22:12:13,276][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_4.predict)=100.00%\n",
      "[ 2018-07-31 22:12:14,598][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_5.predict)=100.00%\n",
      "[ 2018-07-31 22:12:15,894][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_6.predict)=100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:12:17,128][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_7.predict)=100.00%\n",
      "[ 2018-07-31 22:12:18,222][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_8.predict)=100.00%\n",
      "[ 2018-07-31 22:12:19,391][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_9.predict)=100.00%\n",
      "[ 2018-07-31 22:12:19,605][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_cv.predict)=99.86%\n",
      "[ 2018-07-31 22:12:19,606][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.test.predict)=100.00%\n",
      "[ 2018-07-31 22:12:19,614][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_0.predict)=100.00%\n",
      "[ 2018-07-31 22:12:19,620][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-31 22:12:19,627][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_2.predict)=98.59%\n",
      "[ 2018-07-31 22:12:19,632][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_3.predict)=98.59%\n",
      "[ 2018-07-31 22:12:19,639][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_4.predict)=100.00%\n",
      "[ 2018-07-31 22:12:19,647][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_5.predict)=100.00%\n",
      "[ 2018-07-31 22:12:19,653][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_6.predict)=100.00%\n",
      "[ 2018-07-31 22:12:19,658][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_7.predict)=100.00%\n",
      "[ 2018-07-31 22:12:19,667][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_8.predict)=98.59%\n",
      "[ 2018-07-31 22:12:19,674][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_9.predict)=100.00%\n",
      "[ 2018-07-31 22:12:19,676][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_cv.predict)=99.58%\n",
      "[ 2018-07-31 22:12:19,678][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.test.predict)=100.00%\n",
      "[ 2018-07-31 22:12:19,681][cascade_classifier.calc_accuracy] Accuracy(layer_1 - train.classifier_average)=99.72%\n",
      "[ 2018-07-31 22:12:19,683][cascade_classifier.calc_accuracy] Accuracy(layer_1 - test.classifier_average)=100.00%\n",
      "[ 2018-07-31 22:12:19,686][cascade_classifier.fit_transform] [layer=2] look_indexs=[0], X_cur_train.shape=(709, 15), X_cur_test.shape=(304, 15)\n",
      "[ 2018-07-31 22:12:20,607][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_0.predict)=100.00%\n",
      "[ 2018-07-31 22:12:21,939][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-31 22:12:23,352][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_2.predict)=100.00%\n",
      "[ 2018-07-31 22:12:24,332][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_3.predict)=100.00%\n",
      "[ 2018-07-31 22:12:25,380][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_4.predict)=100.00%\n",
      "[ 2018-07-31 22:12:26,642][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_5.predict)=100.00%\n",
      "[ 2018-07-31 22:12:27,792][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_6.predict)=100.00%\n",
      "[ 2018-07-31 22:12:29,178][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_7.predict)=98.59%\n",
      "[ 2018-07-31 22:12:30,713][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_8.predict)=100.00%\n",
      "[ 2018-07-31 22:12:32,076][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_9.predict)=100.00%\n",
      "[ 2018-07-31 22:12:32,339][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_cv.predict)=99.86%\n",
      "[ 2018-07-31 22:12:32,340][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.test.predict)=100.00%\n",
      "[ 2018-07-31 22:12:33,273][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_0.predict)=100.00%\n",
      "[ 2018-07-31 22:12:34,517][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_1.predict)=98.59%\n",
      "[ 2018-07-31 22:12:35,671][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_2.predict)=100.00%\n",
      "[ 2018-07-31 22:12:36,956][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_3.predict)=100.00%\n",
      "[ 2018-07-31 22:12:38,567][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_4.predict)=100.00%\n",
      "[ 2018-07-31 22:12:39,901][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_5.predict)=100.00%\n",
      "[ 2018-07-31 22:12:41,231][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_6.predict)=98.59%\n",
      "[ 2018-07-31 22:12:42,558][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_7.predict)=100.00%\n",
      "[ 2018-07-31 22:12:43,875][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_8.predict)=100.00%\n",
      "[ 2018-07-31 22:12:45,067][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_9.predict)=100.00%\n",
      "[ 2018-07-31 22:12:45,465][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_cv.predict)=99.72%\n",
      "[ 2018-07-31 22:12:45,472][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.test.predict)=100.00%\n",
      "[ 2018-07-31 22:12:45,483][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_0.predict)=100.00%\n",
      "[ 2018-07-31 22:12:45,489][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-31 22:12:45,505][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_2.predict)=100.00%\n",
      "[ 2018-07-31 22:12:45,517][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_3.predict)=100.00%\n",
      "[ 2018-07-31 22:12:45,534][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_4.predict)=98.59%\n",
      "[ 2018-07-31 22:12:45,541][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_5.predict)=98.59%\n",
      "[ 2018-07-31 22:12:45,547][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_6.predict)=100.00%\n",
      "[ 2018-07-31 22:12:45,552][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_7.predict)=100.00%\n",
      "[ 2018-07-31 22:12:45,561][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_8.predict)=100.00%\n",
      "[ 2018-07-31 22:12:45,571][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_9.predict)=100.00%\n",
      "[ 2018-07-31 22:12:45,580][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_cv.predict)=99.72%\n",
      "[ 2018-07-31 22:12:45,582][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.test.predict)=100.00%\n",
      "[ 2018-07-31 22:12:45,590][cascade_classifier.calc_accuracy] Accuracy(layer_2 - train.classifier_average)=99.72%\n",
      "[ 2018-07-31 22:12:45,593][cascade_classifier.calc_accuracy] Accuracy(layer_2 - test.classifier_average)=100.00%\n",
      "[ 2018-07-31 22:12:45,594][cascade_classifier.fit_transform] [layer=3] look_indexs=[0], X_cur_train.shape=(709, 15), X_cur_test.shape=(304, 15)\n",
      "[ 2018-07-31 22:12:46,964][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_0.predict)=100.00%\n",
      "[ 2018-07-31 22:12:48,325][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_1.predict)=98.59%\n",
      "[ 2018-07-31 22:12:49,460][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_2.predict)=100.00%\n",
      "[ 2018-07-31 22:12:50,668][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_3.predict)=100.00%\n",
      "[ 2018-07-31 22:12:51,978][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_4.predict)=100.00%\n",
      "[ 2018-07-31 22:12:53,460][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_5.predict)=100.00%\n",
      "[ 2018-07-31 22:12:54,619][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_6.predict)=100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:12:55,889][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_7.predict)=100.00%\n",
      "[ 2018-07-31 22:12:57,126][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_8.predict)=100.00%\n",
      "[ 2018-07-31 22:12:58,406][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_9.predict)=100.00%\n",
      "[ 2018-07-31 22:12:58,654][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_cv.predict)=99.86%\n",
      "[ 2018-07-31 22:12:58,656][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.test.predict)=100.00%\n",
      "[ 2018-07-31 22:12:59,571][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_0.predict)=100.00%\n",
      "[ 2018-07-31 22:13:00,829][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-31 22:13:01,939][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_2.predict)=100.00%\n",
      "[ 2018-07-31 22:13:03,152][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_3.predict)=100.00%\n",
      "[ 2018-07-31 22:13:04,405][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_4.predict)=100.00%\n",
      "[ 2018-07-31 22:13:05,867][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_5.predict)=100.00%\n",
      "[ 2018-07-31 22:13:07,116][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_6.predict)=100.00%\n",
      "[ 2018-07-31 22:13:08,226][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_7.predict)=98.57%\n",
      "[ 2018-07-31 22:13:09,684][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_8.predict)=100.00%\n",
      "[ 2018-07-31 22:13:10,952][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_9.predict)=100.00%\n",
      "[ 2018-07-31 22:13:11,207][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_cv.predict)=99.86%\n",
      "[ 2018-07-31 22:13:11,211][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.test.predict)=100.00%\n",
      "[ 2018-07-31 22:13:11,218][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_0.predict)=100.00%\n",
      "[ 2018-07-31 22:13:11,229][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_1.predict)=98.59%\n",
      "[ 2018-07-31 22:13:11,250][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_2.predict)=100.00%\n",
      "[ 2018-07-31 22:13:11,259][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_3.predict)=100.00%\n",
      "[ 2018-07-31 22:13:11,281][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_4.predict)=100.00%\n",
      "[ 2018-07-31 22:13:11,298][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_5.predict)=100.00%\n",
      "[ 2018-07-31 22:13:11,317][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_6.predict)=98.59%\n",
      "[ 2018-07-31 22:13:11,324][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_7.predict)=98.59%\n",
      "[ 2018-07-31 22:13:11,339][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_8.predict)=100.00%\n",
      "[ 2018-07-31 22:13:11,355][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_9.predict)=98.59%\n",
      "[ 2018-07-31 22:13:11,360][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_cv.predict)=99.44%\n",
      "[ 2018-07-31 22:13:11,367][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.test.predict)=100.00%\n",
      "[ 2018-07-31 22:13:11,369][cascade_classifier.calc_accuracy] Accuracy(layer_3 - train.classifier_average)=99.72%\n",
      "[ 2018-07-31 22:13:11,372][cascade_classifier.calc_accuracy] Accuracy(layer_3 - test.classifier_average)=100.00%\n",
      "[ 2018-07-31 22:13:11,373][cascade_classifier.fit_transform] [layer=4] look_indexs=[0], X_cur_train.shape=(709, 15), X_cur_test.shape=(304, 15)\n",
      "[ 2018-07-31 22:13:12,482][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_0.predict)=100.00%\n",
      "[ 2018-07-31 22:13:13,582][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-31 22:13:14,901][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_2.predict)=98.59%\n",
      "[ 2018-07-31 22:13:16,227][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_3.predict)=100.00%\n",
      "[ 2018-07-31 22:13:17,379][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_4.predict)=100.00%\n",
      "[ 2018-07-31 22:13:18,584][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_5.predict)=100.00%\n",
      "[ 2018-07-31 22:13:19,862][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_6.predict)=100.00%\n",
      "[ 2018-07-31 22:13:21,518][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_7.predict)=100.00%\n",
      "[ 2018-07-31 22:13:23,144][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_8.predict)=100.00%\n",
      "[ 2018-07-31 22:13:24,745][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_9.predict)=100.00%\n",
      "[ 2018-07-31 22:13:25,085][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_cv.predict)=99.86%\n",
      "[ 2018-07-31 22:13:25,109][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.test.predict)=100.00%\n",
      "[ 2018-07-31 22:13:26,087][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_0.predict)=100.00%\n",
      "[ 2018-07-31 22:13:27,505][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-31 22:13:28,693][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_2.predict)=100.00%\n",
      "[ 2018-07-31 22:13:30,371][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_3.predict)=100.00%\n",
      "[ 2018-07-31 22:13:32,198][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_4.predict)=100.00%\n",
      "[ 2018-07-31 22:13:33,464][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_5.predict)=100.00%\n",
      "[ 2018-07-31 22:13:34,880][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_6.predict)=100.00%\n",
      "[ 2018-07-31 22:13:36,722][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_7.predict)=98.59%\n",
      "[ 2018-07-31 22:13:38,297][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_8.predict)=100.00%\n",
      "[ 2018-07-31 22:13:39,978][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_9.predict)=100.00%\n",
      "[ 2018-07-31 22:13:40,345][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_cv.predict)=99.86%\n",
      "[ 2018-07-31 22:13:40,347][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.test.predict)=100.00%\n",
      "[ 2018-07-31 22:13:40,359][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_0.predict)=98.61%\n",
      "[ 2018-07-31 22:13:40,369][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-31 22:13:40,405][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_2.predict)=100.00%\n",
      "[ 2018-07-31 22:13:40,417][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_3.predict)=98.59%\n",
      "[ 2018-07-31 22:13:40,427][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_4.predict)=98.59%\n",
      "[ 2018-07-31 22:13:40,451][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_5.predict)=98.59%\n",
      "[ 2018-07-31 22:13:40,461][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_6.predict)=100.00%\n",
      "[ 2018-07-31 22:13:40,477][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_7.predict)=100.00%\n",
      "[ 2018-07-31 22:13:40,485][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_8.predict)=100.00%\n",
      "[ 2018-07-31 22:13:40,493][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_9.predict)=100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:13:40,495][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_cv.predict)=99.44%\n",
      "[ 2018-07-31 22:13:40,496][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.test.predict)=100.00%\n",
      "[ 2018-07-31 22:13:40,501][cascade_classifier.calc_accuracy] Accuracy(layer_4 - train.classifier_average)=99.72%\n",
      "[ 2018-07-31 22:13:40,502][cascade_classifier.calc_accuracy] Accuracy(layer_4 - test.classifier_average)=100.00%\n",
      "[ 2018-07-31 22:13:40,504][cascade_classifier.fit_transform] [Result][Optimal Level Detected] opt_layer_num=2, accuracy_train=99.72%, accuracy_test=100.00%\n"
     ]
    }
   ],
   "source": [
    "t0=time()\n",
    "# X_enc is the concatenated predict_proba result of each estimators of the last layer of the GCForest model\n",
    "    # X_enc.shape =\n",
    "    #   (n_datas, n_estimators * n_classes): If cascade is provided\n",
    "    #   (n_datas, n_estimators * n_classes, dimX, dimY): If only finegrained part is provided\n",
    "    # You can also pass X_test, y_test to fit_transform method, then the accracy on test data will be logged when training.\n",
    "X_train_enc, X_test_enc = gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test)\n",
    "    # WARNING: if you set gc.set_keep_model_in_mem(True), you would have to use\n",
    "    # gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test) to evaluate your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:13:40,539][cascade_classifier.transform] X_groups_test.shape=[(304, 9)]\n",
      "[ 2018-07-31 22:13:40,542][cascade_classifier.transform] group_dims=[9]\n",
      "[ 2018-07-31 22:13:40,546][cascade_classifier.transform] X_test.shape=(304, 9)\n",
      "[ 2018-07-31 22:13:40,550][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(304, 9)\n",
      "[ 2018-07-31 22:13:47,396][cascade_classifier.transform] [layer=1] look_indexs=[0], X_cur_test.shape=(304, 15)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GCForest = 100.000000 %\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "y_pred = gc.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy of GCForest = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' Time ', '139.666', ' seconds')\n",
      "[[299   0]\n",
      " [  0   5]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00       299\n",
      "        1.0       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       1.00      1.00      1.00       304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "638/638 [==============================] - 1s 2ms/step - loss: 0.2459 - acc: 0.9875\n",
      "Epoch 2/50\n",
      "638/638 [==============================] - 0s 496us/step - loss: 0.0869 - acc: 0.9890\n",
      "Epoch 3/50\n",
      "638/638 [==============================] - 0s 526us/step - loss: 0.0614 - acc: 0.9890\n",
      "Epoch 4/50\n",
      "638/638 [==============================] - 0s 470us/step - loss: 0.0607 - acc: 0.9890\n",
      "Epoch 5/50\n",
      "638/638 [==============================] - 0s 483us/step - loss: 0.0594 - acc: 0.9890\n",
      "Epoch 6/50\n",
      "638/638 [==============================] - 0s 600us/step - loss: 0.0597 - acc: 0.9890\n",
      "Epoch 7/50\n",
      "638/638 [==============================] - 0s 594us/step - loss: 0.0612 - acc: 0.9890\n",
      "Epoch 8/50\n",
      "638/638 [==============================] - 0s 472us/step - loss: 0.0563 - acc: 0.9890\n",
      "Epoch 9/50\n",
      "638/638 [==============================] - 0s 481us/step - loss: 0.0557 - acc: 0.9890\n",
      "Epoch 10/50\n",
      "638/638 [==============================] - 0s 513us/step - loss: 0.0536 - acc: 0.9890\n",
      "Epoch 11/50\n",
      "638/638 [==============================] - 0s 611us/step - loss: 0.0531 - acc: 0.9890\n",
      "Epoch 12/50\n",
      "638/638 [==============================] - 0s 615us/step - loss: 0.0528 - acc: 0.9890\n",
      "Epoch 13/50\n",
      "638/638 [==============================] - 0s 534us/step - loss: 0.0504 - acc: 0.9890\n",
      "Epoch 14/50\n",
      "638/638 [==============================] - 0s 491us/step - loss: 0.0476 - acc: 0.9890\n",
      "Epoch 15/50\n",
      "638/638 [==============================] - 0s 493us/step - loss: 0.0450 - acc: 0.9890\n",
      "Epoch 16/50\n",
      "638/638 [==============================] - 0s 461us/step - loss: 0.0531 - acc: 0.9890\n",
      "Epoch 17/50\n",
      "638/638 [==============================] - 0s 534us/step - loss: 0.0482 - acc: 0.9890\n",
      "Epoch 18/50\n",
      "638/638 [==============================] - 0s 566us/step - loss: 0.0436 - acc: 0.9890\n",
      "Epoch 19/50\n",
      "638/638 [==============================] - 0s 407us/step - loss: 0.0383 - acc: 0.9890\n",
      "Epoch 20/50\n",
      "638/638 [==============================] - 0s 470us/step - loss: 0.0435 - acc: 0.9890\n",
      "Epoch 21/50\n",
      "638/638 [==============================] - 0s 455us/step - loss: 0.0340 - acc: 0.9890\n",
      "Epoch 22/50\n",
      "638/638 [==============================] - 0s 523us/step - loss: 0.0341 - acc: 0.9890\n",
      "Epoch 23/50\n",
      "638/638 [==============================] - 0s 495us/step - loss: 0.0343 - acc: 0.9890\n",
      "Epoch 24/50\n",
      "638/638 [==============================] - 0s 625us/step - loss: 0.0329 - acc: 0.9906\n",
      "Epoch 25/50\n",
      "638/638 [==============================] - 0s 588us/step - loss: 0.0355 - acc: 0.9890\n",
      "Epoch 26/50\n",
      "638/638 [==============================] - 0s 439us/step - loss: 0.0321 - acc: 0.9906\n",
      "Epoch 27/50\n",
      "638/638 [==============================] - 0s 498us/step - loss: 0.0290 - acc: 0.9906\n",
      "Epoch 28/50\n",
      "638/638 [==============================] - 0s 544us/step - loss: 0.0199 - acc: 0.9922\n",
      "Epoch 29/50\n",
      "638/638 [==============================] - 0s 558us/step - loss: 0.0199 - acc: 0.9922\n",
      "Epoch 30/50\n",
      "638/638 [==============================] - 0s 598us/step - loss: 0.0187 - acc: 0.9922 0s - loss: 0.0233 - acc: 0.\n",
      "Epoch 31/50\n",
      "638/638 [==============================] - 0s 521us/step - loss: 0.0141 - acc: 0.9937\n",
      "Epoch 32/50\n",
      "638/638 [==============================] - 0s 474us/step - loss: 0.0271 - acc: 0.9922\n",
      "Epoch 33/50\n",
      "638/638 [==============================] - 0s 488us/step - loss: 0.0118 - acc: 0.9937\n",
      "Epoch 34/50\n",
      "638/638 [==============================] - 0s 509us/step - loss: 0.0090 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "638/638 [==============================] - 0s 455us/step - loss: 0.0092 - acc: 0.9984\n",
      "Epoch 36/50\n",
      "638/638 [==============================] - 0s 608us/step - loss: 0.0086 - acc: 0.9953\n",
      "Epoch 37/50\n",
      "638/638 [==============================] - 0s 509us/step - loss: 0.0078 - acc: 0.9969\n",
      "Epoch 38/50\n",
      "638/638 [==============================] - 0s 540us/step - loss: 0.0058 - acc: 0.9984\n",
      "Epoch 39/50\n",
      "638/638 [==============================] - 0s 485us/step - loss: 0.0049 - acc: 0.9984\n",
      "Epoch 40/50\n",
      "638/638 [==============================] - 0s 491us/step - loss: 0.0089 - acc: 0.9969\n",
      "Epoch 41/50\n",
      "638/638 [==============================] - 0s 538us/step - loss: 0.0062 - acc: 0.9984\n",
      "Epoch 42/50\n",
      "638/638 [==============================] - 0s 523us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "638/638 [==============================] - 0s 470us/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "638/638 [==============================] - 0s 566us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "638/638 [==============================] - 0s 454us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "638/638 [==============================] - 0s 458us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "638/638 [==============================] - 0s 587us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "638/638 [==============================] - 0s 570us/step - loss: 9.9121e-04 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "638/638 [==============================] - 0s 503us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "638/638 [==============================] - 0s 419us/step - loss: 0.0014 - acc: 1.0000\n",
      "71/71 [==============================] - 0s 625us/step\n",
      "Epoch 1/50\n",
      "638/638 [==============================] - 2s 3ms/step - loss: 0.2760 - acc: 0.9404\n",
      "Epoch 2/50\n",
      "638/638 [==============================] - 0s 461us/step - loss: 0.0860 - acc: 0.9875\n",
      "Epoch 3/50\n",
      "638/638 [==============================] - 0s 512us/step - loss: 0.0689 - acc: 0.9875\n",
      "Epoch 4/50\n",
      "638/638 [==============================] - 0s 558us/step - loss: 0.0668 - acc: 0.9875\n",
      "Epoch 5/50\n",
      "638/638 [==============================] - 0s 543us/step - loss: 0.0653 - acc: 0.9875\n",
      "Epoch 6/50\n",
      "638/638 [==============================] - 0s 473us/step - loss: 0.0649 - acc: 0.9875\n",
      "Epoch 7/50\n",
      "638/638 [==============================] - 0s 483us/step - loss: 0.0644 - acc: 0.9875\n",
      "Epoch 8/50\n",
      "638/638 [==============================] - 0s 472us/step - loss: 0.0613 - acc: 0.9875\n",
      "Epoch 9/50\n",
      "638/638 [==============================] - 0s 543us/step - loss: 0.0596 - acc: 0.9875\n",
      "Epoch 10/50\n",
      "638/638 [==============================] - 0s 497us/step - loss: 0.0579 - acc: 0.9875\n",
      "Epoch 11/50\n",
      "638/638 [==============================] - 0s 476us/step - loss: 0.0566 - acc: 0.9875\n",
      "Epoch 12/50\n",
      "638/638 [==============================] - 0s 466us/step - loss: 0.0563 - acc: 0.9875\n",
      "Epoch 13/50\n",
      "638/638 [==============================] - 0s 519us/step - loss: 0.0518 - acc: 0.9875\n",
      "Epoch 14/50\n",
      "638/638 [==============================] - 0s 471us/step - loss: 0.0514 - acc: 0.9875\n",
      "Epoch 15/50\n",
      "638/638 [==============================] - 0s 471us/step - loss: 0.0511 - acc: 0.9875\n",
      "Epoch 16/50\n",
      "638/638 [==============================] - 0s 507us/step - loss: 0.0480 - acc: 0.9875\n",
      "Epoch 17/50\n",
      "638/638 [==============================] - 0s 547us/step - loss: 0.0440 - acc: 0.9875\n",
      "Epoch 18/50\n",
      "638/638 [==============================] - 0s 474us/step - loss: 0.0435 - acc: 0.9875\n",
      "Epoch 19/50\n",
      "638/638 [==============================] - 0s 573us/step - loss: 0.0439 - acc: 0.9875\n",
      "Epoch 20/50\n",
      "638/638 [==============================] - 0s 565us/step - loss: 0.0380 - acc: 0.9875\n",
      "Epoch 21/50\n",
      "638/638 [==============================] - 0s 524us/step - loss: 0.0351 - acc: 0.9890\n",
      "Epoch 22/50\n",
      "638/638 [==============================] - 0s 477us/step - loss: 0.0345 - acc: 0.9875\n",
      "Epoch 23/50\n",
      "638/638 [==============================] - 0s 493us/step - loss: 0.0329 - acc: 0.9890\n",
      "Epoch 24/50\n",
      "638/638 [==============================] - 0s 505us/step - loss: 0.0328 - acc: 0.9890\n",
      "Epoch 25/50\n",
      "638/638 [==============================] - 0s 653us/step - loss: 0.0247 - acc: 0.9890\n",
      "Epoch 26/50\n",
      "638/638 [==============================] - 0s 543us/step - loss: 0.0179 - acc: 0.9906\n",
      "Epoch 27/50\n",
      "638/638 [==============================] - 0s 537us/step - loss: 0.0254 - acc: 0.9922\n",
      "Epoch 28/50\n",
      "638/638 [==============================] - 0s 470us/step - loss: 0.0153 - acc: 0.9937\n",
      "Epoch 29/50\n",
      "638/638 [==============================] - 0s 547us/step - loss: 0.0157 - acc: 0.9953\n",
      "Epoch 30/50\n",
      "638/638 [==============================] - 0s 566us/step - loss: 0.0100 - acc: 0.9969\n",
      "Epoch 31/50\n",
      "638/638 [==============================] - 0s 474us/step - loss: 0.0093 - acc: 0.9969\n",
      "Epoch 32/50\n",
      "638/638 [==============================] - 0s 693us/step - loss: 0.0259 - acc: 0.9937\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638/638 [==============================] - 0s 505us/step - loss: 0.0327 - acc: 0.9937\n",
      "Epoch 34/50\n",
      "638/638 [==============================] - 0s 622us/step - loss: 0.0084 - acc: 0.9969\n",
      "Epoch 35/50\n",
      "638/638 [==============================] - 0s 617us/step - loss: 0.0059 - acc: 0.9984\n",
      "Epoch 36/50\n",
      "638/638 [==============================] - 0s 608us/step - loss: 0.0059 - acc: 0.9984 0s - loss: 0.0051 - acc: 1.\n",
      "Epoch 37/50\n",
      "638/638 [==============================] - 0s 526us/step - loss: 0.0050 - acc: 0.9984\n",
      "Epoch 38/50\n",
      "638/638 [==============================] - 0s 503us/step - loss: 0.0075 - acc: 0.9969\n",
      "Epoch 39/50\n",
      "638/638 [==============================] - 0s 555us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "638/638 [==============================] - 0s 649us/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "638/638 [==============================] - 0s 518us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "638/638 [==============================] - 0s 523us/step - loss: 0.0037 - acc: 0.9984\n",
      "Epoch 43/50\n",
      "638/638 [==============================] - 0s 541us/step - loss: 0.0065 - acc: 0.9984\n",
      "Epoch 44/50\n",
      "638/638 [==============================] - 0s 611us/step - loss: 0.0079 - acc: 0.9969\n",
      "Epoch 45/50\n",
      "638/638 [==============================] - 0s 514us/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "638/638 [==============================] - 0s 519us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "638/638 [==============================] - 0s 573us/step - loss: 0.0040 - acc: 0.9984\n",
      "Epoch 48/50\n",
      "638/638 [==============================] - 0s 669us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "638/638 [==============================] - 0s 547us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "638/638 [==============================] - 0s 741us/step - loss: 0.0010 - acc: 1.0000\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "638/638 [==============================] - 2s 3ms/step - loss: 0.2710 - acc: 0.9389\n",
      "Epoch 2/50\n",
      "638/638 [==============================] - 0s 731us/step - loss: 0.0753 - acc: 0.9890\n",
      "Epoch 3/50\n",
      "638/638 [==============================] - 0s 662us/step - loss: 0.0615 - acc: 0.9890\n",
      "Epoch 4/50\n",
      "638/638 [==============================] - 0s 732us/step - loss: 0.0606 - acc: 0.9890\n",
      "Epoch 5/50\n",
      "638/638 [==============================] - 0s 558us/step - loss: 0.0599 - acc: 0.9890\n",
      "Epoch 6/50\n",
      "638/638 [==============================] - 0s 636us/step - loss: 0.0588 - acc: 0.9890\n",
      "Epoch 7/50\n",
      "638/638 [==============================] - 0s 658us/step - loss: 0.0572 - acc: 0.9890\n",
      "Epoch 8/50\n",
      "638/638 [==============================] - 0s 667us/step - loss: 0.0565 - acc: 0.9890\n",
      "Epoch 9/50\n",
      "638/638 [==============================] - 0s 751us/step - loss: 0.0551 - acc: 0.9890\n",
      "Epoch 10/50\n",
      "638/638 [==============================] - 0s 654us/step - loss: 0.0537 - acc: 0.9890\n",
      "Epoch 11/50\n",
      "638/638 [==============================] - 1s 788us/step - loss: 0.0561 - acc: 0.9890\n",
      "Epoch 12/50\n",
      "638/638 [==============================] - 0s 579us/step - loss: 0.0531 - acc: 0.9890\n",
      "Epoch 13/50\n",
      "638/638 [==============================] - 0s 625us/step - loss: 0.0510 - acc: 0.9890\n",
      "Epoch 14/50\n",
      "638/638 [==============================] - 0s 569us/step - loss: 0.0491 - acc: 0.9890\n",
      "Epoch 15/50\n",
      "638/638 [==============================] - 0s 732us/step - loss: 0.0521 - acc: 0.9890\n",
      "Epoch 16/50\n",
      "638/638 [==============================] - 0s 541us/step - loss: 0.0441 - acc: 0.9890\n",
      "Epoch 17/50\n",
      "638/638 [==============================] - 0s 638us/step - loss: 0.0435 - acc: 0.9890\n",
      "Epoch 18/50\n",
      "638/638 [==============================] - 0s 469us/step - loss: 0.0465 - acc: 0.9890\n",
      "Epoch 19/50\n",
      "638/638 [==============================] - 0s 513us/step - loss: 0.0449 - acc: 0.9890\n",
      "Epoch 20/50\n",
      "638/638 [==============================] - 0s 522us/step - loss: 0.0403 - acc: 0.9890\n",
      "Epoch 21/50\n",
      "638/638 [==============================] - 0s 774us/step - loss: 0.0468 - acc: 0.9890\n",
      "Epoch 22/50\n",
      "638/638 [==============================] - 0s 538us/step - loss: 0.0351 - acc: 0.9890\n",
      "Epoch 23/50\n",
      "638/638 [==============================] - 0s 633us/step - loss: 0.0328 - acc: 0.9890\n",
      "Epoch 24/50\n",
      "638/638 [==============================] - 0s 722us/step - loss: 0.0303 - acc: 0.9906\n",
      "Epoch 25/50\n",
      "638/638 [==============================] - 0s 677us/step - loss: 0.0314 - acc: 0.9922\n",
      "Epoch 26/50\n",
      "638/638 [==============================] - 0s 584us/step - loss: 0.0340 - acc: 0.9890\n",
      "Epoch 27/50\n",
      "638/638 [==============================] - 0s 602us/step - loss: 0.0256 - acc: 0.9906\n",
      "Epoch 28/50\n",
      "638/638 [==============================] - 0s 618us/step - loss: 0.0221 - acc: 0.9922\n",
      "Epoch 29/50\n",
      "638/638 [==============================] - 0s 531us/step - loss: 0.0187 - acc: 0.9922\n",
      "Epoch 30/50\n",
      "638/638 [==============================] - 0s 611us/step - loss: 0.0209 - acc: 0.9922\n",
      "Epoch 31/50\n",
      "638/638 [==============================] - 0s 527us/step - loss: 0.0266 - acc: 0.9922\n",
      "Epoch 32/50\n",
      "638/638 [==============================] - 0s 537us/step - loss: 0.0146 - acc: 0.9969\n",
      "Epoch 33/50\n",
      "638/638 [==============================] - 0s 470us/step - loss: 0.0128 - acc: 0.9953\n",
      "Epoch 34/50\n",
      "638/638 [==============================] - 0s 560us/step - loss: 0.0104 - acc: 0.9969\n",
      "Epoch 35/50\n",
      "638/638 [==============================] - 0s 564us/step - loss: 0.0089 - acc: 0.9969\n",
      "Epoch 36/50\n",
      "638/638 [==============================] - 0s 582us/step - loss: 0.0080 - acc: 0.9984\n",
      "Epoch 37/50\n",
      "638/638 [==============================] - 0s 609us/step - loss: 0.0071 - acc: 0.9969\n",
      "Epoch 38/50\n",
      "638/638 [==============================] - 0s 525us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "638/638 [==============================] - 0s 571us/step - loss: 0.0060 - acc: 0.9969\n",
      "Epoch 40/50\n",
      "638/638 [==============================] - 0s 627us/step - loss: 0.0043 - acc: 0.9984\n",
      "Epoch 41/50\n",
      "638/638 [==============================] - 0s 636us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "638/638 [==============================] - 0s 549us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "638/638 [==============================] - 0s 481us/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "638/638 [==============================] - 0s 498us/step - loss: 0.0178 - acc: 0.9937\n",
      "Epoch 45/50\n",
      "638/638 [==============================] - 0s 493us/step - loss: 0.0125 - acc: 0.9937\n",
      "Epoch 46/50\n",
      "638/638 [==============================] - 0s 506us/step - loss: 0.0124 - acc: 0.9953\n",
      "Epoch 47/50\n",
      "638/638 [==============================] - 0s 521us/step - loss: 0.0118 - acc: 0.9969\n",
      "Epoch 48/50\n",
      "638/638 [==============================] - 0s 610us/step - loss: 0.0091 - acc: 0.9953\n",
      "Epoch 49/50\n",
      "638/638 [==============================] - 0s 628us/step - loss: 0.0058 - acc: 0.9984\n",
      "Epoch 50/50\n",
      "638/638 [==============================] - 0s 569us/step - loss: 0.0025 - acc: 1.0000\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "638/638 [==============================] - 3s 5ms/step - loss: 0.2293 - acc: 0.9906\n",
      "Epoch 2/50\n",
      "638/638 [==============================] - 0s 535us/step - loss: 0.0685 - acc: 0.9922\n",
      "Epoch 3/50\n",
      "638/638 [==============================] - 0s 649us/step - loss: 0.0520 - acc: 0.9922\n",
      "Epoch 4/50\n",
      "638/638 [==============================] - 0s 649us/step - loss: 0.0458 - acc: 0.9922\n",
      "Epoch 5/50\n",
      "638/638 [==============================] - 0s 663us/step - loss: 0.0471 - acc: 0.9922\n",
      "Epoch 6/50\n",
      "638/638 [==============================] - 0s 609us/step - loss: 0.0447 - acc: 0.9922\n",
      "Epoch 7/50\n",
      "638/638 [==============================] - 0s 638us/step - loss: 0.0450 - acc: 0.9922\n",
      "Epoch 8/50\n",
      "638/638 [==============================] - 0s 603us/step - loss: 0.0451 - acc: 0.9922\n",
      "Epoch 9/50\n",
      "638/638 [==============================] - 0s 579us/step - loss: 0.0430 - acc: 0.9922\n",
      "Epoch 10/50\n",
      "638/638 [==============================] - 0s 700us/step - loss: 0.0416 - acc: 0.9922\n",
      "Epoch 11/50\n",
      "638/638 [==============================] - 0s 634us/step - loss: 0.0423 - acc: 0.9922\n",
      "Epoch 12/50\n",
      "638/638 [==============================] - 0s 586us/step - loss: 0.0399 - acc: 0.9922\n",
      "Epoch 13/50\n",
      "638/638 [==============================] - 0s 596us/step - loss: 0.0387 - acc: 0.9922\n",
      "Epoch 14/50\n",
      "638/638 [==============================] - 0s 576us/step - loss: 0.0401 - acc: 0.9922\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638/638 [==============================] - 0s 627us/step - loss: 0.0363 - acc: 0.9922\n",
      "Epoch 16/50\n",
      "638/638 [==============================] - 0s 594us/step - loss: 0.0362 - acc: 0.9922\n",
      "Epoch 17/50\n",
      "638/638 [==============================] - 0s 559us/step - loss: 0.0351 - acc: 0.9922\n",
      "Epoch 18/50\n",
      "638/638 [==============================] - 0s 496us/step - loss: 0.0355 - acc: 0.9922\n",
      "Epoch 19/50\n",
      "638/638 [==============================] - 0s 501us/step - loss: 0.0333 - acc: 0.9922\n",
      "Epoch 20/50\n",
      "638/638 [==============================] - 0s 615us/step - loss: 0.0321 - acc: 0.9922\n",
      "Epoch 21/50\n",
      "638/638 [==============================] - 0s 777us/step - loss: 0.0312 - acc: 0.9922\n",
      "Epoch 22/50\n",
      "638/638 [==============================] - 0s 704us/step - loss: 0.0328 - acc: 0.9922\n",
      "Epoch 23/50\n",
      "638/638 [==============================] - 0s 611us/step - loss: 0.0302 - acc: 0.9922\n",
      "Epoch 24/50\n",
      "638/638 [==============================] - 0s 569us/step - loss: 0.0263 - acc: 0.9922\n",
      "Epoch 25/50\n",
      "638/638 [==============================] - 0s 563us/step - loss: 0.0239 - acc: 0.9937\n",
      "Epoch 26/50\n",
      "638/638 [==============================] - 0s 548us/step - loss: 0.0274 - acc: 0.9937\n",
      "Epoch 27/50\n",
      "638/638 [==============================] - 0s 661us/step - loss: 0.0243 - acc: 0.9937\n",
      "Epoch 28/50\n",
      "638/638 [==============================] - 0s 614us/step - loss: 0.0213 - acc: 0.9937\n",
      "Epoch 29/50\n",
      "638/638 [==============================] - 0s 713us/step - loss: 0.0209 - acc: 0.9937\n",
      "Epoch 30/50\n",
      "638/638 [==============================] - 0s 674us/step - loss: 0.0175 - acc: 0.9937\n",
      "Epoch 31/50\n",
      "638/638 [==============================] - 0s 726us/step - loss: 0.0195 - acc: 0.9937\n",
      "Epoch 32/50\n",
      "638/638 [==============================] - 0s 732us/step - loss: 0.0204 - acc: 0.9937\n",
      "Epoch 33/50\n",
      "638/638 [==============================] - 0s 662us/step - loss: 0.0162 - acc: 0.9969\n",
      "Epoch 34/50\n",
      "638/638 [==============================] - 0s 616us/step - loss: 0.0122 - acc: 0.9953\n",
      "Epoch 35/50\n",
      "638/638 [==============================] - 0s 657us/step - loss: 0.0128 - acc: 0.9969\n",
      "Epoch 36/50\n",
      "638/638 [==============================] - 0s 520us/step - loss: 0.0091 - acc: 0.9953\n",
      "Epoch 37/50\n",
      "638/638 [==============================] - 0s 606us/step - loss: 0.0111 - acc: 0.9969\n",
      "Epoch 38/50\n",
      "638/638 [==============================] - 1s 932us/step - loss: 0.0143 - acc: 0.9953\n",
      "Epoch 39/50\n",
      "638/638 [==============================] - 0s 635us/step - loss: 0.0127 - acc: 0.9969\n",
      "Epoch 40/50\n",
      "638/638 [==============================] - 0s 697us/step - loss: 0.0085 - acc: 0.9969\n",
      "Epoch 41/50\n",
      "638/638 [==============================] - 0s 751us/step - loss: 0.0089 - acc: 0.9984\n",
      "Epoch 42/50\n",
      "638/638 [==============================] - 1s 803us/step - loss: 0.0127 - acc: 0.9969\n",
      "Epoch 43/50\n",
      "638/638 [==============================] - 0s 715us/step - loss: 0.0044 - acc: 0.9984\n",
      "Epoch 44/50\n",
      "638/638 [==============================] - 0s 623us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "638/638 [==============================] - 0s 512us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "638/638 [==============================] - 1s 816us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "638/638 [==============================] - 0s 612us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "638/638 [==============================] - 0s 730us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "638/638 [==============================] - 0s 721us/step - loss: 0.0038 - acc: 0.9984\n",
      "Epoch 50/50\n",
      "638/638 [==============================] - 0s 707us/step - loss: 0.0084 - acc: 0.9969\n",
      "71/71 [==============================] - 0s 7ms/step\n",
      "Epoch 1/50\n",
      "638/638 [==============================] - 3s 5ms/step - loss: 0.2623 - acc: 0.9890\n",
      "Epoch 2/50\n",
      "638/638 [==============================] - 0s 780us/step - loss: 0.0860 - acc: 0.9890\n",
      "Epoch 3/50\n",
      "638/638 [==============================] - 1s 880us/step - loss: 0.0615 - acc: 0.9890\n",
      "Epoch 4/50\n",
      "638/638 [==============================] - 1s 826us/step - loss: 0.0610 - acc: 0.9890\n",
      "Epoch 5/50\n",
      "638/638 [==============================] - 1s 862us/step - loss: 0.0594 - acc: 0.9890\n",
      "Epoch 6/50\n",
      "638/638 [==============================] - 1s 824us/step - loss: 0.0583 - acc: 0.9890\n",
      "Epoch 7/50\n",
      "638/638 [==============================] - 0s 782us/step - loss: 0.0594 - acc: 0.9890\n",
      "Epoch 8/50\n",
      "638/638 [==============================] - 1s 1ms/step - loss: 0.0566 - acc: 0.9890\n",
      "Epoch 9/50\n",
      "638/638 [==============================] - 1s 1ms/step - loss: 0.0567 - acc: 0.9890\n",
      "Epoch 10/50\n",
      "638/638 [==============================] - 1s 915us/step - loss: 0.0548 - acc: 0.9890\n",
      "Epoch 11/50\n",
      "638/638 [==============================] - 1s 910us/step - loss: 0.0546 - acc: 0.9890\n",
      "Epoch 12/50\n",
      "638/638 [==============================] - 1s 856us/step - loss: 0.0514 - acc: 0.9890\n",
      "Epoch 13/50\n",
      "638/638 [==============================] - 1s 785us/step - loss: 0.0522 - acc: 0.9890\n",
      "Epoch 14/50\n",
      "638/638 [==============================] - 0s 749us/step - loss: 0.0491 - acc: 0.9890\n",
      "Epoch 15/50\n",
      "638/638 [==============================] - 1s 908us/step - loss: 0.0535 - acc: 0.9890\n",
      "Epoch 16/50\n",
      "638/638 [==============================] - 0s 720us/step - loss: 0.0482 - acc: 0.9890\n",
      "Epoch 17/50\n",
      "638/638 [==============================] - 0s 744us/step - loss: 0.0464 - acc: 0.9890\n",
      "Epoch 18/50\n",
      "638/638 [==============================] - 1s 859us/step - loss: 0.0445 - acc: 0.9890\n",
      "Epoch 19/50\n",
      "638/638 [==============================] - 1s 890us/step - loss: 0.0419 - acc: 0.9890\n",
      "Epoch 20/50\n",
      "638/638 [==============================] - 1s 872us/step - loss: 0.0402 - acc: 0.9890\n",
      "Epoch 21/50\n",
      "638/638 [==============================] - 1s 961us/step - loss: 0.0367 - acc: 0.9890\n",
      "Epoch 22/50\n",
      "638/638 [==============================] - 1s 789us/step - loss: 0.0336 - acc: 0.9890\n",
      "Epoch 23/50\n",
      "638/638 [==============================] - 0s 646us/step - loss: 0.0383 - acc: 0.9890\n",
      "Epoch 24/50\n",
      "638/638 [==============================] - 0s 678us/step - loss: 0.0309 - acc: 0.9890\n",
      "Epoch 25/50\n",
      "638/638 [==============================] - 0s 646us/step - loss: 0.0266 - acc: 0.9906\n",
      "Epoch 26/50\n",
      "638/638 [==============================] - 0s 594us/step - loss: 0.0323 - acc: 0.9922\n",
      "Epoch 27/50\n",
      "638/638 [==============================] - 0s 692us/step - loss: 0.0421 - acc: 0.9906\n",
      "Epoch 28/50\n",
      "638/638 [==============================] - 0s 547us/step - loss: 0.0287 - acc: 0.9906\n",
      "Epoch 29/50\n",
      "638/638 [==============================] - 0s 695us/step - loss: 0.0254 - acc: 0.9922\n",
      "Epoch 30/50\n",
      "638/638 [==============================] - 0s 765us/step - loss: 0.0228 - acc: 0.9922\n",
      "Epoch 31/50\n",
      "638/638 [==============================] - 0s 663us/step - loss: 0.0159 - acc: 0.9922\n",
      "Epoch 32/50\n",
      "638/638 [==============================] - 0s 590us/step - loss: 0.0132 - acc: 0.9969\n",
      "Epoch 33/50\n",
      "638/638 [==============================] - 0s 562us/step - loss: 0.0185 - acc: 0.9953\n",
      "Epoch 34/50\n",
      "638/638 [==============================] - 0s 591us/step - loss: 0.0091 - acc: 0.9984\n",
      "Epoch 35/50\n",
      "638/638 [==============================] - 0s 659us/step - loss: 0.0100 - acc: 0.9969\n",
      "Epoch 36/50\n",
      "638/638 [==============================] - 0s 564us/step - loss: 0.0104 - acc: 0.9953\n",
      "Epoch 37/50\n",
      "638/638 [==============================] - 0s 633us/step - loss: 0.0126 - acc: 0.9953\n",
      "Epoch 38/50\n",
      "638/638 [==============================] - 0s 643us/step - loss: 0.0068 - acc: 0.9984\n",
      "Epoch 39/50\n",
      "638/638 [==============================] - 0s 642us/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "638/638 [==============================] - 1s 853us/step - loss: 0.0050 - acc: 0.9984\n",
      "Epoch 41/50\n",
      "638/638 [==============================] - 0s 670us/step - loss: 0.0050 - acc: 0.9984\n",
      "Epoch 42/50\n",
      "638/638 [==============================] - 0s 719us/step - loss: 0.0050 - acc: 0.9984\n",
      "Epoch 43/50\n",
      "638/638 [==============================] - 1s 848us/step - loss: 0.0061 - acc: 0.9984\n",
      "Epoch 44/50\n",
      "638/638 [==============================] - 1s 894us/step - loss: 0.0064 - acc: 0.9984\n",
      "Epoch 45/50\n",
      "638/638 [==============================] - 0s 763us/step - loss: 0.0131 - acc: 0.9953\n",
      "Epoch 46/50\n",
      "638/638 [==============================] - 1s 807us/step - loss: 0.0083 - acc: 0.9969\n",
      "Epoch 47/50\n",
      "638/638 [==============================] - 1s 839us/step - loss: 0.0059 - acc: 0.9984\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638/638 [==============================] - 0s 759us/step - loss: 0.0024 - acc: 0.9984\n",
      "Epoch 49/50\n",
      "638/638 [==============================] - 0s 772us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "638/638 [==============================] - 1s 805us/step - loss: 0.0018 - acc: 1.0000\n",
      "71/71 [==============================] - 1s 9ms/step\n",
      "Epoch 1/50\n",
      "638/638 [==============================] - 4s 5ms/step - loss: 0.2460 - acc: 0.9875\n",
      "Epoch 2/50\n",
      "638/638 [==============================] - 0s 594us/step - loss: 0.0890 - acc: 0.9875\n",
      "Epoch 3/50\n",
      "638/638 [==============================] - 0s 545us/step - loss: 0.0688 - acc: 0.9875\n",
      "Epoch 4/50\n",
      "638/638 [==============================] - 0s 589us/step - loss: 0.0678 - acc: 0.9875\n",
      "Epoch 5/50\n",
      "638/638 [==============================] - 0s 693us/step - loss: 0.0667 - acc: 0.9875\n",
      "Epoch 6/50\n",
      "638/638 [==============================] - 0s 703us/step - loss: 0.0658 - acc: 0.9875\n",
      "Epoch 7/50\n",
      "638/638 [==============================] - 0s 550us/step - loss: 0.0641 - acc: 0.9875\n",
      "Epoch 8/50\n",
      "638/638 [==============================] - 0s 617us/step - loss: 0.0686 - acc: 0.9875\n",
      "Epoch 9/50\n",
      "638/638 [==============================] - 1s 784us/step - loss: 0.0593 - acc: 0.9875\n",
      "Epoch 10/50\n",
      "638/638 [==============================] - 0s 662us/step - loss: 0.0610 - acc: 0.9875\n",
      "Epoch 11/50\n",
      "638/638 [==============================] - 0s 660us/step - loss: 0.0574 - acc: 0.9875\n",
      "Epoch 12/50\n",
      "638/638 [==============================] - 0s 659us/step - loss: 0.0587 - acc: 0.9875\n",
      "Epoch 13/50\n",
      "638/638 [==============================] - 0s 640us/step - loss: 0.0544 - acc: 0.9875\n",
      "Epoch 14/50\n",
      "638/638 [==============================] - 0s 588us/step - loss: 0.0530 - acc: 0.9875\n",
      "Epoch 15/50\n",
      "638/638 [==============================] - 0s 566us/step - loss: 0.0528 - acc: 0.9875\n",
      "Epoch 16/50\n",
      "638/638 [==============================] - 0s 556us/step - loss: 0.0500 - acc: 0.9875\n",
      "Epoch 17/50\n",
      "638/638 [==============================] - 0s 632us/step - loss: 0.0473 - acc: 0.9875\n",
      "Epoch 18/50\n",
      "638/638 [==============================] - 0s 705us/step - loss: 0.0433 - acc: 0.9875\n",
      "Epoch 19/50\n",
      "638/638 [==============================] - 0s 614us/step - loss: 0.0400 - acc: 0.9875\n",
      "Epoch 20/50\n",
      "638/638 [==============================] - 0s 549us/step - loss: 0.0340 - acc: 0.9875\n",
      "Epoch 21/50\n",
      "638/638 [==============================] - 0s 749us/step - loss: 0.0407 - acc: 0.9875\n",
      "Epoch 22/50\n",
      "638/638 [==============================] - 0s 751us/step - loss: 0.0339 - acc: 0.9890\n",
      "Epoch 23/50\n",
      "638/638 [==============================] - 0s 709us/step - loss: 0.0318 - acc: 0.9890\n",
      "Epoch 24/50\n",
      "638/638 [==============================] - 0s 693us/step - loss: 0.0288 - acc: 0.9906\n",
      "Epoch 25/50\n",
      "638/638 [==============================] - 0s 686us/step - loss: 0.0232 - acc: 0.9906\n",
      "Epoch 26/50\n",
      "638/638 [==============================] - 1s 810us/step - loss: 0.0235 - acc: 0.9922\n",
      "Epoch 27/50\n",
      "638/638 [==============================] - 0s 670us/step - loss: 0.0258 - acc: 0.9937\n",
      "Epoch 28/50\n",
      "638/638 [==============================] - 0s 480us/step - loss: 0.0241 - acc: 0.9922\n",
      "Epoch 29/50\n",
      "638/638 [==============================] - 0s 596us/step - loss: 0.0345 - acc: 0.9922\n",
      "Epoch 30/50\n",
      "638/638 [==============================] - 0s 530us/step - loss: 0.0138 - acc: 0.9953\n",
      "Epoch 31/50\n",
      "638/638 [==============================] - 0s 555us/step - loss: 0.0151 - acc: 0.9937\n",
      "Epoch 32/50\n",
      "638/638 [==============================] - 0s 606us/step - loss: 0.0126 - acc: 0.9969\n",
      "Epoch 33/50\n",
      "638/638 [==============================] - 0s 693us/step - loss: 0.0144 - acc: 0.9969\n",
      "Epoch 34/50\n",
      "638/638 [==============================] - 0s 657us/step - loss: 0.0081 - acc: 0.9984\n",
      "Epoch 35/50\n",
      "638/638 [==============================] - 0s 685us/step - loss: 0.0069 - acc: 0.9984\n",
      "Epoch 36/50\n",
      "638/638 [==============================] - 0s 735us/step - loss: 0.0081 - acc: 0.9984\n",
      "Epoch 37/50\n",
      "638/638 [==============================] - 0s 775us/step - loss: 0.0100 - acc: 0.9969\n",
      "Epoch 38/50\n",
      "638/638 [==============================] - 0s 722us/step - loss: 0.0107 - acc: 0.9969\n",
      "Epoch 39/50\n",
      "638/638 [==============================] - 0s 765us/step - loss: 0.0061 - acc: 0.9984\n",
      "Epoch 40/50\n",
      "638/638 [==============================] - 0s 631us/step - loss: 0.0062 - acc: 0.9984\n",
      "Epoch 41/50\n",
      "638/638 [==============================] - 0s 719us/step - loss: 0.0084 - acc: 0.9937\n",
      "Epoch 42/50\n",
      "638/638 [==============================] - 0s 745us/step - loss: 0.0119 - acc: 0.9953\n",
      "Epoch 43/50\n",
      "638/638 [==============================] - 1s 786us/step - loss: 0.0047 - acc: 0.9984\n",
      "Epoch 44/50\n",
      "638/638 [==============================] - 1s 799us/step - loss: 0.0026 - acc: 0.9984\n",
      "Epoch 45/50\n",
      "638/638 [==============================] - 1s 917us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "638/638 [==============================] - 1s 856us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "638/638 [==============================] - 1s 789us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "638/638 [==============================] - 1s 820us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "638/638 [==============================] - 1s 786us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "638/638 [==============================] - 0s 675us/step - loss: 0.0012 - acc: 1.0000\n",
      "71/71 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "638/638 [==============================] - 5s 7ms/step - loss: 0.2629 - acc: 0.9373\n",
      "Epoch 2/50\n",
      "638/638 [==============================] - 0s 500us/step - loss: 0.0907 - acc: 0.9875\n",
      "Epoch 3/50\n",
      "638/638 [==============================] - 0s 660us/step - loss: 0.0746 - acc: 0.9875\n",
      "Epoch 4/50\n",
      "638/638 [==============================] - 1s 827us/step - loss: 0.0696 - acc: 0.9875 0s - loss: 0.0159 - acc: \n",
      "Epoch 5/50\n",
      "638/638 [==============================] - 1s 895us/step - loss: 0.0695 - acc: 0.9875\n",
      "Epoch 6/50\n",
      "638/638 [==============================] - 0s 767us/step - loss: 0.0672 - acc: 0.9875\n",
      "Epoch 7/50\n",
      "638/638 [==============================] - 0s 658us/step - loss: 0.0643 - acc: 0.9875\n",
      "Epoch 8/50\n",
      "638/638 [==============================] - 1s 910us/step - loss: 0.0634 - acc: 0.9875\n",
      "Epoch 9/50\n",
      "638/638 [==============================] - 1s 849us/step - loss: 0.0620 - acc: 0.9875\n",
      "Epoch 10/50\n",
      "638/638 [==============================] - 1s 902us/step - loss: 0.0604 - acc: 0.9875\n",
      "Epoch 11/50\n",
      "638/638 [==============================] - 1s 1ms/step - loss: 0.0609 - acc: 0.9875\n",
      "Epoch 12/50\n",
      "638/638 [==============================] - 1s 917us/step - loss: 0.0570 - acc: 0.9875\n",
      "Epoch 13/50\n",
      "638/638 [==============================] - 1s 845us/step - loss: 0.0567 - acc: 0.9875\n",
      "Epoch 14/50\n",
      "638/638 [==============================] - 0s 746us/step - loss: 0.0589 - acc: 0.9875\n",
      "Epoch 15/50\n",
      "638/638 [==============================] - 0s 746us/step - loss: 0.0558 - acc: 0.9875\n",
      "Epoch 16/50\n",
      "638/638 [==============================] - 0s 642us/step - loss: 0.0540 - acc: 0.9875\n",
      "Epoch 17/50\n",
      "638/638 [==============================] - 0s 754us/step - loss: 0.0491 - acc: 0.9875\n",
      "Epoch 18/50\n",
      "638/638 [==============================] - 0s 734us/step - loss: 0.0461 - acc: 0.9875\n",
      "Epoch 19/50\n",
      "638/638 [==============================] - 0s 717us/step - loss: 0.0457 - acc: 0.9875\n",
      "Epoch 20/50\n",
      "638/638 [==============================] - 1s 854us/step - loss: 0.0414 - acc: 0.9875\n",
      "Epoch 21/50\n",
      "638/638 [==============================] - 0s 746us/step - loss: 0.0371 - acc: 0.9875\n",
      "Epoch 22/50\n",
      "638/638 [==============================] - 0s 752us/step - loss: 0.0387 - acc: 0.9875\n",
      "Epoch 23/50\n",
      "638/638 [==============================] - 0s 701us/step - loss: 0.0423 - acc: 0.9890\n",
      "Epoch 24/50\n",
      "638/638 [==============================] - 0s 655us/step - loss: 0.0352 - acc: 0.9875\n",
      "Epoch 25/50\n",
      "638/638 [==============================] - 1s 836us/step - loss: 0.0297 - acc: 0.9875\n",
      "Epoch 26/50\n",
      "638/638 [==============================] - 1s 868us/step - loss: 0.0262 - acc: 0.9906\n",
      "Epoch 27/50\n",
      "638/638 [==============================] - 0s 764us/step - loss: 0.0242 - acc: 0.9890\n",
      "Epoch 28/50\n",
      "638/638 [==============================] - 0s 706us/step - loss: 0.0207 - acc: 0.9890\n",
      "Epoch 29/50\n",
      "638/638 [==============================] - 0s 776us/step - loss: 0.0237 - acc: 0.9937\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638/638 [==============================] - 0s 677us/step - loss: 0.0352 - acc: 0.9906\n",
      "Epoch 31/50\n",
      "638/638 [==============================] - 0s 744us/step - loss: 0.0249 - acc: 0.9922\n",
      "Epoch 32/50\n",
      "638/638 [==============================] - 1s 851us/step - loss: 0.0166 - acc: 0.9969\n",
      "Epoch 33/50\n",
      "638/638 [==============================] - 0s 741us/step - loss: 0.0156 - acc: 0.9937\n",
      "Epoch 34/50\n",
      "638/638 [==============================] - 1s 942us/step - loss: 0.0114 - acc: 0.9969\n",
      "Epoch 35/50\n",
      "638/638 [==============================] - 1s 810us/step - loss: 0.0120 - acc: 0.9969\n",
      "Epoch 36/50\n",
      "638/638 [==============================] - 0s 701us/step - loss: 0.0096 - acc: 0.9969\n",
      "Epoch 37/50\n",
      "638/638 [==============================] - 0s 752us/step - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "638/638 [==============================] - 1s 830us/step - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "638/638 [==============================] - 0s 702us/step - loss: 0.0165 - acc: 0.9953\n",
      "Epoch 40/50\n",
      "638/638 [==============================] - 0s 682us/step - loss: 0.0180 - acc: 0.9937\n",
      "Epoch 41/50\n",
      "638/638 [==============================] - 0s 769us/step - loss: 0.0111 - acc: 0.9953\n",
      "Epoch 42/50\n",
      "638/638 [==============================] - 1s 796us/step - loss: 0.0112 - acc: 0.9937\n",
      "Epoch 43/50\n",
      "638/638 [==============================] - 0s 639us/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "638/638 [==============================] - 0s 655us/step - loss: 0.0043 - acc: 0.9984\n",
      "Epoch 45/50\n",
      "638/638 [==============================] - 0s 596us/step - loss: 0.0051 - acc: 0.9984\n",
      "Epoch 46/50\n",
      "638/638 [==============================] - 0s 698us/step - loss: 0.0028 - acc: 1.0000 0s - loss: 0.0032 - acc: 1\n",
      "Epoch 47/50\n",
      "638/638 [==============================] - 1s 826us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "638/638 [==============================] - 1s 907us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "638/638 [==============================] - 0s 643us/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "638/638 [==============================] - 1s 793us/step - loss: 0.0031 - acc: 1.0000\n",
      "71/71 [==============================] - 1s 11ms/step\n",
      "Epoch 1/50\n",
      "638/638 [==============================] - 4s 6ms/step - loss: 0.2662 - acc: 0.9420\n",
      "Epoch 2/50\n",
      "638/638 [==============================] - 0s 778us/step - loss: 0.0762 - acc: 0.9890\n",
      "Epoch 3/50\n",
      "638/638 [==============================] - 0s 659us/step - loss: 0.0634 - acc: 0.9890\n",
      "Epoch 4/50\n",
      "638/638 [==============================] - 0s 704us/step - loss: 0.0603 - acc: 0.9890\n",
      "Epoch 5/50\n",
      "638/638 [==============================] - 0s 730us/step - loss: 0.0597 - acc: 0.9890\n",
      "Epoch 6/50\n",
      "638/638 [==============================] - 0s 758us/step - loss: 0.0586 - acc: 0.9890\n",
      "Epoch 7/50\n",
      "638/638 [==============================] - 1s 787us/step - loss: 0.0572 - acc: 0.9890\n",
      "Epoch 8/50\n",
      "638/638 [==============================] - 1s 879us/step - loss: 0.0562 - acc: 0.9890\n",
      "Epoch 9/50\n",
      "638/638 [==============================] - 1s 890us/step - loss: 0.0558 - acc: 0.9890\n",
      "Epoch 10/50\n",
      "638/638 [==============================] - 1s 812us/step - loss: 0.0582 - acc: 0.9890\n",
      "Epoch 11/50\n",
      "638/638 [==============================] - 0s 754us/step - loss: 0.0544 - acc: 0.9890\n",
      "Epoch 12/50\n",
      "638/638 [==============================] - 0s 761us/step - loss: 0.0534 - acc: 0.9890\n",
      "Epoch 13/50\n",
      "638/638 [==============================] - 1s 793us/step - loss: 0.0515 - acc: 0.9890\n",
      "Epoch 14/50\n",
      "638/638 [==============================] - 0s 617us/step - loss: 0.0537 - acc: 0.9890\n",
      "Epoch 15/50\n",
      "638/638 [==============================] - 0s 579us/step - loss: 0.0533 - acc: 0.9890\n",
      "Epoch 16/50\n",
      "638/638 [==============================] - 0s 712us/step - loss: 0.0494 - acc: 0.9890\n",
      "Epoch 17/50\n",
      "638/638 [==============================] - 0s 702us/step - loss: 0.0506 - acc: 0.9890\n",
      "Epoch 18/50\n",
      "638/638 [==============================] - 1s 839us/step - loss: 0.0514 - acc: 0.9890\n",
      "Epoch 19/50\n",
      "638/638 [==============================] - 1s 884us/step - loss: 0.0461 - acc: 0.9890\n",
      "Epoch 20/50\n",
      "638/638 [==============================] - 0s 732us/step - loss: 0.0456 - acc: 0.9890\n",
      "Epoch 21/50\n",
      "638/638 [==============================] - 0s 753us/step - loss: 0.0426 - acc: 0.9890\n",
      "Epoch 22/50\n",
      "638/638 [==============================] - 0s 726us/step - loss: 0.0412 - acc: 0.9890\n",
      "Epoch 23/50\n",
      "638/638 [==============================] - 0s 595us/step - loss: 0.0386 - acc: 0.9890\n",
      "Epoch 24/50\n",
      "638/638 [==============================] - 0s 713us/step - loss: 0.0344 - acc: 0.9890\n",
      "Epoch 25/50\n",
      "638/638 [==============================] - 0s 761us/step - loss: 0.0309 - acc: 0.9890\n",
      "Epoch 26/50\n",
      "638/638 [==============================] - 0s 675us/step - loss: 0.0353 - acc: 0.9890\n",
      "Epoch 27/50\n",
      "638/638 [==============================] - 0s 779us/step - loss: 0.0268 - acc: 0.9890\n",
      "Epoch 28/50\n",
      "638/638 [==============================] - 1s 798us/step - loss: 0.0274 - acc: 0.9890\n",
      "Epoch 29/50\n",
      "638/638 [==============================] - 1s 796us/step - loss: 0.0207 - acc: 0.9890\n",
      "Epoch 30/50\n",
      "638/638 [==============================] - 0s 742us/step - loss: 0.0221 - acc: 0.9906\n",
      "Epoch 31/50\n",
      "638/638 [==============================] - 0s 715us/step - loss: 0.0233 - acc: 0.9922\n",
      "Epoch 32/50\n",
      "638/638 [==============================] - 0s 694us/step - loss: 0.0208 - acc: 0.9922\n",
      "Epoch 33/50\n",
      "638/638 [==============================] - 0s 684us/step - loss: 0.0268 - acc: 0.9922\n",
      "Epoch 34/50\n",
      "638/638 [==============================] - 0s 754us/step - loss: 0.0403 - acc: 0.9922\n",
      "Epoch 35/50\n",
      "638/638 [==============================] - 0s 610us/step - loss: 0.0186 - acc: 0.9937\n",
      "Epoch 36/50\n",
      "638/638 [==============================] - 0s 592us/step - loss: 0.0160 - acc: 0.9953\n",
      "Epoch 37/50\n",
      "638/638 [==============================] - 0s 630us/step - loss: 0.0128 - acc: 0.9984\n",
      "Epoch 38/50\n",
      "638/638 [==============================] - 0s 637us/step - loss: 0.0103 - acc: 0.9984\n",
      "Epoch 39/50\n",
      "638/638 [==============================] - 0s 758us/step - loss: 0.0105 - acc: 0.9969\n",
      "Epoch 40/50\n",
      "638/638 [==============================] - 0s 767us/step - loss: 0.0101 - acc: 0.9984\n",
      "Epoch 41/50\n",
      "638/638 [==============================] - 1s 870us/step - loss: 0.0079 - acc: 0.9984\n",
      "Epoch 42/50\n",
      "638/638 [==============================] - 1s 823us/step - loss: 0.0078 - acc: 0.9984\n",
      "Epoch 43/50\n",
      "638/638 [==============================] - 0s 641us/step - loss: 0.0070 - acc: 0.9984\n",
      "Epoch 44/50\n",
      "638/638 [==============================] - 0s 594us/step - loss: 0.0047 - acc: 0.9984\n",
      "Epoch 45/50\n",
      "638/638 [==============================] - 0s 720us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "638/638 [==============================] - 1s 797us/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "638/638 [==============================] - 0s 651us/step - loss: 0.0070 - acc: 0.9984\n",
      "Epoch 48/50\n",
      "638/638 [==============================] - 1s 919us/step - loss: 0.0045 - acc: 0.9984\n",
      "Epoch 49/50\n",
      "638/638 [==============================] - 1s 966us/step - loss: 0.0048 - acc: 0.9969\n",
      "Epoch 50/50\n",
      "638/638 [==============================] - 1s 921us/step - loss: 0.0023 - acc: 1.0000\n",
      "71/71 [==============================] - 1s 9ms/step\n",
      "Epoch 1/50\n",
      "638/638 [==============================] - 4s 6ms/step - loss: 0.2473 - acc: 0.9875\n",
      "Epoch 2/50\n",
      "638/638 [==============================] - 0s 734us/step - loss: 0.0893 - acc: 0.9875\n",
      "Epoch 3/50\n",
      "638/638 [==============================] - 1s 834us/step - loss: 0.0721 - acc: 0.9875\n",
      "Epoch 4/50\n",
      "638/638 [==============================] - 1s 791us/step - loss: 0.0661 - acc: 0.9875\n",
      "Epoch 5/50\n",
      "638/638 [==============================] - 0s 694us/step - loss: 0.0690 - acc: 0.9875\n",
      "Epoch 6/50\n",
      "638/638 [==============================] - 1s 813us/step - loss: 0.0647 - acc: 0.9875\n",
      "Epoch 7/50\n",
      "638/638 [==============================] - 0s 743us/step - loss: 0.0628 - acc: 0.9875\n",
      "Epoch 8/50\n",
      "638/638 [==============================] - 1s 931us/step - loss: 0.0617 - acc: 0.9875\n",
      "Epoch 9/50\n",
      "638/638 [==============================] - 0s 695us/step - loss: 0.0646 - acc: 0.9875\n",
      "Epoch 10/50\n",
      "638/638 [==============================] - 1s 784us/step - loss: 0.0631 - acc: 0.9875\n",
      "Epoch 11/50\n",
      "638/638 [==============================] - 0s 705us/step - loss: 0.0585 - acc: 0.9875\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638/638 [==============================] - 0s 753us/step - loss: 0.0555 - acc: 0.9875\n",
      "Epoch 13/50\n",
      "638/638 [==============================] - 1s 851us/step - loss: 0.0540 - acc: 0.9875\n",
      "Epoch 14/50\n",
      "638/638 [==============================] - 0s 714us/step - loss: 0.0510 - acc: 0.9875\n",
      "Epoch 15/50\n",
      "638/638 [==============================] - 1s 850us/step - loss: 0.0508 - acc: 0.9875\n",
      "Epoch 16/50\n",
      "638/638 [==============================] - 1s 809us/step - loss: 0.0504 - acc: 0.9875\n",
      "Epoch 17/50\n",
      "638/638 [==============================] - 1s 785us/step - loss: 0.0452 - acc: 0.9875\n",
      "Epoch 18/50\n",
      "638/638 [==============================] - 1s 803us/step - loss: 0.0450 - acc: 0.9875\n",
      "Epoch 19/50\n",
      "638/638 [==============================] - 1s 856us/step - loss: 0.0414 - acc: 0.9875\n",
      "Epoch 20/50\n",
      "638/638 [==============================] - 0s 680us/step - loss: 0.0370 - acc: 0.9875\n",
      "Epoch 21/50\n",
      "638/638 [==============================] - 0s 624us/step - loss: 0.0376 - acc: 0.9875\n",
      "Epoch 22/50\n",
      "638/638 [==============================] - 0s 661us/step - loss: 0.0306 - acc: 0.9890\n",
      "Epoch 23/50\n",
      "638/638 [==============================] - 0s 487us/step - loss: 0.0281 - acc: 0.9890\n",
      "Epoch 24/50\n",
      "638/638 [==============================] - 0s 746us/step - loss: 0.0279 - acc: 0.9890\n",
      "Epoch 25/50\n",
      "638/638 [==============================] - 0s 670us/step - loss: 0.0234 - acc: 0.9890\n",
      "Epoch 26/50\n",
      "638/638 [==============================] - 0s 550us/step - loss: 0.0247 - acc: 0.9906\n",
      "Epoch 27/50\n",
      "638/638 [==============================] - 0s 764us/step - loss: 0.0264 - acc: 0.9937\n",
      "Epoch 28/50\n",
      "638/638 [==============================] - 1s 820us/step - loss: 0.0266 - acc: 0.9937\n",
      "Epoch 29/50\n",
      "638/638 [==============================] - 0s 765us/step - loss: 0.0226 - acc: 0.9937\n",
      "Epoch 30/50\n",
      "638/638 [==============================] - 1s 992us/step - loss: 0.0138 - acc: 0.9937\n",
      "Epoch 31/50\n",
      "638/638 [==============================] - 1s 845us/step - loss: 0.0102 - acc: 0.9969\n",
      "Epoch 32/50\n",
      "638/638 [==============================] - 0s 741us/step - loss: 0.0093 - acc: 0.9969\n",
      "Epoch 33/50\n",
      "638/638 [==============================] - 0s 611us/step - loss: 0.0071 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "638/638 [==============================] - 0s 782us/step - loss: 0.0058 - acc: 0.9984\n",
      "Epoch 35/50\n",
      "638/638 [==============================] - 0s 766us/step - loss: 0.0120 - acc: 0.9969\n",
      "Epoch 36/50\n",
      "638/638 [==============================] - 1s 790us/step - loss: 0.0071 - acc: 0.9984\n",
      "Epoch 37/50\n",
      "638/638 [==============================] - 0s 552us/step - loss: 0.0044 - acc: 0.9984\n",
      "Epoch 38/50\n",
      "638/638 [==============================] - 0s 684us/step - loss: 0.0100 - acc: 0.9937\n",
      "Epoch 39/50\n",
      "638/638 [==============================] - 0s 669us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "638/638 [==============================] - 0s 503us/step - loss: 0.0037 - acc: 0.9984\n",
      "Epoch 41/50\n",
      "638/638 [==============================] - 0s 747us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "638/638 [==============================] - 0s 621us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "638/638 [==============================] - 0s 576us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "638/638 [==============================] - 0s 569us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "638/638 [==============================] - 0s 652us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "638/638 [==============================] - 0s 564us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "638/638 [==============================] - 0s 576us/step - loss: 0.0019 - acc: 1.0000ETA: 0s - loss: 0.0018 - acc: 1.0000 \n",
      "Epoch 48/50\n",
      "638/638 [==============================] - 0s 575us/step - loss: 0.0093 - acc: 0.9953\n",
      "Epoch 49/50\n",
      "638/638 [==============================] - 0s 574us/step - loss: 0.0318 - acc: 0.9906\n",
      "Epoch 50/50\n",
      "638/638 [==============================] - 0s 569us/step - loss: 0.0547 - acc: 0.9890\n",
      "71/71 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "639/639 [==============================] - 5s 8ms/step - loss: 0.2760 - acc: 0.9390\n",
      "Epoch 2/50\n",
      "639/639 [==============================] - 1s 815us/step - loss: 0.0748 - acc: 0.9890\n",
      "Epoch 3/50\n",
      "639/639 [==============================] - 1s 884us/step - loss: 0.0652 - acc: 0.9890\n",
      "Epoch 4/50\n",
      "639/639 [==============================] - 0s 723us/step - loss: 0.0593 - acc: 0.9890\n",
      "Epoch 5/50\n",
      "639/639 [==============================] - 1s 815us/step - loss: 0.0603 - acc: 0.9890\n",
      "Epoch 6/50\n",
      "639/639 [==============================] - 1s 1ms/step - loss: 0.0589 - acc: 0.9890A: 0s - loss: 0.0319 - acc: 0.9\n",
      "Epoch 7/50\n",
      "639/639 [==============================] - 1s 945us/step - loss: 0.0574 - acc: 0.9890\n",
      "Epoch 8/50\n",
      "639/639 [==============================] - 0s 747us/step - loss: 0.0563 - acc: 0.9890\n",
      "Epoch 9/50\n",
      "639/639 [==============================] - 0s 478us/step - loss: 0.0545 - acc: 0.9890\n",
      "Epoch 10/50\n",
      "639/639 [==============================] - 0s 684us/step - loss: 0.0540 - acc: 0.9890\n",
      "Epoch 11/50\n",
      "639/639 [==============================] - 1s 868us/step - loss: 0.0569 - acc: 0.9890\n",
      "Epoch 12/50\n",
      "639/639 [==============================] - 1s 895us/step - loss: 0.0551 - acc: 0.9890\n",
      "Epoch 13/50\n",
      "639/639 [==============================] - 1s 948us/step - loss: 0.0537 - acc: 0.9890\n",
      "Epoch 14/50\n",
      "639/639 [==============================] - 1s 879us/step - loss: 0.0491 - acc: 0.9890\n",
      "Epoch 15/50\n",
      "639/639 [==============================] - 0s 680us/step - loss: 0.0473 - acc: 0.9890\n",
      "Epoch 16/50\n",
      "639/639 [==============================] - 0s 768us/step - loss: 0.0511 - acc: 0.9890\n",
      "Epoch 17/50\n",
      "639/639 [==============================] - 1s 800us/step - loss: 0.0447 - acc: 0.9890\n",
      "Epoch 18/50\n",
      "639/639 [==============================] - 1s 906us/step - loss: 0.0445 - acc: 0.9890\n",
      "Epoch 19/50\n",
      "639/639 [==============================] - 1s 848us/step - loss: 0.0406 - acc: 0.9890\n",
      "Epoch 20/50\n",
      "639/639 [==============================] - 0s 777us/step - loss: 0.0413 - acc: 0.9890\n",
      "Epoch 21/50\n",
      "639/639 [==============================] - 1s 868us/step - loss: 0.0381 - acc: 0.9890\n",
      "Epoch 22/50\n",
      "639/639 [==============================] - 1s 837us/step - loss: 0.0342 - acc: 0.9890\n",
      "Epoch 23/50\n",
      "639/639 [==============================] - 1s 789us/step - loss: 0.0433 - acc: 0.9890\n",
      "Epoch 24/50\n",
      "639/639 [==============================] - 1s 795us/step - loss: 0.0313 - acc: 0.9890\n",
      "Epoch 25/50\n",
      "639/639 [==============================] - 0s 768us/step - loss: 0.0288 - acc: 0.9890\n",
      "Epoch 26/50\n",
      "639/639 [==============================] - 1s 864us/step - loss: 0.0264 - acc: 0.9890\n",
      "Epoch 27/50\n",
      "639/639 [==============================] - 0s 774us/step - loss: 0.0244 - acc: 0.9906\n",
      "Epoch 28/50\n",
      "639/639 [==============================] - 1s 790us/step - loss: 0.0263 - acc: 0.9906\n",
      "Epoch 29/50\n",
      "639/639 [==============================] - 1s 840us/step - loss: 0.0271 - acc: 0.9937\n",
      "Epoch 30/50\n",
      "639/639 [==============================] - 0s 704us/step - loss: 0.0189 - acc: 0.9922\n",
      "Epoch 31/50\n",
      "639/639 [==============================] - 1s 869us/step - loss: 0.0298 - acc: 0.9906\n",
      "Epoch 32/50\n",
      "639/639 [==============================] - 1s 813us/step - loss: 0.0268 - acc: 0.9937\n",
      "Epoch 33/50\n",
      "639/639 [==============================] - ETA: 0s - loss: 0.0165 - acc: 0.993 - 1s 929us/step - loss: 0.0157 - acc: 0.9937\n",
      "Epoch 34/50\n",
      "639/639 [==============================] - 1s 932us/step - loss: 0.0141 - acc: 0.9937\n",
      "Epoch 35/50\n",
      "639/639 [==============================] - 1s 801us/step - loss: 0.0106 - acc: 0.9969\n",
      "Epoch 36/50\n",
      "639/639 [==============================] - 0s 757us/step - loss: 0.0137 - acc: 0.9953\n",
      "Epoch 37/50\n",
      "639/639 [==============================] - 1s 957us/step - loss: 0.0119 - acc: 0.9953\n",
      "Epoch 38/50\n",
      "639/639 [==============================] - 1s 889us/step - loss: 0.0082 - acc: 0.9984\n",
      "Epoch 39/50\n",
      "639/639 [==============================] - 0s 716us/step - loss: 0.0093 - acc: 0.9969\n",
      "Epoch 40/50\n",
      "639/639 [==============================] - 0s 616us/step - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "639/639 [==============================] - 1s 793us/step - loss: 0.0067 - acc: 0.9969\n",
      "Epoch 42/50\n",
      "639/639 [==============================] - 1s 843us/step - loss: 0.0075 - acc: 0.9969\n",
      "Epoch 43/50\n",
      "639/639 [==============================] - 1s 819us/step - loss: 0.0058 - acc: 0.9984\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "639/639 [==============================] - 1s 891us/step - loss: 0.0060 - acc: 0.9984\n",
      "Epoch 45/50\n",
      "639/639 [==============================] - 1s 881us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "639/639 [==============================] - 0s 755us/step - loss: 0.0026 - acc: 0.9984\n",
      "Epoch 47/50\n",
      "639/639 [==============================] - 1s 930us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "639/639 [==============================] - 1s 824us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "639/639 [==============================] - 1s 946us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "639/639 [==============================] - 1s 804us/step - loss: 0.0019 - acc: 1.0000\n",
      "70/70 [==============================] - 1s 11ms/step\n",
      "Accuracy mean: 0.998591549296\n",
      "Accuracy variance: 0.00422535211268\n",
      "(' Time ', '294.841', ' seconds')\n",
      "[[299   0]\n",
      " [  0   5]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00       299\n",
      "        1.0       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       1.00      1.00      1.00       304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# estimators \n",
    "# Evaluating the ANN\n",
    "t0 = time()\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 1024, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n",
    "    classifier.add(Dense(units = 512, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 50)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of DecisionTreeClassifier = 100.000000 %\n",
      "(' Time ', '0.004', ' seconds')\n",
      "[[299   0]\n",
      " [  0   5]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00       299\n",
      "        1.0       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       1.00      1.00      1.00       304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of DecisionTreeClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of RandomForestClassifier = 100.000000 %\n",
      "(' Time ', '1.628', ' seconds')\n",
      "[[299   0]\n",
      " [  0   5]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00       299\n",
      "        1.0       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       1.00      1.00      1.00       304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of RandomForestClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of ExtraTreesClassifier = 100.000000 %\n",
      "(' Time ', '2.808', ' seconds')\n",
      "[[299   0]\n",
      " [  0   5]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00       299\n",
      "        1.0       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       1.00      1.00      1.00       304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of ExtraTreesClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of AdaBoostClassifier = 100.000000 %\n",
      "(' Time ', '0.049', ' seconds')\n",
      "[[299   0]\n",
      " [  0   5]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00       299\n",
      "        1.0       1.00      1.00      1.00         5\n",
      "\n",
      "avg / total       1.00      1.00      1.00       304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of AdaBoostClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Naive_bayes  GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GaussianNB = 82.565789 %\n",
      "(' Time ', '0.052', ' seconds')\n",
      "[[246  53]\n",
      " [  0   5]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.82      0.90       299\n",
      "        1.0       0.09      1.00      0.16         5\n",
      "\n",
      "avg / total       0.98      0.83      0.89       304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred= gnb.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of GaussianNB = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
