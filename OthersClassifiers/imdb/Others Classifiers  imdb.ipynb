{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt \n",
    "from pprint import pprint\n",
    "from numpy import array\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GcForeest\n",
    "import argparse\n",
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "sys.path.insert(0, \"lib\")\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.utils.config_utils import load_json\n",
    "config = load_json(\"./examples/imbd.json\")  \n",
    "gc = GCForest(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of class\n",
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 18:35:46,775][cascade_classifier.fit_transform] X_groups_train.shape=[(25000, 500)],y_train.shape=(25000,),X_groups_test.shape=[(25000, 500)],y_test.shape=(25000,)\n",
      "[ 2018-07-31 18:35:46,803][cascade_classifier.fit_transform] group_dims=[500]\n",
      "[ 2018-07-31 18:35:46,804][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-31 18:35:46,805][cascade_classifier.fit_transform] group_ends=[500]\n",
      "[ 2018-07-31 18:35:46,806][cascade_classifier.fit_transform] X_train.shape=(25000, 500),X_test.shape=(25000, 500)\n",
      "[ 2018-07-31 18:35:46,874][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(25000, 500), X_cur_test.shape=(25000, 500)\n",
      "[ 2018-07-31 18:35:52,057][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=52.28%\n",
      "[ 2018-07-31 18:35:57,337][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=54.40%\n",
      "[ 2018-07-31 18:36:02,606][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=53.44%\n",
      "[ 2018-07-31 18:36:10,437][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=53.64%\n",
      "[ 2018-07-31 18:36:16,851][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=52.88%\n",
      "[ 2018-07-31 18:36:22,265][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=55.08%\n",
      "[ 2018-07-31 18:36:27,674][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=52.68%\n",
      "[ 2018-07-31 18:36:33,080][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=52.64%\n",
      "[ 2018-07-31 18:36:38,478][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=53.36%\n",
      "[ 2018-07-31 18:36:43,723][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=53.72%\n",
      "[ 2018-07-31 18:36:43,966][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=53.41%\n",
      "[ 2018-07-31 18:36:43,968][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=54.98%\n",
      "[ 2018-07-31 18:36:48,423][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_0.predict)=53.20%\n",
      "[ 2018-07-31 18:36:52,968][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_1.predict)=52.68%\n",
      "[ 2018-07-31 18:36:57,557][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_2.predict)=51.92%\n",
      "[ 2018-07-31 18:37:02,013][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_3.predict)=52.32%\n",
      "[ 2018-07-31 18:37:06,793][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_4.predict)=50.92%\n",
      "[ 2018-07-31 18:37:12,103][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_5.predict)=52.28%\n",
      "[ 2018-07-31 18:37:17,089][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_6.predict)=53.32%\n",
      "[ 2018-07-31 18:37:21,598][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_7.predict)=51.80%\n",
      "[ 2018-07-31 18:37:26,165][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_8.predict)=52.68%\n",
      "[ 2018-07-31 18:37:30,551][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_9.predict)=52.48%\n",
      "[ 2018-07-31 18:37:30,909][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_cv.predict)=52.36%\n",
      "[ 2018-07-31 18:37:30,911][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.test.predict)=52.48%\n",
      "[ 2018-07-31 18:38:02,401][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_0.predict)=49.40%\n",
      "[ 2018-07-31 18:38:29,222][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_1.predict)=50.00%\n",
      "[ 2018-07-31 18:38:59,117][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_2.predict)=52.12%\n",
      "[ 2018-07-31 18:39:28,412][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_3.predict)=50.64%\n",
      "[ 2018-07-31 18:40:02,787][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_4.predict)=51.44%\n",
      "[ 2018-07-31 18:40:27,822][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_5.predict)=50.56%\n",
      "[ 2018-07-31 18:40:55,866][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_6.predict)=50.76%\n",
      "[ 2018-07-31 18:41:23,163][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_7.predict)=51.24%\n",
      "[ 2018-07-31 18:41:56,005][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_8.predict)=50.68%\n",
      "[ 2018-07-31 18:42:27,394][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_9.predict)=49.64%\n",
      "[ 2018-07-31 18:42:27,413][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_cv.predict)=50.65%\n",
      "[ 2018-07-31 18:42:27,416][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.test.predict)=50.84%\n",
      "[ 2018-07-31 18:42:27,419][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=52.93%\n",
      "[ 2018-07-31 18:42:27,420][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=52.88%\n",
      "[ 2018-07-31 18:42:27,506][cascade_classifier.fit_transform] [layer=1] look_indexs=[0], X_cur_train.shape=(25000, 506), X_cur_test.shape=(25000, 506)\n",
      "[ 2018-07-31 18:42:34,018][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_0.predict)=53.00%\n",
      "[ 2018-07-31 18:42:41,264][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_1.predict)=53.84%\n",
      "[ 2018-07-31 18:42:47,615][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_2.predict)=52.76%\n",
      "[ 2018-07-31 18:42:53,183][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_3.predict)=54.04%\n",
      "[ 2018-07-31 18:42:58,662][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_4.predict)=53.64%\n",
      "[ 2018-07-31 18:43:04,165][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_5.predict)=55.28%\n",
      "[ 2018-07-31 18:43:10,087][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_6.predict)=54.24%\n",
      "[ 2018-07-31 18:43:16,673][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_7.predict)=54.64%\n",
      "[ 2018-07-31 18:43:22,292][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_8.predict)=54.12%\n",
      "[ 2018-07-31 18:43:27,871][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_9.predict)=54.20%\n",
      "[ 2018-07-31 18:43:28,241][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_cv.predict)=53.98%\n",
      "[ 2018-07-31 18:43:28,243][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.test.predict)=54.60%\n",
      "[ 2018-07-31 18:43:32,882][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_0.predict)=51.84%\n",
      "[ 2018-07-31 18:43:37,649][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_1.predict)=53.40%\n",
      "[ 2018-07-31 18:43:42,206][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_2.predict)=50.96%\n",
      "[ 2018-07-31 18:43:46,962][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_3.predict)=54.80%\n",
      "[ 2018-07-31 18:43:51,516][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_4.predict)=51.60%\n",
      "[ 2018-07-31 18:43:56,291][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_5.predict)=55.40%\n",
      "[ 2018-07-31 18:44:00,936][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_6.predict)=52.80%\n",
      "[ 2018-07-31 18:44:05,989][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_7.predict)=52.96%\n",
      "[ 2018-07-31 18:44:11,238][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_8.predict)=51.28%\n",
      "[ 2018-07-31 18:44:16,685][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_9.predict)=53.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 18:44:17,159][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_cv.predict)=52.84%\n",
      "[ 2018-07-31 18:44:17,160][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.test.predict)=53.50%\n",
      "[ 2018-07-31 18:44:58,439][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_0.predict)=58.72%\n",
      "[ 2018-07-31 18:45:42,094][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_1.predict)=58.60%\n",
      "[ 2018-07-31 18:46:22,934][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_2.predict)=57.28%\n",
      "[ 2018-07-31 18:47:04,062][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_3.predict)=55.48%\n",
      "[ 2018-07-31 18:47:46,291][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_4.predict)=54.24%\n",
      "[ 2018-07-31 18:48:26,267][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_5.predict)=53.40%\n",
      "[ 2018-07-31 18:49:05,168][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_6.predict)=55.36%\n",
      "[ 2018-07-31 18:49:46,110][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_7.predict)=56.52%\n",
      "[ 2018-07-31 18:50:27,160][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_8.predict)=53.92%\n",
      "[ 2018-07-31 18:51:09,254][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_9.predict)=53.28%\n",
      "[ 2018-07-31 18:51:09,271][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_cv.predict)=55.68%\n",
      "[ 2018-07-31 18:51:09,273][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.test.predict)=52.46%\n",
      "[ 2018-07-31 18:51:09,275][cascade_classifier.calc_accuracy] Accuracy(layer_1 - train.classifier_average)=55.81%\n",
      "[ 2018-07-31 18:51:09,277][cascade_classifier.calc_accuracy] Accuracy(layer_1 - test.classifier_average)=53.52%\n",
      "[ 2018-07-31 18:51:09,360][cascade_classifier.fit_transform] [layer=2] look_indexs=[0], X_cur_train.shape=(25000, 506), X_cur_test.shape=(25000, 506)\n",
      "[ 2018-07-31 18:51:14,399][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_0.predict)=55.28%\n",
      "[ 2018-07-31 18:51:21,595][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_1.predict)=54.36%\n",
      "[ 2018-07-31 18:51:27,189][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_2.predict)=53.92%\n",
      "[ 2018-07-31 18:51:32,566][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_3.predict)=56.00%\n",
      "[ 2018-07-31 18:51:38,053][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_4.predict)=55.56%\n",
      "[ 2018-07-31 18:51:45,037][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_5.predict)=54.48%\n",
      "[ 2018-07-31 18:51:50,511][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_6.predict)=54.20%\n",
      "[ 2018-07-31 18:51:55,910][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_7.predict)=53.68%\n",
      "[ 2018-07-31 18:52:01,290][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_8.predict)=55.24%\n",
      "[ 2018-07-31 18:52:08,362][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_9.predict)=55.28%\n",
      "[ 2018-07-31 18:52:08,826][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_cv.predict)=54.80%\n",
      "[ 2018-07-31 18:52:08,828][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.test.predict)=54.24%\n",
      "[ 2018-07-31 18:52:13,175][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_0.predict)=54.28%\n",
      "[ 2018-07-31 18:52:17,969][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_1.predict)=51.48%\n",
      "[ 2018-07-31 18:52:22,928][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_2.predict)=53.28%\n",
      "[ 2018-07-31 18:52:30,125][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_3.predict)=53.60%\n",
      "[ 2018-07-31 18:52:36,469][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_4.predict)=53.84%\n",
      "[ 2018-07-31 18:52:42,631][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_5.predict)=55.24%\n",
      "[ 2018-07-31 18:52:47,181][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_6.predict)=54.44%\n",
      "[ 2018-07-31 18:52:51,846][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_7.predict)=53.36%\n",
      "[ 2018-07-31 18:52:56,417][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_8.predict)=54.00%\n",
      "[ 2018-07-31 18:53:01,053][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_9.predict)=52.48%\n",
      "[ 2018-07-31 18:53:01,417][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_cv.predict)=53.60%\n",
      "[ 2018-07-31 18:53:01,418][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.test.predict)=53.11%\n",
      "[ 2018-07-31 18:53:37,632][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_0.predict)=52.24%\n",
      "[ 2018-07-31 18:54:15,097][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_1.predict)=52.04%\n",
      "[ 2018-07-31 18:54:54,571][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_2.predict)=51.88%\n",
      "[ 2018-07-31 18:55:34,775][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_3.predict)=51.64%\n",
      "[ 2018-07-31 18:56:08,554][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_4.predict)=51.24%\n",
      "[ 2018-07-31 18:56:48,682][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_5.predict)=53.64%\n",
      "[ 2018-07-31 18:57:31,716][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_6.predict)=52.28%\n",
      "[ 2018-07-31 18:58:06,807][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_7.predict)=53.12%\n",
      "[ 2018-07-31 18:58:40,788][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_8.predict)=53.52%\n",
      "[ 2018-07-31 18:59:15,443][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_9.predict)=52.36%\n",
      "[ 2018-07-31 18:59:15,460][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_cv.predict)=52.40%\n",
      "[ 2018-07-31 18:59:15,461][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.test.predict)=52.50%\n",
      "[ 2018-07-31 18:59:15,463][cascade_classifier.calc_accuracy] Accuracy(layer_2 - train.classifier_average)=54.16%\n",
      "[ 2018-07-31 18:59:15,465][cascade_classifier.calc_accuracy] Accuracy(layer_2 - test.classifier_average)=53.16%\n",
      "[ 2018-07-31 18:59:15,545][cascade_classifier.fit_transform] [layer=3] look_indexs=[0], X_cur_train.shape=(25000, 506), X_cur_test.shape=(25000, 506)\n",
      "[ 2018-07-31 18:59:20,561][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_0.predict)=54.44%\n",
      "[ 2018-07-31 18:59:25,970][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_1.predict)=52.60%\n",
      "[ 2018-07-31 18:59:31,337][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_2.predict)=53.32%\n",
      "[ 2018-07-31 18:59:36,819][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_3.predict)=54.32%\n",
      "[ 2018-07-31 18:59:42,191][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_4.predict)=55.08%\n",
      "[ 2018-07-31 18:59:47,658][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_5.predict)=53.80%\n",
      "[ 2018-07-31 18:59:53,131][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_6.predict)=54.56%\n",
      "[ 2018-07-31 18:59:58,625][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_7.predict)=53.04%\n",
      "[ 2018-07-31 19:00:04,514][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_8.predict)=53.32%\n",
      "[ 2018-07-31 19:00:12,016][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_9.predict)=51.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 19:00:12,371][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_cv.predict)=53.55%\n",
      "[ 2018-07-31 19:00:12,373][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.test.predict)=54.95%\n",
      "[ 2018-07-31 19:00:17,540][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_0.predict)=52.64%\n",
      "[ 2018-07-31 19:00:22,912][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_1.predict)=50.92%\n",
      "[ 2018-07-31 19:00:27,562][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_2.predict)=54.24%\n",
      "[ 2018-07-31 19:00:32,546][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_3.predict)=53.00%\n",
      "[ 2018-07-31 19:00:37,491][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_4.predict)=53.48%\n",
      "[ 2018-07-31 19:00:45,480][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_5.predict)=54.04%\n",
      "[ 2018-07-31 19:00:51,542][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_6.predict)=53.76%\n",
      "[ 2018-07-31 19:00:56,387][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_7.predict)=52.12%\n",
      "[ 2018-07-31 19:01:01,174][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_8.predict)=51.64%\n",
      "[ 2018-07-31 19:01:06,238][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_9.predict)=54.16%\n",
      "[ 2018-07-31 19:01:06,688][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_cv.predict)=53.00%\n",
      "[ 2018-07-31 19:01:06,691][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.test.predict)=53.59%\n",
      "[ 2018-07-31 19:01:48,632][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_0.predict)=52.32%\n",
      "[ 2018-07-31 19:02:30,533][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_1.predict)=54.40%\n",
      "[ 2018-07-31 19:03:14,643][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_2.predict)=55.48%\n",
      "[ 2018-07-31 19:03:56,122][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_3.predict)=54.12%\n",
      "[ 2018-07-31 19:04:36,003][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_4.predict)=53.16%\n",
      "[ 2018-07-31 19:05:17,528][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_5.predict)=54.56%\n",
      "[ 2018-07-31 19:05:59,378][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_6.predict)=56.40%\n",
      "[ 2018-07-31 19:06:41,545][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_7.predict)=54.72%\n",
      "[ 2018-07-31 19:07:22,460][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_8.predict)=55.16%\n",
      "[ 2018-07-31 19:08:04,821][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_9.predict)=58.00%\n",
      "[ 2018-07-31 19:08:04,838][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_cv.predict)=54.83%\n",
      "[ 2018-07-31 19:08:04,840][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.test.predict)=51.82%\n",
      "[ 2018-07-31 19:08:04,842][cascade_classifier.calc_accuracy] Accuracy(layer_3 - train.classifier_average)=55.56%\n",
      "[ 2018-07-31 19:08:04,843][cascade_classifier.calc_accuracy] Accuracy(layer_3 - test.classifier_average)=53.26%\n",
      "[ 2018-07-31 19:08:04,926][cascade_classifier.fit_transform] [layer=4] look_indexs=[0], X_cur_train.shape=(25000, 506), X_cur_test.shape=(25000, 506)\n",
      "[ 2018-07-31 19:08:09,973][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_0.predict)=54.32%\n",
      "[ 2018-07-31 19:08:16,063][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_1.predict)=54.04%\n",
      "[ 2018-07-31 19:08:21,849][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_2.predict)=52.56%\n",
      "[ 2018-07-31 19:08:27,222][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_3.predict)=54.00%\n",
      "[ 2018-07-31 19:08:32,469][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_4.predict)=54.96%\n",
      "[ 2018-07-31 19:08:37,847][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_5.predict)=53.48%\n",
      "[ 2018-07-31 19:08:43,100][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_6.predict)=54.92%\n",
      "[ 2018-07-31 19:08:48,491][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_7.predict)=55.80%\n",
      "[ 2018-07-31 19:08:53,872][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_8.predict)=54.24%\n",
      "[ 2018-07-31 19:08:59,243][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_9.predict)=55.36%\n",
      "[ 2018-07-31 19:08:59,490][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_cv.predict)=54.37%\n",
      "[ 2018-07-31 19:08:59,491][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.test.predict)=54.30%\n",
      "[ 2018-07-31 19:09:03,922][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_0.predict)=51.48%\n",
      "[ 2018-07-31 19:09:10,331][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_1.predict)=53.56%\n",
      "[ 2018-07-31 19:09:15,707][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_2.predict)=53.36%\n",
      "[ 2018-07-31 19:09:20,993][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_3.predict)=53.36%\n",
      "[ 2018-07-31 19:09:25,555][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_4.predict)=50.72%\n",
      "[ 2018-07-31 19:09:30,092][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_5.predict)=54.24%\n",
      "[ 2018-07-31 19:09:34,863][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_6.predict)=53.32%\n",
      "[ 2018-07-31 19:09:39,636][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_7.predict)=54.48%\n",
      "[ 2018-07-31 19:09:44,435][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_8.predict)=51.76%\n",
      "[ 2018-07-31 19:09:48,997][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_9.predict)=53.24%\n",
      "[ 2018-07-31 19:09:49,354][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_cv.predict)=52.95%\n",
      "[ 2018-07-31 19:09:49,356][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.test.predict)=52.99%\n",
      "[ 2018-07-31 19:10:30,321][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_0.predict)=51.88%\n",
      "[ 2018-07-31 19:11:01,009][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_1.predict)=52.04%\n",
      "[ 2018-07-31 19:11:33,799][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_2.predict)=52.88%\n",
      "[ 2018-07-31 19:12:14,075][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_3.predict)=51.00%\n",
      "[ 2018-07-31 19:12:43,788][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_4.predict)=52.40%\n",
      "[ 2018-07-31 19:13:20,152][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_5.predict)=52.76%\n",
      "[ 2018-07-31 19:13:57,454][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_6.predict)=52.04%\n",
      "[ 2018-07-31 19:14:37,750][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_7.predict)=51.80%\n",
      "[ 2018-07-31 19:15:11,857][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_8.predict)=50.00%\n",
      "[ 2018-07-31 19:15:50,995][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_9.predict)=52.48%\n",
      "[ 2018-07-31 19:15:51,014][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_cv.predict)=51.93%\n",
      "[ 2018-07-31 19:15:51,015][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.test.predict)=52.59%\n",
      "[ 2018-07-31 19:15:51,017][cascade_classifier.calc_accuracy] Accuracy(layer_4 - train.classifier_average)=53.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 19:15:51,019][cascade_classifier.calc_accuracy] Accuracy(layer_4 - test.classifier_average)=53.42%\n",
      "[ 2018-07-31 19:15:51,020][cascade_classifier.fit_transform] [Result][Optimal Level Detected] opt_layer_num=2, accuracy_train=55.81%, accuracy_test=53.52%\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "# X_enc is the concatenated predict_proba result of each estimators of the last layer of the GCForest model\n",
    "    # X_enc.shape =\n",
    "    #   (n_datas, n_estimators * n_classes): If cascade is provided\n",
    "    #   (n_datas, n_estimators * n_classes, dimX, dimY): If only finegrained part is provided\n",
    "    # You can also pass X_test, y_test to fit_transform method, then the accracy on test data will be logged when training.\n",
    "X_train_enc, X_test_enc = gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test)\n",
    "    # WARNING: if you set gc.set_keep_model_in_mem(True), you would have to use\n",
    "    # gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test) to evaluate your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 19:15:51,198][cascade_classifier.transform] X_groups_test.shape=[(25000, 500)]\n",
      "[ 2018-07-31 19:15:51,206][cascade_classifier.transform] group_dims=[500]\n",
      "[ 2018-07-31 19:15:51,207][cascade_classifier.transform] X_test.shape=(25000, 500)\n",
      "[ 2018-07-31 19:15:51,240][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(25000, 500)\n",
      "[ 2018-07-31 19:15:57,806][cascade_classifier.transform] [layer=1] look_indexs=[0], X_cur_test.shape=(25000, 506)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GCForest = 53.524000 %\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "y_pred = gc.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy of GCForest = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' Time ', '2417.736', ' seconds')\n",
      "[[7094 5406]\n",
      " [6213 6287]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.57      0.55     12500\n",
      "          1       0.54      0.50      0.52     12500\n",
      "\n",
      "avg / total       0.54      0.54      0.53     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "22500/22500 [==============================] - 6s 280us/step - loss: 8.0346 - acc: 0.5014\n",
      "Epoch 2/50\n",
      "22500/22500 [==============================] - 7s 291us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 3/50\n",
      "22500/22500 [==============================] - 6s 267us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 4/50\n",
      "22500/22500 [==============================] - 6s 259us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 5/50\n",
      "22500/22500 [==============================] - 6s 261us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 6/50\n",
      "22500/22500 [==============================] - 6s 260us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 7/50\n",
      "22500/22500 [==============================] - 6s 260us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 8/50\n",
      "22500/22500 [==============================] - 6s 260us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 9/50\n",
      "22500/22500 [==============================] - 6s 261us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 10/50\n",
      "22500/22500 [==============================] - 6s 273us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 11/50\n",
      "22500/22500 [==============================] - 6s 267us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 12/50\n",
      "22500/22500 [==============================] - 7s 291us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 13/50\n",
      "22500/22500 [==============================] - 6s 270us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 14/50\n",
      "22500/22500 [==============================] - 6s 261us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 15/50\n",
      "22500/22500 [==============================] - 6s 263us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 16/50\n",
      "22500/22500 [==============================] - 6s 264us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 17/50\n",
      "22500/22500 [==============================] - 6s 263us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 18/50\n",
      "22500/22500 [==============================] - 6s 263us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 19/50\n",
      "22500/22500 [==============================] - 6s 263us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 20/50\n",
      "22500/22500 [==============================] - 8s 335us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 21/50\n",
      "22500/22500 [==============================] - 7s 301us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 22/50\n",
      "22500/22500 [==============================] - 7s 290us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 23/50\n",
      "22500/22500 [==============================] - 6s 263us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 24/50\n",
      "22500/22500 [==============================] - 6s 266us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 25/50\n",
      "22500/22500 [==============================] - 6s 265us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 26/50\n",
      "22500/22500 [==============================] - 6s 263us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 27/50\n",
      "22500/22500 [==============================] - 6s 266us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 28/50\n",
      "22500/22500 [==============================] - 6s 264us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 29/50\n",
      "22500/22500 [==============================] - 6s 269us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 30/50\n",
      "22500/22500 [==============================] - 6s 271us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 31/50\n",
      "22500/22500 [==============================] - 6s 275us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 32/50\n",
      "22500/22500 [==============================] - 6s 286us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 33/50\n",
      "22500/22500 [==============================] - 6s 260us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 34/50\n",
      "22500/22500 [==============================] - 6s 264us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 35/50\n",
      "22500/22500 [==============================] - 6s 264us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 36/50\n",
      "22500/22500 [==============================] - 6s 267us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 37/50\n",
      "22500/22500 [==============================] - 6s 265us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 38/50\n",
      "22500/22500 [==============================] - 6s 262us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 39/50\n",
      "22500/22500 [==============================] - 6s 270us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 40/50\n",
      "22500/22500 [==============================] - 6s 268us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 41/50\n",
      "22500/22500 [==============================] - 6s 282us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 42/50\n",
      "22500/22500 [==============================] - 6s 285us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 43/50\n",
      "22500/22500 [==============================] - 6s 270us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 44/50\n",
      "22500/22500 [==============================] - 6s 266us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 45/50\n",
      "22500/22500 [==============================] - 6s 265us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 46/50\n",
      "22500/22500 [==============================] - 6s 267us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 47/50\n",
      "22500/22500 [==============================] - 6s 266us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 48/50\n",
      "22500/22500 [==============================] - 6s 267us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 49/50\n",
      "22500/22500 [==============================] - 6s 286us/step - loss: 8.0354 - acc: 0.5015\n",
      "Epoch 50/50\n",
      "22500/22500 [==============================] - 8s 345us/step - loss: 8.0354 - acc: 0.5015\n",
      "2500/2500 [==============================] - 0s 82us/step\n",
      "Epoch 1/50\n",
      "22500/22500 [==============================] - 7s 321us/step - loss: 8.0458 - acc: 0.5008\n",
      "Epoch 2/50\n",
      "22500/22500 [==============================] - 6s 270us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 3/50\n",
      "22500/22500 [==============================] - 6s 269us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 4/50\n",
      "22500/22500 [==============================] - 6s 268us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 5/50\n",
      "22500/22500 [==============================] - 6s 271us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 6/50\n",
      "22500/22500 [==============================] - 6s 269us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 7/50\n",
      "22500/22500 [==============================] - 6s 267us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 8/50\n",
      "22500/22500 [==============================] - 6s 266us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 9/50\n",
      "22500/22500 [==============================] - 6s 271us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 10/50\n",
      "22500/22500 [==============================] - 6s 278us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 11/50\n",
      "22500/22500 [==============================] - 7s 295us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 12/50\n",
      "22500/22500 [==============================] - 6s 266us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 13/50\n",
      "22500/22500 [==============================] - 6s 265us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 14/50\n",
      "22500/22500 [==============================] - 6s 267us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 15/50\n",
      "22500/22500 [==============================] - 6s 264us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 16/50\n",
      "22500/22500 [==============================] - 6s 264us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 17/50\n",
      "22500/22500 [==============================] - 6s 266us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 18/50\n",
      "22500/22500 [==============================] - 6s 271us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 19/50\n",
      "22500/22500 [==============================] - 6s 268us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 20/50\n",
      "22500/22500 [==============================] - 6s 282us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 21/50\n",
      "22500/22500 [==============================] - 7s 293us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 22/50\n",
      "22500/22500 [==============================] - 6s 265us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 23/50\n",
      "22500/22500 [==============================] - 6s 270us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 24/50\n",
      "22500/22500 [==============================] - 6s 270us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 25/50\n",
      "22500/22500 [==============================] - 6s 266us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 26/50\n",
      "22500/22500 [==============================] - 6s 265us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 27/50\n",
      "22500/22500 [==============================] - 6s 266us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 28/50\n",
      "22500/22500 [==============================] - 7s 296us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 29/50\n",
      "22500/22500 [==============================] - 8s 338us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 7s 291us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 31/50\n",
      "22500/22500 [==============================] - 6s 275us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 32/50\n",
      "22500/22500 [==============================] - 6s 270us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 33/50\n",
      "22500/22500 [==============================] - 6s 269us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 34/50\n",
      "22500/22500 [==============================] - 6s 271us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 35/50\n",
      "22500/22500 [==============================] - 6s 268us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 36/50\n",
      "22500/22500 [==============================] - 6s 267us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 37/50\n",
      "22500/22500 [==============================] - 6s 267us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 38/50\n",
      "22500/22500 [==============================] - 6s 276us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 39/50\n",
      "22500/22500 [==============================] - 6s 277us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 40/50\n",
      "22500/22500 [==============================] - 7s 297us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 41/50\n",
      "22500/22500 [==============================] - 6s 270us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 42/50\n",
      "22500/22500 [==============================] - 6s 270us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 43/50\n",
      "22500/22500 [==============================] - 6s 267us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 44/50\n",
      "22500/22500 [==============================] - 6s 265us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 45/50\n",
      "22500/22500 [==============================] - 6s 270us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 46/50\n",
      "22500/22500 [==============================] - 6s 271us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 47/50\n",
      "22500/22500 [==============================] - 6s 272us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 48/50\n",
      "22500/22500 [==============================] - 6s 276us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 49/50\n",
      "22500/22500 [==============================] - 6s 283us/step - loss: 8.0490 - acc: 0.5006\n",
      "Epoch 50/50\n",
      "22500/22500 [==============================] - 7s 293us/step - loss: 8.0490 - acc: 0.5006\n",
      "2500/2500 [==============================] - 0s 80us/step\n",
      "Epoch 1/50\n",
      "22500/22500 [==============================] - 7s 294us/step - loss: 8.0591 - acc: 0.5000\n",
      "Epoch 2/50\n",
      "22500/22500 [==============================] - 6s 271us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 3/50\n",
      "22500/22500 [==============================] - 6s 274us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 4/50\n",
      "22500/22500 [==============================] - 6s 275us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 5/50\n",
      "22500/22500 [==============================] - 6s 271us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 6/50\n",
      "22500/22500 [==============================] - 6s 272us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 7/50\n",
      "22500/22500 [==============================] - 8s 365us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 8/50\n",
      "22500/22500 [==============================] - 7s 293us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 9/50\n",
      "22500/22500 [==============================] - 7s 302us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 10/50\n",
      "22500/22500 [==============================] - 6s 271us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 11/50\n",
      "22500/22500 [==============================] - 6s 272us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 12/50\n",
      "22500/22500 [==============================] - 6s 271us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 13/50\n",
      "22500/22500 [==============================] - 6s 269us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 14/50\n",
      "22500/22500 [==============================] - 6s 272us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 15/50\n",
      "22500/22500 [==============================] - 6s 275us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 16/50\n",
      "22500/22500 [==============================] - 6s 280us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 17/50\n",
      "22500/22500 [==============================] - 6s 276us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 18/50\n",
      "22500/22500 [==============================] - 7s 292us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 19/50\n",
      "22500/22500 [==============================] - 6s 286us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 20/50\n",
      "22500/22500 [==============================] - 6s 272us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 21/50\n",
      "22500/22500 [==============================] - 6s 274us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 22/50\n",
      "22500/22500 [==============================] - 6s 272us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 23/50\n",
      "22500/22500 [==============================] - 6s 273us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 24/50\n",
      "22500/22500 [==============================] - 6s 275us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 25/50\n",
      "22500/22500 [==============================] - 6s 270us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 26/50\n",
      "22500/22500 [==============================] - 6s 281us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 27/50\n",
      "22500/22500 [==============================] - 6s 282us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 28/50\n",
      "22500/22500 [==============================] - 7s 302us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 29/50\n",
      "22500/22500 [==============================] - 6s 276us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 30/50\n",
      "22500/22500 [==============================] - 6s 273us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 31/50\n",
      "22500/22500 [==============================] - 6s 273us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 32/50\n",
      "22500/22500 [==============================] - 6s 270us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 33/50\n",
      "22500/22500 [==============================] - 6s 270us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 34/50\n",
      "22500/22500 [==============================] - 6s 271us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 35/50\n",
      "22500/22500 [==============================] - 6s 282us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 36/50\n",
      "22500/22500 [==============================] - 8s 361us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 37/50\n",
      "22500/22500 [==============================] - 7s 299us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 38/50\n",
      "22500/22500 [==============================] - 6s 289us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 39/50\n",
      "22500/22500 [==============================] - 6s 277us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 40/50\n",
      "22500/22500 [==============================] - 6s 276us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 41/50\n",
      "22500/22500 [==============================] - 6s 276us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 42/50\n",
      "22500/22500 [==============================] - 6s 276us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 43/50\n",
      "22500/22500 [==============================] - 6s 275us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 44/50\n",
      "22500/22500 [==============================] - 6s 274us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 45/50\n",
      "22500/22500 [==============================] - 6s 284us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 46/50\n",
      "22500/22500 [==============================] - 6s 280us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 47/50\n",
      "22500/22500 [==============================] - 7s 305us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 48/50\n",
      "22500/22500 [==============================] - 6s 275us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 49/50\n",
      "22500/22500 [==============================] - 6s 274us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 50/50\n",
      "22500/22500 [==============================] - 6s 272us/step - loss: 8.0583 - acc: 0.5000\n",
      "2500/2500 [==============================] - 0s 86us/step\n",
      "Epoch 1/50\n",
      "22500/22500 [==============================] - 6s 289us/step - loss: 8.0601 - acc: 0.4971\n",
      "Epoch 2/50\n",
      "22500/22500 [==============================] - 6s 272us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 3/50\n",
      "22500/22500 [==============================] - 6s 270us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 4/50\n",
      "22500/22500 [==============================] - 6s 280us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 5/50\n",
      "22500/22500 [==============================] - 6s 280us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 6/50\n",
      "22500/22500 [==============================] - 7s 299us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 7/50\n",
      "22500/22500 [==============================] - 6s 288us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 8/50\n",
      "22500/22500 [==============================] - 6s 268us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 6s 270us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 10/50\n",
      "22500/22500 [==============================] - 6s 275us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 11/50\n",
      "22500/22500 [==============================] - 6s 273us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 12/50\n",
      "22500/22500 [==============================] - 6s 273us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 13/50\n",
      "22500/22500 [==============================] - 6s 274us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 14/50\n",
      "22500/22500 [==============================] - 8s 370us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 15/50\n",
      "22500/22500 [==============================] - 6s 287us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 16/50\n",
      "22500/22500 [==============================] - 7s 297us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 17/50\n",
      "22500/22500 [==============================] - 6s 270us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 18/50\n",
      "22500/22500 [==============================] - 6s 274us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 19/50\n",
      "22500/22500 [==============================] - 6s 275us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 20/50\n",
      "22500/22500 [==============================] - 6s 275us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 21/50\n",
      "22500/22500 [==============================] - 6s 272us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 22/50\n",
      "22500/22500 [==============================] - 6s 271us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 23/50\n",
      "22500/22500 [==============================] - 6s 278us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 24/50\n",
      "22500/22500 [==============================] - 6s 278us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 25/50\n",
      "22500/22500 [==============================] - 7s 298us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 26/50\n",
      "22500/22500 [==============================] - 7s 289us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 27/50\n",
      "22500/22500 [==============================] - 6s 273us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 28/50\n",
      "22500/22500 [==============================] - 6s 275us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 29/50\n",
      "22500/22500 [==============================] - 6s 274us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 30/50\n",
      "22500/22500 [==============================] - 6s 274us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 31/50\n",
      "22500/22500 [==============================] - 6s 273us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 32/50\n",
      "22500/22500 [==============================] - 6s 277us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 33/50\n",
      "22500/22500 [==============================] - 6s 280us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 34/50\n",
      "22500/22500 [==============================] - 6s 283us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 35/50\n",
      "22500/22500 [==============================] - 7s 299us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 36/50\n",
      "22500/22500 [==============================] - 6s 271us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 37/50\n",
      "22500/22500 [==============================] - 6s 274us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 38/50\n",
      "22500/22500 [==============================] - 6s 278us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 39/50\n",
      "22500/22500 [==============================] - 6s 273us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 40/50\n",
      "22500/22500 [==============================] - 6s 273us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 41/50\n",
      "22500/22500 [==============================] - 6s 276us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 42/50\n",
      "22500/22500 [==============================] - 8s 347us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 43/50\n",
      "22500/22500 [==============================] - 7s 306us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 44/50\n",
      "22500/22500 [==============================] - 7s 308us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 45/50\n",
      "22500/22500 [==============================] - 6s 282us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 46/50\n",
      "22500/22500 [==============================] - 6s 273us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 47/50\n",
      "22500/22500 [==============================] - 6s 273us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 48/50\n",
      "22500/22500 [==============================] - 6s 271us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 49/50\n",
      "22500/22500 [==============================] - 6s 274us/step - loss: 7.9754 - acc: 0.4997\n",
      "Epoch 50/50\n",
      "22500/22500 [==============================] - 6s 274us/step - loss: 7.9754 - acc: 0.4997\n",
      "2500/2500 [==============================] - 0s 92us/step\n",
      "Epoch 1/50\n",
      "22500/22500 [==============================] - 7s 294us/step - loss: 7.9828 - acc: 0.4992\n",
      "Epoch 2/50\n",
      "22500/22500 [==============================] - 6s 278us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 3/50\n",
      "22500/22500 [==============================] - 7s 291us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 4/50\n",
      "22500/22500 [==============================] - 6s 288us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 5/50\n",
      "22500/22500 [==============================] - 6s 274us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 6/50\n",
      "22500/22500 [==============================] - 6s 272us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 7/50\n",
      "22500/22500 [==============================] - 6s 274us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 8/50\n",
      "22500/22500 [==============================] - 6s 273us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 9/50\n",
      "22500/22500 [==============================] - 6s 273us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 10/50\n",
      "22500/22500 [==============================] - 6s 272us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 11/50\n",
      "22500/22500 [==============================] - 6s 276us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 12/50\n",
      "22500/22500 [==============================] - 6s 280us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 13/50\n",
      "22500/22500 [==============================] - 7s 299us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 14/50\n",
      "22500/22500 [==============================] - 6s 280us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 15/50\n",
      "22500/22500 [==============================] - 6s 275us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 16/50\n",
      "22500/22500 [==============================] - 6s 270us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 17/50\n",
      "22500/22500 [==============================] - 6s 273us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 18/50\n",
      "22500/22500 [==============================] - 6s 272us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 19/50\n",
      "22500/22500 [==============================] - 6s 273us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 20/50\n",
      "22500/22500 [==============================] - 7s 307us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 21/50\n",
      "22500/22500 [==============================] - 8s 337us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 22/50\n",
      "22500/22500 [==============================] - 7s 296us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 23/50\n",
      "22500/22500 [==============================] - 7s 292us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 24/50\n",
      "22500/22500 [==============================] - 6s 273us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 25/50\n",
      "22500/22500 [==============================] - 6s 275us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 26/50\n",
      "22500/22500 [==============================] - 6s 277us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 27/50\n",
      "22500/22500 [==============================] - 6s 275us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 28/50\n",
      "22500/22500 [==============================] - 6s 273us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 29/50\n",
      "22500/22500 [==============================] - 6s 271us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 30/50\n",
      "22500/22500 [==============================] - 6s 280us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 31/50\n",
      "22500/22500 [==============================] - 6s 288us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 32/50\n",
      "22500/22500 [==============================] - 9s 397us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 33/50\n",
      "22500/22500 [==============================] - 7s 332us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 34/50\n",
      "22500/22500 [==============================] - 6s 275us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 35/50\n",
      "22500/22500 [==============================] - 7s 293us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 36/50\n",
      "22500/22500 [==============================] - 7s 333us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 37/50\n",
      "22500/22500 [==============================] - 6s 274us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 38/50\n",
      "22500/22500 [==============================] - 7s 300us/step - loss: 7.9747 - acc: 0.4998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "22500/22500 [==============================] - 7s 332us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 40/50\n",
      "22500/22500 [==============================] - 6s 285us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 41/50\n",
      "22500/22500 [==============================] - 7s 295us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 42/50\n",
      "22500/22500 [==============================] - 7s 323us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 43/50\n",
      "22500/22500 [==============================] - 6s 275us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 44/50\n",
      "22500/22500 [==============================] - 6s 288us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 45/50\n",
      "22500/22500 [==============================] - 8s 339us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 46/50\n",
      "22500/22500 [==============================] - 6s 276us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 47/50\n",
      "22500/22500 [==============================] - 9s 379us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 48/50\n",
      "22500/22500 [==============================] - 8s 367us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 49/50\n",
      "22500/22500 [==============================] - 6s 278us/step - loss: 7.9747 - acc: 0.4998\n",
      "Epoch 50/50\n",
      "22500/22500 [==============================] - 7s 331us/step - loss: 7.9747 - acc: 0.4998\n",
      "2500/2500 [==============================] - 0s 196us/step\n",
      "Epoch 1/50\n",
      "22500/22500 [==============================] - 8s 366us/step - loss: 7.9481 - acc: 0.5014\n",
      "Epoch 2/50\n",
      "22500/22500 [==============================] - 7s 315us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 3/50\n",
      "22500/22500 [==============================] - 6s 279us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 4/50\n",
      "22500/22500 [==============================] - 6s 279us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 5/50\n",
      "22500/22500 [==============================] - 6s 283us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 6/50\n",
      "22500/22500 [==============================] - 6s 275us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 7/50\n",
      "22500/22500 [==============================] - 7s 306us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 8/50\n",
      "22500/22500 [==============================] - 7s 296us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 9/50\n",
      "22500/22500 [==============================] - 6s 277us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 10/50\n",
      "22500/22500 [==============================] - 6s 279us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 11/50\n",
      "22500/22500 [==============================] - 6s 279us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 12/50\n",
      "22500/22500 [==============================] - 6s 277us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 13/50\n",
      "22500/22500 [==============================] - 6s 277us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 14/50\n",
      "22500/22500 [==============================] - 6s 282us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 15/50\n",
      "22500/22500 [==============================] - 6s 277us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 16/50\n",
      "22500/22500 [==============================] - 7s 289us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 17/50\n",
      "22500/22500 [==============================] - 7s 314us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 18/50\n",
      "22500/22500 [==============================] - 6s 282us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 19/50\n",
      "22500/22500 [==============================] - 6s 281us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 20/50\n",
      "22500/22500 [==============================] - 6s 281us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 21/50\n",
      "22500/22500 [==============================] - 6s 284us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 22/50\n",
      "22500/22500 [==============================] - 6s 281us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 23/50\n",
      "22500/22500 [==============================] - 6s 280us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 24/50\n",
      "22500/22500 [==============================] - 8s 376us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 25/50\n",
      "22500/22500 [==============================] - 7s 294us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 26/50\n",
      "22500/22500 [==============================] - 6s 286us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 27/50\n",
      "22500/22500 [==============================] - 6s 287us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 28/50\n",
      "22500/22500 [==============================] - 10s 457us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 29/50\n",
      "22500/22500 [==============================] - 6s 279us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 30/50\n",
      "22500/22500 [==============================] - 6s 280us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 31/50\n",
      "22500/22500 [==============================] - 8s 355us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 32/50\n",
      "22500/22500 [==============================] - 6s 287us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 33/50\n",
      "22500/22500 [==============================] - 6s 282us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 34/50\n",
      "22500/22500 [==============================] - 8s 370us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 35/50\n",
      "22500/22500 [==============================] - 6s 281us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 36/50\n",
      "22500/22500 [==============================] - 6s 280us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 37/50\n",
      "22500/22500 [==============================] - 8s 350us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 38/50\n",
      "22500/22500 [==============================] - 6s 276us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 39/50\n",
      "22500/22500 [==============================] - 6s 275us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 40/50\n",
      "22500/22500 [==============================] - 8s 352us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 41/50\n",
      "22500/22500 [==============================] - 6s 286us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 42/50\n",
      "22500/22500 [==============================] - 6s 283us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 43/50\n",
      "22500/22500 [==============================] - 8s 369us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 44/50\n",
      "22500/22500 [==============================] - 6s 279us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 45/50\n",
      "22500/22500 [==============================] - 6s 279us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 46/50\n",
      "22500/22500 [==============================] - 10s 426us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 47/50\n",
      "22500/22500 [==============================] - 8s 339us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 48/50\n",
      "22500/22500 [==============================] - 7s 296us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 49/50\n",
      "22500/22500 [==============================] - 8s 361us/step - loss: 7.9535 - acc: 0.5011\n",
      "Epoch 50/50\n",
      "22500/22500 [==============================] - 7s 297us/step - loss: 7.9535 - acc: 0.5011\n",
      "2500/2500 [==============================] - 0s 113us/step\n",
      "Epoch 1/50\n",
      "22500/22500 [==============================] - 8s 335us/step - loss: 7.9834 - acc: 0.4992\n",
      "Epoch 2/50\n",
      "22500/22500 [==============================] - 6s 284us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 3/50\n",
      "22500/22500 [==============================] - 6s 281us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 4/50\n",
      "22500/22500 [==============================] - 6s 284us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 5/50\n",
      "22500/22500 [==============================] - 6s 283us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 6/50\n",
      "22500/22500 [==============================] - 6s 282us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 7/50\n",
      "22500/22500 [==============================] - 6s 280us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 8/50\n",
      "22500/22500 [==============================] - 6s 289us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 9/50\n",
      "22500/22500 [==============================] - 6s 283us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 10/50\n",
      "22500/22500 [==============================] - 7s 307us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 11/50\n",
      "22500/22500 [==============================] - 7s 298us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 12/50\n",
      "22500/22500 [==============================] - 6s 280us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 13/50\n",
      "22500/22500 [==============================] - 6s 284us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 14/50\n",
      "22500/22500 [==============================] - 6s 285us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 15/50\n",
      "22500/22500 [==============================] - 6s 282us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 16/50\n",
      "22500/22500 [==============================] - 6s 281us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 17/50\n",
      "22500/22500 [==============================] - 7s 290us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 6s 282us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 19/50\n",
      "22500/22500 [==============================] - 7s 302us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 20/50\n",
      "22500/22500 [==============================] - 7s 319us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 21/50\n",
      "22500/22500 [==============================] - 7s 290us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 22/50\n",
      "22500/22500 [==============================] - 6s 285us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 23/50\n",
      "22500/22500 [==============================] - 9s 390us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 24/50\n",
      "22500/22500 [==============================] - 8s 349us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 25/50\n",
      "22500/22500 [==============================] - 6s 282us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 26/50\n",
      "22500/22500 [==============================] - 10s 449us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 27/50\n",
      "22500/22500 [==============================] - 7s 310us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 28/50\n",
      "22500/22500 [==============================] - 6s 284us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 29/50\n",
      "22500/22500 [==============================] - 8s 345us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 30/50\n",
      "22500/22500 [==============================] - 6s 289us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 31/50\n",
      "22500/22500 [==============================] - 6s 281us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 32/50\n",
      "22500/22500 [==============================] - 8s 347us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 33/50\n",
      "22500/22500 [==============================] - 6s 286us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 34/50\n",
      "22500/22500 [==============================] - 6s 285us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 35/50\n",
      "22500/22500 [==============================] - 8s 349us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 36/50\n",
      "22500/22500 [==============================] - 7s 291us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 37/50\n",
      "22500/22500 [==============================] - 6s 286us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 38/50\n",
      "22500/22500 [==============================] - 8s 353us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 39/50\n",
      "22500/22500 [==============================] - 6s 278us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 40/50\n",
      "22500/22500 [==============================] - 6s 278us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 41/50\n",
      "22500/22500 [==============================] - 9s 411us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 42/50\n",
      "22500/22500 [==============================] - 8s 363us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 43/50\n",
      "22500/22500 [==============================] - 6s 284us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 44/50\n",
      "22500/22500 [==============================] - 7s 293us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 45/50\n",
      "22500/22500 [==============================] - 7s 306us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 46/50\n",
      "22500/22500 [==============================] - 6s 278us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 47/50\n",
      "22500/22500 [==============================] - 6s 279us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 48/50\n",
      "22500/22500 [==============================] - 6s 278us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 49/50\n",
      "22500/22500 [==============================] - 6s 275us/step - loss: 7.9832 - acc: 0.4992\n",
      "Epoch 50/50\n",
      "22500/22500 [==============================] - 6s 278us/step - loss: 7.9832 - acc: 0.4992\n",
      "2500/2500 [==============================] - 0s 105us/step\n",
      "Epoch 1/50\n",
      "22500/22500 [==============================] - 8s 340us/step - loss: 8.0684 - acc: 0.4993\n",
      "Epoch 2/50\n",
      "22500/22500 [==============================] - 8s 336us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 3/50\n",
      "22500/22500 [==============================] - 7s 290us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 4/50\n",
      "22500/22500 [==============================] - 7s 310us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 5/50\n",
      "22500/22500 [==============================] - 6s 282us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 6/50\n",
      "22500/22500 [==============================] - 6s 280us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 7/50\n",
      "22500/22500 [==============================] - 6s 279us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 8/50\n",
      "22500/22500 [==============================] - 6s 280us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 9/50\n",
      "22500/22500 [==============================] - 6s 280us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 10/50\n",
      "22500/22500 [==============================] - 6s 286us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 11/50\n",
      "22500/22500 [==============================] - 6s 280us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 12/50\n",
      "22500/22500 [==============================] - 6s 282us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 13/50\n",
      "22500/22500 [==============================] - 7s 302us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 14/50\n",
      "22500/22500 [==============================] - 7s 295us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 15/50\n",
      "22500/22500 [==============================] - 6s 281us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 16/50\n",
      "22500/22500 [==============================] - 6s 278us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 17/50\n",
      "22500/22500 [==============================] - 10s 440us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 18/50\n",
      "22500/22500 [==============================] - 7s 296us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 19/50\n",
      "22500/22500 [==============================] - 6s 280us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 20/50\n",
      "22500/22500 [==============================] - 7s 328us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 21/50\n",
      "22500/22500 [==============================] - 7s 306us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 22/50\n",
      "22500/22500 [==============================] - 6s 277us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 23/50\n",
      "22500/22500 [==============================] - 7s 333us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 24/50\n",
      "22500/22500 [==============================] - 7s 297us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 25/50\n",
      "22500/22500 [==============================] - 6s 276us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 26/50\n",
      "22500/22500 [==============================] - 7s 331us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 27/50\n",
      "22500/22500 [==============================] - 7s 304us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 28/50\n",
      "22500/22500 [==============================] - 8s 373us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 29/50\n",
      "22500/22500 [==============================] - 8s 357us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 30/50\n",
      "22500/22500 [==============================] - 6s 283us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 31/50\n",
      "22500/22500 [==============================] - 6s 279us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 32/50\n",
      "22500/22500 [==============================] - 8s 348us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 33/50\n",
      "22500/22500 [==============================] - 6s 275us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 34/50\n",
      "22500/22500 [==============================] - 7s 295us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 35/50\n",
      "22500/22500 [==============================] - 10s 423us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 36/50\n",
      "22500/22500 [==============================] - 8s 336us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 37/50\n",
      "22500/22500 [==============================] - 6s 284us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 38/50\n",
      "22500/22500 [==============================] - 7s 293us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 39/50\n",
      "22500/22500 [==============================] - 7s 305us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 40/50\n",
      "22500/22500 [==============================] - 6s 278us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 41/50\n",
      "22500/22500 [==============================] - 6s 278us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 42/50\n",
      "22500/22500 [==============================] - 6s 278us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 43/50\n",
      "22500/22500 [==============================] - 6s 277us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 44/50\n",
      "22500/22500 [==============================] - 6s 274us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 45/50\n",
      "22500/22500 [==============================] - 6s 282us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 46/50\n",
      "22500/22500 [==============================] - 6s 278us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 6s 280us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 48/50\n",
      "22500/22500 [==============================] - 7s 300us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 49/50\n",
      "22500/22500 [==============================] - 6s 284us/step - loss: 8.0727 - acc: 0.4992\n",
      "Epoch 50/50\n",
      "22500/22500 [==============================] - 6s 277us/step - loss: 8.0727 - acc: 0.4992\n",
      "2500/2500 [==============================] - 0s 118us/step\n",
      "Epoch 1/50\n",
      "22500/22500 [==============================] - 7s 298us/step - loss: 8.0562 - acc: 0.5001\n",
      "Epoch 2/50\n",
      "22500/22500 [==============================] - 6s 275us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 3/50\n",
      "22500/22500 [==============================] - 6s 278us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 4/50\n",
      "22500/22500 [==============================] - 7s 298us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 5/50\n",
      "22500/22500 [==============================] - 8s 356us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 6/50\n",
      "22500/22500 [==============================] - 6s 286us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 7/50\n",
      "22500/22500 [==============================] - 7s 301us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 8/50\n",
      "22500/22500 [==============================] - 6s 286us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 9/50\n",
      "22500/22500 [==============================] - 6s 280us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 10/50\n",
      "22500/22500 [==============================] - 7s 292us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 11/50\n",
      "22500/22500 [==============================] - 10s 465us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 12/50\n",
      "22500/22500 [==============================] - 6s 276us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 13/50\n",
      "22500/22500 [==============================] - 6s 281us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 14/50\n",
      "22500/22500 [==============================] - 8s 347us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 15/50\n",
      "22500/22500 [==============================] - 6s 287us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 16/50\n",
      "22500/22500 [==============================] - 6s 277us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 17/50\n",
      "22500/22500 [==============================] - 8s 352us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 18/50\n",
      "22500/22500 [==============================] - 6s 278us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 19/50\n",
      "22500/22500 [==============================] - 6s 277us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 20/50\n",
      "22500/22500 [==============================] - 8s 358us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 21/50\n",
      "22500/22500 [==============================] - 6s 284us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 22/50\n",
      "22500/22500 [==============================] - 6s 281us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 23/50\n",
      "22500/22500 [==============================] - 8s 354us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 24/50\n",
      "22500/22500 [==============================] - 6s 283us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 25/50\n",
      "22500/22500 [==============================] - 6s 278us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 26/50\n",
      "22500/22500 [==============================] - 8s 358us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 27/50\n",
      "22500/22500 [==============================] - 6s 273us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 28/50\n",
      "22500/22500 [==============================] - 6s 282us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 29/50\n",
      "22500/22500 [==============================] - 9s 421us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 30/50\n",
      "22500/22500 [==============================] - 10s 439us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 31/50\n",
      "22500/22500 [==============================] - 7s 291us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 32/50\n",
      "22500/22500 [==============================] - 7s 301us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 33/50\n",
      "22500/22500 [==============================] - 7s 293us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 34/50\n",
      "22500/22500 [==============================] - 6s 284us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 35/50\n",
      "22500/22500 [==============================] - 6s 280us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 36/50\n",
      "22500/22500 [==============================] - 6s 280us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 37/50\n",
      "22500/22500 [==============================] - 6s 277us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 38/50\n",
      "22500/22500 [==============================] - 6s 281us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 39/50\n",
      "22500/22500 [==============================] - 6s 286us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 40/50\n",
      "22500/22500 [==============================] - 6s 278us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 41/50\n",
      "22500/22500 [==============================] - 7s 292us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 42/50\n",
      "22500/22500 [==============================] - 7s 308us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 43/50\n",
      "22500/22500 [==============================] - 6s 282us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 44/50\n",
      "22500/22500 [==============================] - 6s 280us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 45/50\n",
      "22500/22500 [==============================] - 6s 282us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 46/50\n",
      "22500/22500 [==============================] - 6s 281us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 47/50\n",
      "22500/22500 [==============================] - 6s 281us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 48/50\n",
      "22500/22500 [==============================] - 6s 288us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 49/50\n",
      "22500/22500 [==============================] - 6s 282us/step - loss: 8.0583 - acc: 0.5000\n",
      "Epoch 50/50\n",
      "22500/22500 [==============================] - 6s 284us/step - loss: 8.0583 - acc: 0.5000\n",
      "2500/2500 [==============================] - 0s 126us/step\n",
      "Epoch 1/50\n",
      "22500/22500 [==============================] - 8s 337us/step - loss: 8.0804 - acc: 0.4986\n",
      "Epoch 2/50\n",
      "22500/22500 [==============================] - 6s 286us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 3/50\n",
      "22500/22500 [==============================] - 6s 289us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 4/50\n",
      "22500/22500 [==============================] - 6s 286us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 5/50\n",
      "22500/22500 [==============================] - 6s 287us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 6/50\n",
      "22500/22500 [==============================] - 10s 426us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 7/50\n",
      "22500/22500 [==============================] - 9s 418us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 8/50\n",
      "22500/22500 [==============================] - 6s 289us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 9/50\n",
      "22500/22500 [==============================] - 8s 360us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 10/50\n",
      "22500/22500 [==============================] - 6s 288us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 11/50\n",
      "22500/22500 [==============================] - 6s 286us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 12/50\n",
      "22500/22500 [==============================] - 8s 358us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 13/50\n",
      "22500/22500 [==============================] - 6s 285us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 14/50\n",
      "22500/22500 [==============================] - 6s 284us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 15/50\n",
      "22500/22500 [==============================] - 8s 362us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 16/50\n",
      "22500/22500 [==============================] - 6s 281us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 17/50\n",
      "22500/22500 [==============================] - 7s 296us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 18/50\n",
      "22500/22500 [==============================] - 8s 361us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 19/50\n",
      "22500/22500 [==============================] - 7s 290us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 20/50\n",
      "22500/22500 [==============================] - 7s 290us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 21/50\n",
      "22500/22500 [==============================] - 8s 356us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 22/50\n",
      "22500/22500 [==============================] - 6s 286us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 23/50\n",
      "22500/22500 [==============================] - 7s 315us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 24/50\n",
      "22500/22500 [==============================] - 10s 449us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 25/50\n",
      "22500/22500 [==============================] - 8s 346us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 7s 313us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 27/50\n",
      "22500/22500 [==============================] - 6s 286us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 28/50\n",
      "22500/22500 [==============================] - 6s 284us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 29/50\n",
      "22500/22500 [==============================] - 6s 288us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 30/50\n",
      "22500/22500 [==============================] - 6s 285us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 31/50\n",
      "22500/22500 [==============================] - 6s 287us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 32/50\n",
      "22500/22500 [==============================] - 8s 375us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 33/50\n",
      "22500/22500 [==============================] - 6s 281us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 34/50\n",
      "22500/22500 [==============================] - 7s 296us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 35/50\n",
      "22500/22500 [==============================] - 7s 306us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 36/50\n",
      "22500/22500 [==============================] - 6s 286us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 37/50\n",
      "22500/22500 [==============================] - 6s 285us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 38/50\n",
      "22500/22500 [==============================] - 6s 284us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 39/50\n",
      "22500/22500 [==============================] - 6s 283us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 40/50\n",
      "22500/22500 [==============================] - 6s 282us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 41/50\n",
      "22500/22500 [==============================] - 6s 286us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 42/50\n",
      "22500/22500 [==============================] - 6s 279us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 43/50\n",
      "22500/22500 [==============================] - 6s 286us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 44/50\n",
      "22500/22500 [==============================] - 7s 314us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 45/50\n",
      "22500/22500 [==============================] - 6s 283us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 46/50\n",
      "22500/22500 [==============================] - 6s 284us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 47/50\n",
      "22500/22500 [==============================] - 6s 280us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 48/50\n",
      "22500/22500 [==============================] - 6s 279us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 49/50\n",
      "22500/22500 [==============================] - 6s 279us/step - loss: 8.0813 - acc: 0.4986\n",
      "Epoch 50/50\n",
      "22500/22500 [==============================] - 6s 284us/step - loss: 8.0813 - acc: 0.4986\n",
      "2500/2500 [==============================] - 0s 124us/step\n",
      "Accuracy mean: 0.50024\n",
      "Accuracy variance: 0.00749869321949\n",
      "(' Time ', '3301.406', ' seconds')\n",
      "[[7094 5406]\n",
      " [6213 6287]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.57      0.55     12500\n",
      "          1       0.54      0.50      0.52     12500\n",
      "\n",
      "avg / total       0.54      0.54      0.53     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# estimators \n",
    "# Evaluating the ANN\n",
    "t0 = time()\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 1024, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n",
    "    classifier.add(Dense(units = 512, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 50)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of DecisionTreeClassifier = 50.720000 %\n",
      "(' Time ', '8.001', ' seconds')\n",
      "[[6400 6100]\n",
      " [6220 6280]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.51      0.51     12500\n",
      "          1       0.51      0.50      0.50     12500\n",
      "\n",
      "avg / total       0.51      0.51      0.51     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of DecisionTreeClassifier = {:.6f} %\".format(acc * 100))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of RandomForestClassifier = 53.060000 %\n",
      "(' Time ', '28.021', ' seconds')\n",
      "[[7162 5338]\n",
      " [6397 6103]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.57      0.55     12500\n",
      "          1       0.53      0.49      0.51     12500\n",
      "\n",
      "avg / total       0.53      0.53      0.53     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of RandomForestClassifier = {:.6f} %\".format(acc * 100))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of ExtraTreesClassifier = 51.828000 %\n",
      "(' Time ', '19.606', ' seconds')\n",
      "[[7260 5240]\n",
      " [6803 5697]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.58      0.55     12500\n",
      "          1       0.52      0.46      0.49     12500\n",
      "\n",
      "avg / total       0.52      0.52      0.52     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of ExtraTreesClassifier = {:.6f} %\".format(acc * 100))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of AdaBoostClassifier = 54.508000 %\n",
      "(' Time ', '57.975', ' seconds')\n",
      "[[7135 5365]\n",
      " [6008 6492]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.57      0.56     12500\n",
      "          1       0.55      0.52      0.53     12500\n",
      "\n",
      "avg / total       0.55      0.55      0.54     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of AdaBoostClassifier = {:.6f} %\".format(acc * 100))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Naive_bayes  GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GaussianNB = 50.416000 %\n",
      "(' Time ', '0.459', ' seconds')\n",
      "[[10032  2468]\n",
      " [ 9928  2572]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.80      0.62     12500\n",
      "          1       0.51      0.21      0.29     12500\n",
      "\n",
      "avg / total       0.51      0.50      0.46     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred= gnb.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of GaussianNB = {:.6f} %\".format(acc * 100))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
