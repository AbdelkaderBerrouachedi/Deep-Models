{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt \n",
    "from pprint import pprint\n",
    "from numpy import array\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GLCM_pan</th>\n",
       "      <th>Mean_Green</th>\n",
       "      <th>Mean_Red</th>\n",
       "      <th>Mean_NIR</th>\n",
       "      <th>SD_pan</th>\n",
       "      <th>outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.656711</td>\n",
       "      <td>0.050984</td>\n",
       "      <td>0.044570</td>\n",
       "      <td>0.218476</td>\n",
       "      <td>0.132110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.680591</td>\n",
       "      <td>0.049425</td>\n",
       "      <td>0.041939</td>\n",
       "      <td>0.177275</td>\n",
       "      <td>0.106749</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.734892</td>\n",
       "      <td>0.047396</td>\n",
       "      <td>0.042926</td>\n",
       "      <td>0.259034</td>\n",
       "      <td>0.143741</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698087</td>\n",
       "      <td>0.035317</td>\n",
       "      <td>0.027066</td>\n",
       "      <td>0.127065</td>\n",
       "      <td>0.095697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.738927</td>\n",
       "      <td>0.046076</td>\n",
       "      <td>0.040228</td>\n",
       "      <td>0.295501</td>\n",
       "      <td>0.112481</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GLCM_pan  Mean_Green  Mean_Red  Mean_NIR    SD_pan  outlier\n",
       "0  0.656711    0.050984  0.044570  0.218476  0.132110        1\n",
       "1  0.680591    0.049425  0.041939  0.177275  0.106749        1\n",
       "2  0.734892    0.047396  0.042926  0.259034  0.143741        1\n",
       "3  0.698087    0.035317  0.027066  0.127065  0.095697        1\n",
       "4  0.738927    0.046076  0.040228  0.295501  0.112481        1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df=pd.read_csv('Wilt_withoutdupl_norm_05.csv')  \n",
    "\n",
    "del df['id']\n",
    "del df['Unnamed: 0']\n",
    "df['outlier'] = df.outlier.apply(lambda label: 1 if label == \"'yes'\" else 0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df to values\n",
    "df = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GC Forest\n",
    "import argparse\n",
    "import sys\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "sys.path.insert(0, \"lib\")\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.utils.config_utils import load_json\n",
    "config = load_json(\"./examples/Wilt.json\")   \n",
    "gc = GCForest(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# train test \n",
    "from sklearn.cross_validation import train_test_split\n",
    "y = df[:,5]\n",
    "X = df[:,0:5]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of class\n",
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:12:13,706][cascade_classifier.fit_transform] X_groups_train.shape=[(3373, 5)],y_train.shape=(3373,),X_groups_test.shape=[(1446, 5)],y_test.shape=(1446,)\n",
      "[ 2018-07-31 22:12:13,708][cascade_classifier.fit_transform] group_dims=[5]\n",
      "[ 2018-07-31 22:12:13,709][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-31 22:12:13,725][cascade_classifier.fit_transform] group_ends=[5]\n",
      "[ 2018-07-31 22:12:13,726][cascade_classifier.fit_transform] X_train.shape=(3373, 5),X_test.shape=(1446, 5)\n",
      "[ 2018-07-31 22:12:13,729][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(3373, 5), X_cur_test.shape=(1446, 5)\n",
      "[ 2018-07-31 22:12:15,032][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=98.52%\n",
      "[ 2018-07-31 22:12:16,673][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=98.22%\n",
      "[ 2018-07-31 22:12:17,881][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=98.82%\n",
      "[ 2018-07-31 22:12:19,146][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=98.52%\n",
      "[ 2018-07-31 22:12:20,709][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=98.52%\n",
      "[ 2018-07-31 22:12:22,190][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=98.22%\n",
      "[ 2018-07-31 22:12:23,522][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=97.92%\n",
      "[ 2018-07-31 22:12:24,837][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=98.51%\n",
      "[ 2018-07-31 22:12:26,073][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=99.11%\n",
      "[ 2018-07-31 22:12:27,274][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=98.21%\n",
      "[ 2018-07-31 22:12:27,495][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=98.46%\n",
      "[ 2018-07-31 22:12:27,496][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=97.23%\n",
      "[ 2018-07-31 22:12:28,403][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_0.predict)=97.93%\n",
      "[ 2018-07-31 22:12:29,656][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_1.predict)=98.82%\n",
      "[ 2018-07-31 22:12:30,881][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_2.predict)=97.93%\n",
      "[ 2018-07-31 22:12:32,267][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_3.predict)=98.52%\n",
      "[ 2018-07-31 22:12:33,517][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_4.predict)=98.52%\n",
      "[ 2018-07-31 22:12:34,937][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_5.predict)=97.93%\n",
      "[ 2018-07-31 22:12:36,255][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_6.predict)=98.81%\n",
      "[ 2018-07-31 22:12:37,731][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_7.predict)=97.62%\n",
      "[ 2018-07-31 22:12:39,264][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_8.predict)=100.00%\n",
      "[ 2018-07-31 22:12:40,682][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_9.predict)=98.21%\n",
      "[ 2018-07-31 22:12:40,908][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_cv.predict)=98.43%\n",
      "[ 2018-07-31 22:12:40,913][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.test.predict)=97.51%\n",
      "[ 2018-07-31 22:12:41,097][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_0.predict)=94.67%\n",
      "[ 2018-07-31 22:12:41,117][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_1.predict)=94.67%\n",
      "[ 2018-07-31 22:12:41,139][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_2.predict)=94.67%\n",
      "[ 2018-07-31 22:12:41,149][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_3.predict)=94.67%\n",
      "[ 2018-07-31 22:12:41,165][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_4.predict)=94.67%\n",
      "[ 2018-07-31 22:12:41,178][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_5.predict)=94.67%\n",
      "[ 2018-07-31 22:12:41,193][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_6.predict)=94.96%\n",
      "[ 2018-07-31 22:12:41,205][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_7.predict)=94.94%\n",
      "[ 2018-07-31 22:12:41,217][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_8.predict)=94.94%\n",
      "[ 2018-07-31 22:12:41,229][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_9.predict)=94.94%\n",
      "[ 2018-07-31 22:12:41,231][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_cv.predict)=94.78%\n",
      "[ 2018-07-31 22:12:41,233][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.test.predict)=94.40%\n",
      "[ 2018-07-31 22:12:41,235][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=97.42%\n",
      "[ 2018-07-31 22:12:41,237][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=96.68%\n",
      "[ 2018-07-31 22:12:41,239][cascade_classifier.fit_transform] [layer=1] look_indexs=[0], X_cur_train.shape=(3373, 11), X_cur_test.shape=(1446, 11)\n",
      "[ 2018-07-31 22:12:42,518][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_0.predict)=99.11%\n",
      "[ 2018-07-31 22:12:44,007][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_1.predict)=99.41%\n",
      "[ 2018-07-31 22:12:45,582][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_2.predict)=98.82%\n",
      "[ 2018-07-31 22:12:47,026][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_3.predict)=98.52%\n",
      "[ 2018-07-31 22:12:48,429][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_4.predict)=98.52%\n",
      "[ 2018-07-31 22:12:49,772][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_5.predict)=98.22%\n",
      "[ 2018-07-31 22:12:51,481][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_6.predict)=99.70%\n",
      "[ 2018-07-31 22:12:52,973][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_7.predict)=98.51%\n",
      "[ 2018-07-31 22:12:54,414][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_8.predict)=98.51%\n",
      "[ 2018-07-31 22:12:55,676][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_9.predict)=97.62%\n",
      "[ 2018-07-31 22:12:55,955][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_cv.predict)=98.70%\n",
      "[ 2018-07-31 22:12:55,957][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.test.predict)=98.20%\n",
      "[ 2018-07-31 22:12:56,831][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_0.predict)=97.93%\n",
      "[ 2018-07-31 22:12:58,111][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_1.predict)=98.52%\n",
      "[ 2018-07-31 22:12:59,231][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_2.predict)=99.11%\n",
      "[ 2018-07-31 22:13:00,502][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_3.predict)=99.11%\n",
      "[ 2018-07-31 22:13:01,729][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_4.predict)=98.52%\n",
      "[ 2018-07-31 22:13:03,154][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_5.predict)=99.11%\n",
      "[ 2018-07-31 22:13:04,425][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_6.predict)=98.52%\n",
      "[ 2018-07-31 22:13:05,613][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_7.predict)=98.51%\n",
      "[ 2018-07-31 22:13:06,975][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_8.predict)=98.81%\n",
      "[ 2018-07-31 22:13:07,989][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_9.predict)=98.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:13:08,378][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_cv.predict)=98.70%\n",
      "[ 2018-07-31 22:13:08,381][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.test.predict)=98.34%\n",
      "[ 2018-07-31 22:13:08,411][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_0.predict)=98.82%\n",
      "[ 2018-07-31 22:13:08,446][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_1.predict)=98.52%\n",
      "[ 2018-07-31 22:13:08,493][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_2.predict)=99.11%\n",
      "[ 2018-07-31 22:13:08,529][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_3.predict)=98.82%\n",
      "[ 2018-07-31 22:13:08,547][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_4.predict)=97.93%\n",
      "[ 2018-07-31 22:13:08,564][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_5.predict)=98.52%\n",
      "[ 2018-07-31 22:13:08,583][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_6.predict)=98.52%\n",
      "[ 2018-07-31 22:13:08,602][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_7.predict)=97.32%\n",
      "[ 2018-07-31 22:13:08,628][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_8.predict)=99.70%\n",
      "[ 2018-07-31 22:13:08,667][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_9.predict)=99.11%\n",
      "[ 2018-07-31 22:13:08,681][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_cv.predict)=98.64%\n",
      "[ 2018-07-31 22:13:08,683][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.test.predict)=97.58%\n",
      "[ 2018-07-31 22:13:08,686][cascade_classifier.calc_accuracy] Accuracy(layer_1 - train.classifier_average)=98.67%\n",
      "[ 2018-07-31 22:13:08,688][cascade_classifier.calc_accuracy] Accuracy(layer_1 - test.classifier_average)=98.20%\n",
      "[ 2018-07-31 22:13:08,690][cascade_classifier.fit_transform] [layer=2] look_indexs=[0], X_cur_train.shape=(3373, 11), X_cur_test.shape=(1446, 11)\n",
      "[ 2018-07-31 22:13:09,891][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_0.predict)=98.22%\n",
      "[ 2018-07-31 22:13:11,179][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_1.predict)=97.63%\n",
      "[ 2018-07-31 22:13:12,524][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_2.predict)=98.52%\n",
      "[ 2018-07-31 22:13:13,914][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_3.predict)=98.52%\n",
      "[ 2018-07-31 22:13:15,343][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_4.predict)=99.11%\n",
      "[ 2018-07-31 22:13:16,726][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_5.predict)=99.11%\n",
      "[ 2018-07-31 22:13:18,192][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_6.predict)=98.52%\n",
      "[ 2018-07-31 22:13:19,430][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_7.predict)=99.11%\n",
      "[ 2018-07-31 22:13:20,933][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_8.predict)=98.51%\n",
      "[ 2018-07-31 22:13:22,688][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_9.predict)=97.92%\n",
      "[ 2018-07-31 22:13:23,032][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_cv.predict)=98.52%\n",
      "[ 2018-07-31 22:13:23,034][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.test.predict)=98.13%\n",
      "[ 2018-07-31 22:13:24,187][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_0.predict)=98.52%\n",
      "[ 2018-07-31 22:13:25,698][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_1.predict)=99.11%\n",
      "[ 2018-07-31 22:13:26,978][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_2.predict)=98.82%\n",
      "[ 2018-07-31 22:13:28,521][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_3.predict)=97.93%\n",
      "[ 2018-07-31 22:13:29,838][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_4.predict)=98.82%\n",
      "[ 2018-07-31 22:13:31,414][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_5.predict)=98.82%\n",
      "[ 2018-07-31 22:13:32,876][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_6.predict)=98.22%\n",
      "[ 2018-07-31 22:13:34,294][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_7.predict)=98.51%\n",
      "[ 2018-07-31 22:13:36,016][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_8.predict)=98.21%\n",
      "[ 2018-07-31 22:13:37,506][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_9.predict)=98.81%\n",
      "[ 2018-07-31 22:13:37,791][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_cv.predict)=98.58%\n",
      "[ 2018-07-31 22:13:37,792][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.test.predict)=97.99%\n",
      "[ 2018-07-31 22:13:37,826][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_0.predict)=98.52%\n",
      "[ 2018-07-31 22:13:37,897][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_1.predict)=99.11%\n",
      "[ 2018-07-31 22:13:37,923][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_2.predict)=98.82%\n",
      "[ 2018-07-31 22:13:37,944][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_3.predict)=98.82%\n",
      "[ 2018-07-31 22:13:37,967][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_4.predict)=98.52%\n",
      "[ 2018-07-31 22:13:37,983][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_5.predict)=98.22%\n",
      "[ 2018-07-31 22:13:38,000][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_6.predict)=97.92%\n",
      "[ 2018-07-31 22:13:38,022][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_7.predict)=97.62%\n",
      "[ 2018-07-31 22:13:38,049][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_8.predict)=99.40%\n",
      "[ 2018-07-31 22:13:38,065][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_9.predict)=99.70%\n",
      "[ 2018-07-31 22:13:38,068][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_cv.predict)=98.67%\n",
      "[ 2018-07-31 22:13:38,069][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.test.predict)=98.20%\n",
      "[ 2018-07-31 22:13:38,070][cascade_classifier.calc_accuracy] Accuracy(layer_2 - train.classifier_average)=98.64%\n",
      "[ 2018-07-31 22:13:38,072][cascade_classifier.calc_accuracy] Accuracy(layer_2 - test.classifier_average)=98.06%\n",
      "[ 2018-07-31 22:13:38,073][cascade_classifier.fit_transform] [layer=3] look_indexs=[0], X_cur_train.shape=(3373, 11), X_cur_test.shape=(1446, 11)\n",
      "[ 2018-07-31 22:13:39,680][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_0.predict)=99.41%\n",
      "[ 2018-07-31 22:13:41,419][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_1.predict)=98.82%\n",
      "[ 2018-07-31 22:13:43,447][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_2.predict)=98.22%\n",
      "[ 2018-07-31 22:13:45,057][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_3.predict)=97.63%\n",
      "[ 2018-07-31 22:13:46,902][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_4.predict)=98.52%\n",
      "[ 2018-07-31 22:13:48,634][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_5.predict)=97.93%\n",
      "[ 2018-07-31 22:13:50,007][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_6.predict)=99.11%\n",
      "[ 2018-07-31 22:13:51,656][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_7.predict)=97.62%\n",
      "[ 2018-07-31 22:13:53,300][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_8.predict)=98.81%\n",
      "[ 2018-07-31 22:13:55,218][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_9.predict)=99.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:13:55,568][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_cv.predict)=98.52%\n",
      "[ 2018-07-31 22:13:55,570][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.test.predict)=98.34%\n",
      "[ 2018-07-31 22:13:56,784][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_0.predict)=98.82%\n",
      "[ 2018-07-31 22:13:58,329][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_1.predict)=98.22%\n",
      "[ 2018-07-31 22:14:00,006][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_2.predict)=97.93%\n",
      "[ 2018-07-31 22:14:02,088][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_3.predict)=97.93%\n",
      "[ 2018-07-31 22:14:04,118][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_4.predict)=98.52%\n",
      "[ 2018-07-31 22:14:05,941][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_5.predict)=98.22%\n",
      "[ 2018-07-31 22:14:08,098][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_6.predict)=98.52%\n",
      "[ 2018-07-31 22:14:09,825][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_7.predict)=98.21%\n",
      "[ 2018-07-31 22:14:11,374][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_8.predict)=99.40%\n",
      "[ 2018-07-31 22:14:13,073][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_9.predict)=98.21%\n",
      "[ 2018-07-31 22:14:13,569][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_cv.predict)=98.40%\n",
      "[ 2018-07-31 22:14:13,575][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.test.predict)=98.13%\n",
      "[ 2018-07-31 22:14:13,663][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_0.predict)=98.22%\n",
      "[ 2018-07-31 22:14:13,789][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_1.predict)=98.52%\n",
      "[ 2018-07-31 22:14:13,833][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_2.predict)=99.70%\n",
      "[ 2018-07-31 22:14:13,882][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_3.predict)=97.93%\n",
      "[ 2018-07-31 22:14:13,922][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_4.predict)=97.93%\n",
      "[ 2018-07-31 22:14:13,942][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_5.predict)=99.11%\n",
      "[ 2018-07-31 22:14:13,985][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_6.predict)=98.52%\n",
      "[ 2018-07-31 22:14:14,031][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_7.predict)=99.11%\n",
      "[ 2018-07-31 22:14:14,116][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_8.predict)=98.21%\n",
      "[ 2018-07-31 22:14:14,163][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_9.predict)=97.92%\n",
      "[ 2018-07-31 22:14:14,187][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_cv.predict)=98.52%\n",
      "[ 2018-07-31 22:14:14,197][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.test.predict)=98.20%\n",
      "[ 2018-07-31 22:14:14,201][cascade_classifier.calc_accuracy] Accuracy(layer_3 - train.classifier_average)=98.43%\n",
      "[ 2018-07-31 22:14:14,203][cascade_classifier.calc_accuracy] Accuracy(layer_3 - test.classifier_average)=98.13%\n",
      "[ 2018-07-31 22:14:14,217][cascade_classifier.fit_transform] [layer=4] look_indexs=[0], X_cur_train.shape=(3373, 11), X_cur_test.shape=(1446, 11)\n",
      "[ 2018-07-31 22:14:15,887][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_0.predict)=98.22%\n",
      "[ 2018-07-31 22:14:17,360][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_1.predict)=97.93%\n",
      "[ 2018-07-31 22:14:18,949][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_2.predict)=98.52%\n",
      "[ 2018-07-31 22:14:20,327][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_3.predict)=99.11%\n",
      "[ 2018-07-31 22:14:22,542][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_4.predict)=99.11%\n",
      "[ 2018-07-31 22:14:24,572][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_5.predict)=98.52%\n",
      "[ 2018-07-31 22:14:26,556][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_6.predict)=99.41%\n",
      "[ 2018-07-31 22:14:29,252][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_7.predict)=97.02%\n",
      "[ 2018-07-31 22:14:32,259][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_8.predict)=98.21%\n",
      "[ 2018-07-31 22:14:34,452][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_9.predict)=97.92%\n",
      "[ 2018-07-31 22:14:34,834][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_cv.predict)=98.40%\n",
      "[ 2018-07-31 22:14:34,836][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.test.predict)=98.20%\n",
      "[ 2018-07-31 22:14:36,972][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_0.predict)=97.93%\n",
      "[ 2018-07-31 22:14:38,811][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_1.predict)=99.41%\n",
      "[ 2018-07-31 22:14:41,257][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_2.predict)=99.41%\n",
      "[ 2018-07-31 22:14:43,998][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_3.predict)=97.93%\n",
      "[ 2018-07-31 22:14:46,846][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_4.predict)=98.22%\n",
      "[ 2018-07-31 22:14:49,190][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_5.predict)=97.63%\n",
      "[ 2018-07-31 22:14:52,322][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_6.predict)=98.81%\n",
      "[ 2018-07-31 22:14:55,132][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_7.predict)=99.11%\n",
      "[ 2018-07-31 22:14:57,216][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_8.predict)=98.81%\n",
      "[ 2018-07-31 22:14:59,727][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_9.predict)=99.11%\n",
      "[ 2018-07-31 22:15:00,121][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_cv.predict)=98.64%\n",
      "[ 2018-07-31 22:15:00,123][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.test.predict)=97.79%\n",
      "[ 2018-07-31 22:15:00,209][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_0.predict)=98.82%\n",
      "[ 2018-07-31 22:15:00,289][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_1.predict)=98.82%\n",
      "[ 2018-07-31 22:15:00,322][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_2.predict)=97.93%\n",
      "[ 2018-07-31 22:15:00,367][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_3.predict)=99.11%\n",
      "[ 2018-07-31 22:15:00,417][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_4.predict)=99.11%\n",
      "[ 2018-07-31 22:15:00,488][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_5.predict)=97.63%\n",
      "[ 2018-07-31 22:15:00,506][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_6.predict)=99.11%\n",
      "[ 2018-07-31 22:15:00,546][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_7.predict)=99.11%\n",
      "[ 2018-07-31 22:15:00,647][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_8.predict)=97.32%\n",
      "[ 2018-07-31 22:15:00,689][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_9.predict)=98.21%\n",
      "[ 2018-07-31 22:15:00,697][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_cv.predict)=98.52%\n",
      "[ 2018-07-31 22:15:00,705][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.test.predict)=98.13%\n",
      "[ 2018-07-31 22:15:00,712][cascade_classifier.calc_accuracy] Accuracy(layer_4 - train.classifier_average)=98.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:15:00,714][cascade_classifier.calc_accuracy] Accuracy(layer_4 - test.classifier_average)=98.27%\n",
      "[ 2018-07-31 22:15:00,715][cascade_classifier.fit_transform] [Result][Optimal Level Detected] opt_layer_num=2, accuracy_train=98.67%, accuracy_test=98.20%\n"
     ]
    }
   ],
   "source": [
    "t0=time()\n",
    "# X_enc is the concatenated predict_proba result of each estimators of the last layer of the GCForest model\n",
    "    # X_enc.shape =\n",
    "    #   (n_datas, n_estimators * n_classes): If cascade is provided\n",
    "    #   (n_datas, n_estimators * n_classes, dimX, dimY): If only finegrained part is provided\n",
    "    # You can also pass X_test, y_test to fit_transform method, then the accracy on test data will be logged when training.\n",
    "X_train_enc, X_test_enc = gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test)\n",
    "    # WARNING: if you set gc.set_keep_model_in_mem(True), you would have to use\n",
    "    # gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test) to evaluate your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:15:00,802][cascade_classifier.transform] X_groups_test.shape=[(1446, 5)]\n",
      "[ 2018-07-31 22:15:00,812][cascade_classifier.transform] group_dims=[5]\n",
      "[ 2018-07-31 22:15:00,817][cascade_classifier.transform] X_test.shape=(1446, 5)\n",
      "[ 2018-07-31 22:15:00,822][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(1446, 5)\n",
      "[ 2018-07-31 22:15:08,102][cascade_classifier.transform] [layer=1] look_indexs=[0], X_cur_test.shape=(1446, 11)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GCForest = 98.201936 %\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "y_pred = gc.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy of GCForest = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' Time ', '185.157', ' seconds')\n",
      "[[1356    9]\n",
      " [  17   64]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.99      0.99      1365\n",
      "        1.0       0.88      0.79      0.83        81\n",
      "\n",
      "avg / total       0.98      0.98      0.98      1446\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.2521 - acc: 0.9394A: 4s - lo\n",
      "Epoch 2/50\n",
      "3035/3035 [==============================] - 3s 860us/step - loss: 0.1954 - acc: 0.9486\n",
      "Epoch 3/50\n",
      "3035/3035 [==============================] - 3s 835us/step - loss: 0.1943 - acc: 0.9486\n",
      "Epoch 4/50\n",
      "3035/3035 [==============================] - 3s 890us/step - loss: 0.1908 - acc: 0.9486\n",
      "Epoch 5/50\n",
      "3035/3035 [==============================] - 2s 807us/step - loss: 0.1913 - acc: 0.9486\n",
      "Epoch 6/50\n",
      "3035/3035 [==============================] - 2s 741us/step - loss: 0.1871 - acc: 0.9486\n",
      "Epoch 7/50\n",
      "3035/3035 [==============================] - 2s 785us/step - loss: 0.1882 - acc: 0.9486\n",
      "Epoch 8/50\n",
      "3035/3035 [==============================] - 2s 728us/step - loss: 0.1826 - acc: 0.9486\n",
      "Epoch 9/50\n",
      "3035/3035 [==============================] - 2s 697us/step - loss: 0.1748 - acc: 0.9486\n",
      "Epoch 10/50\n",
      "3035/3035 [==============================] - 2s 713us/step - loss: 0.1682 - acc: 0.9486\n",
      "Epoch 11/50\n",
      "3035/3035 [==============================] - 2s 590us/step - loss: 0.1535 - acc: 0.9486\n",
      "Epoch 12/50\n",
      "3035/3035 [==============================] - 2s 560us/step - loss: 0.1246 - acc: 0.9509\n",
      "Epoch 13/50\n",
      "3035/3035 [==============================] - 2s 643us/step - loss: 0.1234 - acc: 0.9601\n",
      "Epoch 14/50\n",
      "3035/3035 [==============================] - 2s 607us/step - loss: 0.0870 - acc: 0.9680\n",
      "Epoch 15/50\n",
      "3035/3035 [==============================] - 2s 568us/step - loss: 0.0820 - acc: 0.9703\n",
      "Epoch 16/50\n",
      "3035/3035 [==============================] - 2s 606us/step - loss: 0.0730 - acc: 0.9763\n",
      "Epoch 17/50\n",
      "3035/3035 [==============================] - 2s 682us/step - loss: 0.0558 - acc: 0.9802\n",
      "Epoch 18/50\n",
      "3035/3035 [==============================] - 2s 664us/step - loss: 0.0561 - acc: 0.9796\n",
      "Epoch 19/50\n",
      "3035/3035 [==============================] - 2s 685us/step - loss: 0.0598 - acc: 0.9809 0s - loss: 0.0603 - acc: 0.980\n",
      "Epoch 20/50\n",
      "3035/3035 [==============================] - 2s 661us/step - loss: 0.0689 - acc: 0.9792\n",
      "Epoch 21/50\n",
      "3035/3035 [==============================] - 2s 605us/step - loss: 0.0595 - acc: 0.9815\n",
      "Epoch 22/50\n",
      "3035/3035 [==============================] - 2s 657us/step - loss: 0.0482 - acc: 0.9829\n",
      "Epoch 23/50\n",
      "3035/3035 [==============================] - 2s 587us/step - loss: 0.0427 - acc: 0.9845\n",
      "Epoch 24/50\n",
      "3035/3035 [==============================] - 2s 804us/step - loss: 0.0486 - acc: 0.9822\n",
      "Epoch 25/50\n",
      "3035/3035 [==============================] - 2s 736us/step - loss: 0.0401 - acc: 0.9871\n",
      "Epoch 26/50\n",
      "3035/3035 [==============================] - 2s 733us/step - loss: 0.0457 - acc: 0.9842\n",
      "Epoch 27/50\n",
      "3035/3035 [==============================] - 2s 666us/step - loss: 0.0603 - acc: 0.9809\n",
      "Epoch 28/50\n",
      "3035/3035 [==============================] - 2s 708us/step - loss: 0.0419 - acc: 0.9852\n",
      "Epoch 29/50\n",
      "3035/3035 [==============================] - 2s 567us/step - loss: 0.0378 - acc: 0.9881\n",
      "Epoch 30/50\n",
      "3035/3035 [==============================] - 2s 522us/step - loss: 0.0436 - acc: 0.9871\n",
      "Epoch 31/50\n",
      "3035/3035 [==============================] - 2s 619us/step - loss: 0.0374 - acc: 0.9862\n",
      "Epoch 32/50\n",
      "3035/3035 [==============================] - 2s 697us/step - loss: 0.0374 - acc: 0.9862\n",
      "Epoch 33/50\n",
      "3035/3035 [==============================] - 2s 748us/step - loss: 0.0511 - acc: 0.9802\n",
      "Epoch 34/50\n",
      "3035/3035 [==============================] - 3s 893us/step - loss: 0.0466 - acc: 0.9865\n",
      "Epoch 35/50\n",
      "3035/3035 [==============================] - 2s 727us/step - loss: 0.0417 - acc: 0.9848\n",
      "Epoch 36/50\n",
      "3035/3035 [==============================] - 2s 806us/step - loss: 0.0343 - acc: 0.9888\n",
      "Epoch 37/50\n",
      "3035/3035 [==============================] - 2s 802us/step - loss: 0.0427 - acc: 0.9865\n",
      "Epoch 38/50\n",
      "3035/3035 [==============================] - 2s 795us/step - loss: 0.0481 - acc: 0.9865\n",
      "Epoch 39/50\n",
      "3035/3035 [==============================] - 2s 727us/step - loss: 0.0457 - acc: 0.9815\n",
      "Epoch 40/50\n",
      "3035/3035 [==============================] - 2s 717us/step - loss: 0.0393 - acc: 0.9881\n",
      "Epoch 41/50\n",
      "3035/3035 [==============================] - 2s 821us/step - loss: 0.0331 - acc: 0.9891\n",
      "Epoch 42/50\n",
      "3035/3035 [==============================] - 2s 671us/step - loss: 0.0377 - acc: 0.9881\n",
      "Epoch 43/50\n",
      "3035/3035 [==============================] - 2s 735us/step - loss: 0.0422 - acc: 0.9848\n",
      "Epoch 44/50\n",
      "3035/3035 [==============================] - 2s 678us/step - loss: 0.0547 - acc: 0.9822\n",
      "Epoch 45/50\n",
      "3035/3035 [==============================] - 2s 732us/step - loss: 0.0571 - acc: 0.9832\n",
      "Epoch 46/50\n",
      "3035/3035 [==============================] - 2s 698us/step - loss: 0.0403 - acc: 0.9871\n",
      "Epoch 47/50\n",
      "3035/3035 [==============================] - 2s 711us/step - loss: 0.0483 - acc: 0.9829\n",
      "Epoch 48/50\n",
      "3035/3035 [==============================] - 2s 727us/step - loss: 0.0352 - acc: 0.9891\n",
      "Epoch 49/50\n",
      "3035/3035 [==============================] - 2s 752us/step - loss: 0.0457 - acc: 0.9848\n",
      "Epoch 50/50\n",
      "3035/3035 [==============================] - 2s 780us/step - loss: 0.0340 - acc: 0.9885\n",
      "338/338 [==============================] - 0s 686us/step\n",
      "Epoch 1/50\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.2409 - acc: 0.9470\n",
      "Epoch 2/50\n",
      "3035/3035 [==============================] - 2s 700us/step - loss: 0.2022 - acc: 0.9470\n",
      "Epoch 3/50\n",
      "3035/3035 [==============================] - 2s 808us/step - loss: 0.1981 - acc: 0.9470 0s - loss: 0.1916 \n",
      "Epoch 4/50\n",
      "3035/3035 [==============================] - 2s 730us/step - loss: 0.1941 - acc: 0.9470\n",
      "Epoch 5/50\n",
      "3035/3035 [==============================] - 2s 760us/step - loss: 0.1921 - acc: 0.9470\n",
      "Epoch 6/50\n",
      "3035/3035 [==============================] - 2s 721us/step - loss: 0.1899 - acc: 0.9470\n",
      "Epoch 7/50\n",
      "3035/3035 [==============================] - 2s 719us/step - loss: 0.1866 - acc: 0.9470\n",
      "Epoch 8/50\n",
      "3035/3035 [==============================] - 2s 701us/step - loss: 0.1814 - acc: 0.9470\n",
      "Epoch 9/50\n",
      "3035/3035 [==============================] - 2s 755us/step - loss: 0.1761 - acc: 0.9470\n",
      "Epoch 10/50\n",
      "3035/3035 [==============================] - 2s 780us/step - loss: 0.1685 - acc: 0.9470\n",
      "Epoch 11/50\n",
      "3035/3035 [==============================] - 2s 770us/step - loss: 0.1556 - acc: 0.9470\n",
      "Epoch 12/50\n",
      "3035/3035 [==============================] - 2s 752us/step - loss: 0.1360 - acc: 0.9476\n",
      "Epoch 13/50\n",
      "3035/3035 [==============================] - 2s 772us/step - loss: 0.1189 - acc: 0.9549\n",
      "Epoch 14/50\n",
      "3035/3035 [==============================] - 2s 735us/step - loss: 0.1002 - acc: 0.9624 0s - loss: 0.0985 - acc:\n",
      "Epoch 15/50\n",
      "3035/3035 [==============================] - 2s 731us/step - loss: 0.0864 - acc: 0.9707\n",
      "Epoch 16/50\n",
      "3035/3035 [==============================] - 2s 706us/step - loss: 0.0693 - acc: 0.9750\n",
      "Epoch 17/50\n",
      "3035/3035 [==============================] - 2s 620us/step - loss: 0.0624 - acc: 0.9806\n",
      "Epoch 18/50\n",
      "3035/3035 [==============================] - 2s 536us/step - loss: 0.0595 - acc: 0.9806\n",
      "Epoch 19/50\n",
      "3035/3035 [==============================] - 2s 615us/step - loss: 0.0502 - acc: 0.9832\n",
      "Epoch 20/50\n",
      "3035/3035 [==============================] - 2s 537us/step - loss: 0.0491 - acc: 0.9845\n",
      "Epoch 21/50\n",
      "3035/3035 [==============================] - 2s 618us/step - loss: 0.0448 - acc: 0.9825\n",
      "Epoch 22/50\n",
      "3035/3035 [==============================] - 2s 624us/step - loss: 0.0487 - acc: 0.9835\n",
      "Epoch 23/50\n",
      "3035/3035 [==============================] - 2s 625us/step - loss: 0.0498 - acc: 0.9822\n",
      "Epoch 24/50\n",
      "3035/3035 [==============================] - 3s 830us/step - loss: 0.0513 - acc: 0.9829\n",
      "Epoch 25/50\n",
      "3035/3035 [==============================] - 2s 730us/step - loss: 0.0394 - acc: 0.9868\n",
      "Epoch 26/50\n",
      "3035/3035 [==============================] - 2s 745us/step - loss: 0.0364 - acc: 0.9871 1\n",
      "Epoch 27/50\n",
      "3035/3035 [==============================] - 3s 894us/step - loss: 0.0363 - acc: 0.9885\n",
      "Epoch 28/50\n",
      "3035/3035 [==============================] - 3s 827us/step - loss: 0.0467 - acc: 0.9848\n",
      "Epoch 29/50\n",
      "3035/3035 [==============================] - 3s 836us/step - loss: 0.0423 - acc: 0.9848\n",
      "Epoch 30/50\n",
      "3035/3035 [==============================] - 2s 809us/step - loss: 0.0516 - acc: 0.9835\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035/3035 [==============================] - 3s 855us/step - loss: 0.0488 - acc: 0.9848\n",
      "Epoch 32/50\n",
      "3035/3035 [==============================] - 2s 795us/step - loss: 0.0462 - acc: 0.9858\n",
      "Epoch 33/50\n",
      "3035/3035 [==============================] - 2s 813us/step - loss: 0.0338 - acc: 0.9901\n",
      "Epoch 34/50\n",
      "3035/3035 [==============================] - 3s 839us/step - loss: 0.0717 - acc: 0.9802\n",
      "Epoch 35/50\n",
      "3035/3035 [==============================] - 2s 784us/step - loss: 0.0564 - acc: 0.9815\n",
      "Epoch 36/50\n",
      "3035/3035 [==============================] - 2s 750us/step - loss: 0.0364 - acc: 0.9871\n",
      "Epoch 37/50\n",
      "3035/3035 [==============================] - 2s 697us/step - loss: 0.0331 - acc: 0.9908\n",
      "Epoch 38/50\n",
      "3035/3035 [==============================] - 2s 645us/step - loss: 0.0339 - acc: 0.9878\n",
      "Epoch 39/50\n",
      "3035/3035 [==============================] - 2s 605us/step - loss: 0.0392 - acc: 0.9855\n",
      "Epoch 40/50\n",
      "3035/3035 [==============================] - 2s 575us/step - loss: 0.0573 - acc: 0.9829\n",
      "Epoch 41/50\n",
      "3035/3035 [==============================] - 2s 652us/step - loss: 0.0522 - acc: 0.9832\n",
      "Epoch 42/50\n",
      "3035/3035 [==============================] - 2s 760us/step - loss: 0.0386 - acc: 0.9871\n",
      "Epoch 43/50\n",
      "3035/3035 [==============================] - 2s 656us/step - loss: 0.0382 - acc: 0.9875\n",
      "Epoch 44/50\n",
      "3035/3035 [==============================] - 2s 643us/step - loss: 0.0370 - acc: 0.9878 0s - loss: 0.0373 \n",
      "Epoch 45/50\n",
      "3035/3035 [==============================] - 2s 628us/step - loss: 0.0410 - acc: 0.9871\n",
      "Epoch 46/50\n",
      "3035/3035 [==============================] - 2s 610us/step - loss: 0.0351 - acc: 0.9865\n",
      "Epoch 47/50\n",
      "3035/3035 [==============================] - 2s 642us/step - loss: 0.0366 - acc: 0.9858\n",
      "Epoch 48/50\n",
      "3035/3035 [==============================] - 2s 659us/step - loss: 0.0381 - acc: 0.9871\n",
      "Epoch 49/50\n",
      "3035/3035 [==============================] - 2s 628us/step - loss: 0.0523 - acc: 0.9829\n",
      "Epoch 50/50\n",
      "3035/3035 [==============================] - 2s 685us/step - loss: 0.0327 - acc: 0.9898\n",
      "338/338 [==============================] - 0s 518us/step\n",
      "Epoch 1/50\n",
      "3035/3035 [==============================] - 4s 1ms/step - loss: 0.2468 - acc: 0.9470\n",
      "Epoch 2/50\n",
      "3035/3035 [==============================] - 2s 616us/step - loss: 0.2037 - acc: 0.9470\n",
      "Epoch 3/50\n",
      "3035/3035 [==============================] - 2s 498us/step - loss: 0.1990 - acc: 0.9470\n",
      "Epoch 4/50\n",
      "3035/3035 [==============================] - 2s 516us/step - loss: 0.1999 - acc: 0.9470\n",
      "Epoch 5/50\n",
      "3035/3035 [==============================] - 2s 544us/step - loss: 0.2001 - acc: 0.9470\n",
      "Epoch 6/50\n",
      "3035/3035 [==============================] - 2s 689us/step - loss: 0.1943 - acc: 0.9470 0s - loss: 0.1944 - acc: 0.94\n",
      "Epoch 7/50\n",
      "3035/3035 [==============================] - 2s 643us/step - loss: 0.1931 - acc: 0.9470 0s - loss: 0.1968 - a\n",
      "Epoch 8/50\n",
      "3035/3035 [==============================] - 2s 760us/step - loss: 0.1883 - acc: 0.9470\n",
      "Epoch 9/50\n",
      "3035/3035 [==============================] - 2s 709us/step - loss: 0.1847 - acc: 0.9470\n",
      "Epoch 10/50\n",
      "3035/3035 [==============================] - 2s 607us/step - loss: 0.1786 - acc: 0.9470\n",
      "Epoch 11/50\n",
      "3035/3035 [==============================] - 2s 727us/step - loss: 0.1692 - acc: 0.9470\n",
      "Epoch 12/50\n",
      "3035/3035 [==============================] - 2s 683us/step - loss: 0.1452 - acc: 0.9470\n",
      "Epoch 13/50\n",
      "3035/3035 [==============================] - 2s 582us/step - loss: 0.1488 - acc: 0.9493\n",
      "Epoch 14/50\n",
      "3035/3035 [==============================] - 2s 676us/step - loss: 0.1068 - acc: 0.9516\n",
      "Epoch 15/50\n",
      "3035/3035 [==============================] - 2s 644us/step - loss: 0.0935 - acc: 0.9657\n",
      "Epoch 16/50\n",
      "3035/3035 [==============================] - 2s 623us/step - loss: 0.0780 - acc: 0.9717\n",
      "Epoch 17/50\n",
      "3035/3035 [==============================] - 2s 645us/step - loss: 0.0674 - acc: 0.9789\n",
      "Epoch 18/50\n",
      "3035/3035 [==============================] - 2s 622us/step - loss: 0.0610 - acc: 0.9802\n",
      "Epoch 19/50\n",
      "3035/3035 [==============================] - 2s 642us/step - loss: 0.0497 - acc: 0.9845\n",
      "Epoch 20/50\n",
      "3035/3035 [==============================] - 1s 468us/step - loss: 0.0472 - acc: 0.9848\n",
      "Epoch 21/50\n",
      "3035/3035 [==============================] - 1s 464us/step - loss: 0.0448 - acc: 0.9839\n",
      "Epoch 22/50\n",
      "3035/3035 [==============================] - 2s 566us/step - loss: 0.0564 - acc: 0.9799\n",
      "Epoch 23/50\n",
      "3035/3035 [==============================] - 1s 484us/step - loss: 0.0512 - acc: 0.9825\n",
      "Epoch 24/50\n",
      "3035/3035 [==============================] - 2s 678us/step - loss: 0.0402 - acc: 0.9858\n",
      "Epoch 25/50\n",
      "3035/3035 [==============================] - 2s 611us/step - loss: 0.0387 - acc: 0.9845\n",
      "Epoch 26/50\n",
      "3035/3035 [==============================] - 2s 680us/step - loss: 0.0436 - acc: 0.9832\n",
      "Epoch 27/50\n",
      "3035/3035 [==============================] - 2s 618us/step - loss: 0.0534 - acc: 0.9819 1s - loss: 0.03\n",
      "Epoch 28/50\n",
      "3035/3035 [==============================] - 2s 564us/step - loss: 0.0560 - acc: 0.9825\n",
      "Epoch 29/50\n",
      "3035/3035 [==============================] - 2s 564us/step - loss: 0.0439 - acc: 0.9835\n",
      "Epoch 30/50\n",
      "3035/3035 [==============================] - 2s 590us/step - loss: 0.0604 - acc: 0.9806\n",
      "Epoch 31/50\n",
      "3035/3035 [==============================] - 2s 591us/step - loss: 0.0436 - acc: 0.9855\n",
      "Epoch 32/50\n",
      "3035/3035 [==============================] - 2s 628us/step - loss: 0.0353 - acc: 0.9891\n",
      "Epoch 33/50\n",
      "3035/3035 [==============================] - 2s 672us/step - loss: 0.0444 - acc: 0.9825\n",
      "Epoch 34/50\n",
      "3035/3035 [==============================] - 2s 602us/step - loss: 0.0352 - acc: 0.9895\n",
      "Epoch 35/50\n",
      "3035/3035 [==============================] - 2s 559us/step - loss: 0.0452 - acc: 0.9848\n",
      "Epoch 36/50\n",
      "3035/3035 [==============================] - 2s 590us/step - loss: 0.0488 - acc: 0.9839\n",
      "Epoch 37/50\n",
      "3035/3035 [==============================] - 2s 618us/step - loss: 0.0350 - acc: 0.9881\n",
      "Epoch 38/50\n",
      "3035/3035 [==============================] - 2s 710us/step - loss: 0.0378 - acc: 0.9862\n",
      "Epoch 39/50\n",
      "3035/3035 [==============================] - 2s 746us/step - loss: 0.0397 - acc: 0.9858\n",
      "Epoch 40/50\n",
      "3035/3035 [==============================] - 2s 653us/step - loss: 0.0442 - acc: 0.9835\n",
      "Epoch 41/50\n",
      "3035/3035 [==============================] - 2s 759us/step - loss: 0.0569 - acc: 0.9822\n",
      "Epoch 42/50\n",
      "3035/3035 [==============================] - 2s 699us/step - loss: 0.0360 - acc: 0.9888\n",
      "Epoch 43/50\n",
      "3035/3035 [==============================] - 2s 703us/step - loss: 0.0377 - acc: 0.9881\n",
      "Epoch 44/50\n",
      "3035/3035 [==============================] - 2s 557us/step - loss: 0.0469 - acc: 0.9848\n",
      "Epoch 45/50\n",
      "3035/3035 [==============================] - 2s 512us/step - loss: 0.0356 - acc: 0.9875\n",
      "Epoch 46/50\n",
      "3035/3035 [==============================] - 2s 532us/step - loss: 0.0387 - acc: 0.9881\n",
      "Epoch 47/50\n",
      "3035/3035 [==============================] - 2s 565us/step - loss: 0.0368 - acc: 0.9891\n",
      "Epoch 48/50\n",
      "3035/3035 [==============================] - 2s 622us/step - loss: 0.0364 - acc: 0.9862\n",
      "Epoch 49/50\n",
      "3035/3035 [==============================] - 2s 589us/step - loss: 0.0442 - acc: 0.9852\n",
      "Epoch 50/50\n",
      "3035/3035 [==============================] - 2s 600us/step - loss: 0.0503 - acc: 0.9839\n",
      "338/338 [==============================] - 0s 824us/step\n",
      "Epoch 1/50\n",
      "3036/3036 [==============================] - 5s 2ms/step - loss: 0.2377 - acc: 0.9450\n",
      "Epoch 2/50\n",
      "3036/3036 [==============================] - 2s 665us/step - loss: 0.1942 - acc: 0.9499\n",
      "Epoch 3/50\n",
      "3036/3036 [==============================] - 2s 649us/step - loss: 0.1912 - acc: 0.9499\n",
      "Epoch 4/50\n",
      "3036/3036 [==============================] - 2s 652us/step - loss: 0.1926 - acc: 0.9499 0s - loss: 0.1909 \n",
      "Epoch 5/50\n",
      "3036/3036 [==============================] - 2s 688us/step - loss: 0.1860 - acc: 0.9499\n",
      "Epoch 6/50\n",
      "3036/3036 [==============================] - 2s 776us/step - loss: 0.1827 - acc: 0.9499\n",
      "Epoch 7/50\n",
      "3036/3036 [==============================] - 2s 639us/step - loss: 0.1805 - acc: 0.9499\n",
      "Epoch 8/50\n",
      "3036/3036 [==============================] - 2s 709us/step - loss: 0.1755 - acc: 0.9499\n",
      "Epoch 9/50\n",
      "3036/3036 [==============================] - 2s 701us/step - loss: 0.1685 - acc: 0.9499\n",
      "Epoch 10/50\n",
      "3036/3036 [==============================] - 2s 621us/step - loss: 0.1626 - acc: 0.9499\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3036/3036 [==============================] - 2s 599us/step - loss: 0.1476 - acc: 0.9499 1s -\n",
      "Epoch 12/50\n",
      "3036/3036 [==============================] - 2s 662us/step - loss: 0.1292 - acc: 0.9499\n",
      "Epoch 13/50\n",
      "3036/3036 [==============================] - 2s 619us/step - loss: 0.1202 - acc: 0.9529\n",
      "Epoch 14/50\n",
      "3036/3036 [==============================] - 2s 624us/step - loss: 0.0991 - acc: 0.9634\n",
      "Epoch 15/50\n",
      "3036/3036 [==============================] - 2s 663us/step - loss: 0.0819 - acc: 0.9704\n",
      "Epoch 16/50\n",
      "3036/3036 [==============================] - 2s 665us/step - loss: 0.0798 - acc: 0.9740\n",
      "Epoch 17/50\n",
      "3036/3036 [==============================] - 2s 798us/step - loss: 0.0818 - acc: 0.9740\n",
      "Epoch 18/50\n",
      "3036/3036 [==============================] - 2s 751us/step - loss: 0.0779 - acc: 0.9746\n",
      "Epoch 19/50\n",
      "3036/3036 [==============================] - 2s 735us/step - loss: 0.0491 - acc: 0.9848\n",
      "Epoch 20/50\n",
      "3036/3036 [==============================] - 2s 734us/step - loss: 0.0467 - acc: 0.9862\n",
      "Epoch 21/50\n",
      "3036/3036 [==============================] - 2s 737us/step - loss: 0.0466 - acc: 0.9842\n",
      "Epoch 22/50\n",
      "3036/3036 [==============================] - 2s 646us/step - loss: 0.0498 - acc: 0.9835 1s\n",
      "Epoch 23/50\n",
      "3036/3036 [==============================] - 2s 609us/step - loss: 0.0413 - acc: 0.9858\n",
      "Epoch 24/50\n",
      "3036/3036 [==============================] - 2s 542us/step - loss: 0.0403 - acc: 0.9855\n",
      "Epoch 25/50\n",
      "3036/3036 [==============================] - 2s 562us/step - loss: 0.0555 - acc: 0.9822\n",
      "Epoch 26/50\n",
      "3036/3036 [==============================] - 2s 547us/step - loss: 0.0558 - acc: 0.9816\n",
      "Epoch 27/50\n",
      "3036/3036 [==============================] - 2s 642us/step - loss: 0.0643 - acc: 0.9783\n",
      "Epoch 28/50\n",
      "3036/3036 [==============================] - 2s 692us/step - loss: 0.0391 - acc: 0.9868\n",
      "Epoch 29/50\n",
      "3036/3036 [==============================] - 2s 688us/step - loss: 0.0508 - acc: 0.9816\n",
      "Epoch 30/50\n",
      "3036/3036 [==============================] - 2s 633us/step - loss: 0.0477 - acc: 0.9852\n",
      "Epoch 31/50\n",
      "3036/3036 [==============================] - 2s 529us/step - loss: 0.0421 - acc: 0.9845\n",
      "Epoch 32/50\n",
      "3036/3036 [==============================] - 2s 555us/step - loss: 0.0343 - acc: 0.9901\n",
      "Epoch 33/50\n",
      "3036/3036 [==============================] - 2s 609us/step - loss: 0.0462 - acc: 0.9832\n",
      "Epoch 34/50\n",
      "3036/3036 [==============================] - 2s 588us/step - loss: 0.0387 - acc: 0.9865\n",
      "Epoch 35/50\n",
      "3036/3036 [==============================] - 2s 644us/step - loss: 0.0454 - acc: 0.9848\n",
      "Epoch 36/50\n",
      "3036/3036 [==============================] - 2s 698us/step - loss: 0.0623 - acc: 0.9809\n",
      "Epoch 37/50\n",
      "3036/3036 [==============================] - 2s 651us/step - loss: 0.0394 - acc: 0.9848\n",
      "Epoch 38/50\n",
      "3036/3036 [==============================] - 2s 617us/step - loss: 0.0338 - acc: 0.9885\n",
      "Epoch 39/50\n",
      "3036/3036 [==============================] - 2s 661us/step - loss: 0.0340 - acc: 0.9875\n",
      "Epoch 40/50\n",
      "3036/3036 [==============================] - 2s 516us/step - loss: 0.0375 - acc: 0.9872\n",
      "Epoch 41/50\n",
      "3036/3036 [==============================] - 2s 632us/step - loss: 0.0377 - acc: 0.9852\n",
      "Epoch 42/50\n",
      "3036/3036 [==============================] - 2s 703us/step - loss: 0.0373 - acc: 0.9868\n",
      "Epoch 43/50\n",
      "3036/3036 [==============================] - 2s 631us/step - loss: 0.0340 - acc: 0.9891\n",
      "Epoch 44/50\n",
      "3036/3036 [==============================] - 2s 649us/step - loss: 0.0327 - acc: 0.9904\n",
      "Epoch 45/50\n",
      "3036/3036 [==============================] - 2s 627us/step - loss: 0.0449 - acc: 0.9855\n",
      "Epoch 46/50\n",
      "3036/3036 [==============================] - 2s 692us/step - loss: 0.0346 - acc: 0.9868\n",
      "Epoch 47/50\n",
      "3036/3036 [==============================] - 2s 708us/step - loss: 0.0408 - acc: 0.9865\n",
      "Epoch 48/50\n",
      "3036/3036 [==============================] - 2s 752us/step - loss: 0.0443 - acc: 0.9858\n",
      "Epoch 49/50\n",
      "3036/3036 [==============================] - 2s 729us/step - loss: 0.0345 - acc: 0.9881\n",
      "Epoch 50/50\n",
      "3036/3036 [==============================] - 2s 815us/step - loss: 0.0524 - acc: 0.9822\n",
      "337/337 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "3036/3036 [==============================] - 4s 1ms/step - loss: 0.2444 - acc: 0.9470\n",
      "Epoch 2/50\n",
      "3036/3036 [==============================] - 2s 652us/step - loss: 0.2020 - acc: 0.9470 0s - loss: 0.2040 - acc: \n",
      "Epoch 3/50\n",
      "3036/3036 [==============================] - 2s 598us/step - loss: 0.1964 - acc: 0.9470\n",
      "Epoch 4/50\n",
      "3036/3036 [==============================] - 2s 658us/step - loss: 0.1955 - acc: 0.9470\n",
      "Epoch 5/50\n",
      "3036/3036 [==============================] - 2s 753us/step - loss: 0.1900 - acc: 0.9470\n",
      "Epoch 6/50\n",
      "3036/3036 [==============================] - 2s 613us/step - loss: 0.1877 - acc: 0.9470\n",
      "Epoch 7/50\n",
      "3036/3036 [==============================] - 2s 626us/step - loss: 0.1873 - acc: 0.9470\n",
      "Epoch 8/50\n",
      "3036/3036 [==============================] - 2s 631us/step - loss: 0.1774 - acc: 0.9470\n",
      "Epoch 9/50\n",
      "3036/3036 [==============================] - 2s 711us/step - loss: 0.1696 - acc: 0.9470\n",
      "Epoch 10/50\n",
      "3036/3036 [==============================] - 2s 638us/step - loss: 0.1593 - acc: 0.9470\n",
      "Epoch 11/50\n",
      "3036/3036 [==============================] - 2s 553us/step - loss: 0.1487 - acc: 0.9473\n",
      "Epoch 12/50\n",
      "3036/3036 [==============================] - 2s 710us/step - loss: 0.1220 - acc: 0.9522 0s - loss: 0.1181 - acc\n",
      "Epoch 13/50\n",
      "3036/3036 [==============================] - 2s 659us/step - loss: 0.1070 - acc: 0.9595\n",
      "Epoch 14/50\n",
      "3036/3036 [==============================] - 2s 574us/step - loss: 0.0771 - acc: 0.9730\n",
      "Epoch 15/50\n",
      "3036/3036 [==============================] - 2s 552us/step - loss: 0.0695 - acc: 0.9773\n",
      "Epoch 16/50\n",
      "3036/3036 [==============================] - 2s 512us/step - loss: 0.0540 - acc: 0.9832\n",
      "Epoch 17/50\n",
      "3036/3036 [==============================] - 1s 487us/step - loss: 0.0703 - acc: 0.9792\n",
      "Epoch 18/50\n",
      "3036/3036 [==============================] - 1s 475us/step - loss: 0.0543 - acc: 0.9816\n",
      "Epoch 19/50\n",
      "3036/3036 [==============================] - 2s 577us/step - loss: 0.0468 - acc: 0.9835\n",
      "Epoch 20/50\n",
      "3036/3036 [==============================] - 2s 550us/step - loss: 0.0436 - acc: 0.9835\n",
      "Epoch 21/50\n",
      "3036/3036 [==============================] - 2s 599us/step - loss: 0.0422 - acc: 0.9845 1s -\n",
      "Epoch 22/50\n",
      "3036/3036 [==============================] - 2s 627us/step - loss: 0.0413 - acc: 0.9845\n",
      "Epoch 23/50\n",
      "3036/3036 [==============================] - 2s 656us/step - loss: 0.0415 - acc: 0.9862\n",
      "Epoch 24/50\n",
      "3036/3036 [==============================] - 2s 634us/step - loss: 0.0428 - acc: 0.9858\n",
      "Epoch 25/50\n",
      "3036/3036 [==============================] - 2s 565us/step - loss: 0.0473 - acc: 0.9845\n",
      "Epoch 26/50\n",
      "3036/3036 [==============================] - 2s 677us/step - loss: 0.0361 - acc: 0.9868\n",
      "Epoch 27/50\n",
      "3036/3036 [==============================] - 2s 617us/step - loss: 0.0612 - acc: 0.9789\n",
      "Epoch 28/50\n",
      "3036/3036 [==============================] - 2s 745us/step - loss: 0.0409 - acc: 0.9852\n",
      "Epoch 29/50\n",
      "3036/3036 [==============================] - 2s 709us/step - loss: 0.0399 - acc: 0.9878\n",
      "Epoch 30/50\n",
      "3036/3036 [==============================] - 2s 649us/step - loss: 0.0359 - acc: 0.9868\n",
      "Epoch 31/50\n",
      "3036/3036 [==============================] - 2s 587us/step - loss: 0.0328 - acc: 0.9895\n",
      "Epoch 32/50\n",
      "3036/3036 [==============================] - 2s 666us/step - loss: 0.0393 - acc: 0.9868\n",
      "Epoch 33/50\n",
      "3036/3036 [==============================] - 2s 677us/step - loss: 0.0385 - acc: 0.9885\n",
      "Epoch 34/50\n",
      "3036/3036 [==============================] - 2s 683us/step - loss: 0.0428 - acc: 0.9835 0s - loss: 0.0429 - acc: 0.\n",
      "Epoch 35/50\n",
      "3036/3036 [==============================] - 2s 648us/step - loss: 0.0478 - acc: 0.9839\n",
      "Epoch 36/50\n",
      "3036/3036 [==============================] - 2s 687us/step - loss: 0.0326 - acc: 0.9881\n",
      "Epoch 37/50\n",
      "3036/3036 [==============================] - 2s 619us/step - loss: 0.0517 - acc: 0.9822\n",
      "Epoch 38/50\n",
      "3036/3036 [==============================] - 2s 795us/step - loss: 0.0399 - acc: 0.9858 1s\n",
      "Epoch 39/50\n",
      "3036/3036 [==============================] - 2s 653us/step - loss: 0.0393 - acc: 0.9878\n",
      "Epoch 40/50\n",
      "3036/3036 [==============================] - 2s 654us/step - loss: 0.0299 - acc: 0.9898\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3036/3036 [==============================] - 2s 754us/step - loss: 0.0317 - acc: 0.9901 2\n",
      "Epoch 42/50\n",
      "3036/3036 [==============================] - 2s 762us/step - loss: 0.0478 - acc: 0.9822\n",
      "Epoch 43/50\n",
      "3036/3036 [==============================] - 2s 740us/step - loss: 0.0414 - acc: 0.9862\n",
      "Epoch 44/50\n",
      "3036/3036 [==============================] - 2s 625us/step - loss: 0.0347 - acc: 0.9872\n",
      "Epoch 45/50\n",
      "3036/3036 [==============================] - 2s 731us/step - loss: 0.0354 - acc: 0.9885\n",
      "Epoch 46/50\n",
      "3036/3036 [==============================] - 2s 711us/step - loss: 0.0409 - acc: 0.9878 0s - loss: 0.0412 - acc: 0.98\n",
      "Epoch 47/50\n",
      "3036/3036 [==============================] - 2s 780us/step - loss: 0.0337 - acc: 0.9881 2s - loss: 0.0199 - ac - ETA: 1s - lo\n",
      "Epoch 48/50\n",
      "3036/3036 [==============================] - 2s 719us/step - loss: 0.0303 - acc: 0.9878\n",
      "Epoch 49/50\n",
      "3036/3036 [==============================] - 2s 751us/step - loss: 0.0351 - acc: 0.9891\n",
      "Epoch 50/50\n",
      "3036/3036 [==============================] - 2s 621us/step - loss: 0.0349 - acc: 0.9875\n",
      "337/337 [==============================] - 0s 533us/step\n",
      "Epoch 1/50\n",
      "3036/3036 [==============================] - 4s 1ms/step - loss: 0.2461 - acc: 0.9394\n",
      "Epoch 2/50\n",
      "3036/3036 [==============================] - 2s 605us/step - loss: 0.1994 - acc: 0.9486\n",
      "Epoch 3/50\n",
      "3036/3036 [==============================] - 2s 574us/step - loss: 0.1937 - acc: 0.9486\n",
      "Epoch 4/50\n",
      "3036/3036 [==============================] - 2s 584us/step - loss: 0.1958 - acc: 0.9486\n",
      "Epoch 5/50\n",
      "3036/3036 [==============================] - 2s 731us/step - loss: 0.1893 - acc: 0.9486\n",
      "Epoch 6/50\n",
      "3036/3036 [==============================] - 2s 753us/step - loss: 0.1865 - acc: 0.9486\n",
      "Epoch 7/50\n",
      "3036/3036 [==============================] - 2s 686us/step - loss: 0.1862 - acc: 0.9486\n",
      "Epoch 8/50\n",
      "3036/3036 [==============================] - 2s 589us/step - loss: 0.1851 - acc: 0.9486\n",
      "Epoch 9/50\n",
      "3036/3036 [==============================] - 2s 679us/step - loss: 0.1761 - acc: 0.9486\n",
      "Epoch 10/50\n",
      "3036/3036 [==============================] - 2s 635us/step - loss: 0.1761 - acc: 0.9486\n",
      "Epoch 11/50\n",
      "3036/3036 [==============================] - 2s 675us/step - loss: 0.1687 - acc: 0.9486\n",
      "Epoch 12/50\n",
      "3036/3036 [==============================] - 2s 629us/step - loss: 0.1538 - acc: 0.9486\n",
      "Epoch 13/50\n",
      "3036/3036 [==============================] - 2s 640us/step - loss: 0.1333 - acc: 0.9486\n",
      "Epoch 14/50\n",
      "3036/3036 [==============================] - 2s 614us/step - loss: 0.1174 - acc: 0.9562\n",
      "Epoch 15/50\n",
      "3036/3036 [==============================] - 2s 659us/step - loss: 0.0851 - acc: 0.9697\n",
      "Epoch 16/50\n",
      "3036/3036 [==============================] - 2s 657us/step - loss: 0.0959 - acc: 0.9694\n",
      "Epoch 17/50\n",
      "3036/3036 [==============================] - 2s 675us/step - loss: 0.0670 - acc: 0.9792\n",
      "Epoch 18/50\n",
      "3036/3036 [==============================] - 2s 648us/step - loss: 0.0525 - acc: 0.9839\n",
      "Epoch 19/50\n",
      "3036/3036 [==============================] - 2s 708us/step - loss: 0.0534 - acc: 0.9842\n",
      "Epoch 20/50\n",
      "3036/3036 [==============================] - 2s 662us/step - loss: 0.0723 - acc: 0.9753\n",
      "Epoch 21/50\n",
      "3036/3036 [==============================] - 2s 600us/step - loss: 0.0501 - acc: 0.9816\n",
      "Epoch 22/50\n",
      "3036/3036 [==============================] - 2s 603us/step - loss: 0.0501 - acc: 0.9832\n",
      "Epoch 23/50\n",
      "3036/3036 [==============================] - 2s 602us/step - loss: 0.0526 - acc: 0.9832\n",
      "Epoch 24/50\n",
      "3036/3036 [==============================] - 2s 686us/step - loss: 0.0393 - acc: 0.9865 1\n",
      "Epoch 25/50\n",
      "3036/3036 [==============================] - 2s 540us/step - loss: 0.0474 - acc: 0.9852\n",
      "Epoch 26/50\n",
      "3036/3036 [==============================] - 2s 522us/step - loss: 0.0504 - acc: 0.9806\n",
      "Epoch 27/50\n",
      "3036/3036 [==============================] - 2s 563us/step - loss: 0.0397 - acc: 0.9872\n",
      "Epoch 28/50\n",
      "3036/3036 [==============================] - 2s 508us/step - loss: 0.0474 - acc: 0.9848\n",
      "Epoch 29/50\n",
      "3036/3036 [==============================] - 2s 553us/step - loss: 0.0550 - acc: 0.9792\n",
      "Epoch 30/50\n",
      "3036/3036 [==============================] - 2s 597us/step - loss: 0.0523 - acc: 0.9845\n",
      "Epoch 31/50\n",
      "3036/3036 [==============================] - 2s 667us/step - loss: 0.0437 - acc: 0.9855\n",
      "Epoch 32/50\n",
      "3036/3036 [==============================] - 2s 777us/step - loss: 0.0408 - acc: 0.9858\n",
      "Epoch 33/50\n",
      "3036/3036 [==============================] - 3s 896us/step - loss: 0.0396 - acc: 0.9862\n",
      "Epoch 34/50\n",
      "3036/3036 [==============================] - 2s 821us/step - loss: 0.0391 - acc: 0.9875\n",
      "Epoch 35/50\n",
      "3036/3036 [==============================] - 2s 784us/step - loss: 0.0377 - acc: 0.9862\n",
      "Epoch 36/50\n",
      "3036/3036 [==============================] - 3s 825us/step - loss: 0.0436 - acc: 0.9858 0s - loss: 0.0424 - acc: 0\n",
      "Epoch 37/50\n",
      "3036/3036 [==============================] - 2s 746us/step - loss: 0.0366 - acc: 0.9881\n",
      "Epoch 38/50\n",
      "3036/3036 [==============================] - 2s 696us/step - loss: 0.0374 - acc: 0.9891\n",
      "Epoch 39/50\n",
      "3036/3036 [==============================] - 2s 758us/step - loss: 0.0423 - acc: 0.9829\n",
      "Epoch 40/50\n",
      "3036/3036 [==============================] - 2s 752us/step - loss: 0.0362 - acc: 0.9848\n",
      "Epoch 41/50\n",
      "3036/3036 [==============================] - 2s 669us/step - loss: 0.0454 - acc: 0.9848\n",
      "Epoch 42/50\n",
      "3036/3036 [==============================] - 2s 636us/step - loss: 0.0385 - acc: 0.9875\n",
      "Epoch 43/50\n",
      "3036/3036 [==============================] - 2s 598us/step - loss: 0.0377 - acc: 0.9875\n",
      "Epoch 44/50\n",
      "3036/3036 [==============================] - 2s 588us/step - loss: 0.0499 - acc: 0.9825\n",
      "Epoch 45/50\n",
      "3036/3036 [==============================] - 2s 684us/step - loss: 0.0502 - acc: 0.9845\n",
      "Epoch 46/50\n",
      "3036/3036 [==============================] - 2s 750us/step - loss: 0.0325 - acc: 0.9885\n",
      "Epoch 47/50\n",
      "3036/3036 [==============================] - 2s 756us/step - loss: 0.0479 - acc: 0.9852\n",
      "Epoch 48/50\n",
      "3036/3036 [==============================] - 2s 712us/step - loss: 0.0441 - acc: 0.9855\n",
      "Epoch 49/50\n",
      "3036/3036 [==============================] - 2s 759us/step - loss: 0.0442 - acc: 0.9832\n",
      "Epoch 50/50\n",
      "3036/3036 [==============================] - 2s 736us/step - loss: 0.0368 - acc: 0.9881\n",
      "337/337 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "3036/3036 [==============================] - 5s 2ms/step - loss: 0.2509 - acc: 0.9480\n",
      "Epoch 2/50\n",
      "3036/3036 [==============================] - 2s 689us/step - loss: 0.2008 - acc: 0.9480\n",
      "Epoch 3/50\n",
      "3036/3036 [==============================] - 2s 774us/step - loss: 0.2002 - acc: 0.9480\n",
      "Epoch 4/50\n",
      "3036/3036 [==============================] - 2s 769us/step - loss: 0.1962 - acc: 0.9480\n",
      "Epoch 5/50\n",
      "3036/3036 [==============================] - 2s 737us/step - loss: 0.1933 - acc: 0.9480\n",
      "Epoch 6/50\n",
      "3036/3036 [==============================] - 2s 743us/step - loss: 0.1896 - acc: 0.9480\n",
      "Epoch 7/50\n",
      "3036/3036 [==============================] - 3s 831us/step - loss: 0.1911 - acc: 0.9480\n",
      "Epoch 8/50\n",
      "3036/3036 [==============================] - 3s 904us/step - loss: 0.1881 - acc: 0.9480\n",
      "Epoch 9/50\n",
      "3036/3036 [==============================] - 2s 810us/step - loss: 0.1806 - acc: 0.9480\n",
      "Epoch 10/50\n",
      "3036/3036 [==============================] - 3s 863us/step - loss: 0.1728 - acc: 0.9480\n",
      "Epoch 11/50\n",
      "3036/3036 [==============================] - 2s 662us/step - loss: 0.1730 - acc: 0.9480\n",
      "Epoch 12/50\n",
      "3036/3036 [==============================] - 2s 769us/step - loss: 0.1552 - acc: 0.9480\n",
      "Epoch 13/50\n",
      "3036/3036 [==============================] - 2s 736us/step - loss: 0.1370 - acc: 0.9480 0s - loss: 0.1469 - acc\n",
      "Epoch 14/50\n",
      "3036/3036 [==============================] - 2s 684us/step - loss: 0.1120 - acc: 0.9565\n",
      "Epoch 15/50\n",
      "3036/3036 [==============================] - 2s 737us/step - loss: 0.0861 - acc: 0.9704\n",
      "Epoch 16/50\n",
      "3036/3036 [==============================] - 2s 765us/step - loss: 0.0955 - acc: 0.9694\n",
      "Epoch 17/50\n",
      "3036/3036 [==============================] - 2s 712us/step - loss: 0.0682 - acc: 0.9760\n",
      "Epoch 18/50\n",
      "3036/3036 [==============================] - 2s 677us/step - loss: 0.0533 - acc: 0.9799\n",
      "Epoch 19/50\n",
      "3036/3036 [==============================] - 2s 617us/step - loss: 0.0508 - acc: 0.9822\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3036/3036 [==============================] - 2s 810us/step - loss: 0.0479 - acc: 0.9839\n",
      "Epoch 21/50\n",
      "3036/3036 [==============================] - 2s 767us/step - loss: 0.0750 - acc: 0.9753\n",
      "Epoch 22/50\n",
      "3036/3036 [==============================] - 2s 779us/step - loss: 0.0462 - acc: 0.9855\n",
      "Epoch 23/50\n",
      "3036/3036 [==============================] - 2s 733us/step - loss: 0.0375 - acc: 0.9878\n",
      "Epoch 24/50\n",
      "3036/3036 [==============================] - 2s 630us/step - loss: 0.0477 - acc: 0.9839\n",
      "Epoch 25/50\n",
      "3036/3036 [==============================] - 2s 599us/step - loss: 0.0394 - acc: 0.9865\n",
      "Epoch 26/50\n",
      "3036/3036 [==============================] - 2s 631us/step - loss: 0.0476 - acc: 0.9842\n",
      "Epoch 27/50\n",
      "3036/3036 [==============================] - 2s 531us/step - loss: 0.0505 - acc: 0.9809\n",
      "Epoch 28/50\n",
      "3036/3036 [==============================] - 2s 590us/step - loss: 0.0517 - acc: 0.9812\n",
      "Epoch 29/50\n",
      "3036/3036 [==============================] - 2s 561us/step - loss: 0.0492 - acc: 0.9852\n",
      "Epoch 30/50\n",
      "3036/3036 [==============================] - 2s 550us/step - loss: 0.0384 - acc: 0.9865\n",
      "Epoch 31/50\n",
      "3036/3036 [==============================] - 2s 587us/step - loss: 0.0332 - acc: 0.9904\n",
      "Epoch 32/50\n",
      "3036/3036 [==============================] - 2s 657us/step - loss: 0.0380 - acc: 0.9872 0s - loss: 0.041\n",
      "Epoch 33/50\n",
      "3036/3036 [==============================] - 2s 717us/step - loss: 0.0535 - acc: 0.9809\n",
      "Epoch 34/50\n",
      "3036/3036 [==============================] - 2s 711us/step - loss: 0.0401 - acc: 0.9865\n",
      "Epoch 35/50\n",
      "3036/3036 [==============================] - 2s 779us/step - loss: 0.0378 - acc: 0.9868\n",
      "Epoch 36/50\n",
      "3036/3036 [==============================] - 3s 867us/step - loss: 0.0567 - acc: 0.9799\n",
      "Epoch 37/50\n",
      "3036/3036 [==============================] - 3s 901us/step - loss: 0.0369 - acc: 0.9868\n",
      "Epoch 38/50\n",
      "3036/3036 [==============================] - 2s 822us/step - loss: 0.0349 - acc: 0.9904\n",
      "Epoch 39/50\n",
      "3036/3036 [==============================] - 2s 668us/step - loss: 0.0362 - acc: 0.9878\n",
      "Epoch 40/50\n",
      "3036/3036 [==============================] - 2s 728us/step - loss: 0.0399 - acc: 0.9868\n",
      "Epoch 41/50\n",
      "3036/3036 [==============================] - 2s 679us/step - loss: 0.0329 - acc: 0.9891\n",
      "Epoch 42/50\n",
      "3036/3036 [==============================] - 2s 784us/step - loss: 0.0485 - acc: 0.9825 0s - loss: 0.0425 - acc: 0 - ETA: 0s - loss: 0.0480 - ac\n",
      "Epoch 43/50\n",
      "3036/3036 [==============================] - 2s 735us/step - loss: 0.0336 - acc: 0.9891\n",
      "Epoch 44/50\n",
      "3036/3036 [==============================] - 2s 741us/step - loss: 0.0361 - acc: 0.9872\n",
      "Epoch 45/50\n",
      "3036/3036 [==============================] - 2s 752us/step - loss: 0.0358 - acc: 0.9875\n",
      "Epoch 46/50\n",
      "3036/3036 [==============================] - 2s 731us/step - loss: 0.0508 - acc: 0.9819\n",
      "Epoch 47/50\n",
      "3036/3036 [==============================] - 2s 703us/step - loss: 0.0373 - acc: 0.9901\n",
      "Epoch 48/50\n",
      "3036/3036 [==============================] - 2s 744us/step - loss: 0.0394 - acc: 0.9868\n",
      "Epoch 49/50\n",
      "3036/3036 [==============================] - 2s 721us/step - loss: 0.0398 - acc: 0.9865\n",
      "Epoch 50/50\n",
      "3036/3036 [==============================] - 2s 737us/step - loss: 0.0363 - acc: 0.9898\n",
      "337/337 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "3036/3036 [==============================] - 5s 2ms/step - loss: 0.2536 - acc: 0.9361\n",
      "Epoch 2/50\n",
      "3036/3036 [==============================] - 2s 695us/step - loss: 0.2060 - acc: 0.9453\n",
      "Epoch 3/50\n",
      "3036/3036 [==============================] - 2s 732us/step - loss: 0.2043 - acc: 0.9453\n",
      "Epoch 4/50\n",
      "3036/3036 [==============================] - 2s 706us/step - loss: 0.2010 - acc: 0.9453\n",
      "Epoch 5/50\n",
      "3036/3036 [==============================] - 2s 716us/step - loss: 0.1989 - acc: 0.9453\n",
      "Epoch 6/50\n",
      "3036/3036 [==============================] - 2s 750us/step - loss: 0.1975 - acc: 0.9453\n",
      "Epoch 7/50\n",
      "3036/3036 [==============================] - 2s 710us/step - loss: 0.1930 - acc: 0.9453\n",
      "Epoch 8/50\n",
      "3036/3036 [==============================] - ETA: 0s - loss: 0.1899 - acc: 0.945 - 2s 785us/step - loss: 0.1895 - acc: 0.9453\n",
      "Epoch 9/50\n",
      "3036/3036 [==============================] - 2s 819us/step - loss: 0.1889 - acc: 0.9453\n",
      "Epoch 10/50\n",
      "3036/3036 [==============================] - 3s 828us/step - loss: 0.1782 - acc: 0.9453\n",
      "Epoch 11/50\n",
      "3036/3036 [==============================] - 3s 837us/step - loss: 0.1705 - acc: 0.9453\n",
      "Epoch 12/50\n",
      "3036/3036 [==============================] - 2s 730us/step - loss: 0.1456 - acc: 0.9453\n",
      "Epoch 13/50\n",
      "3036/3036 [==============================] - 2s 738us/step - loss: 0.1124 - acc: 0.9519\n",
      "Epoch 14/50\n",
      "3036/3036 [==============================] - 2s 730us/step - loss: 0.0945 - acc: 0.9674\n",
      "Epoch 15/50\n",
      "3036/3036 [==============================] - 2s 715us/step - loss: 0.0793 - acc: 0.9743\n",
      "Epoch 16/50\n",
      "3036/3036 [==============================] - 2s 656us/step - loss: 0.0580 - acc: 0.9806\n",
      "Epoch 17/50\n",
      "3036/3036 [==============================] - 2s 647us/step - loss: 0.0492 - acc: 0.9835\n",
      "Epoch 18/50\n",
      "3036/3036 [==============================] - 2s 685us/step - loss: 0.0545 - acc: 0.9839\n",
      "Epoch 19/50\n",
      "3036/3036 [==============================] - 2s 582us/step - loss: 0.0647 - acc: 0.9792\n",
      "Epoch 20/50\n",
      "3036/3036 [==============================] - 2s 575us/step - loss: 0.0505 - acc: 0.9796\n",
      "Epoch 21/50\n",
      "3036/3036 [==============================] - 2s 527us/step - loss: 0.0460 - acc: 0.9829\n",
      "Epoch 22/50\n",
      "3036/3036 [==============================] - 1s 483us/step - loss: 0.0416 - acc: 0.9832\n",
      "Epoch 23/50\n",
      "3036/3036 [==============================] - 2s 599us/step - loss: 0.0419 - acc: 0.9862\n",
      "Epoch 24/50\n",
      "3036/3036 [==============================] - 2s 610us/step - loss: 0.0388 - acc: 0.9835\n",
      "Epoch 25/50\n",
      "3036/3036 [==============================] - 2s 635us/step - loss: 0.0434 - acc: 0.9848\n",
      "Epoch 26/50\n",
      "3036/3036 [==============================] - 2s 643us/step - loss: 0.0572 - acc: 0.9812\n",
      "Epoch 27/50\n",
      "3036/3036 [==============================] - 2s 574us/step - loss: 0.0509 - acc: 0.9822 1s - \n",
      "Epoch 28/50\n",
      "3036/3036 [==============================] - 2s 601us/step - loss: 0.0461 - acc: 0.9845\n",
      "Epoch 29/50\n",
      "3036/3036 [==============================] - 2s 547us/step - loss: 0.0429 - acc: 0.9845\n",
      "Epoch 30/50\n",
      "3036/3036 [==============================] - 2s 503us/step - loss: 0.0409 - acc: 0.9865\n",
      "Epoch 31/50\n",
      "3036/3036 [==============================] - 2s 516us/step - loss: 0.0448 - acc: 0.9845\n",
      "Epoch 32/50\n",
      "3036/3036 [==============================] - 2s 591us/step - loss: 0.0424 - acc: 0.9835\n",
      "Epoch 33/50\n",
      "3036/3036 [==============================] - 2s 632us/step - loss: 0.0394 - acc: 0.9872\n",
      "Epoch 34/50\n",
      "3036/3036 [==============================] - 2s 612us/step - loss: 0.0346 - acc: 0.9888\n",
      "Epoch 35/50\n",
      "3036/3036 [==============================] - 2s 633us/step - loss: 0.0393 - acc: 0.9881\n",
      "Epoch 36/50\n",
      "3036/3036 [==============================] - 2s 627us/step - loss: 0.0659 - acc: 0.9792\n",
      "Epoch 37/50\n",
      "3036/3036 [==============================] - 2s 655us/step - loss: 0.0329 - acc: 0.9891\n",
      "Epoch 38/50\n",
      "3036/3036 [==============================] - 2s 682us/step - loss: 0.0334 - acc: 0.9885\n",
      "Epoch 39/50\n",
      "3036/3036 [==============================] - 2s 670us/step - loss: 0.0434 - acc: 0.9832\n",
      "Epoch 40/50\n",
      "3036/3036 [==============================] - 2s 759us/step - loss: 0.0411 - acc: 0.9855\n",
      "Epoch 41/50\n",
      "3036/3036 [==============================] - 2s 717us/step - loss: 0.0419 - acc: 0.9875\n",
      "Epoch 42/50\n",
      "3036/3036 [==============================] - 2s 792us/step - loss: 0.0330 - acc: 0.9908\n",
      "Epoch 43/50\n",
      "3036/3036 [==============================] - 2s 730us/step - loss: 0.0341 - acc: 0.9878\n",
      "Epoch 44/50\n",
      "3036/3036 [==============================] - 2s 543us/step - loss: 0.0358 - acc: 0.9881\n",
      "Epoch 45/50\n",
      "3036/3036 [==============================] - 2s 589us/step - loss: 0.0373 - acc: 0.9862\n",
      "Epoch 46/50\n",
      "3036/3036 [==============================] - 2s 599us/step - loss: 0.0351 - acc: 0.9891\n",
      "Epoch 47/50\n",
      "3036/3036 [==============================] - 2s 541us/step - loss: 0.0353 - acc: 0.9881\n",
      "Epoch 48/50\n",
      "3036/3036 [==============================] - 2s 544us/step - loss: 0.0472 - acc: 0.9852\n",
      "Epoch 49/50\n",
      "3036/3036 [==============================] - 2s 628us/step - loss: 0.0549 - acc: 0.9799\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3036/3036 [==============================] - 2s 655us/step - loss: 0.0312 - acc: 0.9908\n",
      "337/337 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "3036/3036 [==============================] - 5s 2ms/step - loss: 0.2404 - acc: 0.9394\n",
      "Epoch 2/50\n",
      "3036/3036 [==============================] - 2s 651us/step - loss: 0.1930 - acc: 0.9499 1\n",
      "Epoch 3/50\n",
      "3036/3036 [==============================] - 2s 692us/step - loss: 0.1884 - acc: 0.9499\n",
      "Epoch 4/50\n",
      "3036/3036 [==============================] - 2s 677us/step - loss: 0.1887 - acc: 0.9499\n",
      "Epoch 5/50\n",
      "3036/3036 [==============================] - 2s 593us/step - loss: 0.1832 - acc: 0.9499\n",
      "Epoch 6/50\n",
      "3036/3036 [==============================] - 2s 623us/step - loss: 0.1820 - acc: 0.9499\n",
      "Epoch 7/50\n",
      "3036/3036 [==============================] - 2s 684us/step - loss: 0.1786 - acc: 0.9499\n",
      "Epoch 8/50\n",
      "3036/3036 [==============================] - 2s 718us/step - loss: 0.1776 - acc: 0.9499\n",
      "Epoch 9/50\n",
      "3036/3036 [==============================] - 2s 623us/step - loss: 0.1684 - acc: 0.9499\n",
      "Epoch 10/50\n",
      "3036/3036 [==============================] - 2s 576us/step - loss: 0.1646 - acc: 0.9499\n",
      "Epoch 11/50\n",
      "3036/3036 [==============================] - 2s 635us/step - loss: 0.1478 - acc: 0.9499\n",
      "Epoch 12/50\n",
      "3036/3036 [==============================] - 2s 537us/step - loss: 0.1321 - acc: 0.9499\n",
      "Epoch 13/50\n",
      "3036/3036 [==============================] - 1s 417us/step - loss: 0.1066 - acc: 0.9565\n",
      "Epoch 14/50\n",
      "3036/3036 [==============================] - 1s 463us/step - loss: 0.0899 - acc: 0.9681\n",
      "Epoch 15/50\n",
      "3036/3036 [==============================] - 2s 663us/step - loss: 0.0722 - acc: 0.9773\n",
      "Epoch 16/50\n",
      "3036/3036 [==============================] - 2s 678us/step - loss: 0.0706 - acc: 0.9769\n",
      "Epoch 17/50\n",
      "3036/3036 [==============================] - 2s 712us/step - loss: 0.0619 - acc: 0.9779\n",
      "Epoch 18/50\n",
      "3036/3036 [==============================] - 2s 701us/step - loss: 0.0425 - acc: 0.9868\n",
      "Epoch 19/50\n",
      "3036/3036 [==============================] - 2s 781us/step - loss: 0.0577 - acc: 0.9789\n",
      "Epoch 20/50\n",
      "3036/3036 [==============================] - 2s 688us/step - loss: 0.0572 - acc: 0.9779\n",
      "Epoch 21/50\n",
      "3036/3036 [==============================] - 2s 534us/step - loss: 0.0513 - acc: 0.9842\n",
      "Epoch 22/50\n",
      "3036/3036 [==============================] - 2s 627us/step - loss: 0.0536 - acc: 0.9832\n",
      "Epoch 23/50\n",
      "3036/3036 [==============================] - 2s 639us/step - loss: 0.0618 - acc: 0.9816\n",
      "Epoch 24/50\n",
      "3036/3036 [==============================] - 2s 588us/step - loss: 0.0399 - acc: 0.9862\n",
      "Epoch 25/50\n",
      "3036/3036 [==============================] - 2s 662us/step - loss: 0.0381 - acc: 0.9875\n",
      "Epoch 26/50\n",
      "3036/3036 [==============================] - 2s 625us/step - loss: 0.0355 - acc: 0.9875\n",
      "Epoch 27/50\n",
      "3036/3036 [==============================] - 2s 652us/step - loss: 0.0338 - acc: 0.9875\n",
      "Epoch 28/50\n",
      "3036/3036 [==============================] - 2s 547us/step - loss: 0.0355 - acc: 0.9878 1s - \n",
      "Epoch 29/50\n",
      "3036/3036 [==============================] - 2s 529us/step - loss: 0.0462 - acc: 0.9868\n",
      "Epoch 30/50\n",
      "3036/3036 [==============================] - 1s 492us/step - loss: 0.0334 - acc: 0.9888\n",
      "Epoch 31/50\n",
      "3036/3036 [==============================] - 2s 505us/step - loss: 0.0324 - acc: 0.9904\n",
      "Epoch 32/50\n",
      "3036/3036 [==============================] - 2s 601us/step - loss: 0.0304 - acc: 0.9898\n",
      "Epoch 33/50\n",
      "3036/3036 [==============================] - 2s 625us/step - loss: 0.0346 - acc: 0.9862\n",
      "Epoch 34/50\n",
      "3036/3036 [==============================] - 2s 671us/step - loss: 0.0435 - acc: 0.9839\n",
      "Epoch 35/50\n",
      "3036/3036 [==============================] - 2s 656us/step - loss: 0.0335 - acc: 0.9885\n",
      "Epoch 36/50\n",
      "3036/3036 [==============================] - 2s 617us/step - loss: 0.0386 - acc: 0.9881\n",
      "Epoch 37/50\n",
      "3036/3036 [==============================] - 2s 622us/step - loss: 0.0408 - acc: 0.9865\n",
      "Epoch 38/50\n",
      "3036/3036 [==============================] - 2s 636us/step - loss: 0.0362 - acc: 0.9885\n",
      "Epoch 39/50\n",
      "3036/3036 [==============================] - 2s 600us/step - loss: 0.0316 - acc: 0.9895\n",
      "Epoch 40/50\n",
      "3036/3036 [==============================] - 2s 618us/step - loss: 0.0320 - acc: 0.9885\n",
      "Epoch 41/50\n",
      "3036/3036 [==============================] - 2s 635us/step - loss: 0.0366 - acc: 0.9858\n",
      "Epoch 42/50\n",
      "3036/3036 [==============================] - 2s 648us/step - loss: 0.0623 - acc: 0.9822\n",
      "Epoch 43/50\n",
      "3036/3036 [==============================] - 2s 561us/step - loss: 0.0377 - acc: 0.9865\n",
      "Epoch 44/50\n",
      "3036/3036 [==============================] - 2s 628us/step - loss: 0.0324 - acc: 0.9895\n",
      "Epoch 45/50\n",
      "3036/3036 [==============================] - 2s 633us/step - loss: 0.0344 - acc: 0.9875\n",
      "Epoch 46/50\n",
      "3036/3036 [==============================] - 2s 565us/step - loss: 0.0336 - acc: 0.9891\n",
      "Epoch 47/50\n",
      "3036/3036 [==============================] - 2s 634us/step - loss: 0.0328 - acc: 0.9868\n",
      "Epoch 48/50\n",
      "3036/3036 [==============================] - 2s 724us/step - loss: 0.0287 - acc: 0.9898\n",
      "Epoch 49/50\n",
      "3036/3036 [==============================] - 2s 677us/step - loss: 0.0346 - acc: 0.9872\n",
      "Epoch 50/50\n",
      "3036/3036 [==============================] - 2s 673us/step - loss: 0.0556 - acc: 0.9816 0s - loss: 0.0559 - \n",
      "337/337 [==============================] - 1s 2ms/step\n",
      "Epoch 1/50\n",
      "3036/3036 [==============================] - 4s 1ms/step - loss: 0.2500 - acc: 0.9466\n",
      "Epoch 2/50\n",
      "3036/3036 [==============================] - 2s 599us/step - loss: 0.2024 - acc: 0.9470\n",
      "Epoch 3/50\n",
      "3036/3036 [==============================] - 2s 605us/step - loss: 0.1963 - acc: 0.9470\n",
      "Epoch 4/50\n",
      "3036/3036 [==============================] - 2s 637us/step - loss: 0.1949 - acc: 0.9470\n",
      "Epoch 5/50\n",
      "3036/3036 [==============================] - 2s 629us/step - loss: 0.1928 - acc: 0.9470\n",
      "Epoch 6/50\n",
      "3036/3036 [==============================] - 2s 598us/step - loss: 0.1930 - acc: 0.9470\n",
      "Epoch 7/50\n",
      "3036/3036 [==============================] - 2s 507us/step - loss: 0.1884 - acc: 0.9470\n",
      "Epoch 8/50\n",
      "3036/3036 [==============================] - 2s 514us/step - loss: 0.1894 - acc: 0.9470\n",
      "Epoch 9/50\n",
      "3036/3036 [==============================] - 2s 608us/step - loss: 0.1809 - acc: 0.9470\n",
      "Epoch 10/50\n",
      "3036/3036 [==============================] - 2s 633us/step - loss: 0.1721 - acc: 0.9470\n",
      "Epoch 11/50\n",
      "3036/3036 [==============================] - 2s 626us/step - loss: 0.1677 - acc: 0.9470\n",
      "Epoch 12/50\n",
      "3036/3036 [==============================] - 2s 608us/step - loss: 0.1413 - acc: 0.9470\n",
      "Epoch 13/50\n",
      "3036/3036 [==============================] - 2s 590us/step - loss: 0.1352 - acc: 0.9486\n",
      "Epoch 14/50\n",
      "3036/3036 [==============================] - 2s 631us/step - loss: 0.1062 - acc: 0.9562\n",
      "Epoch 15/50\n",
      "3036/3036 [==============================] - 2s 622us/step - loss: 0.0828 - acc: 0.9677\n",
      "Epoch 16/50\n",
      "3036/3036 [==============================] - 2s 619us/step - loss: 0.0899 - acc: 0.9704\n",
      "Epoch 17/50\n",
      "3036/3036 [==============================] - 2s 525us/step - loss: 0.0690 - acc: 0.9763\n",
      "Epoch 18/50\n",
      "3036/3036 [==============================] - 2s 563us/step - loss: 0.0540 - acc: 0.9832\n",
      "Epoch 19/50\n",
      "3036/3036 [==============================] - 2s 600us/step - loss: 0.0558 - acc: 0.9835\n",
      "Epoch 20/50\n",
      "3036/3036 [==============================] - 2s 540us/step - loss: 0.0680 - acc: 0.9766\n",
      "Epoch 21/50\n",
      "3036/3036 [==============================] - 2s 662us/step - loss: 0.0435 - acc: 0.9832\n",
      "Epoch 22/50\n",
      "3036/3036 [==============================] - 2s 565us/step - loss: 0.0455 - acc: 0.9855\n",
      "Epoch 23/50\n",
      "3036/3036 [==============================] - 2s 577us/step - loss: 0.0387 - acc: 0.9875\n",
      "Epoch 24/50\n",
      "3036/3036 [==============================] - 2s 592us/step - loss: 0.0446 - acc: 0.9865\n",
      "Epoch 25/50\n",
      "3036/3036 [==============================] - 2s 612us/step - loss: 0.0401 - acc: 0.9852\n",
      "Epoch 26/50\n",
      "3036/3036 [==============================] - 2s 708us/step - loss: 0.0328 - acc: 0.9888\n",
      "Epoch 27/50\n",
      "3036/3036 [==============================] - 2s 668us/step - loss: 0.0368 - acc: 0.9862\n",
      "Epoch 28/50\n",
      "3036/3036 [==============================] - 2s 692us/step - loss: 0.0455 - acc: 0.9812\n",
      "Epoch 29/50\n",
      "3036/3036 [==============================] - 2s 794us/step - loss: 0.0455 - acc: 0.9829\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3036/3036 [==============================] - 2s 633us/step - loss: 0.0446 - acc: 0.9852\n",
      "Epoch 31/50\n",
      "3036/3036 [==============================] - 2s 597us/step - loss: 0.0365 - acc: 0.9881\n",
      "Epoch 32/50\n",
      "3036/3036 [==============================] - 2s 528us/step - loss: 0.0434 - acc: 0.9868\n",
      "Epoch 33/50\n",
      "3036/3036 [==============================] - 1s 478us/step - loss: 0.0323 - acc: 0.9901\n",
      "Epoch 34/50\n",
      "3036/3036 [==============================] - 2s 514us/step - loss: 0.0318 - acc: 0.9855\n",
      "Epoch 35/50\n",
      "3036/3036 [==============================] - 1s 478us/step - loss: 0.0422 - acc: 0.9852\n",
      "Epoch 36/50\n",
      "3036/3036 [==============================] - 1s 480us/step - loss: 0.0357 - acc: 0.9865\n",
      "Epoch 37/50\n",
      "3036/3036 [==============================] - 2s 499us/step - loss: 0.0344 - acc: 0.9872\n",
      "Epoch 38/50\n",
      "3036/3036 [==============================] - 2s 508us/step - loss: 0.0403 - acc: 0.9875\n",
      "Epoch 39/50\n",
      "3036/3036 [==============================] - 2s 560us/step - loss: 0.0308 - acc: 0.9901\n",
      "Epoch 40/50\n",
      "3036/3036 [==============================] - 2s 595us/step - loss: 0.0317 - acc: 0.9895\n",
      "Epoch 41/50\n",
      "3036/3036 [==============================] - 2s 514us/step - loss: 0.0307 - acc: 0.9895\n",
      "Epoch 42/50\n",
      "3036/3036 [==============================] - 2s 593us/step - loss: 0.0377 - acc: 0.9888\n",
      "Epoch 43/50\n",
      "3036/3036 [==============================] - 2s 538us/step - loss: 0.0355 - acc: 0.9868\n",
      "Epoch 44/50\n",
      "3036/3036 [==============================] - 2s 580us/step - loss: 0.0373 - acc: 0.9875\n",
      "Epoch 45/50\n",
      "3036/3036 [==============================] - 2s 523us/step - loss: 0.0340 - acc: 0.9885\n",
      "Epoch 46/50\n",
      "3036/3036 [==============================] - 2s 565us/step - loss: 0.0435 - acc: 0.9842\n",
      "Epoch 47/50\n",
      "3036/3036 [==============================] - 2s 592us/step - loss: 0.0451 - acc: 0.9845\n",
      "Epoch 48/50\n",
      "3036/3036 [==============================] - 2s 614us/step - loss: 0.0379 - acc: 0.9862\n",
      "Epoch 49/50\n",
      "3036/3036 [==============================] - 2s 524us/step - loss: 0.0321 - acc: 0.9885\n",
      "Epoch 50/50\n",
      "3036/3036 [==============================] - 2s 591us/step - loss: 0.0345 - acc: 0.9878\n",
      "337/337 [==============================] - 0s 1ms/step\n",
      "Accuracy mean: 0.985175495478\n",
      "Accuracy variance: 0.00725421337907\n",
      "(' Time ', '1084.05', ' seconds')\n",
      "[[1356    9]\n",
      " [  17   64]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.99      0.99      1365\n",
      "        1.0       0.88      0.79      0.83        81\n",
      "\n",
      "avg / total       0.98      0.98      0.98      1446\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# estimators \n",
    "# Evaluating the ANN\n",
    "t0 = time()\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 1024, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n",
    "    classifier.add(Dense(units = 512, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 50)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of DecisionTreeClassifier = 96.680498 %\n",
      "(' Time ', '0.028', ' seconds')\n",
      "[[1348   17]\n",
      " [  31   50]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.99      0.98      1365\n",
      "        1.0       0.75      0.62      0.68        81\n",
      "\n",
      "avg / total       0.96      0.97      0.97      1446\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of DecisionTreeClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of RandomForestClassifier = 97.233748 %\n",
      "(' Time ', '2.084', ' seconds')\n",
      "[[1358    7]\n",
      " [  33   48]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.99      0.99      1365\n",
      "        1.0       0.87      0.59      0.71        81\n",
      "\n",
      "avg / total       0.97      0.97      0.97      1446\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of RandomForestClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of ExtraTreesClassifier = 97.579530 %\n",
      "(' Time ', '0.923', ' seconds')\n",
      "[[1362    3]\n",
      " [  32   49]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99      1365\n",
      "        1.0       0.94      0.60      0.74        81\n",
      "\n",
      "avg / total       0.98      0.98      0.97      1446\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of ExtraTreesClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of AdaBoostClassifier = 97.510373 %\n",
      "(' Time ', '0.889', ' seconds')\n",
      "[[1357    8]\n",
      " [  28   53]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.99      0.99      1365\n",
      "        1.0       0.87      0.65      0.75        81\n",
      "\n",
      "avg / total       0.97      0.98      0.97      1446\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of AdaBoostClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Naive_bayes  GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GaussianNB = 90.525588 %\n",
      "(' Time ', '0.006', ' seconds')\n",
      "[[1265  100]\n",
      " [  37   44]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.93      0.95      1365\n",
      "        1.0       0.31      0.54      0.39        81\n",
      "\n",
      "avg / total       0.93      0.91      0.92      1446\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred= gnb.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of GaussianNB = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
