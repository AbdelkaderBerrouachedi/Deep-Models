{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt \n",
    "from pprint import pprint\n",
    "from numpy import array\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>att1</th>\n",
       "      <th>att2</th>\n",
       "      <th>att3</th>\n",
       "      <th>att4</th>\n",
       "      <th>att5</th>\n",
       "      <th>att6</th>\n",
       "      <th>att7</th>\n",
       "      <th>att8</th>\n",
       "      <th>att9</th>\n",
       "      <th>att10</th>\n",
       "      <th>...</th>\n",
       "      <th>att13</th>\n",
       "      <th>att14</th>\n",
       "      <th>att15</th>\n",
       "      <th>att16</th>\n",
       "      <th>att17</th>\n",
       "      <th>att18</th>\n",
       "      <th>att19</th>\n",
       "      <th>att20</th>\n",
       "      <th>att21</th>\n",
       "      <th>outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.323657</td>\n",
       "      <td>0.793785</td>\n",
       "      <td>0.848661</td>\n",
       "      <td>0.660063</td>\n",
       "      <td>0.622244</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.760762</td>\n",
       "      <td>0.671655</td>\n",
       "      <td>0.603723</td>\n",
       "      <td>0.636170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281899</td>\n",
       "      <td>0.203557</td>\n",
       "      <td>0.286607</td>\n",
       "      <td>0.474383</td>\n",
       "      <td>0.352483</td>\n",
       "      <td>0.358857</td>\n",
       "      <td>0.275626</td>\n",
       "      <td>0.465937</td>\n",
       "      <td>0.220884</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.423803</td>\n",
       "      <td>0.769774</td>\n",
       "      <td>0.632130</td>\n",
       "      <td>0.572471</td>\n",
       "      <td>0.747495</td>\n",
       "      <td>0.670408</td>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.617958</td>\n",
       "      <td>0.637411</td>\n",
       "      <td>0.457447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302671</td>\n",
       "      <td>0.375494</td>\n",
       "      <td>0.296429</td>\n",
       "      <td>0.383302</td>\n",
       "      <td>0.545278</td>\n",
       "      <td>0.394286</td>\n",
       "      <td>0.451025</td>\n",
       "      <td>0.470803</td>\n",
       "      <td>0.468541</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.477504</td>\n",
       "      <td>0.580508</td>\n",
       "      <td>0.554133</td>\n",
       "      <td>0.476538</td>\n",
       "      <td>0.851703</td>\n",
       "      <td>0.509184</td>\n",
       "      <td>0.745861</td>\n",
       "      <td>0.785211</td>\n",
       "      <td>0.508865</td>\n",
       "      <td>0.519149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341246</td>\n",
       "      <td>0.384387</td>\n",
       "      <td>0.229464</td>\n",
       "      <td>0.350095</td>\n",
       "      <td>0.117819</td>\n",
       "      <td>0.406857</td>\n",
       "      <td>0.149203</td>\n",
       "      <td>0.402676</td>\n",
       "      <td>0.370817</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.645864</td>\n",
       "      <td>0.570621</td>\n",
       "      <td>0.525029</td>\n",
       "      <td>0.631908</td>\n",
       "      <td>0.682365</td>\n",
       "      <td>0.382653</td>\n",
       "      <td>0.478477</td>\n",
       "      <td>0.608275</td>\n",
       "      <td>0.476950</td>\n",
       "      <td>0.190426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500495</td>\n",
       "      <td>0.555336</td>\n",
       "      <td>0.463393</td>\n",
       "      <td>0.537951</td>\n",
       "      <td>0.564752</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.576310</td>\n",
       "      <td>0.518248</td>\n",
       "      <td>0.597055</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.219158</td>\n",
       "      <td>0.690678</td>\n",
       "      <td>0.530850</td>\n",
       "      <td>0.715328</td>\n",
       "      <td>0.687375</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.649007</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.523050</td>\n",
       "      <td>0.303191</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190900</td>\n",
       "      <td>0.408103</td>\n",
       "      <td>0.322321</td>\n",
       "      <td>0.425996</td>\n",
       "      <td>0.400195</td>\n",
       "      <td>0.701714</td>\n",
       "      <td>0.515945</td>\n",
       "      <td>0.294404</td>\n",
       "      <td>0.463186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       att1      att2      att3      att4      att5      att6      att7  \\\n",
       "0  0.323657  0.793785  0.848661  0.660063  0.622244  0.755102  0.760762   \n",
       "1  0.423803  0.769774  0.632130  0.572471  0.747495  0.670408  0.715232   \n",
       "2  0.477504  0.580508  0.554133  0.476538  0.851703  0.509184  0.745861   \n",
       "3  0.645864  0.570621  0.525029  0.631908  0.682365  0.382653  0.478477   \n",
       "4  0.219158  0.690678  0.530850  0.715328  0.687375  0.571429  0.649007   \n",
       "\n",
       "       att8      att9     att10   ...        att13     att14     att15  \\\n",
       "0  0.671655  0.603723  0.636170   ...     0.281899  0.203557  0.286607   \n",
       "1  0.617958  0.637411  0.457447   ...     0.302671  0.375494  0.296429   \n",
       "2  0.785211  0.508865  0.519149   ...     0.341246  0.384387  0.229464   \n",
       "3  0.608275  0.476950  0.190426   ...     0.500495  0.555336  0.463393   \n",
       "4  0.562500  0.523050  0.303191   ...     0.190900  0.408103  0.322321   \n",
       "\n",
       "      att16     att17     att18     att19     att20     att21  outlier  \n",
       "0  0.474383  0.352483  0.358857  0.275626  0.465937  0.220884        1  \n",
       "1  0.383302  0.545278  0.394286  0.451025  0.470803  0.468541        1  \n",
       "2  0.350095  0.117819  0.406857  0.149203  0.402676  0.370817        1  \n",
       "3  0.537951  0.564752  0.485714  0.576310  0.518248  0.597055        1  \n",
       "4  0.425996  0.400195  0.701714  0.515945  0.294404  0.463186        1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    " \n",
    "df=pd.read_csv('Waveform_withoutdupl_norm_v01.csv')  \n",
    "del df['id']\n",
    "del df['Unnamed: 0']\n",
    "df['outlier'] = df.outlier.apply(lambda label: 1 if label == \"'yes'\" else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3443, 22)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df to values\n",
    "df = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GC Forest\n",
    "import argparse\n",
    "import sys\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "sys.path.insert(0, \"lib\")\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.utils.config_utils import load_json\n",
    "config = load_json(\"./examples/waveform.json\")   \n",
    "gc = GCForest(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# train test \n",
    "from sklearn.cross_validation import train_test_split\n",
    "y = df[:,21]\n",
    "X = df[:,0:21]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of class\n",
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:12:00,193][cascade_classifier.fit_transform] X_groups_train.shape=[(2410, 21)],y_train.shape=(2410,),X_groups_test.shape=[(1033, 21)],y_test.shape=(1033,)\n",
      "[ 2018-07-31 22:12:00,196][cascade_classifier.fit_transform] group_dims=[21]\n",
      "[ 2018-07-31 22:12:00,199][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-31 22:12:00,200][cascade_classifier.fit_transform] group_ends=[21]\n",
      "[ 2018-07-31 22:12:00,202][cascade_classifier.fit_transform] X_train.shape=(2410, 21),X_test.shape=(1033, 21)\n",
      "[ 2018-07-31 22:12:00,203][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(2410, 21), X_cur_test.shape=(1033, 21)\n",
      "[ 2018-07-31 22:12:01,280][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=97.11%\n",
      "[ 2018-07-31 22:12:02,746][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=97.10%\n",
      "[ 2018-07-31 22:12:04,667][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=97.10%\n",
      "[ 2018-07-31 22:12:06,160][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=97.51%\n",
      "[ 2018-07-31 22:12:08,048][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=97.10%\n",
      "[ 2018-07-31 22:12:10,238][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=97.93%\n",
      "[ 2018-07-31 22:12:12,020][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=97.51%\n",
      "[ 2018-07-31 22:12:14,007][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=97.51%\n",
      "[ 2018-07-31 22:12:15,530][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=97.10%\n",
      "[ 2018-07-31 22:12:16,998][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=97.08%\n",
      "[ 2018-07-31 22:12:17,213][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=97.30%\n",
      "[ 2018-07-31 22:12:17,215][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=97.29%\n",
      "[ 2018-07-31 22:12:18,510][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_0.predict)=96.69%\n",
      "[ 2018-07-31 22:12:19,675][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_1.predict)=97.10%\n",
      "[ 2018-07-31 22:12:20,992][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_2.predict)=97.10%\n",
      "[ 2018-07-31 22:12:22,549][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_3.predict)=97.51%\n",
      "[ 2018-07-31 22:12:23,757][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_4.predict)=97.51%\n",
      "[ 2018-07-31 22:12:25,233][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_5.predict)=97.51%\n",
      "[ 2018-07-31 22:12:26,618][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_6.predict)=97.51%\n",
      "[ 2018-07-31 22:12:28,021][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_7.predict)=97.10%\n",
      "[ 2018-07-31 22:12:29,229][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_8.predict)=97.51%\n",
      "[ 2018-07-31 22:12:30,334][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_9.predict)=97.08%\n",
      "[ 2018-07-31 22:12:30,555][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_cv.predict)=97.26%\n",
      "[ 2018-07-31 22:12:30,556][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.test.predict)=97.29%\n",
      "[ 2018-07-31 22:12:30,631][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_0.predict)=96.69%\n",
      "[ 2018-07-31 22:12:30,646][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_1.predict)=97.10%\n",
      "[ 2018-07-31 22:12:30,660][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_2.predict)=97.10%\n",
      "[ 2018-07-31 22:12:30,721][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_3.predict)=97.10%\n",
      "[ 2018-07-31 22:12:30,761][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_4.predict)=97.10%\n",
      "[ 2018-07-31 22:12:30,784][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_5.predict)=97.10%\n",
      "[ 2018-07-31 22:12:30,861][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_6.predict)=97.10%\n",
      "[ 2018-07-31 22:12:30,898][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_7.predict)=96.68%\n",
      "[ 2018-07-31 22:12:30,923][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_8.predict)=97.10%\n",
      "[ 2018-07-31 22:12:31,011][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_9.predict)=97.08%\n",
      "[ 2018-07-31 22:12:31,037][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_cv.predict)=97.01%\n",
      "[ 2018-07-31 22:12:31,042][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.test.predict)=97.19%\n",
      "[ 2018-07-31 22:12:31,049][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=97.14%\n",
      "[ 2018-07-31 22:12:31,055][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=97.19%\n",
      "[ 2018-07-31 22:12:31,057][cascade_classifier.fit_transform] [layer=1] look_indexs=[0], X_cur_train.shape=(2410, 27), X_cur_test.shape=(1033, 27)\n",
      "[ 2018-07-31 22:12:32,294][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_0.predict)=97.11%\n",
      "[ 2018-07-31 22:12:33,764][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_1.predict)=97.93%\n",
      "[ 2018-07-31 22:12:35,179][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_2.predict)=97.93%\n",
      "[ 2018-07-31 22:12:36,592][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_3.predict)=97.10%\n",
      "[ 2018-07-31 22:12:38,299][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_4.predict)=97.51%\n",
      "[ 2018-07-31 22:12:40,005][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_5.predict)=99.17%\n",
      "[ 2018-07-31 22:12:41,606][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_6.predict)=97.93%\n",
      "[ 2018-07-31 22:12:43,355][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_7.predict)=97.10%\n",
      "[ 2018-07-31 22:12:45,122][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_8.predict)=99.17%\n",
      "[ 2018-07-31 22:12:46,569][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_9.predict)=97.92%\n",
      "[ 2018-07-31 22:12:47,066][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_cv.predict)=97.88%\n",
      "[ 2018-07-31 22:12:47,068][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.test.predict)=97.87%\n",
      "[ 2018-07-31 22:12:48,034][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_0.predict)=98.76%\n",
      "[ 2018-07-31 22:12:49,165][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_1.predict)=98.34%\n",
      "[ 2018-07-31 22:12:50,411][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_2.predict)=98.34%\n",
      "[ 2018-07-31 22:12:51,962][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_3.predict)=97.93%\n",
      "[ 2018-07-31 22:12:53,446][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_4.predict)=97.10%\n",
      "[ 2018-07-31 22:12:54,752][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_5.predict)=98.34%\n",
      "[ 2018-07-31 22:12:56,143][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_6.predict)=98.34%\n",
      "[ 2018-07-31 22:12:57,433][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_7.predict)=98.76%\n",
      "[ 2018-07-31 22:12:58,503][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_8.predict)=97.51%\n",
      "[ 2018-07-31 22:12:59,662][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_9.predict)=96.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:13:00,076][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_cv.predict)=98.01%\n",
      "[ 2018-07-31 22:13:00,077][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.test.predict)=97.87%\n",
      "[ 2018-07-31 22:13:00,095][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_0.predict)=97.93%\n",
      "[ 2018-07-31 22:13:00,114][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_1.predict)=97.51%\n",
      "[ 2018-07-31 22:13:00,138][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_2.predict)=98.34%\n",
      "[ 2018-07-31 22:13:00,161][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_3.predict)=97.51%\n",
      "[ 2018-07-31 22:13:00,200][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_4.predict)=97.51%\n",
      "[ 2018-07-31 22:13:00,215][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_5.predict)=97.93%\n",
      "[ 2018-07-31 22:13:00,239][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_6.predict)=97.10%\n",
      "[ 2018-07-31 22:13:00,265][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_7.predict)=97.51%\n",
      "[ 2018-07-31 22:13:00,283][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_8.predict)=97.51%\n",
      "[ 2018-07-31 22:13:00,304][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_9.predict)=96.67%\n",
      "[ 2018-07-31 22:13:00,321][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_cv.predict)=97.55%\n",
      "[ 2018-07-31 22:13:00,324][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.test.predict)=97.58%\n",
      "[ 2018-07-31 22:13:00,327][cascade_classifier.calc_accuracy] Accuracy(layer_1 - train.classifier_average)=97.88%\n",
      "[ 2018-07-31 22:13:00,330][cascade_classifier.calc_accuracy] Accuracy(layer_1 - test.classifier_average)=97.87%\n",
      "[ 2018-07-31 22:13:00,332][cascade_classifier.fit_transform] [layer=2] look_indexs=[0], X_cur_train.shape=(2410, 27), X_cur_test.shape=(1033, 27)\n",
      "[ 2018-07-31 22:13:01,603][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_0.predict)=97.11%\n",
      "[ 2018-07-31 22:13:03,065][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_1.predict)=97.93%\n",
      "[ 2018-07-31 22:13:04,557][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_2.predict)=98.76%\n",
      "[ 2018-07-31 22:13:06,007][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_3.predict)=97.51%\n",
      "[ 2018-07-31 22:13:07,425][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_4.predict)=98.34%\n",
      "[ 2018-07-31 22:13:08,893][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_5.predict)=97.51%\n",
      "[ 2018-07-31 22:13:10,342][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_6.predict)=98.34%\n",
      "[ 2018-07-31 22:13:11,622][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_7.predict)=97.93%\n",
      "[ 2018-07-31 22:13:13,022][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_8.predict)=97.51%\n",
      "[ 2018-07-31 22:13:14,532][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_9.predict)=98.33%\n",
      "[ 2018-07-31 22:13:14,761][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_cv.predict)=97.93%\n",
      "[ 2018-07-31 22:13:14,763][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.test.predict)=97.87%\n",
      "[ 2018-07-31 22:13:15,880][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_0.predict)=96.69%\n",
      "[ 2018-07-31 22:13:17,162][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_1.predict)=96.68%\n",
      "[ 2018-07-31 22:13:18,627][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_2.predict)=98.34%\n",
      "[ 2018-07-31 22:13:19,978][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_3.predict)=97.93%\n",
      "[ 2018-07-31 22:13:21,518][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_4.predict)=98.76%\n",
      "[ 2018-07-31 22:13:23,479][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_5.predict)=98.34%\n",
      "[ 2018-07-31 22:13:25,295][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_6.predict)=98.34%\n",
      "[ 2018-07-31 22:13:26,737][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_7.predict)=97.51%\n",
      "[ 2018-07-31 22:13:28,453][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_8.predict)=97.93%\n",
      "[ 2018-07-31 22:13:29,873][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_9.predict)=98.33%\n",
      "[ 2018-07-31 22:13:30,097][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_cv.predict)=97.88%\n",
      "[ 2018-07-31 22:13:30,104][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.test.predict)=97.87%\n",
      "[ 2018-07-31 22:13:30,155][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_0.predict)=97.52%\n",
      "[ 2018-07-31 22:13:30,242][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_1.predict)=97.51%\n",
      "[ 2018-07-31 22:13:30,344][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_2.predict)=97.51%\n",
      "[ 2018-07-31 22:13:30,462][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_3.predict)=97.51%\n",
      "[ 2018-07-31 22:13:30,484][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_4.predict)=97.93%\n",
      "[ 2018-07-31 22:13:30,518][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_5.predict)=97.93%\n",
      "[ 2018-07-31 22:13:30,590][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_6.predict)=98.34%\n",
      "[ 2018-07-31 22:13:30,652][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_7.predict)=97.93%\n",
      "[ 2018-07-31 22:13:30,747][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_8.predict)=97.51%\n",
      "[ 2018-07-31 22:13:30,810][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_9.predict)=97.50%\n",
      "[ 2018-07-31 22:13:30,823][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_cv.predict)=97.72%\n",
      "[ 2018-07-31 22:13:30,824][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.test.predict)=97.87%\n",
      "[ 2018-07-31 22:13:30,831][cascade_classifier.calc_accuracy] Accuracy(layer_2 - train.classifier_average)=97.88%\n",
      "[ 2018-07-31 22:13:30,834][cascade_classifier.calc_accuracy] Accuracy(layer_2 - test.classifier_average)=97.87%\n",
      "[ 2018-07-31 22:13:30,838][cascade_classifier.fit_transform] [layer=3] look_indexs=[0], X_cur_train.shape=(2410, 27), X_cur_test.shape=(1033, 27)\n",
      "[ 2018-07-31 22:13:32,463][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_0.predict)=97.93%\n",
      "[ 2018-07-31 22:13:34,330][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_1.predict)=97.10%\n",
      "[ 2018-07-31 22:13:36,269][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_2.predict)=99.17%\n",
      "[ 2018-07-31 22:13:38,102][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_3.predict)=97.93%\n",
      "[ 2018-07-31 22:13:40,477][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_4.predict)=97.10%\n",
      "[ 2018-07-31 22:13:42,205][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_5.predict)=97.93%\n",
      "[ 2018-07-31 22:13:43,949][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_6.predict)=97.51%\n",
      "[ 2018-07-31 22:13:45,948][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_7.predict)=98.34%\n",
      "[ 2018-07-31 22:13:47,870][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_8.predict)=97.51%\n",
      "[ 2018-07-31 22:13:49,458][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_9.predict)=97.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:13:49,805][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_cv.predict)=97.80%\n",
      "[ 2018-07-31 22:13:49,807][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.test.predict)=97.87%\n",
      "[ 2018-07-31 22:13:50,813][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_0.predict)=97.11%\n",
      "[ 2018-07-31 22:13:52,266][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_1.predict)=98.34%\n",
      "[ 2018-07-31 22:13:53,735][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_2.predict)=99.17%\n",
      "[ 2018-07-31 22:13:55,228][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_3.predict)=97.93%\n",
      "[ 2018-07-31 22:13:56,740][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_4.predict)=96.68%\n",
      "[ 2018-07-31 22:13:58,809][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_5.predict)=97.93%\n",
      "[ 2018-07-31 22:14:00,729][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_6.predict)=98.34%\n",
      "[ 2018-07-31 22:14:02,201][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_7.predict)=97.93%\n",
      "[ 2018-07-31 22:14:03,825][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_8.predict)=97.93%\n",
      "[ 2018-07-31 22:14:05,606][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_9.predict)=97.08%\n",
      "[ 2018-07-31 22:14:05,968][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_cv.predict)=97.84%\n",
      "[ 2018-07-31 22:14:05,970][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.test.predict)=97.87%\n",
      "[ 2018-07-31 22:14:06,026][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_0.predict)=97.52%\n",
      "[ 2018-07-31 22:14:06,134][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_1.predict)=97.51%\n",
      "[ 2018-07-31 22:14:06,231][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_2.predict)=99.59%\n",
      "[ 2018-07-31 22:14:06,291][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_3.predict)=97.93%\n",
      "[ 2018-07-31 22:14:06,334][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_4.predict)=97.51%\n",
      "[ 2018-07-31 22:14:06,453][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_5.predict)=97.51%\n",
      "[ 2018-07-31 22:14:06,555][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_6.predict)=97.10%\n",
      "[ 2018-07-31 22:14:06,634][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_7.predict)=97.51%\n",
      "[ 2018-07-31 22:14:06,786][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_8.predict)=98.34%\n",
      "[ 2018-07-31 22:14:06,853][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_9.predict)=97.92%\n",
      "[ 2018-07-31 22:14:06,881][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_cv.predict)=97.84%\n",
      "[ 2018-07-31 22:14:06,882][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.test.predict)=97.87%\n",
      "[ 2018-07-31 22:14:06,895][cascade_classifier.calc_accuracy] Accuracy(layer_3 - train.classifier_average)=97.84%\n",
      "[ 2018-07-31 22:14:06,896][cascade_classifier.calc_accuracy] Accuracy(layer_3 - test.classifier_average)=97.87%\n",
      "[ 2018-07-31 22:14:06,913][cascade_classifier.fit_transform] [layer=4] look_indexs=[0], X_cur_train.shape=(2410, 27), X_cur_test.shape=(1033, 27)\n",
      "[ 2018-07-31 22:14:08,589][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_0.predict)=97.93%\n",
      "[ 2018-07-31 22:14:10,490][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_1.predict)=96.68%\n",
      "[ 2018-07-31 22:14:12,280][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_2.predict)=97.93%\n",
      "[ 2018-07-31 22:14:13,996][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_3.predict)=98.34%\n",
      "[ 2018-07-31 22:14:15,744][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_4.predict)=97.93%\n",
      "[ 2018-07-31 22:14:17,703][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_5.predict)=97.93%\n",
      "[ 2018-07-31 22:14:19,686][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_6.predict)=97.93%\n",
      "[ 2018-07-31 22:14:21,490][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_7.predict)=97.10%\n",
      "[ 2018-07-31 22:14:23,289][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_8.predict)=97.93%\n",
      "[ 2018-07-31 22:14:25,697][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_9.predict)=97.92%\n",
      "[ 2018-07-31 22:14:26,023][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_cv.predict)=97.76%\n",
      "[ 2018-07-31 22:14:26,024][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.test.predict)=97.87%\n",
      "[ 2018-07-31 22:14:27,527][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_0.predict)=97.11%\n",
      "[ 2018-07-31 22:14:30,645][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_1.predict)=97.93%\n",
      "[ 2018-07-31 22:14:32,356][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_2.predict)=98.34%\n",
      "[ 2018-07-31 22:14:35,426][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_3.predict)=98.34%\n",
      "[ 2018-07-31 22:14:37,952][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_4.predict)=97.93%\n",
      "[ 2018-07-31 22:14:40,454][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_5.predict)=99.17%\n",
      "[ 2018-07-31 22:14:42,922][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_6.predict)=97.10%\n",
      "[ 2018-07-31 22:14:45,575][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_7.predict)=97.51%\n",
      "[ 2018-07-31 22:14:47,296][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_8.predict)=97.10%\n",
      "[ 2018-07-31 22:14:49,542][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_9.predict)=97.92%\n",
      "[ 2018-07-31 22:14:49,874][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_cv.predict)=97.84%\n",
      "[ 2018-07-31 22:14:49,877][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.test.predict)=97.87%\n",
      "[ 2018-07-31 22:14:49,924][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_0.predict)=97.52%\n",
      "[ 2018-07-31 22:14:50,084][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_1.predict)=98.34%\n",
      "[ 2018-07-31 22:14:50,139][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_2.predict)=97.51%\n",
      "[ 2018-07-31 22:14:50,277][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_3.predict)=98.34%\n",
      "[ 2018-07-31 22:14:50,402][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_4.predict)=97.51%\n",
      "[ 2018-07-31 22:14:50,445][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_5.predict)=97.51%\n",
      "[ 2018-07-31 22:14:50,474][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_6.predict)=97.10%\n",
      "[ 2018-07-31 22:14:50,524][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_7.predict)=97.10%\n",
      "[ 2018-07-31 22:14:50,565][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_8.predict)=98.34%\n",
      "[ 2018-07-31 22:14:50,667][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_9.predict)=97.92%\n",
      "[ 2018-07-31 22:14:50,705][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_cv.predict)=97.72%\n",
      "[ 2018-07-31 22:14:50,707][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.test.predict)=97.87%\n",
      "[ 2018-07-31 22:14:50,708][cascade_classifier.calc_accuracy] Accuracy(layer_4 - train.classifier_average)=97.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:14:50,710][cascade_classifier.calc_accuracy] Accuracy(layer_4 - test.classifier_average)=97.87%\n",
      "[ 2018-07-31 22:14:50,711][cascade_classifier.fit_transform] [Result][Optimal Level Detected] opt_layer_num=2, accuracy_train=97.88%, accuracy_test=97.87%\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "# X_enc is the concatenated predict_proba result of each estimators of the last layer of the GCForest model\n",
    "    # X_enc.shape =\n",
    "    #   (n_datas, n_estimators * n_classes): If cascade is provided\n",
    "    #   (n_datas, n_estimators * n_classes, dimX, dimY): If only finegrained part is provided\n",
    "    # You can also pass X_test, y_test to fit_transform method, then the accracy on test data will be logged when training.\n",
    "X_train_enc, X_test_enc = gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test)\n",
    "    # WARNING: if you set gc.set_keep_model_in_mem(True), you would have to use\n",
    "    # gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test) to evaluate your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:14:50,849][cascade_classifier.transform] X_groups_test.shape=[(1033, 21)]\n",
      "[ 2018-07-31 22:14:50,857][cascade_classifier.transform] group_dims=[21]\n",
      "[ 2018-07-31 22:14:50,863][cascade_classifier.transform] X_test.shape=(1033, 21)\n",
      "[ 2018-07-31 22:14:50,878][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(1033, 21)\n",
      "[ 2018-07-31 22:14:58,111][cascade_classifier.transform] [layer=1] look_indexs=[0], X_cur_test.shape=(1033, 27)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GCForest = 97.870281 %\n",
      "(' Time ', '185.08', ' seconds')\n",
      "[[1003    1]\n",
      " [  21    8]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99      1004\n",
      "        1.0       0.89      0.28      0.42        29\n",
      "\n",
      "avg / total       0.98      0.98      0.97      1033\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "y_pred = gc.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy of GCForest = {:.6f} %\".format(acc * 100))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2169/2169 [==============================] - 4s 2ms/step - loss: 0.1692 - acc: 0.9700\n",
      "Epoch 2/50\n",
      "2169/2169 [==============================] - 1s 660us/step - loss: 0.1228 - acc: 0.9700\n",
      "Epoch 3/50\n",
      "2169/2169 [==============================] - 1s 599us/step - loss: 0.1057 - acc: 0.9700\n",
      "Epoch 4/50\n",
      "2169/2169 [==============================] - 1s 658us/step - loss: 0.0998 - acc: 0.9700\n",
      "Epoch 5/50\n",
      "2169/2169 [==============================] - 1s 601us/step - loss: 0.0924 - acc: 0.9700\n",
      "Epoch 6/50\n",
      "2169/2169 [==============================] - 1s 553us/step - loss: 0.0787 - acc: 0.9719\n",
      "Epoch 7/50\n",
      "2169/2169 [==============================] - 1s 546us/step - loss: 0.0756 - acc: 0.9751\n",
      "Epoch 8/50\n",
      "2169/2169 [==============================] - 1s 623us/step - loss: 0.0708 - acc: 0.9769\n",
      "Epoch 9/50\n",
      "2169/2169 [==============================] - 1s 575us/step - loss: 0.0701 - acc: 0.9779\n",
      "Epoch 10/50\n",
      "2169/2169 [==============================] - 1s 586us/step - loss: 0.0617 - acc: 0.9802\n",
      "Epoch 11/50\n",
      "2169/2169 [==============================] - 1s 512us/step - loss: 0.0637 - acc: 0.9788\n",
      "Epoch 12/50\n",
      "2169/2169 [==============================] - 1s 690us/step - loss: 0.0594 - acc: 0.9797\n",
      "Epoch 13/50\n",
      "2169/2169 [==============================] - 2s 842us/step - loss: 0.0637 - acc: 0.9806\n",
      "Epoch 14/50\n",
      "2169/2169 [==============================] - 2s 750us/step - loss: 0.0590 - acc: 0.9825\n",
      "Epoch 15/50\n",
      "2169/2169 [==============================] - 2s 920us/step - loss: 0.0575 - acc: 0.9806\n",
      "Epoch 16/50\n",
      "2169/2169 [==============================] - 2s 920us/step - loss: 0.0577 - acc: 0.9843\n",
      "Epoch 17/50\n",
      "2169/2169 [==============================] - 2s 843us/step - loss: 0.0753 - acc: 0.9774\n",
      "Epoch 18/50\n",
      "2169/2169 [==============================] - 2s 978us/step - loss: 0.0570 - acc: 0.9816\n",
      "Epoch 19/50\n",
      "2169/2169 [==============================] - 2s 762us/step - loss: 0.0605 - acc: 0.9788 1s - loss: 0.065\n",
      "Epoch 20/50\n",
      "2169/2169 [==============================] - 2s 772us/step - loss: 0.0572 - acc: 0.9820\n",
      "Epoch 21/50\n",
      "2169/2169 [==============================] - 2s 809us/step - loss: 0.0568 - acc: 0.9806\n",
      "Epoch 22/50\n",
      "2169/2169 [==============================] - 2s 778us/step - loss: 0.0533 - acc: 0.9829\n",
      "Epoch 23/50\n",
      "2169/2169 [==============================] - 2s 830us/step - loss: 0.0550 - acc: 0.9806\n",
      "Epoch 24/50\n",
      "2169/2169 [==============================] - 2s 757us/step - loss: 0.0580 - acc: 0.9834\n",
      "Epoch 25/50\n",
      "2169/2169 [==============================] - 2s 751us/step - loss: 0.0650 - acc: 0.9825\n",
      "Epoch 26/50\n",
      "2169/2169 [==============================] - 2s 708us/step - loss: 0.0594 - acc: 0.9802\n",
      "Epoch 27/50\n",
      "2169/2169 [==============================] - 1s 675us/step - loss: 0.0533 - acc: 0.9829\n",
      "Epoch 28/50\n",
      "2169/2169 [==============================] - 1s 686us/step - loss: 0.0547 - acc: 0.9829\n",
      "Epoch 29/50\n",
      "2169/2169 [==============================] - 1s 652us/step - loss: 0.0580 - acc: 0.9811\n",
      "Epoch 30/50\n",
      "2169/2169 [==============================] - 1s 687us/step - loss: 0.0520 - acc: 0.9852\n",
      "Epoch 31/50\n",
      "2169/2169 [==============================] - 1s 567us/step - loss: 0.0532 - acc: 0.9829\n",
      "Epoch 32/50\n",
      "2169/2169 [==============================] - 1s 546us/step - loss: 0.0570 - acc: 0.9820\n",
      "Epoch 33/50\n",
      "2169/2169 [==============================] - 2s 714us/step - loss: 0.0513 - acc: 0.9829\n",
      "Epoch 34/50\n",
      "2169/2169 [==============================] - 1s 679us/step - loss: 0.0571 - acc: 0.9825\n",
      "Epoch 35/50\n",
      "2169/2169 [==============================] - 1s 667us/step - loss: 0.0493 - acc: 0.9857\n",
      "Epoch 36/50\n",
      "2169/2169 [==============================] - 2s 717us/step - loss: 0.0543 - acc: 0.9834\n",
      "Epoch 37/50\n",
      "2169/2169 [==============================] - 1s 692us/step - loss: 0.0492 - acc: 0.9857\n",
      "Epoch 38/50\n",
      "2169/2169 [==============================] - 2s 714us/step - loss: 0.0516 - acc: 0.9825\n",
      "Epoch 39/50\n",
      "2169/2169 [==============================] - 2s 717us/step - loss: 0.0473 - acc: 0.9852\n",
      "Epoch 40/50\n",
      "2169/2169 [==============================] - 2s 698us/step - loss: 0.0530 - acc: 0.9825\n",
      "Epoch 41/50\n",
      "2169/2169 [==============================] - 1s 665us/step - loss: 0.0531 - acc: 0.9843\n",
      "Epoch 42/50\n",
      "2169/2169 [==============================] - 2s 700us/step - loss: 0.0464 - acc: 0.9839\n",
      "Epoch 43/50\n",
      "2169/2169 [==============================] - 2s 710us/step - loss: 0.0519 - acc: 0.9829\n",
      "Epoch 44/50\n",
      "2169/2169 [==============================] - 1s 613us/step - loss: 0.0514 - acc: 0.9834\n",
      "Epoch 45/50\n",
      "2169/2169 [==============================] - 2s 699us/step - loss: 0.0469 - acc: 0.9857\n",
      "Epoch 46/50\n",
      "2169/2169 [==============================] - 2s 781us/step - loss: 0.0492 - acc: 0.9848\n",
      "Epoch 47/50\n",
      "2169/2169 [==============================] - 1s 687us/step - loss: 0.0521 - acc: 0.9848\n",
      "Epoch 48/50\n",
      "2169/2169 [==============================] - 1s 688us/step - loss: 0.0468 - acc: 0.9871\n",
      "Epoch 49/50\n",
      "2169/2169 [==============================] - 1s 553us/step - loss: 0.0479 - acc: 0.9862\n",
      "Epoch 50/50\n",
      "2169/2169 [==============================] - 1s 574us/step - loss: 0.0506 - acc: 0.9839\n",
      "241/241 [==============================] - 0s 893us/step\n",
      "Epoch 1/50\n",
      "2169/2169 [==============================] - 5s 2ms/step - loss: 0.1608 - acc: 0.9719\n",
      "Epoch 2/50\n",
      "2169/2169 [==============================] - 2s 717us/step - loss: 0.1114 - acc: 0.9719\n",
      "Epoch 3/50\n",
      "2169/2169 [==============================] - 2s 708us/step - loss: 0.0957 - acc: 0.9719\n",
      "Epoch 4/50\n",
      "2169/2169 [==============================] - 2s 741us/step - loss: 0.0903 - acc: 0.9719\n",
      "Epoch 5/50\n",
      "2169/2169 [==============================] - 2s 797us/step - loss: 0.0800 - acc: 0.9719\n",
      "Epoch 6/50\n",
      "2169/2169 [==============================] - 2s 831us/step - loss: 0.0770 - acc: 0.9719\n",
      "Epoch 7/50\n",
      "2169/2169 [==============================] - 2s 729us/step - loss: 0.0762 - acc: 0.9733\n",
      "Epoch 8/50\n",
      "2169/2169 [==============================] - 2s 763us/step - loss: 0.0692 - acc: 0.9774\n",
      "Epoch 9/50\n",
      "2169/2169 [==============================] - 2s 781us/step - loss: 0.0637 - acc: 0.9788\n",
      "Epoch 10/50\n",
      "2169/2169 [==============================] - 2s 836us/step - loss: 0.0666 - acc: 0.9797\n",
      "Epoch 11/50\n",
      "2169/2169 [==============================] - 2s 802us/step - loss: 0.0636 - acc: 0.9788\n",
      "Epoch 12/50\n",
      "2169/2169 [==============================] - 2s 822us/step - loss: 0.0610 - acc: 0.9802\n",
      "Epoch 13/50\n",
      "2169/2169 [==============================] - 1s 656us/step - loss: 0.0624 - acc: 0.9811\n",
      "Epoch 14/50\n",
      "2169/2169 [==============================] - 1s 624us/step - loss: 0.0612 - acc: 0.9788\n",
      "Epoch 15/50\n",
      "2169/2169 [==============================] - 1s 674us/step - loss: 0.0614 - acc: 0.9769\n",
      "Epoch 16/50\n",
      "2169/2169 [==============================] - 1s 670us/step - loss: 0.0615 - acc: 0.9820\n",
      "Epoch 17/50\n",
      "2169/2169 [==============================] - 1s 608us/step - loss: 0.0597 - acc: 0.9797\n",
      "Epoch 18/50\n",
      "2169/2169 [==============================] - 1s 572us/step - loss: 0.0574 - acc: 0.9825\n",
      "Epoch 19/50\n",
      "2169/2169 [==============================] - 1s 647us/step - loss: 0.0591 - acc: 0.9829\n",
      "Epoch 20/50\n",
      "2169/2169 [==============================] - 2s 840us/step - loss: 0.0553 - acc: 0.9816\n",
      "Epoch 21/50\n",
      "2169/2169 [==============================] - 2s 702us/step - loss: 0.0539 - acc: 0.9829\n",
      "Epoch 22/50\n",
      "2169/2169 [==============================] - 2s 693us/step - loss: 0.0548 - acc: 0.9834\n",
      "Epoch 23/50\n",
      "2169/2169 [==============================] - 2s 701us/step - loss: 0.0542 - acc: 0.9829\n",
      "Epoch 24/50\n",
      "2169/2169 [==============================] - 2s 781us/step - loss: 0.0515 - acc: 0.9839\n",
      "Epoch 25/50\n",
      "2169/2169 [==============================] - 1s 673us/step - loss: 0.0518 - acc: 0.9834\n",
      "Epoch 26/50\n",
      "2169/2169 [==============================] - 1s 595us/step - loss: 0.0611 - acc: 0.9802\n",
      "Epoch 27/50\n",
      "2169/2169 [==============================] - 1s 574us/step - loss: 0.0549 - acc: 0.9825\n",
      "Epoch 28/50\n",
      "2169/2169 [==============================] - 1s 632us/step - loss: 0.0542 - acc: 0.9811\n",
      "Epoch 29/50\n",
      "2169/2169 [==============================] - 1s 645us/step - loss: 0.0537 - acc: 0.9829\n",
      "Epoch 30/50\n",
      "2169/2169 [==============================] - 2s 713us/step - loss: 0.0525 - acc: 0.9834\n",
      "Epoch 31/50\n",
      "2169/2169 [==============================] - 2s 790us/step - loss: 0.0490 - acc: 0.9843\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2169/2169 [==============================] - 2s 841us/step - loss: 0.0497 - acc: 0.9820\n",
      "Epoch 33/50\n",
      "2169/2169 [==============================] - 2s 778us/step - loss: 0.0601 - acc: 0.9825\n",
      "Epoch 34/50\n",
      "2169/2169 [==============================] - 2s 866us/step - loss: 0.0528 - acc: 0.9829\n",
      "Epoch 35/50\n",
      "2169/2169 [==============================] - 2s 756us/step - loss: 0.0570 - acc: 0.9843\n",
      "Epoch 36/50\n",
      "2169/2169 [==============================] - 2s 790us/step - loss: 0.0519 - acc: 0.9848\n",
      "Epoch 37/50\n",
      "2169/2169 [==============================] - 2s 827us/step - loss: 0.0528 - acc: 0.9820\n",
      "Epoch 38/50\n",
      "2169/2169 [==============================] - 2s 862us/step - loss: 0.0569 - acc: 0.9843\n",
      "Epoch 39/50\n",
      "2169/2169 [==============================] - 2s 780us/step - loss: 0.0490 - acc: 0.9852 0s - loss: 0.0451 - acc: 0.9\n",
      "Epoch 40/50\n",
      "2169/2169 [==============================] - 1s 615us/step - loss: 0.0485 - acc: 0.9839\n",
      "Epoch 41/50\n",
      "2169/2169 [==============================] - 2s 776us/step - loss: 0.0531 - acc: 0.9820\n",
      "Epoch 42/50\n",
      "2169/2169 [==============================] - 2s 781us/step - loss: 0.0517 - acc: 0.9843\n",
      "Epoch 43/50\n",
      "2169/2169 [==============================] - 2s 717us/step - loss: 0.0476 - acc: 0.9848\n",
      "Epoch 44/50\n",
      "2169/2169 [==============================] - 2s 770us/step - loss: 0.0559 - acc: 0.9811\n",
      "Epoch 45/50\n",
      "2169/2169 [==============================] - 1s 646us/step - loss: 0.0542 - acc: 0.9829\n",
      "Epoch 46/50\n",
      "2169/2169 [==============================] - 1s 556us/step - loss: 0.0511 - acc: 0.9862\n",
      "Epoch 47/50\n",
      "2169/2169 [==============================] - 2s 750us/step - loss: 0.0464 - acc: 0.9857\n",
      "Epoch 48/50\n",
      "2169/2169 [==============================] - 2s 747us/step - loss: 0.0502 - acc: 0.9848\n",
      "Epoch 49/50\n",
      "2169/2169 [==============================] - 2s 747us/step - loss: 0.0456 - acc: 0.9857 0s - loss: 0.0418 - acc: 0. - ETA: 0s - loss: 0.0394 - acc: 0.98\n",
      "Epoch 50/50\n",
      "2169/2169 [==============================] - 2s 835us/step - loss: 0.0503 - acc: 0.9848\n",
      "241/241 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "2169/2169 [==============================] - 4s 2ms/step - loss: 0.1811 - acc: 0.9557\n",
      "Epoch 2/50\n",
      "2169/2169 [==============================] - 1s 640us/step - loss: 0.1165 - acc: 0.9696\n",
      "Epoch 3/50\n",
      "2169/2169 [==============================] - 2s 749us/step - loss: 0.1042 - acc: 0.9696\n",
      "Epoch 4/50\n",
      "2169/2169 [==============================] - 2s 786us/step - loss: 0.0892 - acc: 0.9696\n",
      "Epoch 5/50\n",
      "2169/2169 [==============================] - 2s 753us/step - loss: 0.0842 - acc: 0.9705\n",
      "Epoch 6/50\n",
      "2169/2169 [==============================] - 2s 727us/step - loss: 0.0817 - acc: 0.9714\n",
      "Epoch 7/50\n",
      "2169/2169 [==============================] - 2s 844us/step - loss: 0.0773 - acc: 0.9742\n",
      "Epoch 8/50\n",
      "2169/2169 [==============================] - 2s 870us/step - loss: 0.0766 - acc: 0.9746 0s - loss: 0.0746 - acc\n",
      "Epoch 9/50\n",
      "2169/2169 [==============================] - 2s 793us/step - loss: 0.0681 - acc: 0.9779\n",
      "Epoch 10/50\n",
      "2169/2169 [==============================] - 2s 829us/step - loss: 0.0709 - acc: 0.9769\n",
      "Epoch 11/50\n",
      "2169/2169 [==============================] - 2s 759us/step - loss: 0.0645 - acc: 0.9797\n",
      "Epoch 12/50\n",
      "2169/2169 [==============================] - 1s 651us/step - loss: 0.0628 - acc: 0.9774\n",
      "Epoch 13/50\n",
      "2169/2169 [==============================] - 2s 771us/step - loss: 0.0656 - acc: 0.9825 1s - lo - ETA: 0s - loss: 0.0633 - acc: 0.98\n",
      "Epoch 14/50\n",
      "2169/2169 [==============================] - 2s 849us/step - loss: 0.0637 - acc: 0.9779\n",
      "Epoch 15/50\n",
      "2169/2169 [==============================] - 2s 889us/step - loss: 0.0619 - acc: 0.9793\n",
      "Epoch 16/50\n",
      "2169/2169 [==============================] - 2s 828us/step - loss: 0.0637 - acc: 0.9779\n",
      "Epoch 17/50\n",
      "2169/2169 [==============================] - 2s 946us/step - loss: 0.0568 - acc: 0.9797\n",
      "Epoch 18/50\n",
      "2169/2169 [==============================] - 2s 833us/step - loss: 0.0631 - acc: 0.9793\n",
      "Epoch 19/50\n",
      "2169/2169 [==============================] - 2s 875us/step - loss: 0.0574 - acc: 0.9816\n",
      "Epoch 20/50\n",
      "2169/2169 [==============================] - 2s 882us/step - loss: 0.0562 - acc: 0.9816\n",
      "Epoch 21/50\n",
      "2169/2169 [==============================] - 2s 767us/step - loss: 0.0545 - acc: 0.9820\n",
      "Epoch 22/50\n",
      "2169/2169 [==============================] - 1s 633us/step - loss: 0.0540 - acc: 0.9825\n",
      "Epoch 23/50\n",
      "2169/2169 [==============================] - 1s 629us/step - loss: 0.0570 - acc: 0.9816\n",
      "Epoch 24/50\n",
      "2169/2169 [==============================] - 1s 613us/step - loss: 0.0660 - acc: 0.9765\n",
      "Epoch 25/50\n",
      "2169/2169 [==============================] - 1s 636us/step - loss: 0.0591 - acc: 0.9793\n",
      "Epoch 26/50\n",
      "2169/2169 [==============================] - 1s 677us/step - loss: 0.0563 - acc: 0.9829\n",
      "Epoch 27/50\n",
      "2169/2169 [==============================] - 1s 673us/step - loss: 0.0579 - acc: 0.9825\n",
      "Epoch 28/50\n",
      "2169/2169 [==============================] - 1s 565us/step - loss: 0.0533 - acc: 0.9834\n",
      "Epoch 29/50\n",
      "2169/2169 [==============================] - 1s 678us/step - loss: 0.0518 - acc: 0.9829\n",
      "Epoch 30/50\n",
      "2169/2169 [==============================] - 1s 576us/step - loss: 0.0490 - acc: 0.9825\n",
      "Epoch 31/50\n",
      "2169/2169 [==============================] - 2s 733us/step - loss: 0.0566 - acc: 0.9825\n",
      "Epoch 32/50\n",
      "2169/2169 [==============================] - 2s 697us/step - loss: 0.0559 - acc: 0.9811\n",
      "Epoch 33/50\n",
      "2169/2169 [==============================] - 1s 663us/step - loss: 0.0559 - acc: 0.9811\n",
      "Epoch 34/50\n",
      "2169/2169 [==============================] - 1s 685us/step - loss: 0.0540 - acc: 0.9806\n",
      "Epoch 35/50\n",
      "2169/2169 [==============================] - 1s 672us/step - loss: 0.0515 - acc: 0.9834\n",
      "Epoch 36/50\n",
      "2169/2169 [==============================] - 2s 698us/step - loss: 0.0539 - acc: 0.9834\n",
      "Epoch 37/50\n",
      "2169/2169 [==============================] - 1s 673us/step - loss: 0.0495 - acc: 0.9843\n",
      "Epoch 38/50\n",
      "2169/2169 [==============================] - 1s 623us/step - loss: 0.0533 - acc: 0.9811\n",
      "Epoch 39/50\n",
      "2169/2169 [==============================] - 1s 599us/step - loss: 0.0495 - acc: 0.9839\n",
      "Epoch 40/50\n",
      "2169/2169 [==============================] - 1s 544us/step - loss: 0.0477 - acc: 0.9857\n",
      "Epoch 41/50\n",
      "2169/2169 [==============================] - 1s 650us/step - loss: 0.0525 - acc: 0.9829\n",
      "Epoch 42/50\n",
      "2169/2169 [==============================] - 2s 709us/step - loss: 0.0539 - acc: 0.9834\n",
      "Epoch 43/50\n",
      "2169/2169 [==============================] - 2s 701us/step - loss: 0.0476 - acc: 0.9857\n",
      "Epoch 44/50\n",
      "2169/2169 [==============================] - 1s 598us/step - loss: 0.0471 - acc: 0.9852\n",
      "Epoch 45/50\n",
      "2169/2169 [==============================] - 1s 524us/step - loss: 0.0487 - acc: 0.9843\n",
      "Epoch 46/50\n",
      "2169/2169 [==============================] - 1s 534us/step - loss: 0.0572 - acc: 0.9793\n",
      "Epoch 47/50\n",
      "2169/2169 [==============================] - 1s 563us/step - loss: 0.0537 - acc: 0.9829\n",
      "Epoch 48/50\n",
      "2169/2169 [==============================] - 1s 573us/step - loss: 0.0478 - acc: 0.9839\n",
      "Epoch 49/50\n",
      "2169/2169 [==============================] - 1s 594us/step - loss: 0.0475 - acc: 0.9852\n",
      "Epoch 50/50\n",
      "2169/2169 [==============================] - 1s 584us/step - loss: 0.0454 - acc: 0.9862\n",
      "241/241 [==============================] - 0s 461us/step\n",
      "Epoch 1/50\n",
      "2169/2169 [==============================] - 5s 2ms/step - loss: 0.1562 - acc: 0.9604\n",
      "Epoch 2/50\n",
      "2169/2169 [==============================] - 2s 693us/step - loss: 0.1077 - acc: 0.9733\n",
      "Epoch 3/50\n",
      "2169/2169 [==============================] - 2s 712us/step - loss: 0.0928 - acc: 0.9733\n",
      "Epoch 4/50\n",
      "2169/2169 [==============================] - 2s 807us/step - loss: 0.0877 - acc: 0.9733\n",
      "Epoch 5/50\n",
      "2169/2169 [==============================] - 2s 754us/step - loss: 0.0808 - acc: 0.9733\n",
      "Epoch 6/50\n",
      "2169/2169 [==============================] - 2s 735us/step - loss: 0.0766 - acc: 0.9733\n",
      "Epoch 7/50\n",
      "2169/2169 [==============================] - 2s 783us/step - loss: 0.0689 - acc: 0.9760\n",
      "Epoch 8/50\n",
      "2169/2169 [==============================] - 2s 809us/step - loss: 0.0680 - acc: 0.9760\n",
      "Epoch 9/50\n",
      "2169/2169 [==============================] - 2s 766us/step - loss: 0.0669 - acc: 0.9788\n",
      "Epoch 10/50\n",
      "2169/2169 [==============================] - 2s 718us/step - loss: 0.0649 - acc: 0.9788\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2169/2169 [==============================] - 1s 618us/step - loss: 0.0681 - acc: 0.9793\n",
      "Epoch 12/50\n",
      "2169/2169 [==============================] - 1s 681us/step - loss: 0.0621 - acc: 0.9783\n",
      "Epoch 13/50\n",
      "2169/2169 [==============================] - 2s 713us/step - loss: 0.0615 - acc: 0.9820\n",
      "Epoch 14/50\n",
      "2169/2169 [==============================] - 2s 708us/step - loss: 0.0610 - acc: 0.9816\n",
      "Epoch 15/50\n",
      "2169/2169 [==============================] - 1s 655us/step - loss: 0.0593 - acc: 0.9816\n",
      "Epoch 16/50\n",
      "2169/2169 [==============================] - 2s 697us/step - loss: 0.0593 - acc: 0.9820\n",
      "Epoch 17/50\n",
      "2169/2169 [==============================] - 1s 542us/step - loss: 0.0546 - acc: 0.9816\n",
      "Epoch 18/50\n",
      "2169/2169 [==============================] - 1s 573us/step - loss: 0.0634 - acc: 0.9811\n",
      "Epoch 19/50\n",
      "2169/2169 [==============================] - 1s 548us/step - loss: 0.0590 - acc: 0.9793\n",
      "Epoch 20/50\n",
      "2169/2169 [==============================] - 1s 510us/step - loss: 0.0570 - acc: 0.9820\n",
      "Epoch 21/50\n",
      "2169/2169 [==============================] - 1s 533us/step - loss: 0.0557 - acc: 0.9825\n",
      "Epoch 22/50\n",
      "2169/2169 [==============================] - 1s 609us/step - loss: 0.0564 - acc: 0.9820\n",
      "Epoch 23/50\n",
      "2169/2169 [==============================] - 1s 536us/step - loss: 0.0560 - acc: 0.9811\n",
      "Epoch 24/50\n",
      "2169/2169 [==============================] - 1s 591us/step - loss: 0.0493 - acc: 0.9839\n",
      "Epoch 25/50\n",
      "2169/2169 [==============================] - 1s 563us/step - loss: 0.0514 - acc: 0.9825\n",
      "Epoch 26/50\n",
      "2169/2169 [==============================] - 1s 650us/step - loss: 0.0597 - acc: 0.9811\n",
      "Epoch 27/50\n",
      "2169/2169 [==============================] - 1s 571us/step - loss: 0.0524 - acc: 0.9834\n",
      "Epoch 28/50\n",
      "2169/2169 [==============================] - 1s 663us/step - loss: 0.0525 - acc: 0.9816\n",
      "Epoch 29/50\n",
      "2169/2169 [==============================] - 1s 648us/step - loss: 0.0534 - acc: 0.9806\n",
      "Epoch 30/50\n",
      "2169/2169 [==============================] - 1s 624us/step - loss: 0.0468 - acc: 0.9829\n",
      "Epoch 31/50\n",
      "2169/2169 [==============================] - 1s 666us/step - loss: 0.0554 - acc: 0.9834\n",
      "Epoch 32/50\n",
      "2169/2169 [==============================] - 1s 661us/step - loss: 0.0515 - acc: 0.9829\n",
      "Epoch 33/50\n",
      "2169/2169 [==============================] - 1s 658us/step - loss: 0.0498 - acc: 0.9829\n",
      "Epoch 34/50\n",
      "2169/2169 [==============================] - 1s 671us/step - loss: 0.0536 - acc: 0.9834\n",
      "Epoch 35/50\n",
      "2169/2169 [==============================] - 1s 680us/step - loss: 0.0550 - acc: 0.9811\n",
      "Epoch 36/50\n",
      "2169/2169 [==============================] - 2s 703us/step - loss: 0.0494 - acc: 0.9839\n",
      "Epoch 37/50\n",
      "2169/2169 [==============================] - 1s 614us/step - loss: 0.0538 - acc: 0.9839\n",
      "Epoch 38/50\n",
      "2169/2169 [==============================] - 1s 591us/step - loss: 0.0471 - acc: 0.9834\n",
      "Epoch 39/50\n",
      "2169/2169 [==============================] - 1s 633us/step - loss: 0.0463 - acc: 0.9862\n",
      "Epoch 40/50\n",
      "2169/2169 [==============================] - 2s 704us/step - loss: 0.0496 - acc: 0.9829\n",
      "Epoch 41/50\n",
      "2169/2169 [==============================] - 1s 678us/step - loss: 0.0507 - acc: 0.9820 0s - loss: 0.0506 - acc\n",
      "Epoch 42/50\n",
      "2169/2169 [==============================] - 1s 642us/step - loss: 0.0496 - acc: 0.9834\n",
      "Epoch 43/50\n",
      "2169/2169 [==============================] - 1s 635us/step - loss: 0.0474 - acc: 0.9839\n",
      "Epoch 44/50\n",
      "2169/2169 [==============================] - 1s 549us/step - loss: 0.0494 - acc: 0.9862\n",
      "Epoch 45/50\n",
      "2169/2169 [==============================] - 1s 682us/step - loss: 0.0483 - acc: 0.9857\n",
      "Epoch 46/50\n",
      "2169/2169 [==============================] - 2s 837us/step - loss: 0.0487 - acc: 0.9852\n",
      "Epoch 47/50\n",
      "2169/2169 [==============================] - 2s 747us/step - loss: 0.0576 - acc: 0.9806\n",
      "Epoch 48/50\n",
      "2169/2169 [==============================] - 2s 738us/step - loss: 0.0487 - acc: 0.9825\n",
      "Epoch 49/50\n",
      "2169/2169 [==============================] - 2s 833us/step - loss: 0.0446 - acc: 0.9866 2s - \n",
      "Epoch 50/50\n",
      "2169/2169 [==============================] - 1s 686us/step - loss: 0.0461 - acc: 0.9862\n",
      "241/241 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "2169/2169 [==============================] - 4s 2ms/step - loss: 0.1740 - acc: 0.9553\n",
      "Epoch 2/50\n",
      "2169/2169 [==============================] - 1s 598us/step - loss: 0.1163 - acc: 0.9700\n",
      "Epoch 3/50\n",
      "2169/2169 [==============================] - 1s 616us/step - loss: 0.1051 - acc: 0.9700\n",
      "Epoch 4/50\n",
      "2169/2169 [==============================] - 1s 605us/step - loss: 0.0936 - acc: 0.9700\n",
      "Epoch 5/50\n",
      "2169/2169 [==============================] - 1s 535us/step - loss: 0.0863 - acc: 0.9700\n",
      "Epoch 6/50\n",
      "2169/2169 [==============================] - 1s 538us/step - loss: 0.0741 - acc: 0.9742 0s - loss: 0.0822 -\n",
      "Epoch 7/50\n",
      "2169/2169 [==============================] - 1s 662us/step - loss: 0.0734 - acc: 0.9774\n",
      "Epoch 8/50\n",
      "2169/2169 [==============================] - 1s 585us/step - loss: 0.0725 - acc: 0.9746\n",
      "Epoch 9/50\n",
      "2169/2169 [==============================] - 1s 615us/step - loss: 0.0638 - acc: 0.9802\n",
      "Epoch 10/50\n",
      "2169/2169 [==============================] - 2s 729us/step - loss: 0.0627 - acc: 0.9774\n",
      "Epoch 11/50\n",
      "2169/2169 [==============================] - 2s 748us/step - loss: 0.0780 - acc: 0.9751\n",
      "Epoch 12/50\n",
      "2169/2169 [==============================] - 1s 673us/step - loss: 0.0679 - acc: 0.9783\n",
      "Epoch 13/50\n",
      "2169/2169 [==============================] - 2s 832us/step - loss: 0.0624 - acc: 0.9802\n",
      "Epoch 14/50\n",
      "2169/2169 [==============================] - 2s 705us/step - loss: 0.0598 - acc: 0.9802\n",
      "Epoch 15/50\n",
      "2169/2169 [==============================] - 2s 733us/step - loss: 0.0573 - acc: 0.9806\n",
      "Epoch 16/50\n",
      "2169/2169 [==============================] - 2s 705us/step - loss: 0.0579 - acc: 0.9816\n",
      "Epoch 17/50\n",
      "2169/2169 [==============================] - 2s 766us/step - loss: 0.0577 - acc: 0.9793\n",
      "Epoch 18/50\n",
      "2169/2169 [==============================] - 2s 756us/step - loss: 0.0541 - acc: 0.9829\n",
      "Epoch 19/50\n",
      "2169/2169 [==============================] - 1s 607us/step - loss: 0.0588 - acc: 0.9802\n",
      "Epoch 20/50\n",
      "2169/2169 [==============================] - 1s 586us/step - loss: 0.0572 - acc: 0.9825\n",
      "Epoch 21/50\n",
      "2169/2169 [==============================] - 1s 571us/step - loss: 0.0519 - acc: 0.9825\n",
      "Epoch 22/50\n",
      "2169/2169 [==============================] - 2s 701us/step - loss: 0.0525 - acc: 0.9834\n",
      "Epoch 23/50\n",
      "2169/2169 [==============================] - 1s 611us/step - loss: 0.0541 - acc: 0.9843 1s - loss: \n",
      "Epoch 24/50\n",
      "2169/2169 [==============================] - 2s 701us/step - loss: 0.0534 - acc: 0.9834\n",
      "Epoch 25/50\n",
      "2169/2169 [==============================] - 2s 730us/step - loss: 0.0554 - acc: 0.9806\n",
      "Epoch 26/50\n",
      "2169/2169 [==============================] - 1s 580us/step - loss: 0.0541 - acc: 0.9816\n",
      "Epoch 27/50\n",
      "2169/2169 [==============================] - 2s 696us/step - loss: 0.0576 - acc: 0.9839\n",
      "Epoch 28/50\n",
      "2169/2169 [==============================] - 1s 648us/step - loss: 0.0556 - acc: 0.9825\n",
      "Epoch 29/50\n",
      "2169/2169 [==============================] - 1s 679us/step - loss: 0.0484 - acc: 0.9839\n",
      "Epoch 30/50\n",
      "2169/2169 [==============================] - 1s 622us/step - loss: 0.0466 - acc: 0.9852\n",
      "Epoch 31/50\n",
      "2169/2169 [==============================] - 2s 760us/step - loss: 0.0476 - acc: 0.9839\n",
      "Epoch 32/50\n",
      "2169/2169 [==============================] - 1s 688us/step - loss: 0.0564 - acc: 0.9816\n",
      "Epoch 33/50\n",
      "2169/2169 [==============================] - 2s 708us/step - loss: 0.0532 - acc: 0.9834\n",
      "Epoch 34/50\n",
      "2169/2169 [==============================] - 2s 742us/step - loss: 0.0471 - acc: 0.9839\n",
      "Epoch 35/50\n",
      "2169/2169 [==============================] - 2s 784us/step - loss: 0.0623 - acc: 0.9806\n",
      "Epoch 36/50\n",
      "2169/2169 [==============================] - 2s 800us/step - loss: 0.0503 - acc: 0.9848\n",
      "Epoch 37/50\n",
      "2169/2169 [==============================] - 2s 736us/step - loss: 0.0474 - acc: 0.9848\n",
      "Epoch 38/50\n",
      "2169/2169 [==============================] - 2s 759us/step - loss: 0.0486 - acc: 0.9839\n",
      "Epoch 39/50\n",
      "2169/2169 [==============================] - 1s 662us/step - loss: 0.0468 - acc: 0.9848\n",
      "Epoch 40/50\n",
      "2169/2169 [==============================] - 1s 566us/step - loss: 0.0455 - acc: 0.9857\n",
      "Epoch 41/50\n",
      "2169/2169 [==============================] - 1s 562us/step - loss: 0.0521 - acc: 0.9829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "2169/2169 [==============================] - 1s 516us/step - loss: 0.0539 - acc: 0.9816\n",
      "Epoch 43/50\n",
      "2169/2169 [==============================] - 1s 551us/step - loss: 0.0515 - acc: 0.9852\n",
      "Epoch 44/50\n",
      "2169/2169 [==============================] - 1s 528us/step - loss: 0.0489 - acc: 0.9839\n",
      "Epoch 45/50\n",
      "2169/2169 [==============================] - 1s 540us/step - loss: 0.0464 - acc: 0.9862\n",
      "Epoch 46/50\n",
      "2169/2169 [==============================] - 1s 651us/step - loss: 0.0488 - acc: 0.9852\n",
      "Epoch 47/50\n",
      "2169/2169 [==============================] - 1s 661us/step - loss: 0.0513 - acc: 0.9839\n",
      "Epoch 48/50\n",
      "2169/2169 [==============================] - 1s 556us/step - loss: 0.0469 - acc: 0.9852\n",
      "Epoch 49/50\n",
      "2169/2169 [==============================] - 1s 662us/step - loss: 0.0465 - acc: 0.9866\n",
      "Epoch 50/50\n",
      "2169/2169 [==============================] - 1s 612us/step - loss: 0.0520 - acc: 0.9866\n",
      "241/241 [==============================] - 0s 666us/step\n",
      "Epoch 1/50\n",
      "2169/2169 [==============================] - 3s 1ms/step - loss: 0.1750 - acc: 0.9714\n",
      "Epoch 2/50\n",
      "2169/2169 [==============================] - 2s 711us/step - loss: 0.1174 - acc: 0.9714\n",
      "Epoch 3/50\n",
      "2169/2169 [==============================] - 1s 656us/step - loss: 0.0968 - acc: 0.9714\n",
      "Epoch 4/50\n",
      "2169/2169 [==============================] - 1s 667us/step - loss: 0.0928 - acc: 0.9714\n",
      "Epoch 5/50\n",
      "2169/2169 [==============================] - 2s 693us/step - loss: 0.0822 - acc: 0.9714\n",
      "Epoch 6/50\n",
      "2169/2169 [==============================] - 1s 606us/step - loss: 0.0731 - acc: 0.9714\n",
      "Epoch 7/50\n",
      "2169/2169 [==============================] - 1s 618us/step - loss: 0.0707 - acc: 0.9737\n",
      "Epoch 8/50\n",
      "2169/2169 [==============================] - 1s 664us/step - loss: 0.0756 - acc: 0.9783\n",
      "Epoch 9/50\n",
      "2169/2169 [==============================] - 1s 672us/step - loss: 0.0656 - acc: 0.9816\n",
      "Epoch 10/50\n",
      "2169/2169 [==============================] - 1s 669us/step - loss: 0.0613 - acc: 0.9811\n",
      "Epoch 11/50\n",
      "2169/2169 [==============================] - 2s 749us/step - loss: 0.0569 - acc: 0.9820\n",
      "Epoch 12/50\n",
      "2169/2169 [==============================] - 1s 611us/step - loss: 0.0563 - acc: 0.9820\n",
      "Epoch 13/50\n",
      "2169/2169 [==============================] - 1s 594us/step - loss: 0.0594 - acc: 0.9834\n",
      "Epoch 14/50\n",
      "2169/2169 [==============================] - 1s 651us/step - loss: 0.0563 - acc: 0.9848\n",
      "Epoch 15/50\n",
      "2169/2169 [==============================] - 1s 582us/step - loss: 0.0562 - acc: 0.9839\n",
      "Epoch 16/50\n",
      "2169/2169 [==============================] - 1s 593us/step - loss: 0.0685 - acc: 0.9802\n",
      "Epoch 17/50\n",
      "2169/2169 [==============================] - 1s 652us/step - loss: 0.0576 - acc: 0.9820\n",
      "Epoch 18/50\n",
      "2169/2169 [==============================] - 1s 654us/step - loss: 0.0559 - acc: 0.9829\n",
      "Epoch 19/50\n",
      "2169/2169 [==============================] - 2s 844us/step - loss: 0.0543 - acc: 0.9852\n",
      "Epoch 20/50\n",
      "2169/2169 [==============================] - 2s 754us/step - loss: 0.0541 - acc: 0.9834\n",
      "Epoch 21/50\n",
      "2169/2169 [==============================] - 2s 848us/step - loss: 0.0582 - acc: 0.9843 0s - loss: 0.0594 - acc: 0\n",
      "Epoch 22/50\n",
      "2169/2169 [==============================] - 2s 737us/step - loss: 0.0527 - acc: 0.9862 1s - loss: \n",
      "Epoch 23/50\n",
      "2169/2169 [==============================] - 2s 759us/step - loss: 0.0506 - acc: 0.9843\n",
      "Epoch 24/50\n",
      "2169/2169 [==============================] - 1s 638us/step - loss: 0.0519 - acc: 0.9829\n",
      "Epoch 25/50\n",
      "2169/2169 [==============================] - 1s 604us/step - loss: 0.0537 - acc: 0.9834\n",
      "Epoch 26/50\n",
      "2169/2169 [==============================] - 1s 562us/step - loss: 0.0492 - acc: 0.9834\n",
      "Epoch 27/50\n",
      "2169/2169 [==============================] - 1s 514us/step - loss: 0.0502 - acc: 0.9852\n",
      "Epoch 28/50\n",
      "2169/2169 [==============================] - 1s 508us/step - loss: 0.0536 - acc: 0.9852\n",
      "Epoch 29/50\n",
      "2169/2169 [==============================] - 1s 556us/step - loss: 0.0616 - acc: 0.9802\n",
      "Epoch 30/50\n",
      "2169/2169 [==============================] - 1s 566us/step - loss: 0.0614 - acc: 0.9820\n",
      "Epoch 31/50\n",
      "2169/2169 [==============================] - 1s 670us/step - loss: 0.0499 - acc: 0.9852\n",
      "Epoch 32/50\n",
      "2169/2169 [==============================] - 1s 609us/step - loss: 0.0519 - acc: 0.9843 1s - loss: 0\n",
      "Epoch 33/50\n",
      "2169/2169 [==============================] - 1s 655us/step - loss: 0.0508 - acc: 0.9839\n",
      "Epoch 34/50\n",
      "2169/2169 [==============================] - 1s 518us/step - loss: 0.0524 - acc: 0.9862\n",
      "Epoch 35/50\n",
      "2169/2169 [==============================] - 1s 526us/step - loss: 0.0519 - acc: 0.9829\n",
      "Epoch 36/50\n",
      "2169/2169 [==============================] - 1s 633us/step - loss: 0.0493 - acc: 0.9839\n",
      "Epoch 37/50\n",
      "2169/2169 [==============================] - 1s 642us/step - loss: 0.0525 - acc: 0.9843\n",
      "Epoch 38/50\n",
      "2169/2169 [==============================] - 2s 694us/step - loss: 0.0459 - acc: 0.9871\n",
      "Epoch 39/50\n",
      "2169/2169 [==============================] - 2s 704us/step - loss: 0.0479 - acc: 0.9866\n",
      "Epoch 40/50\n",
      "2169/2169 [==============================] - 1s 644us/step - loss: 0.0478 - acc: 0.9862\n",
      "Epoch 41/50\n",
      "2169/2169 [==============================] - 1s 576us/step - loss: 0.0520 - acc: 0.9843\n",
      "Epoch 42/50\n",
      "2169/2169 [==============================] - 2s 695us/step - loss: 0.0474 - acc: 0.9880\n",
      "Epoch 43/50\n",
      "2169/2169 [==============================] - 1s 605us/step - loss: 0.0471 - acc: 0.9862\n",
      "Epoch 44/50\n",
      "2169/2169 [==============================] - 2s 705us/step - loss: 0.0498 - acc: 0.9843\n",
      "Epoch 45/50\n",
      "2169/2169 [==============================] - 1s 607us/step - loss: 0.0522 - acc: 0.9843\n",
      "Epoch 46/50\n",
      "2169/2169 [==============================] - 1s 555us/step - loss: 0.0498 - acc: 0.9852\n",
      "Epoch 47/50\n",
      "2169/2169 [==============================] - 1s 558us/step - loss: 0.0470 - acc: 0.9834\n",
      "Epoch 48/50\n",
      "2169/2169 [==============================] - 1s 601us/step - loss: 0.0534 - acc: 0.9857\n",
      "Epoch 49/50\n",
      "2169/2169 [==============================] - 1s 647us/step - loss: 0.0493 - acc: 0.9848\n",
      "Epoch 50/50\n",
      "2169/2169 [==============================] - 1s 618us/step - loss: 0.0473 - acc: 0.9857\n",
      "241/241 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "2169/2169 [==============================] - 4s 2ms/step - loss: 0.1818 - acc: 0.9691\n",
      "Epoch 2/50\n",
      "2169/2169 [==============================] - 1s 529us/step - loss: 0.1226 - acc: 0.9691\n",
      "Epoch 3/50\n",
      "2169/2169 [==============================] - 1s 556us/step - loss: 0.1000 - acc: 0.9691\n",
      "Epoch 4/50\n",
      "2169/2169 [==============================] - 1s 658us/step - loss: 0.0917 - acc: 0.9691\n",
      "Epoch 5/50\n",
      "2169/2169 [==============================] - 2s 727us/step - loss: 0.0898 - acc: 0.9691\n",
      "Epoch 6/50\n",
      "2169/2169 [==============================] - 1s 674us/step - loss: 0.0779 - acc: 0.9719\n",
      "Epoch 7/50\n",
      "2169/2169 [==============================] - 1s 661us/step - loss: 0.0720 - acc: 0.9769\n",
      "Epoch 8/50\n",
      "2169/2169 [==============================] - 1s 669us/step - loss: 0.0714 - acc: 0.9765\n",
      "Epoch 9/50\n",
      "2169/2169 [==============================] - 1s 591us/step - loss: 0.0630 - acc: 0.9793\n",
      "Epoch 10/50\n",
      "2169/2169 [==============================] - 1s 655us/step - loss: 0.0629 - acc: 0.9797\n",
      "Epoch 11/50\n",
      "2169/2169 [==============================] - 1s 591us/step - loss: 0.0622 - acc: 0.9797\n",
      "Epoch 12/50\n",
      "2169/2169 [==============================] - 1s 536us/step - loss: 0.0613 - acc: 0.9802\n",
      "Epoch 13/50\n",
      "2169/2169 [==============================] - 1s 640us/step - loss: 0.0599 - acc: 0.9802\n",
      "Epoch 14/50\n",
      "2169/2169 [==============================] - 1s 657us/step - loss: 0.0515 - acc: 0.9825\n",
      "Epoch 15/50\n",
      "2169/2169 [==============================] - 2s 781us/step - loss: 0.0551 - acc: 0.9816\n",
      "Epoch 16/50\n",
      "2169/2169 [==============================] - 2s 797us/step - loss: 0.0535 - acc: 0.9802\n",
      "Epoch 17/50\n",
      "2169/2169 [==============================] - 2s 715us/step - loss: 0.0591 - acc: 0.9811\n",
      "Epoch 18/50\n",
      "2169/2169 [==============================] - 2s 698us/step - loss: 0.0547 - acc: 0.9843 0s - loss: 0.0567 - acc: 0.98\n",
      "Epoch 19/50\n",
      "2169/2169 [==============================] - 2s 706us/step - loss: 0.0605 - acc: 0.9816\n",
      "Epoch 20/50\n",
      "2169/2169 [==============================] - 1s 630us/step - loss: 0.0568 - acc: 0.9834\n",
      "Epoch 21/50\n",
      "2169/2169 [==============================] - 1s 554us/step - loss: 0.0589 - acc: 0.9829\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2169/2169 [==============================] - 1s 565us/step - loss: 0.0545 - acc: 0.9820\n",
      "Epoch 23/50\n",
      "2169/2169 [==============================] - 1s 588us/step - loss: 0.0488 - acc: 0.9852\n",
      "Epoch 24/50\n",
      "2169/2169 [==============================] - 1s 624us/step - loss: 0.0524 - acc: 0.9829\n",
      "Epoch 25/50\n",
      "2169/2169 [==============================] - 1s 574us/step - loss: 0.0539 - acc: 0.9834\n",
      "Epoch 26/50\n",
      "2169/2169 [==============================] - 1s 671us/step - loss: 0.0476 - acc: 0.9857\n",
      "Epoch 27/50\n",
      "2169/2169 [==============================] - 2s 793us/step - loss: 0.0483 - acc: 0.9839\n",
      "Epoch 28/50\n",
      "2169/2169 [==============================] - 1s 624us/step - loss: 0.0509 - acc: 0.9839\n",
      "Epoch 29/50\n",
      "2169/2169 [==============================] - 2s 723us/step - loss: 0.0506 - acc: 0.9820\n",
      "Epoch 30/50\n",
      "2169/2169 [==============================] - 2s 755us/step - loss: 0.0480 - acc: 0.9811\n",
      "Epoch 31/50\n",
      "2169/2169 [==============================] - 1s 687us/step - loss: 0.0492 - acc: 0.9843\n",
      "Epoch 32/50\n",
      "2169/2169 [==============================] - 1s 661us/step - loss: 0.0513 - acc: 0.9866\n",
      "Epoch 33/50\n",
      "2169/2169 [==============================] - 2s 821us/step - loss: 0.0471 - acc: 0.9829 0s - loss: 0.0446 - acc\n",
      "Epoch 34/50\n",
      "2169/2169 [==============================] - 2s 699us/step - loss: 0.0476 - acc: 0.9829 1s - los\n",
      "Epoch 35/50\n",
      "2169/2169 [==============================] - 2s 702us/step - loss: 0.0436 - acc: 0.9852 0s - loss: 0.0501 - acc:\n",
      "Epoch 36/50\n",
      "2169/2169 [==============================] - 2s 761us/step - loss: 0.0447 - acc: 0.9866\n",
      "Epoch 37/50\n",
      "2169/2169 [==============================] - 2s 730us/step - loss: 0.0489 - acc: 0.9843\n",
      "Epoch 38/50\n",
      "2169/2169 [==============================] - 2s 733us/step - loss: 0.0460 - acc: 0.9862\n",
      "Epoch 39/50\n",
      "2169/2169 [==============================] - 2s 754us/step - loss: 0.0449 - acc: 0.9862\n",
      "Epoch 40/50\n",
      "2169/2169 [==============================] - 2s 735us/step - loss: 0.0457 - acc: 0.9857\n",
      "Epoch 41/50\n",
      "2169/2169 [==============================] - 2s 761us/step - loss: 0.0442 - acc: 0.9852\n",
      "Epoch 42/50\n",
      "2169/2169 [==============================] - 1s 595us/step - loss: 0.0510 - acc: 0.9825\n",
      "Epoch 43/50\n",
      "2169/2169 [==============================] - 1s 590us/step - loss: 0.0522 - acc: 0.9811\n",
      "Epoch 44/50\n",
      "2169/2169 [==============================] - 2s 761us/step - loss: 0.0441 - acc: 0.9857\n",
      "Epoch 45/50\n",
      "2169/2169 [==============================] - 1s 623us/step - loss: 0.0469 - acc: 0.9852\n",
      "Epoch 46/50\n",
      "2169/2169 [==============================] - 1s 565us/step - loss: 0.0459 - acc: 0.9852\n",
      "Epoch 47/50\n",
      "2169/2169 [==============================] - 1s 557us/step - loss: 0.0439 - acc: 0.9852\n",
      "Epoch 48/50\n",
      "2169/2169 [==============================] - 1s 541us/step - loss: 0.0489 - acc: 0.9852\n",
      "Epoch 49/50\n",
      "2169/2169 [==============================] - 1s 597us/step - loss: 0.0447 - acc: 0.9848\n",
      "Epoch 50/50\n",
      "2169/2169 [==============================] - 1s 556us/step - loss: 0.0446 - acc: 0.9834\n",
      "241/241 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "2169/2169 [==============================] - 4s 2ms/step - loss: 0.1741 - acc: 0.9567\n",
      "Epoch 2/50\n",
      "2169/2169 [==============================] - 2s 782us/step - loss: 0.1155 - acc: 0.9714\n",
      "Epoch 3/50\n",
      "2169/2169 [==============================] - 2s 786us/step - loss: 0.0987 - acc: 0.9714\n",
      "Epoch 4/50\n",
      "2169/2169 [==============================] - 2s 727us/step - loss: 0.0861 - acc: 0.9714\n",
      "Epoch 5/50\n",
      "2169/2169 [==============================] - 2s 729us/step - loss: 0.0792 - acc: 0.9714\n",
      "Epoch 6/50\n",
      "2169/2169 [==============================] - 2s 693us/step - loss: 0.0724 - acc: 0.9719\n",
      "Epoch 7/50\n",
      "2169/2169 [==============================] - 1s 608us/step - loss: 0.0639 - acc: 0.9779\n",
      "Epoch 8/50\n",
      "2169/2169 [==============================] - 1s 685us/step - loss: 0.0641 - acc: 0.9797\n",
      "Epoch 9/50\n",
      "2169/2169 [==============================] - 1s 685us/step - loss: 0.0593 - acc: 0.9779\n",
      "Epoch 10/50\n",
      "2169/2169 [==============================] - 1s 650us/step - loss: 0.0615 - acc: 0.9788\n",
      "Epoch 11/50\n",
      "2169/2169 [==============================] - 1s 651us/step - loss: 0.0612 - acc: 0.9811\n",
      "Epoch 12/50\n",
      "2169/2169 [==============================] - 2s 725us/step - loss: 0.0556 - acc: 0.9797\n",
      "Epoch 13/50\n",
      "2169/2169 [==============================] - ETA: 0s - loss: 0.0561 - acc: 0.983 - 2s 715us/step - loss: 0.0554 - acc: 0.9839\n",
      "Epoch 14/50\n",
      "2169/2169 [==============================] - 1s 645us/step - loss: 0.0481 - acc: 0.9820\n",
      "Epoch 15/50\n",
      "2169/2169 [==============================] - 1s 590us/step - loss: 0.0457 - acc: 0.9862\n",
      "Epoch 16/50\n",
      "2169/2169 [==============================] - 1s 619us/step - loss: 0.0498 - acc: 0.9816\n",
      "Epoch 17/50\n",
      "2169/2169 [==============================] - 2s 695us/step - loss: 0.0461 - acc: 0.9866\n",
      "Epoch 18/50\n",
      "2169/2169 [==============================] - 1s 628us/step - loss: 0.0506 - acc: 0.9797\n",
      "Epoch 19/50\n",
      "2169/2169 [==============================] - 1s 577us/step - loss: 0.0508 - acc: 0.9834\n",
      "Epoch 20/50\n",
      "2169/2169 [==============================] - 1s 588us/step - loss: 0.0461 - acc: 0.9871\n",
      "Epoch 21/50\n",
      "2169/2169 [==============================] - 1s 690us/step - loss: 0.0470 - acc: 0.9852\n",
      "Epoch 22/50\n",
      "2169/2169 [==============================] - 1s 603us/step - loss: 0.0451 - acc: 0.9834\n",
      "Epoch 23/50\n",
      "2169/2169 [==============================] - 1s 669us/step - loss: 0.0462 - acc: 0.9862\n",
      "Epoch 24/50\n",
      "2169/2169 [==============================] - 1s 619us/step - loss: 0.0467 - acc: 0.9843\n",
      "Epoch 25/50\n",
      "2169/2169 [==============================] - 2s 726us/step - loss: 0.0423 - acc: 0.9843\n",
      "Epoch 26/50\n",
      "2169/2169 [==============================] - 1s 690us/step - loss: 0.0465 - acc: 0.9848\n",
      "Epoch 27/50\n",
      "2169/2169 [==============================] - 1s 609us/step - loss: 0.0429 - acc: 0.9857\n",
      "Epoch 28/50\n",
      "2169/2169 [==============================] - 1s 531us/step - loss: 0.0417 - acc: 0.9839\n",
      "Epoch 29/50\n",
      "2169/2169 [==============================] - 1s 581us/step - loss: 0.0407 - acc: 0.9857\n",
      "Epoch 30/50\n",
      "2169/2169 [==============================] - 1s 564us/step - loss: 0.0437 - acc: 0.9876\n",
      "Epoch 31/50\n",
      "2169/2169 [==============================] - 1s 601us/step - loss: 0.0404 - acc: 0.9889 0s - loss: 0.\n",
      "Epoch 32/50\n",
      "2169/2169 [==============================] - 1s 539us/step - loss: 0.0383 - acc: 0.9880\n",
      "Epoch 33/50\n",
      "2169/2169 [==============================] - 1s 495us/step - loss: 0.0397 - acc: 0.9862\n",
      "Epoch 34/50\n",
      "2169/2169 [==============================] - 1s 546us/step - loss: 0.0389 - acc: 0.9866\n",
      "Epoch 35/50\n",
      "2169/2169 [==============================] - 1s 640us/step - loss: 0.0426 - acc: 0.9862\n",
      "Epoch 36/50\n",
      "2169/2169 [==============================] - 1s 630us/step - loss: 0.0396 - acc: 0.9857\n",
      "Epoch 37/50\n",
      "2169/2169 [==============================] - 1s 620us/step - loss: 0.0422 - acc: 0.9848\n",
      "Epoch 38/50\n",
      "2169/2169 [==============================] - 1s 647us/step - loss: 0.0447 - acc: 0.9852\n",
      "Epoch 39/50\n",
      "2169/2169 [==============================] - 2s 813us/step - loss: 0.0391 - acc: 0.9885\n",
      "Epoch 40/50\n",
      "2169/2169 [==============================] - 2s 825us/step - loss: 0.0433 - acc: 0.9852\n",
      "Epoch 41/50\n",
      "2169/2169 [==============================] - 2s 967us/step - loss: 0.0404 - acc: 0.9862\n",
      "Epoch 42/50\n",
      "2169/2169 [==============================] - 2s 857us/step - loss: 0.0412 - acc: 0.9852\n",
      "Epoch 43/50\n",
      "2169/2169 [==============================] - 2s 842us/step - loss: 0.0355 - acc: 0.9899\n",
      "Epoch 44/50\n",
      "2169/2169 [==============================] - 2s 839us/step - loss: 0.0360 - acc: 0.9889\n",
      "Epoch 45/50\n",
      "2169/2169 [==============================] - 2s 757us/step - loss: 0.0370 - acc: 0.9862\n",
      "Epoch 46/50\n",
      "2169/2169 [==============================] - 2s 703us/step - loss: 0.0379 - acc: 0.9876 0s - loss: 0.0352 - acc: 0.\n",
      "Epoch 47/50\n",
      "2169/2169 [==============================] - 2s 695us/step - loss: 0.0373 - acc: 0.9871\n",
      "Epoch 48/50\n",
      "2169/2169 [==============================] - 1s 664us/step - loss: 0.0351 - acc: 0.9876\n",
      "Epoch 49/50\n",
      "2169/2169 [==============================] - 2s 714us/step - loss: 0.0353 - acc: 0.9880\n",
      "Epoch 50/50\n",
      "2169/2169 [==============================] - 2s 762us/step - loss: 0.0393 - acc: 0.9862\n",
      "241/241 [==============================] - 1s 3ms/step\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2169/2169 [==============================] - 5s 2ms/step - loss: 0.1731 - acc: 0.9539\n",
      "Epoch 2/50\n",
      "2169/2169 [==============================] - 2s 741us/step - loss: 0.1208 - acc: 0.9677\n",
      "Epoch 3/50\n",
      "2169/2169 [==============================] - 2s 754us/step - loss: 0.1088 - acc: 0.9677\n",
      "Epoch 4/50\n",
      "2169/2169 [==============================] - 2s 772us/step - loss: 0.0981 - acc: 0.9677\n",
      "Epoch 5/50\n",
      "2169/2169 [==============================] - 2s 766us/step - loss: 0.0851 - acc: 0.9677\n",
      "Epoch 6/50\n",
      "2169/2169 [==============================] - 2s 732us/step - loss: 0.0837 - acc: 0.9686\n",
      "Epoch 7/50\n",
      "2169/2169 [==============================] - 2s 754us/step - loss: 0.0776 - acc: 0.9733\n",
      "Epoch 8/50\n",
      "2169/2169 [==============================] - 2s 694us/step - loss: 0.0701 - acc: 0.9760\n",
      "Epoch 9/50\n",
      "2169/2169 [==============================] - 1s 623us/step - loss: 0.0702 - acc: 0.9774\n",
      "Epoch 10/50\n",
      "2169/2169 [==============================] - 1s 681us/step - loss: 0.0640 - acc: 0.9765\n",
      "Epoch 11/50\n",
      "2169/2169 [==============================] - 1s 660us/step - loss: 0.0612 - acc: 0.9797\n",
      "Epoch 12/50\n",
      "2169/2169 [==============================] - 1s 623us/step - loss: 0.0646 - acc: 0.9811\n",
      "Epoch 13/50\n",
      "2169/2169 [==============================] - 1s 648us/step - loss: 0.0617 - acc: 0.9806\n",
      "Epoch 14/50\n",
      "2169/2169 [==============================] - 2s 719us/step - loss: 0.0602 - acc: 0.9779\n",
      "Epoch 15/50\n",
      "2169/2169 [==============================] - 2s 712us/step - loss: 0.0609 - acc: 0.9829\n",
      "Epoch 16/50\n",
      "2169/2169 [==============================] - 2s 753us/step - loss: 0.0625 - acc: 0.9788\n",
      "Epoch 17/50\n",
      "2169/2169 [==============================] - 2s 750us/step - loss: 0.0577 - acc: 0.9811\n",
      "Epoch 18/50\n",
      "2169/2169 [==============================] - 2s 763us/step - loss: 0.0611 - acc: 0.9797\n",
      "Epoch 19/50\n",
      "2169/2169 [==============================] - 2s 783us/step - loss: 0.0535 - acc: 0.9820\n",
      "Epoch 20/50\n",
      "2169/2169 [==============================] - 2s 732us/step - loss: 0.0557 - acc: 0.9797\n",
      "Epoch 21/50\n",
      "2169/2169 [==============================] - 2s 830us/step - loss: 0.0558 - acc: 0.9820\n",
      "Epoch 22/50\n",
      "2169/2169 [==============================] - 2s 892us/step - loss: 0.0577 - acc: 0.9829\n",
      "Epoch 23/50\n",
      "2169/2169 [==============================] - 2s 850us/step - loss: 0.0545 - acc: 0.9802\n",
      "Epoch 24/50\n",
      "2169/2169 [==============================] - 2s 864us/step - loss: 0.0600 - acc: 0.9806\n",
      "Epoch 25/50\n",
      "2169/2169 [==============================] - 2s 824us/step - loss: 0.0597 - acc: 0.9834\n",
      "Epoch 26/50\n",
      "2169/2169 [==============================] - 2s 859us/step - loss: 0.0540 - acc: 0.9797\n",
      "Epoch 27/50\n",
      "2169/2169 [==============================] - 2s 817us/step - loss: 0.0565 - acc: 0.9820\n",
      "Epoch 28/50\n",
      "2169/2169 [==============================] - 2s 709us/step - loss: 0.0585 - acc: 0.9806\n",
      "Epoch 29/50\n",
      "2169/2169 [==============================] - 2s 763us/step - loss: 0.0518 - acc: 0.9843\n",
      "Epoch 30/50\n",
      "2169/2169 [==============================] - 2s 743us/step - loss: 0.0532 - acc: 0.9820\n",
      "Epoch 31/50\n",
      "2169/2169 [==============================] - 2s 741us/step - loss: 0.0527 - acc: 0.9829\n",
      "Epoch 32/50\n",
      "2169/2169 [==============================] - 2s 756us/step - loss: 0.0573 - acc: 0.9797\n",
      "Epoch 33/50\n",
      "2169/2169 [==============================] - 2s 742us/step - loss: 0.0544 - acc: 0.9820\n",
      "Epoch 34/50\n",
      "2169/2169 [==============================] - 1s 591us/step - loss: 0.0534 - acc: 0.9806\n",
      "Epoch 35/50\n",
      "2169/2169 [==============================] - 1s 685us/step - loss: 0.0532 - acc: 0.9834\n",
      "Epoch 36/50\n",
      "2169/2169 [==============================] - 1s 657us/step - loss: 0.0491 - acc: 0.9839\n",
      "Epoch 37/50\n",
      "2169/2169 [==============================] - 1s 685us/step - loss: 0.0499 - acc: 0.9857\n",
      "Epoch 38/50\n",
      "2169/2169 [==============================] - 2s 728us/step - loss: 0.0602 - acc: 0.9797 0s - loss: 0.0597 - a\n",
      "Epoch 39/50\n",
      "2169/2169 [==============================] - 2s 702us/step - loss: 0.0508 - acc: 0.9852\n",
      "Epoch 40/50\n",
      "2169/2169 [==============================] - 2s 806us/step - loss: 0.0502 - acc: 0.9825\n",
      "Epoch 41/50\n",
      "2169/2169 [==============================] - 2s 813us/step - loss: 0.0561 - acc: 0.9811\n",
      "Epoch 42/50\n",
      "2169/2169 [==============================] - 2s 842us/step - loss: 0.0494 - acc: 0.9843\n",
      "Epoch 43/50\n",
      "2169/2169 [==============================] - 2s 747us/step - loss: 0.0486 - acc: 0.9843\n",
      "Epoch 44/50\n",
      "2169/2169 [==============================] - 1s 677us/step - loss: 0.0502 - acc: 0.9825\n",
      "Epoch 45/50\n",
      "2169/2169 [==============================] - 1s 638us/step - loss: 0.0488 - acc: 0.9825\n",
      "Epoch 46/50\n",
      "2169/2169 [==============================] - 2s 719us/step - loss: 0.0632 - acc: 0.9825\n",
      "Epoch 47/50\n",
      "2169/2169 [==============================] - 2s 741us/step - loss: 0.0528 - acc: 0.9839\n",
      "Epoch 48/50\n",
      "2169/2169 [==============================] - 2s 714us/step - loss: 0.0456 - acc: 0.9862\n",
      "Epoch 49/50\n",
      "2169/2169 [==============================] - 1s 560us/step - loss: 0.0507 - acc: 0.9816\n",
      "Epoch 50/50\n",
      "2169/2169 [==============================] - 1s 674us/step - loss: 0.0459 - acc: 0.9848\n",
      "241/241 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "2169/2169 [==============================] - 5s 2ms/step - loss: 0.1638 - acc: 0.9710\n",
      "Epoch 2/50\n",
      "2169/2169 [==============================] - 2s 773us/step - loss: 0.1162 - acc: 0.9710\n",
      "Epoch 3/50\n",
      "2169/2169 [==============================] - 2s 831us/step - loss: 0.0972 - acc: 0.9710\n",
      "Epoch 4/50\n",
      "2169/2169 [==============================] - 2s 882us/step - loss: 0.0861 - acc: 0.9710 0s - loss: 0.0873 - acc: 0.97\n",
      "Epoch 5/50\n",
      "2169/2169 [==============================] - 2s 849us/step - loss: 0.0798 - acc: 0.9710\n",
      "Epoch 6/50\n",
      "2169/2169 [==============================] - 2s 884us/step - loss: 0.0690 - acc: 0.9746\n",
      "Epoch 7/50\n",
      "2169/2169 [==============================] - 2s 777us/step - loss: 0.0633 - acc: 0.9779\n",
      "Epoch 8/50\n",
      "2169/2169 [==============================] - 2s 920us/step - loss: 0.0636 - acc: 0.9802\n",
      "Epoch 9/50\n",
      "2169/2169 [==============================] - 2s 780us/step - loss: 0.0600 - acc: 0.9806\n",
      "Epoch 10/50\n",
      "2169/2169 [==============================] - 2s 713us/step - loss: 0.0648 - acc: 0.9756\n",
      "Epoch 11/50\n",
      "2169/2169 [==============================] - 2s 777us/step - loss: 0.0551 - acc: 0.9811\n",
      "Epoch 12/50\n",
      "2169/2169 [==============================] - 2s 747us/step - loss: 0.0602 - acc: 0.9806\n",
      "Epoch 13/50\n",
      "2169/2169 [==============================] - 2s 710us/step - loss: 0.0588 - acc: 0.9811\n",
      "Epoch 14/50\n",
      "2169/2169 [==============================] - 2s 703us/step - loss: 0.0541 - acc: 0.9834\n",
      "Epoch 15/50\n",
      "2169/2169 [==============================] - 2s 723us/step - loss: 0.0511 - acc: 0.9816\n",
      "Epoch 16/50\n",
      "2169/2169 [==============================] - 1s 680us/step - loss: 0.0555 - acc: 0.9829\n",
      "Epoch 17/50\n",
      "2169/2169 [==============================] - 2s 721us/step - loss: 0.0547 - acc: 0.9829\n",
      "Epoch 18/50\n",
      "2169/2169 [==============================] - 2s 724us/step - loss: 0.0481 - acc: 0.9834\n",
      "Epoch 19/50\n",
      "2169/2169 [==============================] - 2s 800us/step - loss: 0.0551 - acc: 0.9820 1s -\n",
      "Epoch 20/50\n",
      "2169/2169 [==============================] - 2s 728us/step - loss: 0.0494 - acc: 0.9839\n",
      "Epoch 21/50\n",
      "2169/2169 [==============================] - 2s 759us/step - loss: 0.0470 - acc: 0.9857\n",
      "Epoch 22/50\n",
      "2169/2169 [==============================] - 2s 710us/step - loss: 0.0501 - acc: 0.9825\n",
      "Epoch 23/50\n",
      "2169/2169 [==============================] - 2s 773us/step - loss: 0.0517 - acc: 0.9816\n",
      "Epoch 24/50\n",
      "2169/2169 [==============================] - 2s 703us/step - loss: 0.0457 - acc: 0.9848\n",
      "Epoch 25/50\n",
      "2169/2169 [==============================] - 2s 704us/step - loss: 0.0518 - acc: 0.9848\n",
      "Epoch 26/50\n",
      "2169/2169 [==============================] - 1s 647us/step - loss: 0.0460 - acc: 0.9857\n",
      "Epoch 27/50\n",
      "2169/2169 [==============================] - 1s 611us/step - loss: 0.0486 - acc: 0.9829\n",
      "Epoch 28/50\n",
      "2169/2169 [==============================] - 1s 598us/step - loss: 0.0526 - acc: 0.9843\n",
      "Epoch 29/50\n",
      "2169/2169 [==============================] - 1s 663us/step - loss: 0.0518 - acc: 0.9816\n",
      "Epoch 30/50\n",
      "2169/2169 [==============================] - 1s 605us/step - loss: 0.0464 - acc: 0.9866\n",
      "Epoch 31/50\n",
      "2169/2169 [==============================] - 2s 704us/step - loss: 0.0445 - acc: 0.9857\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2169/2169 [==============================] - 2s 709us/step - loss: 0.0446 - acc: 0.9848\n",
      "Epoch 33/50\n",
      "2169/2169 [==============================] - 2s 732us/step - loss: 0.0477 - acc: 0.9848\n",
      "Epoch 34/50\n",
      "2169/2169 [==============================] - 1s 682us/step - loss: 0.0455 - acc: 0.9839\n",
      "Epoch 35/50\n",
      "2169/2169 [==============================] - 2s 749us/step - loss: 0.0471 - acc: 0.9834\n",
      "Epoch 36/50\n",
      "2169/2169 [==============================] - 2s 763us/step - loss: 0.0454 - acc: 0.9843\n",
      "Epoch 37/50\n",
      "2169/2169 [==============================] - 2s 741us/step - loss: 0.0489 - acc: 0.9876\n",
      "Epoch 38/50\n",
      "2169/2169 [==============================] - 2s 743us/step - loss: 0.0446 - acc: 0.9862\n",
      "Epoch 39/50\n",
      "2169/2169 [==============================] - 2s 745us/step - loss: 0.0476 - acc: 0.9839\n",
      "Epoch 40/50\n",
      "2169/2169 [==============================] - 2s 754us/step - loss: 0.0440 - acc: 0.9862\n",
      "Epoch 41/50\n",
      "2169/2169 [==============================] - 2s 802us/step - loss: 0.0486 - acc: 0.9852\n",
      "Epoch 42/50\n",
      "2169/2169 [==============================] - 2s 815us/step - loss: 0.0438 - acc: 0.9843\n",
      "Epoch 43/50\n",
      "2169/2169 [==============================] - 2s 885us/step - loss: 0.0392 - acc: 0.9885\n",
      "Epoch 44/50\n",
      "2169/2169 [==============================] - 2s 860us/step - loss: 0.0461 - acc: 0.9862 1s - lo\n",
      "Epoch 45/50\n",
      "2169/2169 [==============================] - 2s 793us/step - loss: 0.0435 - acc: 0.9852\n",
      "Epoch 46/50\n",
      "2169/2169 [==============================] - 2s 788us/step - loss: 0.0415 - acc: 0.9866 0s - loss: 0.0453 - acc\n",
      "Epoch 47/50\n",
      "2169/2169 [==============================] - 2s 753us/step - loss: 0.0452 - acc: 0.9866\n",
      "Epoch 48/50\n",
      "2169/2169 [==============================] - 2s 786us/step - loss: 0.0424 - acc: 0.9848\n",
      "Epoch 49/50\n",
      "2169/2169 [==============================] - 2s 741us/step - loss: 0.0477 - acc: 0.9852\n",
      "Epoch 50/50\n",
      "2169/2169 [==============================] - 2s 771us/step - loss: 0.0416 - acc: 0.9862\n",
      "241/241 [==============================] - 1s 3ms/step\n",
      "Accuracy mean: 0.981327801003\n",
      "Accuracy variance: 0.00594100453011\n",
      "(' Time ', '832.507', ' seconds')\n",
      "[[1003    1]\n",
      " [  21    8]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99      1004\n",
      "        1.0       0.89      0.28      0.42        29\n",
      "\n",
      "avg / total       0.98      0.98      0.97      1033\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# estimators \n",
    "# Evaluating the ANN\n",
    "t0 = time()\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 1024, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n",
    "    classifier.add(Dense(units = 512, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 50)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of DecisionTreeClassifier = 95.740561 %\n",
      "(' Time ', '0.16', ' seconds')\n",
      "[[982  22]\n",
      " [ 22   7]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.98      0.98      1004\n",
      "        1.0       0.24      0.24      0.24        29\n",
      "\n",
      "avg / total       0.96      0.96      0.96      1033\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of DecisionTreeClassifier = {:.6f} %\".format(acc * 100))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of RandomForestClassifier = 97.386254 %\n",
      "(' Time ', '3.671', ' seconds')\n",
      "[[1004    0]\n",
      " [  27    2]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.99      1004\n",
      "        1.0       1.00      0.07      0.13        29\n",
      "\n",
      "avg / total       0.97      0.97      0.96      1033\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of RandomForestClassifier = {:.6f} %\".format(acc * 100))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of ExtraTreesClassifier = 97.289448 %\n",
      "(' Time ', '2.915', ' seconds')\n",
      "[[1004    0]\n",
      " [  28    1]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.99      1004\n",
      "        1.0       1.00      0.03      0.07        29\n",
      "\n",
      "avg / total       0.97      0.97      0.96      1033\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of ExtraTreesClassifier = {:.6f} %\".format(acc * 100))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of AdaBoostClassifier = 96.708616 %\n",
      "(' Time ', '3.439', ' seconds')\n",
      "[[992  12]\n",
      " [ 22   7]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.99      0.98      1004\n",
      "        1.0       0.37      0.24      0.29        29\n",
      "\n",
      "avg / total       0.96      0.97      0.96      1033\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of AdaBoostClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Naive_bayes  GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GaussianNB = 93.901258 %\n",
      "(' Time ', '0.018', ' seconds')\n",
      "[[961  43]\n",
      " [ 20   9]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.96      0.97      1004\n",
      "        1.0       0.17      0.31      0.22        29\n",
      "\n",
      "avg / total       0.96      0.94      0.95      1033\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred= gnb.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of GaussianNB = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
