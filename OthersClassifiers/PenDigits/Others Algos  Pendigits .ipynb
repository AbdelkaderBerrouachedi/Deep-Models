{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt \n",
    "from pprint import pprint\n",
    "from numpy import array\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>att1</th>\n",
       "      <th>att2</th>\n",
       "      <th>att3</th>\n",
       "      <th>att4</th>\n",
       "      <th>att5</th>\n",
       "      <th>att6</th>\n",
       "      <th>att7</th>\n",
       "      <th>att8</th>\n",
       "      <th>att9</th>\n",
       "      <th>att10</th>\n",
       "      <th>att11</th>\n",
       "      <th>att12</th>\n",
       "      <th>att13</th>\n",
       "      <th>att14</th>\n",
       "      <th>att15</th>\n",
       "      <th>att16</th>\n",
       "      <th>outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   att1   att2  att3  att4  att5  att6  att7  att8   att9  att10  att11  \\\n",
       "0  48.0  100.0  20.0  80.0   0.0  51.0  55.0  43.0  100.0   56.0   90.0   \n",
       "1  38.0  100.0   4.0  85.0   0.0  53.0  58.0  46.0  100.0   52.0   88.0   \n",
       "2  53.0  100.0  25.0  70.0   0.0  39.0  50.0  34.0  100.0   42.0   85.0   \n",
       "3  12.0  100.0   0.0  71.0  25.0  43.0  86.0  44.0  100.0   75.0   90.0   \n",
       "4  26.0  100.0   0.0  83.0  23.0  51.0  83.0  42.0  100.0   55.0   79.0   \n",
       "\n",
       "   att12  att13  att14  att15  att16  outlier  \n",
       "0   62.0   86.0   30.0   73.0    0.0        1  \n",
       "1   64.0   78.0   32.0   73.0    0.0        1  \n",
       "2   64.0   77.0   32.0   80.0    0.0        1  \n",
       "3   52.0   90.0   20.0   90.0    0.0        1  \n",
       "4   84.0   56.0   42.0   37.0    0.0        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df=pd.read_csv('PenDigits_withoutdupl_norm_v01.csv')  \n",
    "\n",
    "del df['id']\n",
    "del df['Unnamed: 0']\n",
    "df['outlier'] = df.outlier.apply(lambda label: 1 if label == \"'yes'\" else 0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df to values\n",
    "df = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GC Forest\n",
    "import argparse\n",
    "import sys\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "sys.path.insert(0, \"lib\")\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.utils.config_utils import load_json\n",
    "config = load_json(\"./examples/Pendigits.json\")   \n",
    "gc = GCForest(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# train test \n",
    "from sklearn.cross_validation import train_test_split\n",
    "y = df[:,16]\n",
    "X = df[:,0:16]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of class\n",
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:11:18,721][cascade_classifier.fit_transform] X_groups_train.shape=[(6907, 16)],y_train.shape=(6907,),X_groups_test.shape=[(2961, 16)],y_test.shape=(2961,)\n",
      "[ 2018-07-31 22:11:18,724][cascade_classifier.fit_transform] group_dims=[16]\n",
      "[ 2018-07-31 22:11:18,726][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-31 22:11:18,727][cascade_classifier.fit_transform] group_ends=[16]\n",
      "[ 2018-07-31 22:11:18,728][cascade_classifier.fit_transform] X_train.shape=(6907, 16),X_test.shape=(2961, 16)\n",
      "[ 2018-07-31 22:11:18,730][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(6907, 16), X_cur_test.shape=(2961, 16)\n",
      "[ 2018-07-31 22:11:19,616][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=99.71%\n",
      "[ 2018-07-31 22:11:20,751][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-31 22:11:21,846][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=99.86%\n",
      "[ 2018-07-31 22:11:22,856][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=99.71%\n",
      "[ 2018-07-31 22:11:23,955][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=99.86%\n",
      "[ 2018-07-31 22:11:25,071][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=99.86%\n",
      "[ 2018-07-31 22:11:26,136][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=100.00%\n",
      "[ 2018-07-31 22:11:27,228][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=99.86%\n",
      "[ 2018-07-31 22:11:28,277][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=100.00%\n",
      "[ 2018-07-31 22:11:29,347][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=99.86%\n",
      "[ 2018-07-31 22:11:29,595][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=99.87%\n",
      "[ 2018-07-31 22:11:29,597][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=99.93%\n",
      "[ 2018-07-31 22:11:30,461][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_0.predict)=100.00%\n",
      "[ 2018-07-31 22:11:31,581][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_1.predict)=99.86%\n",
      "[ 2018-07-31 22:11:32,705][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_2.predict)=99.86%\n",
      "[ 2018-07-31 22:11:33,803][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_3.predict)=99.86%\n",
      "[ 2018-07-31 22:11:34,898][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_4.predict)=100.00%\n",
      "[ 2018-07-31 22:11:36,012][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_5.predict)=99.86%\n",
      "[ 2018-07-31 22:11:37,082][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_6.predict)=99.86%\n",
      "[ 2018-07-31 22:11:38,338][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_7.predict)=100.00%\n",
      "[ 2018-07-31 22:11:39,395][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_8.predict)=100.00%\n",
      "[ 2018-07-31 22:11:40,487][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_9.predict)=99.86%\n",
      "[ 2018-07-31 22:11:40,705][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_cv.predict)=99.91%\n",
      "[ 2018-07-31 22:11:40,706][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.test.predict)=99.97%\n",
      "[ 2018-07-31 22:11:40,830][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_0.predict)=99.71%\n",
      "[ 2018-07-31 22:11:40,939][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_1.predict)=99.86%\n",
      "[ 2018-07-31 22:11:41,030][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_2.predict)=99.86%\n",
      "[ 2018-07-31 22:11:41,112][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_3.predict)=100.00%\n",
      "[ 2018-07-31 22:11:41,228][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_4.predict)=99.86%\n",
      "[ 2018-07-31 22:11:41,333][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_5.predict)=99.57%\n",
      "[ 2018-07-31 22:11:41,478][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_6.predict)=99.71%\n",
      "[ 2018-07-31 22:11:41,576][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_7.predict)=99.86%\n",
      "[ 2018-07-31 22:11:41,680][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_8.predict)=99.86%\n",
      "[ 2018-07-31 22:11:41,781][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_9.predict)=99.86%\n",
      "[ 2018-07-31 22:11:41,805][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_cv.predict)=99.81%\n",
      "[ 2018-07-31 22:11:41,807][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.test.predict)=99.90%\n",
      "[ 2018-07-31 22:11:41,815][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=99.93%\n",
      "[ 2018-07-31 22:11:41,816][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=100.00%\n",
      "[ 2018-07-31 22:11:41,821][cascade_classifier.fit_transform] [layer=1] look_indexs=[0], X_cur_train.shape=(6907, 22), X_cur_test.shape=(2961, 22)\n",
      "[ 2018-07-31 22:11:42,792][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_0.predict)=99.86%\n",
      "[ 2018-07-31 22:11:43,957][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-31 22:11:45,029][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_2.predict)=99.86%\n",
      "[ 2018-07-31 22:11:46,135][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_3.predict)=100.00%\n",
      "[ 2018-07-31 22:11:47,195][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_4.predict)=100.00%\n",
      "[ 2018-07-31 22:11:48,261][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_5.predict)=99.86%\n",
      "[ 2018-07-31 22:11:49,330][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_6.predict)=99.86%\n",
      "[ 2018-07-31 22:11:50,380][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_7.predict)=99.86%\n",
      "[ 2018-07-31 22:11:51,784][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_8.predict)=100.00%\n",
      "[ 2018-07-31 22:11:53,048][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_9.predict)=100.00%\n",
      "[ 2018-07-31 22:11:53,302][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_cv.predict)=99.93%\n",
      "[ 2018-07-31 22:11:53,303][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.test.predict)=100.00%\n",
      "[ 2018-07-31 22:11:54,270][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_0.predict)=100.00%\n",
      "[ 2018-07-31 22:11:55,423][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-31 22:11:56,704][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_2.predict)=99.71%\n",
      "[ 2018-07-31 22:11:57,961][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_3.predict)=100.00%\n",
      "[ 2018-07-31 22:11:59,049][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_4.predict)=99.86%\n",
      "[ 2018-07-31 22:12:00,304][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_5.predict)=100.00%\n",
      "[ 2018-07-31 22:12:01,498][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_6.predict)=100.00%\n",
      "[ 2018-07-31 22:12:02,628][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_7.predict)=100.00%\n",
      "[ 2018-07-31 22:12:04,173][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_8.predict)=100.00%\n",
      "[ 2018-07-31 22:12:05,537][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_9.predict)=100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:12:05,859][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_cv.predict)=99.96%\n",
      "[ 2018-07-31 22:12:05,895][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.test.predict)=100.00%\n",
      "[ 2018-07-31 22:12:06,093][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_0.predict)=99.86%\n",
      "[ 2018-07-31 22:12:06,490][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_1.predict)=99.71%\n",
      "[ 2018-07-31 22:12:06,817][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_2.predict)=100.00%\n",
      "[ 2018-07-31 22:12:07,062][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_3.predict)=100.00%\n",
      "[ 2018-07-31 22:12:07,275][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_4.predict)=99.71%\n",
      "[ 2018-07-31 22:12:07,559][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_5.predict)=99.57%\n",
      "[ 2018-07-31 22:12:07,847][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_6.predict)=99.86%\n",
      "[ 2018-07-31 22:12:08,118][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_7.predict)=100.00%\n",
      "[ 2018-07-31 22:12:08,412][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_8.predict)=99.86%\n",
      "[ 2018-07-31 22:12:08,572][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_9.predict)=99.86%\n",
      "[ 2018-07-31 22:12:08,578][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_cv.predict)=99.84%\n",
      "[ 2018-07-31 22:12:08,583][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.test.predict)=99.90%\n",
      "[ 2018-07-31 22:12:08,591][cascade_classifier.calc_accuracy] Accuracy(layer_1 - train.classifier_average)=99.93%\n",
      "[ 2018-07-31 22:12:08,599][cascade_classifier.calc_accuracy] Accuracy(layer_1 - test.classifier_average)=100.00%\n",
      "[ 2018-07-31 22:12:08,601][cascade_classifier.fit_transform] [layer=2] look_indexs=[0], X_cur_train.shape=(6907, 22), X_cur_test.shape=(2961, 22)\n",
      "[ 2018-07-31 22:12:10,374][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_0.predict)=99.86%\n",
      "[ 2018-07-31 22:12:12,036][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-31 22:12:13,764][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_2.predict)=100.00%\n",
      "[ 2018-07-31 22:12:15,317][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_3.predict)=100.00%\n",
      "[ 2018-07-31 22:12:16,650][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_4.predict)=99.71%\n",
      "[ 2018-07-31 22:12:18,118][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_5.predict)=100.00%\n",
      "[ 2018-07-31 22:12:19,492][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_6.predict)=100.00%\n",
      "[ 2018-07-31 22:12:20,865][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_7.predict)=99.86%\n",
      "[ 2018-07-31 22:12:22,468][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_8.predict)=100.00%\n",
      "[ 2018-07-31 22:12:24,157][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_9.predict)=100.00%\n",
      "[ 2018-07-31 22:12:24,401][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_cv.predict)=99.94%\n",
      "[ 2018-07-31 22:12:24,405][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.test.predict)=100.00%\n",
      "[ 2018-07-31 22:12:25,486][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_0.predict)=99.86%\n",
      "[ 2018-07-31 22:12:26,938][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_1.predict)=99.86%\n",
      "[ 2018-07-31 22:12:28,269][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_2.predict)=100.00%\n",
      "[ 2018-07-31 22:12:29,439][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_3.predict)=100.00%\n",
      "[ 2018-07-31 22:12:30,763][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_4.predict)=100.00%\n",
      "[ 2018-07-31 22:12:32,284][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_5.predict)=99.86%\n",
      "[ 2018-07-31 22:12:33,410][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_6.predict)=99.71%\n",
      "[ 2018-07-31 22:12:34,640][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_7.predict)=99.86%\n",
      "[ 2018-07-31 22:12:35,983][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_8.predict)=100.00%\n",
      "[ 2018-07-31 22:12:37,348][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_9.predict)=100.00%\n",
      "[ 2018-07-31 22:12:37,575][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_cv.predict)=99.91%\n",
      "[ 2018-07-31 22:12:37,583][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.test.predict)=100.00%\n",
      "[ 2018-07-31 22:12:37,806][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_0.predict)=100.00%\n",
      "[ 2018-07-31 22:12:38,017][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_1.predict)=99.71%\n",
      "[ 2018-07-31 22:12:38,250][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_2.predict)=100.00%\n",
      "[ 2018-07-31 22:12:38,546][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_3.predict)=99.57%\n",
      "[ 2018-07-31 22:12:38,935][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_4.predict)=99.86%\n",
      "[ 2018-07-31 22:12:39,212][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_5.predict)=99.86%\n",
      "[ 2018-07-31 22:12:39,460][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_6.predict)=99.86%\n",
      "[ 2018-07-31 22:12:39,704][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_7.predict)=99.86%\n",
      "[ 2018-07-31 22:12:39,936][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_8.predict)=99.86%\n",
      "[ 2018-07-31 22:12:40,303][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_9.predict)=100.00%\n",
      "[ 2018-07-31 22:12:40,340][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_cv.predict)=99.86%\n",
      "[ 2018-07-31 22:12:40,345][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.test.predict)=99.97%\n",
      "[ 2018-07-31 22:12:40,349][cascade_classifier.calc_accuracy] Accuracy(layer_2 - train.classifier_average)=99.93%\n",
      "[ 2018-07-31 22:12:40,353][cascade_classifier.calc_accuracy] Accuracy(layer_2 - test.classifier_average)=100.00%\n",
      "[ 2018-07-31 22:12:40,355][cascade_classifier.fit_transform] [layer=3] look_indexs=[0], X_cur_train.shape=(6907, 22), X_cur_test.shape=(2961, 22)\n",
      "[ 2018-07-31 22:12:41,961][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_0.predict)=99.86%\n",
      "[ 2018-07-31 22:12:43,363][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_1.predict)=99.86%\n",
      "[ 2018-07-31 22:12:44,793][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_2.predict)=99.86%\n",
      "[ 2018-07-31 22:12:46,126][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_3.predict)=99.86%\n",
      "[ 2018-07-31 22:12:47,446][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_4.predict)=100.00%\n",
      "[ 2018-07-31 22:12:48,598][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_5.predict)=100.00%\n",
      "[ 2018-07-31 22:12:49,849][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_6.predict)=100.00%\n",
      "[ 2018-07-31 22:12:51,248][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_7.predict)=100.00%\n",
      "[ 2018-07-31 22:12:52,745][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_8.predict)=99.86%\n",
      "[ 2018-07-31 22:12:54,153][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_9.predict)=99.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:12:54,412][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_cv.predict)=99.91%\n",
      "[ 2018-07-31 22:12:54,413][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.test.predict)=100.00%\n",
      "[ 2018-07-31 22:12:55,366][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_0.predict)=99.86%\n",
      "[ 2018-07-31 22:12:56,554][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-31 22:12:57,662][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_2.predict)=100.00%\n",
      "[ 2018-07-31 22:12:59,134][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_3.predict)=99.71%\n",
      "[ 2018-07-31 22:13:00,510][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_4.predict)=99.71%\n",
      "[ 2018-07-31 22:13:01,899][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_5.predict)=100.00%\n",
      "[ 2018-07-31 22:13:03,243][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_6.predict)=100.00%\n",
      "[ 2018-07-31 22:13:04,604][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_7.predict)=100.00%\n",
      "[ 2018-07-31 22:13:05,838][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_8.predict)=99.86%\n",
      "[ 2018-07-31 22:13:07,332][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_9.predict)=100.00%\n",
      "[ 2018-07-31 22:13:07,552][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_cv.predict)=99.91%\n",
      "[ 2018-07-31 22:13:07,554][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.test.predict)=100.00%\n",
      "[ 2018-07-31 22:13:07,793][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_0.predict)=100.00%\n",
      "[ 2018-07-31 22:13:07,996][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_1.predict)=99.86%\n",
      "[ 2018-07-31 22:13:08,190][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_2.predict)=100.00%\n",
      "[ 2018-07-31 22:13:08,333][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_3.predict)=99.42%\n",
      "[ 2018-07-31 22:13:08,613][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_4.predict)=99.86%\n",
      "[ 2018-07-31 22:13:08,920][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_5.predict)=99.86%\n",
      "[ 2018-07-31 22:13:09,182][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_6.predict)=99.71%\n",
      "[ 2018-07-31 22:13:09,329][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_7.predict)=100.00%\n",
      "[ 2018-07-31 22:13:09,607][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_8.predict)=99.71%\n",
      "[ 2018-07-31 22:13:09,812][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_9.predict)=99.71%\n",
      "[ 2018-07-31 22:13:09,825][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_cv.predict)=99.81%\n",
      "[ 2018-07-31 22:13:09,827][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.test.predict)=99.90%\n",
      "[ 2018-07-31 22:13:09,829][cascade_classifier.calc_accuracy] Accuracy(layer_3 - train.classifier_average)=99.93%\n",
      "[ 2018-07-31 22:13:09,830][cascade_classifier.calc_accuracy] Accuracy(layer_3 - test.classifier_average)=100.00%\n",
      "[ 2018-07-31 22:13:09,832][cascade_classifier.fit_transform] [Result][Optimal Level Detected] opt_layer_num=1, accuracy_train=99.93%, accuracy_test=100.00%\n"
     ]
    }
   ],
   "source": [
    "t0=time()\n",
    "# X_enc is the concatenated predict_proba result of each estimators of the last layer of the GCForest model\n",
    "    # X_enc.shape =\n",
    "    #   (n_datas, n_estimators * n_classes): If cascade is provided\n",
    "    #   (n_datas, n_estimators * n_classes, dimX, dimY): If only finegrained part is provided\n",
    "    # You can also pass X_test, y_test to fit_transform method, then the accracy on test data will be logged when training.\n",
    "X_train_enc, X_test_enc = gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test)\n",
    "    # WARNING: if you set gc.set_keep_model_in_mem(True), you would have to use\n",
    "    # gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test) to evaluate your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:13:09,885][cascade_classifier.transform] X_groups_test.shape=[(2961, 16)]\n",
      "[ 2018-07-31 22:13:09,893][cascade_classifier.transform] group_dims=[16]\n",
      "[ 2018-07-31 22:13:09,897][cascade_classifier.transform] X_test.shape=(2961, 16)\n",
      "[ 2018-07-31 22:13:09,898][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(2961, 16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GCForest = 100.000000 %\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "y_pred = gc.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy of GCForest = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' Time ', '116.388', ' seconds')\n",
      "[[2957    0]\n",
      " [   0    4]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      2957\n",
      "        1.0       1.00      1.00      1.00         4\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2961\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6216/6216 [==============================] - 4s 585us/step - loss: 0.0542 - acc: 0.9924\n",
      "Epoch 2/50\n",
      "6216/6216 [==============================] - 3s 423us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 3/50\n",
      "6216/6216 [==============================] - 3s 442us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 4/50\n",
      "6216/6216 [==============================] - 3s 410us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 5/50\n",
      "6216/6216 [==============================] - 3s 454us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 6/50\n",
      "6216/6216 [==============================] - 3s 464us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 7/50\n",
      "6216/6216 [==============================] - 3s 494us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 8/50\n",
      "6216/6216 [==============================] - 3s 526us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 9/50\n",
      "6216/6216 [==============================] - 3s 555us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 10/50\n",
      "6216/6216 [==============================] - 3s 492us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 11/50\n",
      "6216/6216 [==============================] - 3s 440us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 12/50\n",
      "6216/6216 [==============================] - 3s 450us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 13/50\n",
      "6216/6216 [==============================] - 3s 416us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 14/50\n",
      "6216/6216 [==============================] - 3s 445us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 15/50\n",
      "6216/6216 [==============================] - 3s 520us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 16/50\n",
      "6216/6216 [==============================] - 3s 511us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 17/50\n",
      "6216/6216 [==============================] - 3s 522us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 18/50\n",
      "6216/6216 [==============================] - 3s 526us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 19/50\n",
      "6216/6216 [==============================] - 3s 509us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 20/50\n",
      "6216/6216 [==============================] - 3s 436us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 21/50\n",
      "6216/6216 [==============================] - 3s 482us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 22/50\n",
      "6216/6216 [==============================] - 3s 512us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 23/50\n",
      "6216/6216 [==============================] - 3s 504us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 24/50\n",
      "6216/6216 [==============================] - 4s 575us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 25/50\n",
      "6216/6216 [==============================] - 4s 578us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 26/50\n",
      "6216/6216 [==============================] - 4s 596us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 27/50\n",
      "6216/6216 [==============================] - 4s 625us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 28/50\n",
      "6216/6216 [==============================] - 4s 688us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 29/50\n",
      "6216/6216 [==============================] - 3s 542us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 30/50\n",
      "6216/6216 [==============================] - 4s 567us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 31/50\n",
      "6216/6216 [==============================] - 3s 550us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 32/50\n",
      "6216/6216 [==============================] - 3s 543us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 33/50\n",
      "6216/6216 [==============================] - 3s 552us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 34/50\n",
      "6216/6216 [==============================] - 4s 616us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 35/50\n",
      "6216/6216 [==============================] - 4s 592us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 36/50\n",
      "6216/6216 [==============================] - 4s 566us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 37/50\n",
      "6216/6216 [==============================] - 4s 601us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 38/50\n",
      "6216/6216 [==============================] - 5s 725us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 39/50\n",
      "6216/6216 [==============================] - 4s 665us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 40/50\n",
      "6216/6216 [==============================] - 3s 559us/step - loss: 0.0415 - acc: 0.9974 1s - loss\n",
      "Epoch 41/50\n",
      "6216/6216 [==============================] - 4s 565us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 42/50\n",
      "6216/6216 [==============================] - 5s 750us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 43/50\n",
      "6216/6216 [==============================] - 5s 795us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 44/50\n",
      "6216/6216 [==============================] - 5s 815us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 45/50\n",
      "6216/6216 [==============================] - 5s 776us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 46/50\n",
      "6216/6216 [==============================] - 4s 697us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 47/50\n",
      "6216/6216 [==============================] - 5s 754us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 48/50\n",
      "6216/6216 [==============================] - 4s 639us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 49/50\n",
      "6216/6216 [==============================] - 4s 692us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 50/50\n",
      "6216/6216 [==============================] - 4s 586us/step - loss: 0.0415 - acc: 0.9974\n",
      "691/691 [==============================] - 0s 427us/step\n",
      "Epoch 1/50\n",
      "6216/6216 [==============================] - 8s 1ms/step - loss: 0.0339 - acc: 0.9965\n",
      "Epoch 2/50\n",
      "6216/6216 [==============================] - 5s 763us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 3/50\n",
      "6216/6216 [==============================] - 4s 677us/step - loss: 0.0311 - acc: 0.9981 \n",
      "Epoch 4/50\n",
      "6216/6216 [==============================] - 4s 645us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 5/50\n",
      "6216/6216 [==============================] - 5s 833us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 6/50\n",
      "6216/6216 [==============================] - 5s 776us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 7/50\n",
      "6216/6216 [==============================] - 4s 627us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 8/50\n",
      "6216/6216 [==============================] - 5s 744us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 9/50\n",
      "6216/6216 [==============================] - 4s 721us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 10/50\n",
      "6216/6216 [==============================] - 5s 740us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 11/50\n",
      "6216/6216 [==============================] - 4s 656us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 12/50\n",
      "6216/6216 [==============================] - 5s 734us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 13/50\n",
      "6216/6216 [==============================] - 5s 745us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 14/50\n",
      "6216/6216 [==============================] - 4s 696us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 15/50\n",
      "6216/6216 [==============================] - 4s 619us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 16/50\n",
      "6216/6216 [==============================] - 5s 726us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 17/50\n",
      "6216/6216 [==============================] - 5s 837us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 18/50\n",
      "6216/6216 [==============================] - 4s 708us/step - loss: 0.0311 - acc: 0.9981 1s\n",
      "Epoch 19/50\n",
      "6216/6216 [==============================] - 5s 750us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 20/50\n",
      "6216/6216 [==============================] - 4s 713us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 21/50\n",
      "6216/6216 [==============================] - 5s 772us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 22/50\n",
      "6216/6216 [==============================] - 5s 787us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 23/50\n",
      "6216/6216 [==============================] - 5s 764us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 24/50\n",
      "6216/6216 [==============================] - 4s 619us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 25/50\n",
      "6216/6216 [==============================] - 4s 625us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 26/50\n",
      "6216/6216 [==============================] - 4s 665us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 27/50\n",
      "6216/6216 [==============================] - 4s 722us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 28/50\n",
      "6216/6216 [==============================] - 5s 777us/step - loss: 0.0311 - acc: 0.9981 1s - \n",
      "Epoch 29/50\n",
      "6216/6216 [==============================] - 5s 872us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 30/50\n",
      "6216/6216 [==============================] - 5s 838us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 31/50\n",
      "6216/6216 [==============================] - 6s 928us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6216/6216 [==============================] - 5s 759us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 33/50\n",
      "6216/6216 [==============================] - 4s 681us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 34/50\n",
      "6216/6216 [==============================] - 4s 621us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 35/50\n",
      "6216/6216 [==============================] - 4s 644us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 36/50\n",
      "6216/6216 [==============================] - 4s 669us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 37/50\n",
      "6216/6216 [==============================] - 4s 648us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 38/50\n",
      "6216/6216 [==============================] - 4s 692us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 39/50\n",
      "6216/6216 [==============================] - 4s 669us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 40/50\n",
      "6216/6216 [==============================] - 3s 555us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 41/50\n",
      "6216/6216 [==============================] - 3s 527us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 42/50\n",
      "6216/6216 [==============================] - 4s 633us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 43/50\n",
      "6216/6216 [==============================] - 3s 534us/step - loss: 0.0311 - acc: 0.9981 1s - loss: 0.0129 - acc: 0. - ETA:\n",
      "Epoch 44/50\n",
      "6216/6216 [==============================] - 4s 578us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 45/50\n",
      "6216/6216 [==============================] - 4s 699us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 46/50\n",
      "6216/6216 [==============================] - 5s 762us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 47/50\n",
      "6216/6216 [==============================] - 4s 660us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 48/50\n",
      "6216/6216 [==============================] - 4s 618us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 49/50\n",
      "6216/6216 [==============================] - 4s 583us/step - loss: 0.0311 - acc: 0.9981\n",
      "Epoch 50/50\n",
      "6216/6216 [==============================] - 4s 664us/step - loss: 0.0311 - acc: 0.9981 1s - loss\n",
      "691/691 [==============================] - 0s 307us/step\n",
      "Epoch 1/50\n",
      "6216/6216 [==============================] - 5s 756us/step - loss: 0.0395 - acc: 0.9958\n",
      "Epoch 2/50\n",
      "6216/6216 [==============================] - 4s 638us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 3/50\n",
      "6216/6216 [==============================] - 4s 682us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 4/50\n",
      "6216/6216 [==============================] - 4s 627us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 5/50\n",
      "6216/6216 [==============================] - 4s 631us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 6/50\n",
      "6216/6216 [==============================] - 4s 619us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 7/50\n",
      "6216/6216 [==============================] - 4s 673us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 8/50\n",
      "6216/6216 [==============================] - 4s 680us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 9/50\n",
      "6216/6216 [==============================] - 4s 716us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 10/50\n",
      "6216/6216 [==============================] - 5s 732us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 11/50\n",
      "6216/6216 [==============================] - 4s 669us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 12/50\n",
      "6216/6216 [==============================] - 4s 583us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 13/50\n",
      "6216/6216 [==============================] - 4s 583us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 14/50\n",
      "6216/6216 [==============================] - 4s 642us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 15/50\n",
      "6216/6216 [==============================] - 4s 623us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 16/50\n",
      "6216/6216 [==============================] - 4s 603us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 17/50\n",
      "6216/6216 [==============================] - 5s 756us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 18/50\n",
      "6216/6216 [==============================] - 5s 727us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 19/50\n",
      "6216/6216 [==============================] - 4s 627us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 20/50\n",
      "6216/6216 [==============================] - 4s 700us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 21/50\n",
      "6216/6216 [==============================] - 4s 697us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 22/50\n",
      "6216/6216 [==============================] - 4s 638us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 23/50\n",
      "6216/6216 [==============================] - 4s 716us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 24/50\n",
      "6216/6216 [==============================] - 4s 709us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 25/50\n",
      "6216/6216 [==============================] - 4s 681us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 26/50\n",
      "6216/6216 [==============================] - 4s 686us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 27/50\n",
      "6216/6216 [==============================] - 4s 584us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 28/50\n",
      "6216/6216 [==============================] - 3s 553us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 29/50\n",
      "6216/6216 [==============================] - 4s 595us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 30/50\n",
      "6216/6216 [==============================] - 4s 631us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 31/50\n",
      "6216/6216 [==============================] - 3s 520us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 32/50\n",
      "6216/6216 [==============================] - 4s 618us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 33/50\n",
      "6216/6216 [==============================] - 4s 625us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 34/50\n",
      "6216/6216 [==============================] - 4s 599us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 35/50\n",
      "6216/6216 [==============================] - 4s 672us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 36/50\n",
      "6216/6216 [==============================] - 4s 700us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 37/50\n",
      "6216/6216 [==============================] - 4s 669us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 38/50\n",
      "6216/6216 [==============================] - 4s 721us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 39/50\n",
      "6216/6216 [==============================] - 5s 752us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 40/50\n",
      "6216/6216 [==============================] - 5s 735us/step - loss: 0.0363 - acc: 0.9977 0s - loss: 0.0390 - ac\n",
      "Epoch 41/50\n",
      "6216/6216 [==============================] - 4s 598us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 42/50\n",
      "6216/6216 [==============================] - 3s 556us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 43/50\n",
      "6216/6216 [==============================] - 4s 650us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 44/50\n",
      "6216/6216 [==============================] - 4s 647us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 45/50\n",
      "6216/6216 [==============================] - 4s 619us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 46/50\n",
      "6216/6216 [==============================] - 4s 583us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 47/50\n",
      "6216/6216 [==============================] - 4s 599us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 48/50\n",
      "6216/6216 [==============================] - 4s 617us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 49/50\n",
      "6216/6216 [==============================] - 4s 583us/step - loss: 0.0363 - acc: 0.9977\n",
      "Epoch 50/50\n",
      "6216/6216 [==============================] - 3s 530us/step - loss: 0.0363 - acc: 0.9977\n",
      "691/691 [==============================] - 0s 361us/step\n",
      "Epoch 1/50\n",
      "6216/6216 [==============================] - 6s 890us/step - loss: 0.0440 - acc: 0.9960\n",
      "Epoch 2/50\n",
      "6216/6216 [==============================] - 4s 649us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 3/50\n",
      "6216/6216 [==============================] - 5s 739us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 4/50\n",
      "6216/6216 [==============================] - 4s 705us/step - loss: 0.0415 - acc: 0.9974 \n",
      "Epoch 5/50\n",
      "6216/6216 [==============================] - 4s 705us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 6/50\n",
      "6216/6216 [==============================] - 4s 609us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 7/50\n",
      "6216/6216 [==============================] - 4s 655us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 8/50\n",
      "6216/6216 [==============================] - 4s 669us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 9/50\n",
      "6216/6216 [==============================] - 5s 752us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 10/50\n",
      "6216/6216 [==============================] - 4s 660us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 11/50\n",
      "6216/6216 [==============================] - 4s 660us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6216/6216 [==============================] - 4s 724us/step - loss: 0.0415 - acc: 0.9974 1s - loss: 0.0\n",
      "Epoch 13/50\n",
      "6216/6216 [==============================] - 4s 717us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 14/50\n",
      "6216/6216 [==============================] - 4s 656us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 15/50\n",
      "6216/6216 [==============================] - 4s 649us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 16/50\n",
      "6216/6216 [==============================] - 3s 533us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 17/50\n",
      "6216/6216 [==============================] - 4s 605us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 18/50\n",
      "6216/6216 [==============================] - 4s 598us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 19/50\n",
      "6216/6216 [==============================] - 5s 784us/step - loss: 0.0415 - acc: 0.9974 1s - lo\n",
      "Epoch 20/50\n",
      "6216/6216 [==============================] - 4s 674us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 21/50\n",
      "6216/6216 [==============================] - 4s 577us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 22/50\n",
      "6216/6216 [==============================] - 4s 594us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 23/50\n",
      "6216/6216 [==============================] - 4s 672us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 24/50\n",
      "6216/6216 [==============================] - 4s 646us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 25/50\n",
      "6216/6216 [==============================] - 4s 663us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 26/50\n",
      "6216/6216 [==============================] - 4s 653us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 27/50\n",
      "6216/6216 [==============================] - 4s 629us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 28/50\n",
      "6216/6216 [==============================] - 4s 598us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 29/50\n",
      "6216/6216 [==============================] - 4s 573us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 30/50\n",
      "6216/6216 [==============================] - 3s 532us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 31/50\n",
      "6216/6216 [==============================] - 4s 670us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 32/50\n",
      "6216/6216 [==============================] - 4s 682us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 33/50\n",
      "6216/6216 [==============================] - 5s 735us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 34/50\n",
      "6216/6216 [==============================] - 5s 855us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 35/50\n",
      "6216/6216 [==============================] - 5s 724us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 36/50\n",
      "6216/6216 [==============================] - 5s 726us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 37/50\n",
      "6216/6216 [==============================] - 4s 639us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 38/50\n",
      "6216/6216 [==============================] - 4s 674us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 39/50\n",
      "6216/6216 [==============================] - 4s 717us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 40/50\n",
      "6216/6216 [==============================] - 5s 731us/step - loss: 0.0415 - acc: 0.9974 1s - loss\n",
      "Epoch 41/50\n",
      "6216/6216 [==============================] - 4s 700us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 42/50\n",
      "6216/6216 [==============================] - 4s 629us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 43/50\n",
      "6216/6216 [==============================] - 4s 706us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 44/50\n",
      "6216/6216 [==============================] - 5s 745us/step - loss: 0.0415 - acc: 0.9974 0s - loss: 0.0371 \n",
      "Epoch 45/50\n",
      "6216/6216 [==============================] - 5s 748us/step - loss: 0.0415 - acc: 0.9974 0s - loss: 0.0398 - acc:\n",
      "Epoch 46/50\n",
      "6216/6216 [==============================] - 5s 759us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 47/50\n",
      "6216/6216 [==============================] - 5s 794us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 48/50\n",
      "6216/6216 [==============================] - 5s 733us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 49/50\n",
      "6216/6216 [==============================] - 5s 728us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 50/50\n",
      "6216/6216 [==============================] - 4s 712us/step - loss: 0.0415 - acc: 0.9974\n",
      "691/691 [==============================] - 0s 591us/step\n",
      "Epoch 1/50\n",
      "6216/6216 [==============================] - 7s 1ms/step - loss: 0.0391 - acc: 0.9969\n",
      "Epoch 2/50\n",
      "6216/6216 [==============================] - 5s 732us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 3/50\n",
      "6216/6216 [==============================] - 4s 654us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 4/50\n",
      "6216/6216 [==============================] - 4s 565us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 5/50\n",
      "6216/6216 [==============================] - 3s 562us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 6/50\n",
      "6216/6216 [==============================] - 4s 579us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 7/50\n",
      "6216/6216 [==============================] - 4s 697us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 8/50\n",
      "6216/6216 [==============================] - 5s 777us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 9/50\n",
      "6216/6216 [==============================] - 5s 809us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 10/50\n",
      "6216/6216 [==============================] - 5s 776us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 11/50\n",
      "6216/6216 [==============================] - 4s 670us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 12/50\n",
      "6216/6216 [==============================] - 4s 714us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 13/50\n",
      "6216/6216 [==============================] - 5s 754us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 14/50\n",
      "6216/6216 [==============================] - 4s 677us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 15/50\n",
      "6216/6216 [==============================] - 4s 698us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 16/50\n",
      "6216/6216 [==============================] - 4s 642us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 17/50\n",
      "6216/6216 [==============================] - 4s 679us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 18/50\n",
      "6216/6216 [==============================] - 4s 708us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 19/50\n",
      "6216/6216 [==============================] - 4s 717us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 20/50\n",
      "6216/6216 [==============================] - 4s 676us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 21/50\n",
      "6216/6216 [==============================] - 4s 713us/step - loss: 0.0389 - acc: 0.9976 1s - loss: \n",
      "Epoch 22/50\n",
      "6216/6216 [==============================] - 5s 840us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 23/50\n",
      "6216/6216 [==============================] - 5s 829us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 24/50\n",
      "6216/6216 [==============================] - 4s 701us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 25/50\n",
      "6216/6216 [==============================] - 4s 697us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 26/50\n",
      "6216/6216 [==============================] - 4s 589us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 27/50\n",
      "6216/6216 [==============================] - 4s 618us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 28/50\n",
      "6216/6216 [==============================] - 3s 540us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 29/50\n",
      "6216/6216 [==============================] - 4s 592us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 30/50\n",
      "6216/6216 [==============================] - 3s 560us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 31/50\n",
      "6216/6216 [==============================] - 4s 634us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 32/50\n",
      "6216/6216 [==============================] - 3s 529us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 33/50\n",
      "6216/6216 [==============================] - 3s 508us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 34/50\n",
      "6216/6216 [==============================] - 3s 543us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 35/50\n",
      "6216/6216 [==============================] - 4s 634us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 36/50\n",
      "6216/6216 [==============================] - 4s 618us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 37/50\n",
      "6216/6216 [==============================] - 4s 675us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 38/50\n",
      "6216/6216 [==============================] - 4s 706us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 39/50\n",
      "6216/6216 [==============================] - 4s 647us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 40/50\n",
      "6216/6216 [==============================] - 4s 632us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 41/50\n",
      "6216/6216 [==============================] - 4s 593us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6216/6216 [==============================] - 4s 643us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 43/50\n",
      "6216/6216 [==============================] - 4s 589us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 44/50\n",
      "6216/6216 [==============================] - 3s 542us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 45/50\n",
      "6216/6216 [==============================] - 4s 588us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 46/50\n",
      "6216/6216 [==============================] - 5s 735us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 47/50\n",
      "6216/6216 [==============================] - 4s 681us/step - loss: 0.0389 - acc: 0.9976 0s - loss: 0.0438 -\n",
      "Epoch 48/50\n",
      "6216/6216 [==============================] - 4s 647us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 49/50\n",
      "6216/6216 [==============================] - 4s 649us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 50/50\n",
      "6216/6216 [==============================] - 4s 642us/step - loss: 0.0389 - acc: 0.9976\n",
      "691/691 [==============================] - 0s 622us/step\n",
      "Epoch 1/50\n",
      "6216/6216 [==============================] - 5s 842us/step - loss: 0.0269 - acc: 0.9984\n",
      "Epoch 2/50\n",
      "6216/6216 [==============================] - 4s 643us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 3/50\n",
      "6216/6216 [==============================] - 4s 674us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 4/50\n",
      "6216/6216 [==============================] - 4s 611us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 5/50\n",
      "6216/6216 [==============================] - 4s 618us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 6/50\n",
      "6216/6216 [==============================] - 4s 596us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 7/50\n",
      "6216/6216 [==============================] - 4s 639us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 8/50\n",
      "6216/6216 [==============================] - 3s 486us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 9/50\n",
      "6216/6216 [==============================] - 3s 541us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 10/50\n",
      "6216/6216 [==============================] - 4s 597us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 11/50\n",
      "6216/6216 [==============================] - 4s 611us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 12/50\n",
      "6216/6216 [==============================] - 4s 597us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 13/50\n",
      "6216/6216 [==============================] - 4s 632us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 14/50\n",
      "6216/6216 [==============================] - 4s 601us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 15/50\n",
      "6216/6216 [==============================] - 4s 639us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 16/50\n",
      "6216/6216 [==============================] - 4s 578us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 17/50\n",
      "6216/6216 [==============================] - 4s 693us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 18/50\n",
      "6216/6216 [==============================] - 4s 723us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 19/50\n",
      "6216/6216 [==============================] - 3s 558us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 20/50\n",
      "6216/6216 [==============================] - 3s 531us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 21/50\n",
      "6216/6216 [==============================] - 4s 578us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 22/50\n",
      "6216/6216 [==============================] - 4s 597us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 23/50\n",
      "6216/6216 [==============================] - 4s 613us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 24/50\n",
      "6216/6216 [==============================] - 3s 538us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 25/50\n",
      "6216/6216 [==============================] - 4s 597us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 26/50\n",
      "6216/6216 [==============================] - 4s 607us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 27/50\n",
      "6216/6216 [==============================] - 4s 567us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 28/50\n",
      "6216/6216 [==============================] - 4s 624us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 29/50\n",
      "6216/6216 [==============================] - 4s 613us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 30/50\n",
      "6216/6216 [==============================] - 4s 622us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 31/50\n",
      "6216/6216 [==============================] - 4s 621us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 32/50\n",
      "6216/6216 [==============================] - 4s 614us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 33/50\n",
      "6216/6216 [==============================] - 4s 601us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 34/50\n",
      "6216/6216 [==============================] - 4s 718us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 35/50\n",
      "6216/6216 [==============================] - 4s 603us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 36/50\n",
      "6216/6216 [==============================] - 3s 530us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 37/50\n",
      "6216/6216 [==============================] - 3s 504us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 38/50\n",
      "6216/6216 [==============================] - 3s 481us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 39/50\n",
      "6216/6216 [==============================] - 3s 549us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 40/50\n",
      "6216/6216 [==============================] - 4s 569us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 41/50\n",
      "6216/6216 [==============================] - 3s 551us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 42/50\n",
      "6216/6216 [==============================] - 3s 549us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 43/50\n",
      "6216/6216 [==============================] - 3s 556us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 44/50\n",
      "6216/6216 [==============================] - 3s 515us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 45/50\n",
      "6216/6216 [==============================] - 3s 480us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 46/50\n",
      "6216/6216 [==============================] - 3s 422us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 47/50\n",
      "6216/6216 [==============================] - 2s 305us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 48/50\n",
      "6216/6216 [==============================] - 2s 366us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 49/50\n",
      "6216/6216 [==============================] - 2s 379us/step - loss: 0.0259 - acc: 0.9984\n",
      "Epoch 50/50\n",
      "6216/6216 [==============================] - 2s 384us/step - loss: 0.0259 - acc: 0.9984\n",
      "691/691 [==============================] - 0s 294us/step\n",
      "Epoch 1/50\n",
      "6216/6216 [==============================] - 3s 514us/step - loss: 0.0556 - acc: 0.9924\n",
      "Epoch 2/50\n",
      "6216/6216 [==============================] - 3s 427us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 3/50\n",
      "6216/6216 [==============================] - 3s 428us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 4/50\n",
      "6216/6216 [==============================] - 3s 434us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 5/50\n",
      "6216/6216 [==============================] - 3s 444us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 6/50\n",
      "6216/6216 [==============================] - 2s 394us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 7/50\n",
      "6216/6216 [==============================] - 2s 379us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 8/50\n",
      "6216/6216 [==============================] - 2s 371us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 9/50\n",
      "6216/6216 [==============================] - 2s 376us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 10/50\n",
      "6216/6216 [==============================] - 2s 398us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 11/50\n",
      "6216/6216 [==============================] - 2s 397us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 12/50\n",
      "6216/6216 [==============================] - 2s 381us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 13/50\n",
      "6216/6216 [==============================] - 2s 385us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 14/50\n",
      "6216/6216 [==============================] - 2s 385us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 15/50\n",
      "6216/6216 [==============================] - 2s 380us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 16/50\n",
      "6216/6216 [==============================] - 2s 381us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 17/50\n",
      "6216/6216 [==============================] - 2s 388us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 18/50\n",
      "6216/6216 [==============================] - 2s 382us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 19/50\n",
      "6216/6216 [==============================] - 2s 349us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 20/50\n",
      "6216/6216 [==============================] - 2s 308us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 21/50\n",
      "6216/6216 [==============================] - 2s 382us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6216/6216 [==============================] - 2s 385us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 23/50\n",
      "6216/6216 [==============================] - 2s 376us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 24/50\n",
      "6216/6216 [==============================] - 2s 385us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 25/50\n",
      "6216/6216 [==============================] - 2s 377us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 26/50\n",
      "6216/6216 [==============================] - 2s 391us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 27/50\n",
      "6216/6216 [==============================] - 3s 422us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 28/50\n",
      "6216/6216 [==============================] - 3s 422us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 29/50\n",
      "6216/6216 [==============================] - 3s 432us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 30/50\n",
      "6216/6216 [==============================] - 3s 405us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 31/50\n",
      "6216/6216 [==============================] - 2s 384us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 32/50\n",
      "6216/6216 [==============================] - 2s 381us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 33/50\n",
      "6216/6216 [==============================] - 2s 391us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 34/50\n",
      "6216/6216 [==============================] - 2s 379us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 35/50\n",
      "6216/6216 [==============================] - 2s 394us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 36/50\n",
      "6216/6216 [==============================] - 2s 398us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 37/50\n",
      "6216/6216 [==============================] - 2s 387us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 38/50\n",
      "6216/6216 [==============================] - 2s 384us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 39/50\n",
      "6216/6216 [==============================] - 2s 376us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 40/50\n",
      "6216/6216 [==============================] - 2s 371us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 41/50\n",
      "6216/6216 [==============================] - 2s 389us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 42/50\n",
      "6216/6216 [==============================] - 2s 392us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 43/50\n",
      "6216/6216 [==============================] - 2s 367us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 44/50\n",
      "6216/6216 [==============================] - 2s 306us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 45/50\n",
      "6216/6216 [==============================] - 2s 374us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 46/50\n",
      "6216/6216 [==============================] - 2s 385us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 47/50\n",
      "6216/6216 [==============================] - 2s 375us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 48/50\n",
      "6216/6216 [==============================] - 2s 390us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 49/50\n",
      "6216/6216 [==============================] - 2s 382us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 50/50\n",
      "6216/6216 [==============================] - 2s 380us/step - loss: 0.0389 - acc: 0.9976\n",
      "691/691 [==============================] - 0s 336us/step\n",
      "Epoch 1/50\n",
      "6217/6217 [==============================] - 3s 551us/step - loss: 0.0536 - acc: 0.9924\n",
      "Epoch 2/50\n",
      "6217/6217 [==============================] - 3s 412us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 3/50\n",
      "6217/6217 [==============================] - 3s 444us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 4/50\n",
      "6217/6217 [==============================] - 3s 444us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 5/50\n",
      "6217/6217 [==============================] - 2s 395us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 6/50\n",
      "6217/6217 [==============================] - 2s 382us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 7/50\n",
      "6217/6217 [==============================] - 2s 387us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 8/50\n",
      "6217/6217 [==============================] - 2s 374us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 9/50\n",
      "6217/6217 [==============================] - 2s 385us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 10/50\n",
      "6217/6217 [==============================] - 3s 464us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 11/50\n",
      "6217/6217 [==============================] - 3s 468us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 12/50\n",
      "6217/6217 [==============================] - 3s 468us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 13/50\n",
      "6217/6217 [==============================] - 3s 463us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 14/50\n",
      "6217/6217 [==============================] - 3s 408us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 15/50\n",
      "6217/6217 [==============================] - 2s 380us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 16/50\n",
      "6217/6217 [==============================] - 2s 384us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 17/50\n",
      "6217/6217 [==============================] - 2s 304us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 18/50\n",
      "6217/6217 [==============================] - 2s 372us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 19/50\n",
      "6217/6217 [==============================] - 2s 381us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 20/50\n",
      "6217/6217 [==============================] - 2s 380us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 21/50\n",
      "6217/6217 [==============================] - 2s 383us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 22/50\n",
      "6217/6217 [==============================] - 2s 375us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 23/50\n",
      "6217/6217 [==============================] - 2s 387us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 24/50\n",
      "6217/6217 [==============================] - 2s 383us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 25/50\n",
      "6217/6217 [==============================] - 3s 428us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 26/50\n",
      "6217/6217 [==============================] - 3s 429us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 27/50\n",
      "6217/6217 [==============================] - 3s 441us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 28/50\n",
      "6217/6217 [==============================] - 3s 415us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 29/50\n",
      "6217/6217 [==============================] - 2s 394us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 30/50\n",
      "6217/6217 [==============================] - 2s 383us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 31/50\n",
      "6217/6217 [==============================] - 2s 376us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 32/50\n",
      "6217/6217 [==============================] - 2s 378us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 33/50\n",
      "6217/6217 [==============================] - 2s 382us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 34/50\n",
      "6217/6217 [==============================] - 2s 399us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 35/50\n",
      "6217/6217 [==============================] - 2s 374us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 36/50\n",
      "6217/6217 [==============================] - 2s 384us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 37/50\n",
      "6217/6217 [==============================] - 2s 378us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 38/50\n",
      "6217/6217 [==============================] - 2s 381us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 39/50\n",
      "6217/6217 [==============================] - 2s 384us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 40/50\n",
      "6217/6217 [==============================] - 2s 378us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 41/50\n",
      "6217/6217 [==============================] - 2s 312us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 42/50\n",
      "6217/6217 [==============================] - 2s 347us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 43/50\n",
      "6217/6217 [==============================] - 2s 382us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 44/50\n",
      "6217/6217 [==============================] - 2s 369us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 45/50\n",
      "6217/6217 [==============================] - 2s 383us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 46/50\n",
      "6217/6217 [==============================] - 2s 382us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 47/50\n",
      "6217/6217 [==============================] - 2s 375us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 48/50\n",
      "6217/6217 [==============================] - 2s 375us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 49/50\n",
      "6217/6217 [==============================] - 2s 372us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 50/50\n",
      "6217/6217 [==============================] - 3s 413us/step - loss: 0.0389 - acc: 0.9976\n",
      "690/690 [==============================] - 0s 347us/step\n",
      "Epoch 1/50\n",
      "6217/6217 [==============================] - 4s 583us/step - loss: 0.0448 - acc: 0.9950\n",
      "Epoch 2/50\n",
      "6217/6217 [==============================] - 3s 438us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6217/6217 [==============================] - 2s 401us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 4/50\n",
      "6217/6217 [==============================] - 2s 382us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 5/50\n",
      "6217/6217 [==============================] - 2s 381us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 6/50\n",
      "6217/6217 [==============================] - 2s 389us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 7/50\n",
      "6217/6217 [==============================] - 2s 379us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 8/50\n",
      "6217/6217 [==============================] - 2s 388us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 9/50\n",
      "6217/6217 [==============================] - 2s 380us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 10/50\n",
      "6217/6217 [==============================] - 2s 378us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 11/50\n",
      "6217/6217 [==============================] - 2s 383us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 12/50\n",
      "6217/6217 [==============================] - 2s 383us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 13/50\n",
      "6217/6217 [==============================] - 2s 380us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 14/50\n",
      "6217/6217 [==============================] - 2s 316us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 15/50\n",
      "6217/6217 [==============================] - 2s 296us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 16/50\n",
      "6217/6217 [==============================] - 2s 279us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 17/50\n",
      "6217/6217 [==============================] - 2s 264us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 18/50\n",
      "6217/6217 [==============================] - 2s 266us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 19/50\n",
      "6217/6217 [==============================] - 2s 267us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 20/50\n",
      "6217/6217 [==============================] - 2s 264us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 21/50\n",
      "6217/6217 [==============================] - 2s 273us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 22/50\n",
      "6217/6217 [==============================] - 2s 273us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 23/50\n",
      "6217/6217 [==============================] - 2s 274us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 24/50\n",
      "6217/6217 [==============================] - 2s 274us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 25/50\n",
      "6217/6217 [==============================] - 2s 269us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 26/50\n",
      "6217/6217 [==============================] - 2s 269us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 27/50\n",
      "6217/6217 [==============================] - 2s 269us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 28/50\n",
      "6217/6217 [==============================] - 2s 298us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 29/50\n",
      "6217/6217 [==============================] - 2s 287us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 30/50\n",
      "6217/6217 [==============================] - 2s 305us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 31/50\n",
      "6217/6217 [==============================] - 2s 311us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 32/50\n",
      "6217/6217 [==============================] - 2s 306us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 33/50\n",
      "6217/6217 [==============================] - 2s 298us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 34/50\n",
      "6217/6217 [==============================] - 2s 278us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 35/50\n",
      "6217/6217 [==============================] - 2s 267us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 36/50\n",
      "6217/6217 [==============================] - 2s 270us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 37/50\n",
      "6217/6217 [==============================] - 2s 266us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 38/50\n",
      "6217/6217 [==============================] - 2s 269us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 39/50\n",
      "6217/6217 [==============================] - 2s 267us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 40/50\n",
      "6217/6217 [==============================] - 2s 341us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 41/50\n",
      "6217/6217 [==============================] - 2s 366us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 42/50\n",
      "6217/6217 [==============================] - 2s 360us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 43/50\n",
      "6217/6217 [==============================] - 2s 369us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 44/50\n",
      "6217/6217 [==============================] - 2s 297us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 45/50\n",
      "6217/6217 [==============================] - 2s 272us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 46/50\n",
      "6217/6217 [==============================] - 2s 269us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 47/50\n",
      "6217/6217 [==============================] - 2s 267us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 48/50\n",
      "6217/6217 [==============================] - 2s 272us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 49/50\n",
      "6217/6217 [==============================] - 2s 264us/step - loss: 0.0415 - acc: 0.9974\n",
      "Epoch 50/50\n",
      "6217/6217 [==============================] - 2s 270us/step - loss: 0.0415 - acc: 0.9974\n",
      "690/690 [==============================] - 0s 317us/step\n",
      "Epoch 1/50\n",
      "6217/6217 [==============================] - 2s 392us/step - loss: 0.0528 - acc: 0.9924\n",
      "Epoch 2/50\n",
      "6217/6217 [==============================] - 2s 266us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 3/50\n",
      "6217/6217 [==============================] - 2s 266us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 4/50\n",
      "6217/6217 [==============================] - 2s 267us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 5/50\n",
      "6217/6217 [==============================] - 2s 274us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 6/50\n",
      "6217/6217 [==============================] - 2s 270us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 7/50\n",
      "6217/6217 [==============================] - 2s 276us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 8/50\n",
      "6217/6217 [==============================] - 2s 273us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 9/50\n",
      "6217/6217 [==============================] - 2s 269us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 10/50\n",
      "6217/6217 [==============================] - 2s 286us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 11/50\n",
      "6217/6217 [==============================] - 2s 303us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 12/50\n",
      "6217/6217 [==============================] - 2s 273us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 13/50\n",
      "6217/6217 [==============================] - 2s 311us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 14/50\n",
      "6217/6217 [==============================] - 2s 321us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 15/50\n",
      "6217/6217 [==============================] - 2s 315us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 16/50\n",
      "6217/6217 [==============================] - 2s 277us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 17/50\n",
      "6217/6217 [==============================] - 2s 285us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 18/50\n",
      "6217/6217 [==============================] - 2s 267us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 19/50\n",
      "6217/6217 [==============================] - 2s 270us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 20/50\n",
      "6217/6217 [==============================] - 2s 278us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 21/50\n",
      "6217/6217 [==============================] - 2s 268us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 22/50\n",
      "6217/6217 [==============================] - 2s 285us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 23/50\n",
      "6217/6217 [==============================] - 2s 278us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 24/50\n",
      "6217/6217 [==============================] - 2s 276us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 25/50\n",
      "6217/6217 [==============================] - 2s 274us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 26/50\n",
      "6217/6217 [==============================] - 2s 274us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 27/50\n",
      "6217/6217 [==============================] - 2s 272us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 28/50\n",
      "6217/6217 [==============================] - 2s 274us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 29/50\n",
      "6217/6217 [==============================] - 2s 276us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 30/50\n",
      "6217/6217 [==============================] - 2s 271us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 31/50\n",
      "6217/6217 [==============================] - 2s 270us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 32/50\n",
      "6217/6217 [==============================] - 2s 264us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 33/50\n",
      "6217/6217 [==============================] - 2s 274us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6217/6217 [==============================] - 2s 271us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 35/50\n",
      "6217/6217 [==============================] - 2s 277us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 36/50\n",
      "6217/6217 [==============================] - 2s 275us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 37/50\n",
      "6217/6217 [==============================] - 2s 272us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 38/50\n",
      "6217/6217 [==============================] - 2s 275us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 39/50\n",
      "6217/6217 [==============================] - 2s 286us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 40/50\n",
      "6217/6217 [==============================] - 2s 285us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 41/50\n",
      "6217/6217 [==============================] - 2s 274us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 42/50\n",
      "6217/6217 [==============================] - 2s 278us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 43/50\n",
      "6217/6217 [==============================] - 2s 295us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 44/50\n",
      "6217/6217 [==============================] - 2s 271us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 45/50\n",
      "6217/6217 [==============================] - 2s 295us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 46/50\n",
      "6217/6217 [==============================] - 2s 286us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 47/50\n",
      "6217/6217 [==============================] - 2s 274us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 48/50\n",
      "6217/6217 [==============================] - 2s 276us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 49/50\n",
      "6217/6217 [==============================] - 2s 283us/step - loss: 0.0389 - acc: 0.9976\n",
      "Epoch 50/50\n",
      "6217/6217 [==============================] - 2s 364us/step - loss: 0.0389 - acc: 0.9976\n",
      "690/690 [==============================] - 0s 493us/step\n",
      "Accuracy mean: 0.997684095723\n",
      "Accuracy variance: 0.00268397976802\n",
      "(' Time ', '1656.999', ' seconds')\n",
      "[[2957    0]\n",
      " [   0    4]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      2957\n",
      "        1.0       1.00      1.00      1.00         4\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2961\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# estimators \n",
    "# Evaluating the ANN\n",
    "t0 = time()\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 1024, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n",
    "    classifier.add(Dense(units = 512, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 50)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of DecisionTreeClassifier = 99.831138 %\n",
      "(' Time ', '0.03', ' seconds')\n",
      "[[2953    4]\n",
      " [   1    3]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      2957\n",
      "        1.0       0.43      0.75      0.55         4\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2961\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of DecisionTreeClassifier = {:.6f} %\".format(acc * 100))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of RandomForestClassifier = 99.932455 %\n",
      "(' Time ', '1.095', ' seconds')\n",
      "[[2957    0]\n",
      " [   2    2]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      2957\n",
      "        1.0       1.00      0.50      0.67         4\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2961\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of RandomForestClassifier = {:.6f} %\".format(acc * 100))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of ExtraTreesClassifier = 99.966228 %\n",
      "(' Time ', '1.048', ' seconds')\n",
      "[[2957    0]\n",
      " [   1    3]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      2957\n",
      "        1.0       1.00      0.75      0.86         4\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2961\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of ExtraTreesClassifier = {:.6f} %\".format(acc * 100))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of AdaBoostClassifier = 99.932455 %\n",
      "(' Time ', '1.825', ' seconds')\n",
      "[[2957    0]\n",
      " [   2    2]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      2957\n",
      "        1.0       1.00      0.50      0.67         4\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2961\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of AdaBoostClassifier = {:.6f} %\".format(acc * 100))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Naive_bayes  GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GaussianNB = 99.527187 %\n",
      "(' Time ', '0.009', ' seconds')\n",
      "[[2944   13]\n",
      " [   1    3]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      2957\n",
      "        1.0       0.19      0.75      0.30         4\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2961\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred= gnb.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of GaussianNB = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
