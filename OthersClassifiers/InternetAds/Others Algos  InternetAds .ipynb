{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt \n",
    "from pprint import pprint\n",
    "from numpy import array\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>att4</th>\n",
       "      <th>att5</th>\n",
       "      <th>att6</th>\n",
       "      <th>att7</th>\n",
       "      <th>att8</th>\n",
       "      <th>att9</th>\n",
       "      <th>att10</th>\n",
       "      <th>att11</th>\n",
       "      <th>att12</th>\n",
       "      <th>att13</th>\n",
       "      <th>...</th>\n",
       "      <th>att1550</th>\n",
       "      <th>att1551</th>\n",
       "      <th>att1552</th>\n",
       "      <th>att1553</th>\n",
       "      <th>att1554</th>\n",
       "      <th>att1555</th>\n",
       "      <th>att1556</th>\n",
       "      <th>att1557</th>\n",
       "      <th>att1558</th>\n",
       "      <th>outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1556 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   att4  att5  att6  att7  att8  att9  att10  att11  att12  att13   ...     \\\n",
       "0   1.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0    0.0   ...      \n",
       "1   1.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0    0.0   ...      \n",
       "2   1.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0    0.0   ...      \n",
       "3   1.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0    0.0   ...      \n",
       "4   1.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0    0.0   ...      \n",
       "\n",
       "   att1550  att1551  att1552  att1553  att1554  att1555  att1556  att1557  \\\n",
       "0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   att1558  outlier  \n",
       "0      0.0        1  \n",
       "1      0.0        1  \n",
       "2      0.0        1  \n",
       "3      0.0        1  \n",
       "4      0.0        1  \n",
       "\n",
       "[5 rows x 1556 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df=pd.read_csv('InternetAds_norm_19.csv')  \n",
    "\n",
    "del df['id']\n",
    "del df['Unnamed: 0']\n",
    "df['outlier'] = df.outlier.apply(lambda label: 1 if label == \"'yes'\" else 0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df to values\n",
    "df = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GC Forest\n",
    "import argparse\n",
    "import sys\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "sys.path.insert(0, \"lib\")\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.utils.config_utils import load_json\n",
    "config = load_json(\"./examples/InternetAds.json\")   \n",
    "gc = GCForest(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# train test \n",
    "from sklearn.cross_validation import train_test_split\n",
    "y = df[:,1555]\n",
    "X = df[:,0:1555]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of class\n",
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 20:17:13,352][cascade_classifier.fit_transform] X_groups_train.shape=[(2284, 1555)],y_train.shape=(2284,),X_groups_test.shape=[(980, 1555)],y_test.shape=(980,)\n",
      "[ 2018-07-31 20:17:13,367][cascade_classifier.fit_transform] group_dims=[1555]\n",
      "[ 2018-07-31 20:17:13,369][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-31 20:17:13,370][cascade_classifier.fit_transform] group_ends=[1555]\n",
      "[ 2018-07-31 20:17:13,371][cascade_classifier.fit_transform] X_train.shape=(2284, 1555),X_test.shape=(980, 1555)\n",
      "[ 2018-07-31 20:17:13,390][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(2284, 1555), X_cur_test.shape=(980, 1555)\n",
      "[ 2018-07-31 20:17:14,598][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=94.32%\n",
      "[ 2018-07-31 20:17:15,990][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=96.51%\n",
      "[ 2018-07-31 20:17:17,206][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=97.38%\n",
      "[ 2018-07-31 20:17:18,398][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=96.94%\n",
      "[ 2018-07-31 20:17:19,516][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=97.81%\n",
      "[ 2018-07-31 20:17:20,711][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=97.37%\n",
      "[ 2018-07-31 20:17:21,982][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=98.25%\n",
      "[ 2018-07-31 20:17:23,088][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=97.81%\n",
      "[ 2018-07-31 20:17:24,356][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=96.05%\n",
      "[ 2018-07-31 20:17:25,605][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=94.30%\n",
      "[ 2018-07-31 20:17:25,829][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=96.67%\n",
      "[ 2018-07-31 20:17:25,837][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=97.76%\n",
      "[ 2018-07-31 20:17:27,152][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_0.predict)=96.51%\n",
      "[ 2018-07-31 20:17:28,536][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_1.predict)=96.51%\n",
      "[ 2018-07-31 20:17:29,821][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_2.predict)=96.94%\n",
      "[ 2018-07-31 20:17:31,052][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_3.predict)=96.07%\n",
      "[ 2018-07-31 20:17:32,369][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_4.predict)=96.05%\n",
      "[ 2018-07-31 20:17:33,677][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_5.predict)=96.93%\n",
      "[ 2018-07-31 20:17:35,045][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_6.predict)=97.37%\n",
      "[ 2018-07-31 20:17:36,565][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_7.predict)=96.93%\n",
      "[ 2018-07-31 20:17:38,198][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_8.predict)=96.05%\n",
      "[ 2018-07-31 20:17:39,822][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_9.predict)=95.61%\n",
      "[ 2018-07-31 20:17:40,056][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_cv.predict)=96.50%\n",
      "[ 2018-07-31 20:17:40,057][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.test.predict)=97.65%\n",
      "[ 2018-07-31 20:17:40,132][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_0.predict)=97.38%\n",
      "[ 2018-07-31 20:17:40,182][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_1.predict)=95.63%\n",
      "[ 2018-07-31 20:17:40,216][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_2.predict)=96.07%\n",
      "[ 2018-07-31 20:17:40,251][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_3.predict)=96.07%\n",
      "[ 2018-07-31 20:17:40,296][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_4.predict)=96.49%\n",
      "[ 2018-07-31 20:17:40,335][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_5.predict)=97.37%\n",
      "[ 2018-07-31 20:17:40,370][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_6.predict)=96.05%\n",
      "[ 2018-07-31 20:17:40,416][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_7.predict)=96.93%\n",
      "[ 2018-07-31 20:17:40,479][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_8.predict)=96.93%\n",
      "[ 2018-07-31 20:17:40,534][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_9.predict)=99.12%\n",
      "[ 2018-07-31 20:17:40,539][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_cv.predict)=96.80%\n",
      "[ 2018-07-31 20:17:40,540][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.test.predict)=97.45%\n",
      "[ 2018-07-31 20:17:40,543][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=97.20%\n",
      "[ 2018-07-31 20:17:40,545][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=97.86%\n",
      "[ 2018-07-31 20:17:40,560][cascade_classifier.fit_transform] [layer=1] look_indexs=[0], X_cur_train.shape=(2284, 1561), X_cur_test.shape=(980, 1561)\n",
      "[ 2018-07-31 20:17:41,238][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_0.predict)=96.94%\n",
      "[ 2018-07-31 20:17:42,354][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_1.predict)=96.94%\n",
      "[ 2018-07-31 20:17:43,491][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_2.predict)=97.82%\n",
      "[ 2018-07-31 20:17:44,574][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_3.predict)=97.82%\n",
      "[ 2018-07-31 20:17:45,672][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_4.predict)=98.68%\n",
      "[ 2018-07-31 20:17:46,760][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_5.predict)=98.68%\n",
      "[ 2018-07-31 20:17:47,689][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_6.predict)=96.93%\n",
      "[ 2018-07-31 20:17:48,862][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_7.predict)=97.37%\n",
      "[ 2018-07-31 20:17:49,869][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_8.predict)=96.93%\n",
      "[ 2018-07-31 20:17:51,028][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_9.predict)=94.74%\n",
      "[ 2018-07-31 20:17:51,262][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_cv.predict)=97.29%\n",
      "[ 2018-07-31 20:17:51,264][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.test.predict)=97.55%\n",
      "[ 2018-07-31 20:17:52,241][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_0.predict)=97.82%\n",
      "[ 2018-07-31 20:17:53,444][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_1.predict)=97.82%\n",
      "[ 2018-07-31 20:17:54,511][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_2.predict)=96.94%\n",
      "[ 2018-07-31 20:17:55,613][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_3.predict)=96.51%\n",
      "[ 2018-07-31 20:17:56,684][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_4.predict)=96.49%\n",
      "[ 2018-07-31 20:17:57,646][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_5.predict)=95.18%\n",
      "[ 2018-07-31 20:17:58,706][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_6.predict)=98.25%\n",
      "[ 2018-07-31 20:17:59,709][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_7.predict)=96.93%\n",
      "[ 2018-07-31 20:18:00,901][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_8.predict)=96.93%\n",
      "[ 2018-07-31 20:18:02,150][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_9.predict)=98.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 20:18:02,396][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_cv.predict)=97.11%\n",
      "[ 2018-07-31 20:18:02,401][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.test.predict)=97.86%\n",
      "[ 2018-07-31 20:18:02,456][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_0.predict)=96.94%\n",
      "[ 2018-07-31 20:18:02,548][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_1.predict)=98.25%\n",
      "[ 2018-07-31 20:18:02,589][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_2.predict)=96.94%\n",
      "[ 2018-07-31 20:18:02,641][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_3.predict)=97.82%\n",
      "[ 2018-07-31 20:18:02,697][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_4.predict)=97.81%\n",
      "[ 2018-07-31 20:18:02,742][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_5.predict)=97.81%\n",
      "[ 2018-07-31 20:18:02,806][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_6.predict)=96.49%\n",
      "[ 2018-07-31 20:18:02,853][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_7.predict)=97.37%\n",
      "[ 2018-07-31 20:18:02,892][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_8.predict)=96.49%\n",
      "[ 2018-07-31 20:18:02,931][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_9.predict)=96.05%\n",
      "[ 2018-07-31 20:18:02,937][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_cv.predict)=97.20%\n",
      "[ 2018-07-31 20:18:02,942][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.test.predict)=97.76%\n",
      "[ 2018-07-31 20:18:02,943][cascade_classifier.calc_accuracy] Accuracy(layer_1 - train.classifier_average)=97.50%\n",
      "[ 2018-07-31 20:18:02,947][cascade_classifier.calc_accuracy] Accuracy(layer_1 - test.classifier_average)=97.65%\n",
      "[ 2018-07-31 20:18:02,958][cascade_classifier.fit_transform] [layer=2] look_indexs=[0], X_cur_train.shape=(2284, 1561), X_cur_test.shape=(980, 1561)\n",
      "[ 2018-07-31 20:18:03,909][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_0.predict)=97.82%\n",
      "[ 2018-07-31 20:18:05,115][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_1.predict)=99.13%\n",
      "[ 2018-07-31 20:18:06,623][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_2.predict)=96.51%\n",
      "[ 2018-07-31 20:18:08,121][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_3.predict)=98.25%\n",
      "[ 2018-07-31 20:18:09,471][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_4.predict)=98.25%\n",
      "[ 2018-07-31 20:18:10,630][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_5.predict)=96.05%\n",
      "[ 2018-07-31 20:18:11,753][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_6.predict)=97.37%\n",
      "[ 2018-07-31 20:18:12,843][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_7.predict)=96.93%\n",
      "[ 2018-07-31 20:18:13,962][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_8.predict)=96.05%\n",
      "[ 2018-07-31 20:18:14,962][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_9.predict)=98.25%\n",
      "[ 2018-07-31 20:18:15,242][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_cv.predict)=97.46%\n",
      "[ 2018-07-31 20:18:15,243][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.test.predict)=97.86%\n",
      "[ 2018-07-31 20:18:16,073][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_0.predict)=96.94%\n",
      "[ 2018-07-31 20:18:17,188][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_1.predict)=98.69%\n",
      "[ 2018-07-31 20:18:18,311][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_2.predict)=96.07%\n",
      "[ 2018-07-31 20:18:19,412][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_3.predict)=96.07%\n",
      "[ 2018-07-31 20:18:20,655][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_4.predict)=98.25%\n",
      "[ 2018-07-31 20:18:21,844][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_5.predict)=96.93%\n",
      "[ 2018-07-31 20:18:23,104][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_6.predict)=98.25%\n",
      "[ 2018-07-31 20:18:24,437][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_7.predict)=97.37%\n",
      "[ 2018-07-31 20:18:25,694][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_8.predict)=97.37%\n",
      "[ 2018-07-31 20:18:26,938][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_9.predict)=97.81%\n",
      "[ 2018-07-31 20:18:27,173][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_cv.predict)=97.37%\n",
      "[ 2018-07-31 20:18:27,174][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.test.predict)=97.76%\n",
      "[ 2018-07-31 20:18:27,208][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_0.predict)=97.38%\n",
      "[ 2018-07-31 20:18:27,249][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_1.predict)=98.25%\n",
      "[ 2018-07-31 20:18:27,292][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_2.predict)=96.94%\n",
      "[ 2018-07-31 20:18:27,337][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_3.predict)=97.82%\n",
      "[ 2018-07-31 20:18:27,376][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_4.predict)=96.93%\n",
      "[ 2018-07-31 20:18:27,407][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_5.predict)=98.25%\n",
      "[ 2018-07-31 20:18:27,438][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_6.predict)=96.49%\n",
      "[ 2018-07-31 20:18:27,482][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_7.predict)=95.61%\n",
      "[ 2018-07-31 20:18:27,521][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_8.predict)=97.37%\n",
      "[ 2018-07-31 20:18:27,566][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_9.predict)=97.37%\n",
      "[ 2018-07-31 20:18:27,570][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_cv.predict)=97.24%\n",
      "[ 2018-07-31 20:18:27,572][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.test.predict)=97.55%\n",
      "[ 2018-07-31 20:18:27,575][cascade_classifier.calc_accuracy] Accuracy(layer_2 - train.classifier_average)=97.55%\n",
      "[ 2018-07-31 20:18:27,577][cascade_classifier.calc_accuracy] Accuracy(layer_2 - test.classifier_average)=97.86%\n",
      "[ 2018-07-31 20:18:27,591][cascade_classifier.fit_transform] [layer=3] look_indexs=[0], X_cur_train.shape=(2284, 1561), X_cur_test.shape=(980, 1561)\n",
      "[ 2018-07-31 20:18:28,684][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_0.predict)=96.94%\n",
      "[ 2018-07-31 20:18:29,852][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_1.predict)=95.63%\n",
      "[ 2018-07-31 20:18:30,828][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_2.predict)=96.07%\n",
      "[ 2018-07-31 20:18:31,816][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_3.predict)=96.51%\n",
      "[ 2018-07-31 20:18:32,839][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_4.predict)=98.25%\n",
      "[ 2018-07-31 20:18:33,823][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_5.predict)=98.25%\n",
      "[ 2018-07-31 20:18:34,960][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_6.predict)=97.81%\n",
      "[ 2018-07-31 20:18:36,068][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_7.predict)=99.12%\n",
      "[ 2018-07-31 20:18:37,083][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_8.predict)=96.93%\n",
      "[ 2018-07-31 20:18:38,096][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_9.predict)=98.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 20:18:38,340][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_cv.predict)=97.37%\n",
      "[ 2018-07-31 20:18:38,341][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.test.predict)=98.06%\n",
      "[ 2018-07-31 20:18:39,398][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_0.predict)=97.82%\n",
      "[ 2018-07-31 20:18:40,581][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_1.predict)=94.76%\n",
      "[ 2018-07-31 20:18:41,637][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_2.predict)=97.38%\n",
      "[ 2018-07-31 20:18:42,707][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_3.predict)=97.38%\n",
      "[ 2018-07-31 20:18:43,813][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_4.predict)=98.25%\n",
      "[ 2018-07-31 20:18:44,895][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_5.predict)=95.61%\n",
      "[ 2018-07-31 20:18:46,000][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_6.predict)=97.37%\n",
      "[ 2018-07-31 20:18:47,080][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_7.predict)=98.68%\n",
      "[ 2018-07-31 20:18:48,180][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_8.predict)=96.49%\n",
      "[ 2018-07-31 20:18:49,256][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_9.predict)=97.81%\n",
      "[ 2018-07-31 20:18:49,477][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_cv.predict)=97.15%\n",
      "[ 2018-07-31 20:18:49,478][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.test.predict)=98.16%\n",
      "[ 2018-07-31 20:18:49,510][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_0.predict)=96.94%\n",
      "[ 2018-07-31 20:18:49,541][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_1.predict)=96.51%\n",
      "[ 2018-07-31 20:18:49,573][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_2.predict)=96.51%\n",
      "[ 2018-07-31 20:18:49,614][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_3.predict)=97.38%\n",
      "[ 2018-07-31 20:18:49,648][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_4.predict)=96.93%\n",
      "[ 2018-07-31 20:18:49,681][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_5.predict)=96.49%\n",
      "[ 2018-07-31 20:18:49,717][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_6.predict)=97.37%\n",
      "[ 2018-07-31 20:18:49,748][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_7.predict)=99.12%\n",
      "[ 2018-07-31 20:18:49,779][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_8.predict)=97.81%\n",
      "[ 2018-07-31 20:18:49,814][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_9.predict)=96.93%\n",
      "[ 2018-07-31 20:18:49,817][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_cv.predict)=97.20%\n",
      "[ 2018-07-31 20:18:49,818][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.test.predict)=97.55%\n",
      "[ 2018-07-31 20:18:49,820][cascade_classifier.calc_accuracy] Accuracy(layer_3 - train.classifier_average)=97.33%\n",
      "[ 2018-07-31 20:18:49,822][cascade_classifier.calc_accuracy] Accuracy(layer_3 - test.classifier_average)=98.16%\n",
      "[ 2018-07-31 20:18:49,833][cascade_classifier.fit_transform] [layer=4] look_indexs=[0], X_cur_train.shape=(2284, 1561), X_cur_test.shape=(980, 1561)\n",
      "[ 2018-07-31 20:18:50,710][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_0.predict)=97.38%\n",
      "[ 2018-07-31 20:18:51,682][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_1.predict)=98.25%\n",
      "[ 2018-07-31 20:18:52,678][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_2.predict)=97.38%\n",
      "[ 2018-07-31 20:18:53,702][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_3.predict)=97.38%\n",
      "[ 2018-07-31 20:18:54,810][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_4.predict)=96.93%\n",
      "[ 2018-07-31 20:18:55,784][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_5.predict)=97.37%\n",
      "[ 2018-07-31 20:18:56,931][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_6.predict)=97.37%\n",
      "[ 2018-07-31 20:18:57,930][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_7.predict)=96.05%\n",
      "[ 2018-07-31 20:18:59,236][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_8.predict)=97.37%\n",
      "[ 2018-07-31 20:19:00,457][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_9.predict)=96.93%\n",
      "[ 2018-07-31 20:19:00,699][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_cv.predict)=97.24%\n",
      "[ 2018-07-31 20:19:00,700][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.test.predict)=98.06%\n",
      "[ 2018-07-31 20:19:01,849][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_0.predict)=96.94%\n",
      "[ 2018-07-31 20:19:03,224][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_1.predict)=97.38%\n",
      "[ 2018-07-31 20:19:04,306][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_2.predict)=97.38%\n",
      "[ 2018-07-31 20:19:05,355][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_3.predict)=96.07%\n",
      "[ 2018-07-31 20:19:06,459][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_4.predict)=96.49%\n",
      "[ 2018-07-31 20:19:07,489][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_5.predict)=96.05%\n",
      "[ 2018-07-31 20:19:08,593][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_6.predict)=99.12%\n",
      "[ 2018-07-31 20:19:09,735][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_7.predict)=98.25%\n",
      "[ 2018-07-31 20:19:10,858][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_8.predict)=96.49%\n",
      "[ 2018-07-31 20:19:12,040][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_9.predict)=96.49%\n",
      "[ 2018-07-31 20:19:12,280][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_cv.predict)=97.07%\n",
      "[ 2018-07-31 20:19:12,281][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.test.predict)=98.16%\n",
      "[ 2018-07-31 20:19:12,313][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_0.predict)=95.63%\n",
      "[ 2018-07-31 20:19:12,345][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_1.predict)=99.13%\n",
      "[ 2018-07-31 20:19:12,380][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_2.predict)=96.51%\n",
      "[ 2018-07-31 20:19:12,421][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_3.predict)=96.94%\n",
      "[ 2018-07-31 20:19:12,453][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_4.predict)=96.93%\n",
      "[ 2018-07-31 20:19:12,486][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_5.predict)=96.93%\n",
      "[ 2018-07-31 20:19:12,517][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_6.predict)=97.81%\n",
      "[ 2018-07-31 20:19:12,554][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_7.predict)=97.37%\n",
      "[ 2018-07-31 20:19:12,590][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_8.predict)=96.93%\n",
      "[ 2018-07-31 20:19:12,624][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_9.predict)=97.81%\n",
      "[ 2018-07-31 20:19:12,627][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_cv.predict)=97.20%\n",
      "[ 2018-07-31 20:19:12,628][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.test.predict)=98.06%\n",
      "[ 2018-07-31 20:19:12,630][cascade_classifier.calc_accuracy] Accuracy(layer_4 - train.classifier_average)=97.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 20:19:12,631][cascade_classifier.calc_accuracy] Accuracy(layer_4 - test.classifier_average)=98.16%\n",
      "[ 2018-07-31 20:19:12,642][cascade_classifier.fit_transform] [layer=5] look_indexs=[0], X_cur_train.shape=(2284, 1561), X_cur_test.shape=(980, 1561)\n",
      "[ 2018-07-31 20:19:13,539][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_0.predict)=98.25%\n",
      "[ 2018-07-31 20:19:14,511][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_1.predict)=97.38%\n",
      "[ 2018-07-31 20:19:15,499][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_2.predict)=97.82%\n",
      "[ 2018-07-31 20:19:16,516][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_3.predict)=97.38%\n",
      "[ 2018-07-31 20:19:17,448][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_4.predict)=97.37%\n",
      "[ 2018-07-31 20:19:18,597][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_5.predict)=98.25%\n",
      "[ 2018-07-31 20:19:19,695][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_6.predict)=97.37%\n",
      "[ 2018-07-31 20:19:20,815][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_7.predict)=96.05%\n",
      "[ 2018-07-31 20:19:21,957][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_8.predict)=96.05%\n",
      "[ 2018-07-31 20:19:23,055][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_9.predict)=97.81%\n",
      "[ 2018-07-31 20:19:23,301][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_cv.predict)=97.37%\n",
      "[ 2018-07-31 20:19:23,302][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.test.predict)=98.06%\n",
      "[ 2018-07-31 20:19:24,502][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_0.predict)=96.94%\n",
      "[ 2018-07-31 20:19:25,908][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_1.predict)=97.38%\n",
      "[ 2018-07-31 20:19:27,237][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_2.predict)=96.94%\n",
      "[ 2018-07-31 20:19:28,563][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_3.predict)=97.82%\n",
      "[ 2018-07-31 20:19:29,642][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_4.predict)=96.49%\n",
      "[ 2018-07-31 20:19:30,775][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_5.predict)=96.49%\n",
      "[ 2018-07-31 20:19:31,996][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_6.predict)=97.37%\n",
      "[ 2018-07-31 20:19:33,037][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_7.predict)=98.25%\n",
      "[ 2018-07-31 20:19:34,146][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_8.predict)=96.93%\n",
      "[ 2018-07-31 20:19:35,255][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_9.predict)=97.81%\n",
      "[ 2018-07-31 20:19:35,506][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_cv.predict)=97.24%\n",
      "[ 2018-07-31 20:19:35,507][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.test.predict)=97.96%\n",
      "[ 2018-07-31 20:19:35,553][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_0.predict)=98.25%\n",
      "[ 2018-07-31 20:19:35,587][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_1.predict)=96.94%\n",
      "[ 2018-07-31 20:19:35,621][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_2.predict)=96.94%\n",
      "[ 2018-07-31 20:19:35,655][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_3.predict)=97.82%\n",
      "[ 2018-07-31 20:19:35,688][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_4.predict)=96.93%\n",
      "[ 2018-07-31 20:19:35,722][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_5.predict)=98.25%\n",
      "[ 2018-07-31 20:19:35,756][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_6.predict)=96.05%\n",
      "[ 2018-07-31 20:19:35,790][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_7.predict)=95.61%\n",
      "[ 2018-07-31 20:19:35,824][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_8.predict)=96.49%\n",
      "[ 2018-07-31 20:19:35,866][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_9.predict)=97.37%\n",
      "[ 2018-07-31 20:19:35,870][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_cv.predict)=97.07%\n",
      "[ 2018-07-31 20:19:35,871][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.test.predict)=98.06%\n",
      "[ 2018-07-31 20:19:35,874][cascade_classifier.calc_accuracy] Accuracy(layer_5 - train.classifier_average)=97.33%\n",
      "[ 2018-07-31 20:19:35,877][cascade_classifier.calc_accuracy] Accuracy(layer_5 - test.classifier_average)=98.16%\n",
      "[ 2018-07-31 20:19:35,880][cascade_classifier.fit_transform] [Result][Optimal Level Detected] opt_layer_num=3, accuracy_train=97.55%, accuracy_test=97.86%\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "    # X_enc is the concatenated predict_proba result of each estimators of the last layer of the GCForest model\n",
    "    # X_enc.shape =\n",
    "    #   (n_datas, n_estimators * n_classes): If cascade is provided\n",
    "    #   (n_datas, n_estimators * n_classes, dimX, dimY): If only finegrained part is provided\n",
    "    # You can also pass X_test, y_test to fit_transform method, then the accracy on test data will be logged when training.\n",
    "X_train_enc, X_test_enc = gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test)\n",
    "    # WARNING: if you set gc.set_keep_model_in_mem(True), you would have to use\n",
    "    # gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test) to evaluate your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 20:19:35,903][cascade_classifier.transform] X_groups_test.shape=[(980, 1555)]\n",
      "[ 2018-07-31 20:19:35,907][cascade_classifier.transform] group_dims=[1555]\n",
      "[ 2018-07-31 20:19:35,908][cascade_classifier.transform] X_test.shape=(980, 1555)\n",
      "[ 2018-07-31 20:19:35,912][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(980, 1555)\n",
      "[ 2018-07-31 20:19:40,695][cascade_classifier.transform] [layer=1] look_indexs=[0], X_cur_test.shape=(980, 1561)\n",
      "[ 2018-07-31 20:19:45,488][cascade_classifier.transform] [layer=2] look_indexs=[0], X_cur_test.shape=(980, 1561)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GCForest = 97.857143 %\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "y_pred = gc.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy of GCForest = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' Time ', '156.999', ' seconds')\n",
      "[[850  10]\n",
      " [ 11 109]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.99      0.99       860\n",
      "        1.0       0.92      0.91      0.91       120\n",
      "\n",
      "avg / total       0.98      0.98      0.98       980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of DecisionTreeClassifier = 97.040816 %\n",
      "(' Time ', '1.044', ' seconds')\n",
      "[[843  17]\n",
      " [ 12 108]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.98      0.98       860\n",
      "        1.0       0.86      0.90      0.88       120\n",
      "\n",
      "avg / total       0.97      0.97      0.97       980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of DecisionTreeClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of RandomForestClassifier = 97.551020 %\n",
      "(' Time ', '2.297', ' seconds')\n",
      "[[848  12]\n",
      " [ 12 108]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.99      0.99       860\n",
      "        1.0       0.90      0.90      0.90       120\n",
      "\n",
      "avg / total       0.98      0.98      0.98       980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of RandomForestClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of ExtraTreesClassifier = 97.448980 %\n",
      "(' Time ', '4.025', ' seconds')\n",
      "[[846  14]\n",
      " [ 11 109]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.98      0.99       860\n",
      "        1.0       0.89      0.91      0.90       120\n",
      "\n",
      "avg / total       0.97      0.97      0.97       980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of ExtraTreesClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of AdaBoostClassifier = 97.142857 %\n",
      "(' Time ', '4.544', ' seconds')\n",
      "[[849  11]\n",
      " [ 17 103]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.99      0.98       860\n",
      "        1.0       0.90      0.86      0.88       120\n",
      "\n",
      "avg / total       0.97      0.97      0.97       980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of AdaBoostClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Naive_bayes  GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GaussianNB = 78.061224 %\n",
      "(' Time ', '0.074', ' seconds')\n",
      "[[651 209]\n",
      " [  6 114]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.76      0.86       860\n",
      "        1.0       0.35      0.95      0.51       120\n",
      "\n",
      "avg / total       0.91      0.78      0.82       980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred= gnb.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of GaussianNB = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2055/2055 [==============================] - 2s 903us/step - loss: 0.2444 - acc: 0.9163\n",
      "Epoch 2/50\n",
      "2055/2055 [==============================] - 1s 661us/step - loss: 0.0920 - acc: 0.9742\n",
      "Epoch 3/50\n",
      "2055/2055 [==============================] - 1s 684us/step - loss: 0.0602 - acc: 0.9830\n",
      "Epoch 4/50\n",
      "2055/2055 [==============================] - 1s 679us/step - loss: 0.0466 - acc: 0.9859\n",
      "Epoch 5/50\n",
      "2055/2055 [==============================] - 1s 661us/step - loss: 0.0400 - acc: 0.9869\n",
      "Epoch 6/50\n",
      "2055/2055 [==============================] - 1s 679us/step - loss: 0.0348 - acc: 0.9888\n",
      "Epoch 7/50\n",
      "2055/2055 [==============================] - 1s 573us/step - loss: 0.0338 - acc: 0.9898\n",
      "Epoch 8/50\n",
      "2055/2055 [==============================] - 1s 589us/step - loss: 0.0279 - acc: 0.9922\n",
      "Epoch 9/50\n",
      "2055/2055 [==============================] - 1s 658us/step - loss: 0.0279 - acc: 0.9912\n",
      "Epoch 10/50\n",
      "2055/2055 [==============================] - 1s 637us/step - loss: 0.0287 - acc: 0.9903\n",
      "Epoch 11/50\n",
      "2055/2055 [==============================] - 1s 663us/step - loss: 0.0246 - acc: 0.9932\n",
      "Epoch 12/50\n",
      "2055/2055 [==============================] - 1s 728us/step - loss: 0.0243 - acc: 0.9922\n",
      "Epoch 13/50\n",
      "2055/2055 [==============================] - 1s 726us/step - loss: 0.0235 - acc: 0.9927\n",
      "Epoch 14/50\n",
      "2055/2055 [==============================] - 2s 742us/step - loss: 0.0229 - acc: 0.9932\n",
      "Epoch 15/50\n",
      "2055/2055 [==============================] - 2s 756us/step - loss: 0.0221 - acc: 0.9927\n",
      "Epoch 16/50\n",
      "2055/2055 [==============================] - 2s 739us/step - loss: 0.0237 - acc: 0.9908\n",
      "Epoch 17/50\n",
      "2055/2055 [==============================] - 1s 718us/step - loss: 0.0229 - acc: 0.9922\n",
      "Epoch 18/50\n",
      "2055/2055 [==============================] - 1s 661us/step - loss: 0.0213 - acc: 0.9932\n",
      "Epoch 19/50\n",
      "2055/2055 [==============================] - 1s 623us/step - loss: 0.0208 - acc: 0.9932\n",
      "Epoch 20/50\n",
      "2055/2055 [==============================] - 1s 547us/step - loss: 0.0212 - acc: 0.9932\n",
      "Epoch 21/50\n",
      "2055/2055 [==============================] - 1s 612us/step - loss: 0.0197 - acc: 0.9927\n",
      "Epoch 22/50\n",
      "2055/2055 [==============================] - 1s 633us/step - loss: 0.0204 - acc: 0.9932\n",
      "Epoch 23/50\n",
      "2055/2055 [==============================] - 1s 644us/step - loss: 0.0206 - acc: 0.9927\n",
      "Epoch 24/50\n",
      "2055/2055 [==============================] - 1s 639us/step - loss: 0.0218 - acc: 0.9932\n",
      "Epoch 25/50\n",
      "2055/2055 [==============================] - 1s 680us/step - loss: 0.0201 - acc: 0.9927\n",
      "Epoch 26/50\n",
      "2055/2055 [==============================] - 1s 682us/step - loss: 0.0201 - acc: 0.9932\n",
      "Epoch 27/50\n",
      "2055/2055 [==============================] - 1s 649us/step - loss: 0.0219 - acc: 0.9927\n",
      "Epoch 28/50\n",
      "2055/2055 [==============================] - 1s 603us/step - loss: 0.0220 - acc: 0.9912\n",
      "Epoch 29/50\n",
      "2055/2055 [==============================] - 1s 562us/step - loss: 0.0208 - acc: 0.9922\n",
      "Epoch 30/50\n",
      "2055/2055 [==============================] - 1s 638us/step - loss: 0.0207 - acc: 0.9927\n",
      "Epoch 31/50\n",
      "2055/2055 [==============================] - 1s 648us/step - loss: 0.0208 - acc: 0.9927\n",
      "Epoch 32/50\n",
      "2055/2055 [==============================] - 1s 629us/step - loss: 0.0207 - acc: 0.9922\n",
      "Epoch 33/50\n",
      "2055/2055 [==============================] - 1s 623us/step - loss: 0.0198 - acc: 0.9932TA: 0s - loss: 0.\n",
      "Epoch 34/50\n",
      "2055/2055 [==============================] - 1s 641us/step - loss: 0.0195 - acc: 0.9932\n",
      "Epoch 35/50\n",
      "2055/2055 [==============================] - 1s 630us/step - loss: 0.0195 - acc: 0.9937\n",
      "Epoch 36/50\n",
      "2055/2055 [==============================] - 1s 572us/step - loss: 0.0200 - acc: 0.9932\n",
      "Epoch 37/50\n",
      "2055/2055 [==============================] - 1s 579us/step - loss: 0.0274 - acc: 0.9898\n",
      "Epoch 38/50\n",
      "2055/2055 [==============================] - 1s 614us/step - loss: 0.0406 - acc: 0.9878\n",
      "Epoch 39/50\n",
      "2055/2055 [==============================] - 1s 651us/step - loss: 0.0370 - acc: 0.9898\n",
      "Epoch 40/50\n",
      "2055/2055 [==============================] - 1s 639us/step - loss: 0.0234 - acc: 0.9927\n",
      "Epoch 41/50\n",
      "2055/2055 [==============================] - 1s 647us/step - loss: 0.0204 - acc: 0.9932\n",
      "Epoch 42/50\n",
      "2055/2055 [==============================] - 1s 651us/step - loss: 0.0201 - acc: 0.9937\n",
      "Epoch 43/50\n",
      "2055/2055 [==============================] - 1s 681us/step - loss: 0.0198 - acc: 0.9937\n",
      "Epoch 44/50\n",
      "2055/2055 [==============================] - 2s 866us/step - loss: 0.0201 - acc: 0.9932\n",
      "Epoch 45/50\n",
      "2055/2055 [==============================] - 2s 928us/step - loss: 0.0192 - acc: 0.9937\n",
      "Epoch 46/50\n",
      "2055/2055 [==============================] - 2s 925us/step - loss: 0.0193 - acc: 0.9927\n",
      "Epoch 47/50\n",
      "2055/2055 [==============================] - 2s 924us/step - loss: 0.0193 - acc: 0.9917\n",
      "Epoch 48/50\n",
      "2055/2055 [==============================] - 2s 775us/step - loss: 0.0196 - acc: 0.9922\n",
      "Epoch 49/50\n",
      "2055/2055 [==============================] - 1s 642us/step - loss: 0.0202 - acc: 0.9927\n",
      "Epoch 50/50\n",
      "2055/2055 [==============================] - 1s 594us/step - loss: 0.0195 - acc: 0.9937\n",
      "229/229 [==============================] - 0s 284us/step\n",
      "Epoch 1/50\n",
      "2055/2055 [==============================] - 2s 755us/step - loss: 0.2157 - acc: 0.9290\n",
      "Epoch 2/50\n",
      "2055/2055 [==============================] - 1s 530us/step - loss: 0.0955 - acc: 0.9752\n",
      "Epoch 3/50\n",
      "2055/2055 [==============================] - 1s 525us/step - loss: 0.0619 - acc: 0.9805\n",
      "Epoch 4/50\n",
      "2055/2055 [==============================] - 1s 549us/step - loss: 0.0468 - acc: 0.9835\n",
      "Epoch 5/50\n",
      "2055/2055 [==============================] - 2s 730us/step - loss: 0.0356 - acc: 0.9878\n",
      "Epoch 6/50\n",
      "2055/2055 [==============================] - 2s 733us/step - loss: 0.0390 - acc: 0.9859\n",
      "Epoch 7/50\n",
      "2055/2055 [==============================] - 2s 745us/step - loss: 0.0302 - acc: 0.9898\n",
      "Epoch 8/50\n",
      "2055/2055 [==============================] - 1s 699us/step - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 9/50\n",
      "2055/2055 [==============================] - 1s 676us/step - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 10/50\n",
      "2055/2055 [==============================] - 1s 724us/step - loss: 0.0285 - acc: 0.9917\n",
      "Epoch 11/50\n",
      "2055/2055 [==============================] - 2s 769us/step - loss: 0.0258 - acc: 0.9912\n",
      "Epoch 12/50\n",
      "2055/2055 [==============================] - 1s 677us/step - loss: 0.0236 - acc: 0.9932\n",
      "Epoch 13/50\n",
      "2055/2055 [==============================] - 1s 645us/step - loss: 0.0222 - acc: 0.9937\n",
      "Epoch 14/50\n",
      "2055/2055 [==============================] - 1s 651us/step - loss: 0.0222 - acc: 0.9932\n",
      "Epoch 15/50\n",
      "2055/2055 [==============================] - 1s 620us/step - loss: 0.0219 - acc: 0.9932\n",
      "Epoch 16/50\n",
      "2055/2055 [==============================] - 1s 552us/step - loss: 0.0209 - acc: 0.9937\n",
      "Epoch 17/50\n",
      "2055/2055 [==============================] - 1s 606us/step - loss: 0.0203 - acc: 0.9932\n",
      "Epoch 18/50\n",
      "2055/2055 [==============================] - 1s 672us/step - loss: 0.0201 - acc: 0.9927\n",
      "Epoch 19/50\n",
      "2055/2055 [==============================] - 1s 631us/step - loss: 0.0203 - acc: 0.9922\n",
      "Epoch 20/50\n",
      "2055/2055 [==============================] - 1s 626us/step - loss: 0.0210 - acc: 0.9927\n",
      "Epoch 21/50\n",
      "2055/2055 [==============================] - 1s 635us/step - loss: 0.0188 - acc: 0.9937\n",
      "Epoch 22/50\n",
      "2055/2055 [==============================] - 1s 624us/step - loss: 0.0229 - acc: 0.9932\n",
      "Epoch 23/50\n",
      "2055/2055 [==============================] - 1s 630us/step - loss: 0.0193 - acc: 0.9932\n",
      "Epoch 24/50\n",
      "2055/2055 [==============================] - 1s 626us/step - loss: 0.0203 - acc: 0.9937\n",
      "Epoch 25/50\n",
      "2055/2055 [==============================] - 1s 627us/step - loss: 0.0191 - acc: 0.9937\n",
      "Epoch 26/50\n",
      "2055/2055 [==============================] - 1s 614us/step - loss: 0.0187 - acc: 0.9932\n",
      "Epoch 27/50\n",
      "2055/2055 [==============================] - 1s 561us/step - loss: 0.0184 - acc: 0.9932 0s - loss: 0.0191 - acc: 0.9\n",
      "Epoch 28/50\n",
      "2055/2055 [==============================] - 1s 570us/step - loss: 0.0188 - acc: 0.9932\n",
      "Epoch 29/50\n",
      "2055/2055 [==============================] - 1s 635us/step - loss: 0.0187 - acc: 0.9942\n",
      "Epoch 30/50\n",
      "2055/2055 [==============================] - 1s 629us/step - loss: 0.0189 - acc: 0.9946\n",
      "Epoch 31/50\n",
      "2055/2055 [==============================] - 1s 633us/step - loss: 0.0200 - acc: 0.9937\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2055/2055 [==============================] - 1s 640us/step - loss: 0.0208 - acc: 0.9937\n",
      "Epoch 33/50\n",
      "2055/2055 [==============================] - 1s 626us/step - loss: 0.0190 - acc: 0.9932\n",
      "Epoch 34/50\n",
      "2055/2055 [==============================] - 1s 630us/step - loss: 0.0190 - acc: 0.9927\n",
      "Epoch 35/50\n",
      "2055/2055 [==============================] - 1s 586us/step - loss: 0.0193 - acc: 0.9937\n",
      "Epoch 36/50\n",
      "2055/2055 [==============================] - 1s 623us/step - loss: 0.0191 - acc: 0.9932\n",
      "Epoch 37/50\n",
      "2055/2055 [==============================] - 1s 654us/step - loss: 0.0186 - acc: 0.9932 1s - loss: 0.0\n",
      "Epoch 38/50\n",
      "2055/2055 [==============================] - 1s 611us/step - loss: 0.0190 - acc: 0.9942\n",
      "Epoch 39/50\n",
      "2055/2055 [==============================] - 1s 640us/step - loss: 0.0186 - acc: 0.9942\n",
      "Epoch 40/50\n",
      "2055/2055 [==============================] - 1s 628us/step - loss: 0.0188 - acc: 0.9932\n",
      "Epoch 41/50\n",
      "2055/2055 [==============================] - 1s 626us/step - loss: 0.0180 - acc: 0.9937\n",
      "Epoch 42/50\n",
      "2055/2055 [==============================] - 1s 631us/step - loss: 0.0191 - acc: 0.9932\n",
      "Epoch 43/50\n",
      "2055/2055 [==============================] - 1s 647us/step - loss: 0.0187 - acc: 0.9932\n",
      "Epoch 44/50\n",
      "2055/2055 [==============================] - 1s 583us/step - loss: 0.0186 - acc: 0.9927\n",
      "Epoch 45/50\n",
      "2055/2055 [==============================] - 1s 600us/step - loss: 0.0187 - acc: 0.9927\n",
      "Epoch 46/50\n",
      "2055/2055 [==============================] - 1s 609us/step - loss: 0.0184 - acc: 0.9942\n",
      "Epoch 47/50\n",
      "2055/2055 [==============================] - 1s 629us/step - loss: 0.0192 - acc: 0.9932\n",
      "Epoch 48/50\n",
      "2055/2055 [==============================] - 1s 638us/step - loss: 0.0193 - acc: 0.9932\n",
      "Epoch 49/50\n",
      "2055/2055 [==============================] - 1s 631us/step - loss: 0.0187 - acc: 0.9942\n",
      "Epoch 50/50\n",
      "2055/2055 [==============================] - 1s 667us/step - loss: 0.0232 - acc: 0.9927\n",
      "229/229 [==============================] - 0s 235us/step\n",
      "Epoch 1/50\n",
      "2055/2055 [==============================] - 2s 1ms/step - loss: 0.2171 - acc: 0.9285\n",
      "Epoch 2/50\n",
      "2055/2055 [==============================] - 1s 726us/step - loss: 0.0771 - acc: 0.9805\n",
      "Epoch 3/50\n",
      "2055/2055 [==============================] - 1s 699us/step - loss: 0.0535 - acc: 0.9825\n",
      "Epoch 4/50\n",
      "2055/2055 [==============================] - 1s 730us/step - loss: 0.0438 - acc: 0.9844\n",
      "Epoch 5/50\n",
      "2055/2055 [==============================] - 1s 675us/step - loss: 0.0350 - acc: 0.9888\n",
      "Epoch 6/50\n",
      "2055/2055 [==============================] - 1s 672us/step - loss: 0.0332 - acc: 0.9903\n",
      "Epoch 7/50\n",
      "2055/2055 [==============================] - 1s 551us/step - loss: 0.0286 - acc: 0.9912\n",
      "Epoch 8/50\n",
      "2055/2055 [==============================] - 1s 604us/step - loss: 0.0325 - acc: 0.9922\n",
      "Epoch 9/50\n",
      "2055/2055 [==============================] - 1s 638us/step - loss: 0.0248 - acc: 0.9922\n",
      "Epoch 10/50\n",
      "2055/2055 [==============================] - 1s 529us/step - loss: 0.0243 - acc: 0.9917\n",
      "Epoch 11/50\n",
      "2055/2055 [==============================] - 1s 527us/step - loss: 0.0232 - acc: 0.9932\n",
      "Epoch 12/50\n",
      "2055/2055 [==============================] - 1s 531us/step - loss: 0.0214 - acc: 0.9927\n",
      "Epoch 13/50\n",
      "2055/2055 [==============================] - 1s 519us/step - loss: 0.0237 - acc: 0.9917\n",
      "Epoch 14/50\n",
      "2055/2055 [==============================] - 1s 692us/step - loss: 0.0225 - acc: 0.9917\n",
      "Epoch 15/50\n",
      "2055/2055 [==============================] - 1s 561us/step - loss: 0.0199 - acc: 0.9942\n",
      "Epoch 16/50\n",
      "2055/2055 [==============================] - 1s 580us/step - loss: 0.0203 - acc: 0.9922\n",
      "Epoch 17/50\n",
      "2055/2055 [==============================] - 1s 656us/step - loss: 0.0203 - acc: 0.9937\n",
      "Epoch 18/50\n",
      "2055/2055 [==============================] - 1s 654us/step - loss: 0.0196 - acc: 0.9942\n",
      "Epoch 19/50\n",
      "2055/2055 [==============================] - 1s 642us/step - loss: 0.0202 - acc: 0.9932\n",
      "Epoch 20/50\n",
      "2055/2055 [==============================] - 1s 646us/step - loss: 0.0194 - acc: 0.9942\n",
      "Epoch 21/50\n",
      "2055/2055 [==============================] - 1s 646us/step - loss: 0.0193 - acc: 0.9937\n",
      "Epoch 22/50\n",
      "2055/2055 [==============================] - 1s 533us/step - loss: 0.0189 - acc: 0.9942\n",
      "Epoch 23/50\n",
      "2055/2055 [==============================] - 1s 611us/step - loss: 0.0204 - acc: 0.9932\n",
      "Epoch 24/50\n",
      "2055/2055 [==============================] - 1s 648us/step - loss: 0.0222 - acc: 0.9927\n",
      "Epoch 25/50\n",
      "2055/2055 [==============================] - 1s 645us/step - loss: 0.0200 - acc: 0.9932\n",
      "Epoch 26/50\n",
      "2055/2055 [==============================] - 1s 614us/step - loss: 0.0196 - acc: 0.9937\n",
      "Epoch 27/50\n",
      "2055/2055 [==============================] - 1s 616us/step - loss: 0.0203 - acc: 0.9932\n",
      "Epoch 28/50\n",
      "2055/2055 [==============================] - 1s 547us/step - loss: 0.0329 - acc: 0.9903\n",
      "Epoch 29/50\n",
      "2055/2055 [==============================] - 1s 578us/step - loss: 0.0285 - acc: 0.9898\n",
      "Epoch 30/50\n",
      "2055/2055 [==============================] - 1s 623us/step - loss: 0.0390 - acc: 0.9888\n",
      "Epoch 31/50\n",
      "2055/2055 [==============================] - 1s 634us/step - loss: 0.0288 - acc: 0.9898\n",
      "Epoch 32/50\n",
      "2055/2055 [==============================] - 1s 679us/step - loss: 0.0239 - acc: 0.9922\n",
      "Epoch 33/50\n",
      "2055/2055 [==============================] - 1s 641us/step - loss: 0.0193 - acc: 0.9937\n",
      "Epoch 34/50\n",
      "2055/2055 [==============================] - 1s 625us/step - loss: 0.0189 - acc: 0.9937\n",
      "Epoch 35/50\n",
      "2055/2055 [==============================] - 1s 630us/step - loss: 0.0193 - acc: 0.9942\n",
      "Epoch 36/50\n",
      "2055/2055 [==============================] - 1s 627us/step - loss: 0.0194 - acc: 0.9937\n",
      "Epoch 37/50\n",
      "2055/2055 [==============================] - 1s 569us/step - loss: 0.0193 - acc: 0.9942\n",
      "Epoch 38/50\n",
      "2055/2055 [==============================] - 1s 592us/step - loss: 0.0184 - acc: 0.9942\n",
      "Epoch 39/50\n",
      "2055/2055 [==============================] - 1s 629us/step - loss: 0.0184 - acc: 0.9946\n",
      "Epoch 40/50\n",
      "2055/2055 [==============================] - 1s 653us/step - loss: 0.0181 - acc: 0.9946\n",
      "Epoch 41/50\n",
      "2055/2055 [==============================] - 1s 636us/step - loss: 0.0190 - acc: 0.9942\n",
      "Epoch 42/50\n",
      "2055/2055 [==============================] - 1s 628us/step - loss: 0.0190 - acc: 0.9937\n",
      "Epoch 43/50\n",
      "2055/2055 [==============================] - 1s 622us/step - loss: 0.0183 - acc: 0.9942\n",
      "Epoch 44/50\n",
      "2055/2055 [==============================] - 1s 633us/step - loss: 0.0176 - acc: 0.9942\n",
      "Epoch 45/50\n",
      "2055/2055 [==============================] - 1s 611us/step - loss: 0.0190 - acc: 0.9942\n",
      "Epoch 46/50\n",
      "2055/2055 [==============================] - 1s 575us/step - loss: 0.0191 - acc: 0.9946\n",
      "Epoch 47/50\n",
      "2055/2055 [==============================] - 1s 699us/step - loss: 0.0181 - acc: 0.9942\n",
      "Epoch 48/50\n",
      "2055/2055 [==============================] - 1s 672us/step - loss: 0.0183 - acc: 0.9937\n",
      "Epoch 49/50\n",
      "2055/2055 [==============================] - 1s 713us/step - loss: 0.0183 - acc: 0.9937\n",
      "Epoch 50/50\n",
      "2055/2055 [==============================] - 2s 742us/step - loss: 0.0178 - acc: 0.9932\n",
      "229/229 [==============================] - 0s 277us/step\n",
      "Epoch 1/50\n",
      "2055/2055 [==============================] - 2s 934us/step - loss: 0.2370 - acc: 0.9290\n",
      "Epoch 2/50\n",
      "2055/2055 [==============================] - 1s 671us/step - loss: 0.0814 - acc: 0.9766\n",
      "Epoch 3/50\n",
      "2055/2055 [==============================] - 1s 627us/step - loss: 0.0559 - acc: 0.9839\n",
      "Epoch 4/50\n",
      "2055/2055 [==============================] - 1s 641us/step - loss: 0.0422 - acc: 0.9869\n",
      "Epoch 5/50\n",
      "2055/2055 [==============================] - 1s 625us/step - loss: 0.0403 - acc: 0.9878\n",
      "Epoch 6/50\n",
      "2055/2055 [==============================] - 1s 629us/step - loss: 0.0343 - acc: 0.9898\n",
      "Epoch 7/50\n",
      "2055/2055 [==============================] - 1s 626us/step - loss: 0.0298 - acc: 0.9908\n",
      "Epoch 8/50\n",
      "2055/2055 [==============================] - 1s 582us/step - loss: 0.0286 - acc: 0.9908\n",
      "Epoch 9/50\n",
      "2055/2055 [==============================] - 1s 617us/step - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 10/50\n",
      "2055/2055 [==============================] - 1s 594us/step - loss: 0.0256 - acc: 0.9922\n",
      "Epoch 11/50\n",
      "2055/2055 [==============================] - 1s 637us/step - loss: 0.0245 - acc: 0.9922\n",
      "Epoch 12/50\n",
      "2055/2055 [==============================] - 1s 635us/step - loss: 0.0224 - acc: 0.9932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "2055/2055 [==============================] - 1s 624us/step - loss: 0.0227 - acc: 0.9932\n",
      "Epoch 14/50\n",
      "2055/2055 [==============================] - 1s 641us/step - loss: 0.0252 - acc: 0.9932\n",
      "Epoch 15/50\n",
      "2055/2055 [==============================] - 1s 636us/step - loss: 0.0216 - acc: 0.9912\n",
      "Epoch 16/50\n",
      "2055/2055 [==============================] - 1s 632us/step - loss: 0.0217 - acc: 0.9937\n",
      "Epoch 17/50\n",
      "2055/2055 [==============================] - 1s 585us/step - loss: 0.0218 - acc: 0.9927\n",
      "Epoch 18/50\n",
      "2055/2055 [==============================] - 1s 580us/step - loss: 0.0202 - acc: 0.9927\n",
      "Epoch 19/50\n",
      "2055/2055 [==============================] - 1s 599us/step - loss: 0.0212 - acc: 0.9937\n",
      "Epoch 20/50\n",
      "2055/2055 [==============================] - 1s 652us/step - loss: 0.0209 - acc: 0.9942\n",
      "Epoch 21/50\n",
      "2055/2055 [==============================] - 1s 638us/step - loss: 0.0200 - acc: 0.9932\n",
      "Epoch 22/50\n",
      "2055/2055 [==============================] - 1s 630us/step - loss: 0.0208 - acc: 0.9922\n",
      "Epoch 23/50\n",
      "2055/2055 [==============================] - 1s 633us/step - loss: 0.0197 - acc: 0.9932\n",
      "Epoch 24/50\n",
      "2055/2055 [==============================] - 1s 635us/step - loss: 0.0201 - acc: 0.9932\n",
      "Epoch 25/50\n",
      "2055/2055 [==============================] - 1s 628us/step - loss: 0.0197 - acc: 0.9932\n",
      "Epoch 26/50\n",
      "2055/2055 [==============================] - 1s 599us/step - loss: 0.0191 - acc: 0.9937\n",
      "Epoch 27/50\n",
      "2055/2055 [==============================] - 1s 661us/step - loss: 0.0215 - acc: 0.9922\n",
      "Epoch 28/50\n",
      "2055/2055 [==============================] - 2s 864us/step - loss: 0.0197 - acc: 0.9942\n",
      "Epoch 29/50\n",
      "2055/2055 [==============================] - 2s 963us/step - loss: 0.0202 - acc: 0.9922\n",
      "Epoch 30/50\n",
      "2055/2055 [==============================] - 2s 853us/step - loss: 0.0191 - acc: 0.9942\n",
      "Epoch 31/50\n",
      "2055/2055 [==============================] - 2s 760us/step - loss: 0.0193 - acc: 0.9922\n",
      "Epoch 32/50\n",
      "2055/2055 [==============================] - 1s 622us/step - loss: 0.0188 - acc: 0.9937\n",
      "Epoch 33/50\n",
      "2055/2055 [==============================] - 1s 519us/step - loss: 0.0181 - acc: 0.9932\n",
      "Epoch 34/50\n",
      "2055/2055 [==============================] - 1s 527us/step - loss: 0.0187 - acc: 0.9942\n",
      "Epoch 35/50\n",
      "2055/2055 [==============================] - 1s 519us/step - loss: 0.0177 - acc: 0.9946\n",
      "Epoch 36/50\n",
      "2055/2055 [==============================] - 1s 638us/step - loss: 0.0187 - acc: 0.9937\n",
      "Epoch 37/50\n",
      "2055/2055 [==============================] - 1s 650us/step - loss: 0.0186 - acc: 0.9937\n",
      "Epoch 38/50\n",
      "2055/2055 [==============================] - 1s 649us/step - loss: 0.0181 - acc: 0.9942\n",
      "Epoch 39/50\n",
      "2055/2055 [==============================] - 1s 578us/step - loss: 0.0181 - acc: 0.9927\n",
      "Epoch 40/50\n",
      "2055/2055 [==============================] - 1s 570us/step - loss: 0.0192 - acc: 0.9937\n",
      "Epoch 41/50\n",
      "2055/2055 [==============================] - 1s 723us/step - loss: 0.0187 - acc: 0.9942\n",
      "Epoch 42/50\n",
      "2055/2055 [==============================] - 1s 704us/step - loss: 0.0193 - acc: 0.9937\n",
      "Epoch 43/50\n",
      "2055/2055 [==============================] - 1s 717us/step - loss: 0.0183 - acc: 0.9927\n",
      "Epoch 44/50\n",
      "2055/2055 [==============================] - 2s 746us/step - loss: 0.0194 - acc: 0.9942\n",
      "Epoch 45/50\n",
      "2055/2055 [==============================] - 2s 757us/step - loss: 0.0178 - acc: 0.9932\n",
      "Epoch 46/50\n",
      "2055/2055 [==============================] - 2s 738us/step - loss: 0.0177 - acc: 0.9932\n",
      "Epoch 47/50\n",
      "2055/2055 [==============================] - 1s 653us/step - loss: 0.0173 - acc: 0.9937\n",
      "Epoch 48/50\n",
      "2055/2055 [==============================] - 1s 584us/step - loss: 0.0170 - acc: 0.9946\n",
      "Epoch 49/50\n",
      "2055/2055 [==============================] - 1s 619us/step - loss: 0.0182 - acc: 0.9932\n",
      "Epoch 50/50\n",
      "2055/2055 [==============================] - 1s 637us/step - loss: 0.0169 - acc: 0.9942\n",
      "229/229 [==============================] - 0s 317us/step\n",
      "Epoch 1/50\n",
      "2056/2056 [==============================] - 2s 894us/step - loss: 0.2339 - acc: 0.9173\n",
      "Epoch 2/50\n",
      "2056/2056 [==============================] - 1s 573us/step - loss: 0.0827 - acc: 0.9786\n",
      "Epoch 3/50\n",
      "2056/2056 [==============================] - 1s 582us/step - loss: 0.0638 - acc: 0.9805\n",
      "Epoch 4/50\n",
      "2056/2056 [==============================] - 1s 670us/step - loss: 0.0451 - acc: 0.9864\n",
      "Epoch 5/50\n",
      "2056/2056 [==============================] - 1s 630us/step - loss: 0.0351 - acc: 0.9878\n",
      "Epoch 6/50\n",
      "2056/2056 [==============================] - 1s 623us/step - loss: 0.0313 - acc: 0.9883\n",
      "Epoch 7/50\n",
      "2056/2056 [==============================] - 1s 654us/step - loss: 0.0262 - acc: 0.9917\n",
      "Epoch 8/50\n",
      "2056/2056 [==============================] - 1s 645us/step - loss: 0.0268 - acc: 0.9922\n",
      "Epoch 9/50\n",
      "2056/2056 [==============================] - 1s 621us/step - loss: 0.0304 - acc: 0.9893\n",
      "Epoch 10/50\n",
      "2056/2056 [==============================] - 1s 640us/step - loss: 0.0262 - acc: 0.9922\n",
      "Epoch 11/50\n",
      "2056/2056 [==============================] - 1s 619us/step - loss: 0.0240 - acc: 0.9908\n",
      "Epoch 12/50\n",
      "2056/2056 [==============================] - 1s 610us/step - loss: 0.0227 - acc: 0.9927\n",
      "Epoch 13/50\n",
      "2056/2056 [==============================] - 1s 535us/step - loss: 0.0231 - acc: 0.9917\n",
      "Epoch 14/50\n",
      "2056/2056 [==============================] - 1s 624us/step - loss: 0.0223 - acc: 0.9937\n",
      "Epoch 15/50\n",
      "2056/2056 [==============================] - 1s 631us/step - loss: 0.0214 - acc: 0.9927\n",
      "Epoch 16/50\n",
      "2056/2056 [==============================] - 1s 628us/step - loss: 0.0210 - acc: 0.9922\n",
      "Epoch 17/50\n",
      "2056/2056 [==============================] - 1s 625us/step - loss: 0.0254 - acc: 0.9912\n",
      "Epoch 18/50\n",
      "2056/2056 [==============================] - 1s 641us/step - loss: 0.0239 - acc: 0.9917\n",
      "Epoch 19/50\n",
      "2056/2056 [==============================] - 1s 625us/step - loss: 0.0287 - acc: 0.9922\n",
      "Epoch 20/50\n",
      "2056/2056 [==============================] - 1s 612us/step - loss: 0.0239 - acc: 0.9922\n",
      "Epoch 21/50\n",
      "2056/2056 [==============================] - 1s 687us/step - loss: 0.0219 - acc: 0.9922\n",
      "Epoch 22/50\n",
      "2056/2056 [==============================] - 1s 617us/step - loss: 0.0197 - acc: 0.9932\n",
      "Epoch 23/50\n",
      "2056/2056 [==============================] - 1s 596us/step - loss: 0.0201 - acc: 0.9922\n",
      "Epoch 24/50\n",
      "2056/2056 [==============================] - 1s 595us/step - loss: 0.0240 - acc: 0.9917\n",
      "Epoch 25/50\n",
      "2056/2056 [==============================] - 1s 637us/step - loss: 0.0192 - acc: 0.9937\n",
      "Epoch 26/50\n",
      "2056/2056 [==============================] - 1s 644us/step - loss: 0.0193 - acc: 0.9927\n",
      "Epoch 27/50\n",
      "2056/2056 [==============================] - 1s 649us/step - loss: 0.0206 - acc: 0.9937\n",
      "Epoch 28/50\n",
      "2056/2056 [==============================] - 1s 632us/step - loss: 0.0193 - acc: 0.9927\n",
      "Epoch 29/50\n",
      "2056/2056 [==============================] - 1s 634us/step - loss: 0.0193 - acc: 0.9942\n",
      "Epoch 30/50\n",
      "2056/2056 [==============================] - 1s 617us/step - loss: 0.0191 - acc: 0.9932\n",
      "Epoch 31/50\n",
      "2056/2056 [==============================] - 1s 549us/step - loss: 0.0201 - acc: 0.9937\n",
      "Epoch 32/50\n",
      "2056/2056 [==============================] - 1s 617us/step - loss: 0.0212 - acc: 0.9912\n",
      "Epoch 33/50\n",
      "2056/2056 [==============================] - 1s 634us/step - loss: 0.0209 - acc: 0.9932\n",
      "Epoch 34/50\n",
      "2056/2056 [==============================] - 1s 641us/step - loss: 0.0207 - acc: 0.9912\n",
      "Epoch 35/50\n",
      "2056/2056 [==============================] - 1s 691us/step - loss: 0.0204 - acc: 0.9937\n",
      "Epoch 36/50\n",
      "2056/2056 [==============================] - 1s 718us/step - loss: 0.0196 - acc: 0.9932\n",
      "Epoch 37/50\n",
      "2056/2056 [==============================] - 2s 747us/step - loss: 0.0191 - acc: 0.9932\n",
      "Epoch 38/50\n",
      "2056/2056 [==============================] - 1s 720us/step - loss: 0.0184 - acc: 0.9942\n",
      "Epoch 39/50\n",
      "2056/2056 [==============================] - 2s 740us/step - loss: 0.0191 - acc: 0.9932\n",
      "Epoch 40/50\n",
      "2056/2056 [==============================] - 1s 614us/step - loss: 0.0182 - acc: 0.9932\n",
      "Epoch 41/50\n",
      "2056/2056 [==============================] - 1s 596us/step - loss: 0.0183 - acc: 0.9937\n",
      "Epoch 42/50\n",
      "2056/2056 [==============================] - 1s 574us/step - loss: 0.0186 - acc: 0.9932\n",
      "Epoch 43/50\n",
      "2056/2056 [==============================] - 1s 546us/step - loss: 0.0178 - acc: 0.9942\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2056/2056 [==============================] - 1s 684us/step - loss: 0.0180 - acc: 0.9937\n",
      "Epoch 45/50\n",
      "2056/2056 [==============================] - 1s 662us/step - loss: 0.0185 - acc: 0.9937\n",
      "Epoch 46/50\n",
      "2056/2056 [==============================] - 1s 658us/step - loss: 0.0182 - acc: 0.9942\n",
      "Epoch 47/50\n",
      "2056/2056 [==============================] - 1s 520us/step - loss: 0.0182 - acc: 0.9937\n",
      "Epoch 48/50\n",
      "2056/2056 [==============================] - 1s 641us/step - loss: 0.0177 - acc: 0.9942\n",
      "Epoch 49/50\n",
      "2056/2056 [==============================] - 1s 655us/step - loss: 0.0181 - acc: 0.9942A: 1s - loss: 0.0\n",
      "Epoch 50/50\n",
      "2056/2056 [==============================] - 1s 690us/step - loss: 0.0179 - acc: 0.9937\n",
      "228/228 [==============================] - 0s 352us/step\n",
      "Epoch 1/50\n",
      "2056/2056 [==============================] - 2s 965us/step - loss: 0.2277 - acc: 0.9285\n",
      "Epoch 2/50\n",
      "2056/2056 [==============================] - 1s 663us/step - loss: 0.0854 - acc: 0.9762\n",
      "Epoch 3/50\n",
      "2056/2056 [==============================] - 1s 657us/step - loss: 0.0634 - acc: 0.9805\n",
      "Epoch 4/50\n",
      "2056/2056 [==============================] - 1s 637us/step - loss: 0.0483 - acc: 0.9864\n",
      "Epoch 5/50\n",
      "2056/2056 [==============================] - 1s 643us/step - loss: 0.0379 - acc: 0.9878\n",
      "Epoch 6/50\n",
      "2056/2056 [==============================] - 1s 643us/step - loss: 0.0370 - acc: 0.9893\n",
      "Epoch 7/50\n",
      "2056/2056 [==============================] - 1s 632us/step - loss: 0.0325 - acc: 0.9903\n",
      "Epoch 8/50\n",
      "2056/2056 [==============================] - 1s 593us/step - loss: 0.0302 - acc: 0.9908\n",
      "Epoch 9/50\n",
      "2056/2056 [==============================] - 1s 585us/step - loss: 0.0280 - acc: 0.9908\n",
      "Epoch 10/50\n",
      "2056/2056 [==============================] - 1s 673us/step - loss: 0.0260 - acc: 0.9912\n",
      "Epoch 11/50\n",
      "2056/2056 [==============================] - 1s 660us/step - loss: 0.0281 - acc: 0.9908\n",
      "Epoch 12/50\n",
      "2056/2056 [==============================] - 1s 665us/step - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 13/50\n",
      "2056/2056 [==============================] - 1s 646us/step - loss: 0.0229 - acc: 0.9922\n",
      "Epoch 14/50\n",
      "2056/2056 [==============================] - 1s 634us/step - loss: 0.0245 - acc: 0.9927\n",
      "Epoch 15/50\n",
      "2056/2056 [==============================] - 1s 682us/step - loss: 0.0210 - acc: 0.9932\n",
      "Epoch 16/50\n",
      "2056/2056 [==============================] - 1s 648us/step - loss: 0.0216 - acc: 0.9927\n",
      "Epoch 17/50\n",
      "2056/2056 [==============================] - 1s 593us/step - loss: 0.0215 - acc: 0.9932\n",
      "Epoch 18/50\n",
      "2056/2056 [==============================] - 1s 626us/step - loss: 0.0211 - acc: 0.9917\n",
      "Epoch 19/50\n",
      "2056/2056 [==============================] - 1s 630us/step - loss: 0.0218 - acc: 0.9937\n",
      "Epoch 20/50\n",
      "2056/2056 [==============================] - 1s 615us/step - loss: 0.0206 - acc: 0.9942\n",
      "Epoch 21/50\n",
      "2056/2056 [==============================] - 1s 649us/step - loss: 0.0198 - acc: 0.9937\n",
      "Epoch 22/50\n",
      "2056/2056 [==============================] - 1s 644us/step - loss: 0.0194 - acc: 0.9927\n",
      "Epoch 23/50\n",
      "2056/2056 [==============================] - 1s 657us/step - loss: 0.0230 - acc: 0.9932\n",
      "Epoch 24/50\n",
      "2056/2056 [==============================] - 1s 635us/step - loss: 0.0197 - acc: 0.9932\n",
      "Epoch 25/50\n",
      "2056/2056 [==============================] - 1s 641us/step - loss: 0.0202 - acc: 0.9937\n",
      "Epoch 26/50\n",
      "2056/2056 [==============================] - 1s 648us/step - loss: 0.0198 - acc: 0.9932\n",
      "Epoch 27/50\n",
      "2056/2056 [==============================] - 1s 643us/step - loss: 0.0189 - acc: 0.9932\n",
      "Epoch 28/50\n",
      "2056/2056 [==============================] - 1s 571us/step - loss: 0.0195 - acc: 0.9927\n",
      "Epoch 29/50\n",
      "2056/2056 [==============================] - 1s 595us/step - loss: 0.0198 - acc: 0.9932\n",
      "Epoch 30/50\n",
      "2056/2056 [==============================] - 1s 717us/step - loss: 0.0200 - acc: 0.9922\n",
      "Epoch 31/50\n",
      "2056/2056 [==============================] - 1s 710us/step - loss: 0.0206 - acc: 0.9932\n",
      "Epoch 32/50\n",
      "2056/2056 [==============================] - 1s 661us/step - loss: 0.0197 - acc: 0.9932\n",
      "Epoch 33/50\n",
      "2056/2056 [==============================] - 2s 741us/step - loss: 0.0186 - acc: 0.9932\n",
      "Epoch 34/50\n",
      "2056/2056 [==============================] - 2s 748us/step - loss: 0.0201 - acc: 0.9932\n",
      "Epoch 35/50\n",
      "2056/2056 [==============================] - 2s 758us/step - loss: 0.0185 - acc: 0.9937 0s - loss: 0.027\n",
      "Epoch 36/50\n",
      "2056/2056 [==============================] - 2s 746us/step - loss: 0.0211 - acc: 0.9942\n",
      "Epoch 37/50\n",
      "2056/2056 [==============================] - 1s 641us/step - loss: 0.0195 - acc: 0.9932\n",
      "Epoch 38/50\n",
      "2056/2056 [==============================] - 1s 585us/step - loss: 0.0194 - acc: 0.9937\n",
      "Epoch 39/50\n",
      "2056/2056 [==============================] - 1s 554us/step - loss: 0.0199 - acc: 0.9932\n",
      "Epoch 40/50\n",
      "2056/2056 [==============================] - 1s 643us/step - loss: 0.0189 - acc: 0.9942\n",
      "Epoch 41/50\n",
      "2056/2056 [==============================] - 1s 626us/step - loss: 0.0185 - acc: 0.9942\n",
      "Epoch 42/50\n",
      "2056/2056 [==============================] - 1s 644us/step - loss: 0.0192 - acc: 0.9927\n",
      "Epoch 43/50\n",
      "2056/2056 [==============================] - 1s 639us/step - loss: 0.0185 - acc: 0.9937\n",
      "Epoch 44/50\n",
      "2056/2056 [==============================] - 1s 673us/step - loss: 0.0196 - acc: 0.9937\n",
      "Epoch 45/50\n",
      "2056/2056 [==============================] - 1s 654us/step - loss: 0.0190 - acc: 0.9942\n",
      "Epoch 46/50\n",
      "2056/2056 [==============================] - 1s 629us/step - loss: 0.0189 - acc: 0.9942\n",
      "Epoch 47/50\n",
      "2056/2056 [==============================] - 1s 614us/step - loss: 0.0181 - acc: 0.9937\n",
      "Epoch 48/50\n",
      "2056/2056 [==============================] - 1s 573us/step - loss: 0.0189 - acc: 0.9932\n",
      "Epoch 49/50\n",
      "2056/2056 [==============================] - 1s 622us/step - loss: 0.0201 - acc: 0.9932\n",
      "Epoch 50/50\n",
      "2056/2056 [==============================] - 1s 637us/step - loss: 0.0214 - acc: 0.9927\n",
      "228/228 [==============================] - 0s 385us/step\n",
      "Epoch 1/50\n",
      "2056/2056 [==============================] - 2s 824us/step - loss: 0.2301 - acc: 0.9275\n",
      "Epoch 2/50\n",
      "2056/2056 [==============================] - 1s 628us/step - loss: 0.0868 - acc: 0.9747\n",
      "Epoch 3/50\n",
      "2056/2056 [==============================] - 1s 657us/step - loss: 0.0591 - acc: 0.9805\n",
      "Epoch 4/50\n",
      "2056/2056 [==============================] - 1s 666us/step - loss: 0.0445 - acc: 0.9854\n",
      "Epoch 5/50\n",
      "2056/2056 [==============================] - 1s 648us/step - loss: 0.0377 - acc: 0.9874\n",
      "Epoch 6/50\n",
      "2056/2056 [==============================] - 1s 651us/step - loss: 0.0298 - acc: 0.9908\n",
      "Epoch 7/50\n",
      "2056/2056 [==============================] - 1s 650us/step - loss: 0.0300 - acc: 0.9903\n",
      "Epoch 8/50\n",
      "2056/2056 [==============================] - 1s 635us/step - loss: 0.0304 - acc: 0.9898\n",
      "Epoch 9/50\n",
      "2056/2056 [==============================] - 2s 745us/step - loss: 0.0260 - acc: 0.9908\n",
      "Epoch 10/50\n",
      "2056/2056 [==============================] - 2s 879us/step - loss: 0.0254 - acc: 0.9917\n",
      "Epoch 11/50\n",
      "2056/2056 [==============================] - 2s 944us/step - loss: 0.0236 - acc: 0.9922\n",
      "Epoch 12/50\n",
      "2056/2056 [==============================] - 2s 964us/step - loss: 0.0273 - acc: 0.9922\n",
      "Epoch 13/50\n",
      "2056/2056 [==============================] - 2s 912us/step - loss: 0.0215 - acc: 0.9927\n",
      "Epoch 14/50\n",
      "2056/2056 [==============================] - 1s 674us/step - loss: 0.0217 - acc: 0.9927\n",
      "Epoch 15/50\n",
      "2056/2056 [==============================] - 1s 651us/step - loss: 0.0200 - acc: 0.9932\n",
      "Epoch 16/50\n",
      "2056/2056 [==============================] - 1s 637us/step - loss: 0.0195 - acc: 0.9932\n",
      "Epoch 17/50\n",
      "2056/2056 [==============================] - 1s 644us/step - loss: 0.0188 - acc: 0.9937\n",
      "Epoch 18/50\n",
      "2056/2056 [==============================] - 1s 547us/step - loss: 0.0194 - acc: 0.9932\n",
      "Epoch 19/50\n",
      "2056/2056 [==============================] - 1s 539us/step - loss: 0.0197 - acc: 0.9922\n",
      "Epoch 20/50\n",
      "2056/2056 [==============================] - 1s 555us/step - loss: 0.0185 - acc: 0.9942\n",
      "Epoch 21/50\n",
      "2056/2056 [==============================] - 1s 560us/step - loss: 0.0192 - acc: 0.9937\n",
      "Epoch 22/50\n",
      "2056/2056 [==============================] - 1s 588us/step - loss: 0.0197 - acc: 0.9937\n",
      "Epoch 23/50\n",
      "2056/2056 [==============================] - 1s 594us/step - loss: 0.0187 - acc: 0.9922\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2056/2056 [==============================] - 1s 574us/step - loss: 0.0180 - acc: 0.9932TA: 0s - loss: 0.0\n",
      "Epoch 25/50\n",
      "2056/2056 [==============================] - 1s 620us/step - loss: 0.0179 - acc: 0.9922\n",
      "Epoch 26/50\n",
      "2056/2056 [==============================] - 2s 797us/step - loss: 0.0177 - acc: 0.9942\n",
      "Epoch 27/50\n",
      "2056/2056 [==============================] - 2s 781us/step - loss: 0.0175 - acc: 0.9927 0s - loss: 0.0187\n",
      "Epoch 28/50\n",
      "2056/2056 [==============================] - 2s 792us/step - loss: 0.0179 - acc: 0.9937\n",
      "Epoch 29/50\n",
      "2056/2056 [==============================] - 1s 678us/step - loss: 0.0181 - acc: 0.9932\n",
      "Epoch 30/50\n",
      "2056/2056 [==============================] - 1s 587us/step - loss: 0.0179 - acc: 0.9937\n",
      "Epoch 31/50\n",
      "2056/2056 [==============================] - 1s 641us/step - loss: 0.0181 - acc: 0.9932\n",
      "Epoch 32/50\n",
      "2056/2056 [==============================] - 1s 621us/step - loss: 0.0180 - acc: 0.9937\n",
      "Epoch 33/50\n",
      "2056/2056 [==============================] - 1s 678us/step - loss: 0.0179 - acc: 0.9942\n",
      "Epoch 34/50\n",
      "2056/2056 [==============================] - 1s 667us/step - loss: 0.0187 - acc: 0.9937\n",
      "Epoch 35/50\n",
      "2056/2056 [==============================] - 1s 652us/step - loss: 0.0177 - acc: 0.9937\n",
      "Epoch 36/50\n",
      "2056/2056 [==============================] - 1s 656us/step - loss: 0.0263 - acc: 0.9922\n",
      "Epoch 37/50\n",
      "2056/2056 [==============================] - 1s 676us/step - loss: 0.0356 - acc: 0.9898\n",
      "Epoch 38/50\n",
      "2056/2056 [==============================] - 1s 604us/step - loss: 0.0376 - acc: 0.9869\n",
      "Epoch 39/50\n",
      "2056/2056 [==============================] - 1s 595us/step - loss: 0.0390 - acc: 0.9912\n",
      "Epoch 40/50\n",
      "2056/2056 [==============================] - 1s 629us/step - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 41/50\n",
      "2056/2056 [==============================] - 1s 648us/step - loss: 0.0291 - acc: 0.9917\n",
      "Epoch 42/50\n",
      "2056/2056 [==============================] - 1s 633us/step - loss: 0.0201 - acc: 0.9937\n",
      "Epoch 43/50\n",
      "2056/2056 [==============================] - 1s 636us/step - loss: 0.0188 - acc: 0.9937\n",
      "Epoch 44/50\n",
      "2056/2056 [==============================] - 1s 645us/step - loss: 0.0183 - acc: 0.9937\n",
      "Epoch 45/50\n",
      "2056/2056 [==============================] - 1s 636us/step - loss: 0.0178 - acc: 0.9937\n",
      "Epoch 46/50\n",
      "2056/2056 [==============================] - 1s 634us/step - loss: 0.0184 - acc: 0.9932\n",
      "Epoch 47/50\n",
      "2056/2056 [==============================] - 1s 632us/step - loss: 0.0188 - acc: 0.9942\n",
      "Epoch 48/50\n",
      "2056/2056 [==============================] - 1s 609us/step - loss: 0.0182 - acc: 0.9937\n",
      "Epoch 49/50\n",
      "2056/2056 [==============================] - 1s 548us/step - loss: 0.0174 - acc: 0.9942\n",
      "Epoch 50/50\n",
      "2056/2056 [==============================] - 1s 628us/step - loss: 0.0174 - acc: 0.9942\n",
      "228/228 [==============================] - 0s 729us/step\n",
      "Epoch 1/50\n",
      "2056/2056 [==============================] - 2s 1ms/step - loss: 0.2412 - acc: 0.9188\n",
      "Epoch 2/50\n",
      "2056/2056 [==============================] - 1s 680us/step - loss: 0.0798 - acc: 0.9781\n",
      "Epoch 3/50\n",
      "2056/2056 [==============================] - 1s 621us/step - loss: 0.0562 - acc: 0.9839\n",
      "Epoch 4/50\n",
      "2056/2056 [==============================] - 1s 635us/step - loss: 0.0420 - acc: 0.9883\n",
      "Epoch 5/50\n",
      "2056/2056 [==============================] - 1s 637us/step - loss: 0.0406 - acc: 0.9888\n",
      "Epoch 6/50\n",
      "2056/2056 [==============================] - 1s 626us/step - loss: 0.0301 - acc: 0.9898\n",
      "Epoch 7/50\n",
      "2056/2056 [==============================] - 1s 663us/step - loss: 0.0311 - acc: 0.9903\n",
      "Epoch 8/50\n",
      "2056/2056 [==============================] - 1s 675us/step - loss: 0.0291 - acc: 0.9922\n",
      "Epoch 9/50\n",
      "2056/2056 [==============================] - 1s 654us/step - loss: 0.0255 - acc: 0.9922\n",
      "Epoch 10/50\n",
      "2056/2056 [==============================] - 1s 650us/step - loss: 0.0251 - acc: 0.9922\n",
      "Epoch 11/50\n",
      "2056/2056 [==============================] - 1s 638us/step - loss: 0.0233 - acc: 0.9932\n",
      "Epoch 12/50\n",
      "2056/2056 [==============================] - 1s 639us/step - loss: 0.0225 - acc: 0.9942\n",
      "Epoch 13/50\n",
      "2056/2056 [==============================] - 1s 650us/step - loss: 0.0226 - acc: 0.9932 0s - loss: 0.0225 - acc: 0.9\n",
      "Epoch 14/50\n",
      "2056/2056 [==============================] - 1s 586us/step - loss: 0.0217 - acc: 0.9922\n",
      "Epoch 15/50\n",
      "2056/2056 [==============================] - 1s 666us/step - loss: 0.0207 - acc: 0.9942\n",
      "Epoch 16/50\n",
      "2056/2056 [==============================] - 1s 642us/step - loss: 0.0199 - acc: 0.9942\n",
      "Epoch 17/50\n",
      "2056/2056 [==============================] - 2s 730us/step - loss: 0.0202 - acc: 0.9946\n",
      "Epoch 18/50\n",
      "2056/2056 [==============================] - 2s 750us/step - loss: 0.0200 - acc: 0.9942\n",
      "Epoch 19/50\n",
      "2056/2056 [==============================] - 2s 747us/step - loss: 0.0182 - acc: 0.9937\n",
      "Epoch 20/50\n",
      "2056/2056 [==============================] - 2s 809us/step - loss: 0.0198 - acc: 0.9942\n",
      "Epoch 21/50\n",
      "2056/2056 [==============================] - 2s 804us/step - loss: 0.0195 - acc: 0.9942\n",
      "Epoch 22/50\n",
      "2056/2056 [==============================] - 2s 751us/step - loss: 0.0190 - acc: 0.9946\n",
      "Epoch 23/50\n",
      "2056/2056 [==============================] - 1s 615us/step - loss: 0.0185 - acc: 0.9937\n",
      "Epoch 24/50\n",
      "2056/2056 [==============================] - 1s 653us/step - loss: 0.0189 - acc: 0.9946\n",
      "Epoch 25/50\n",
      "2056/2056 [==============================] - 1s 655us/step - loss: 0.0182 - acc: 0.9951\n",
      "Epoch 26/50\n",
      "2056/2056 [==============================] - 1s 661us/step - loss: 0.0177 - acc: 0.9951\n",
      "Epoch 27/50\n",
      "2056/2056 [==============================] - 1s 662us/step - loss: 0.0185 - acc: 0.9942\n",
      "Epoch 28/50\n",
      "2056/2056 [==============================] - 1s 669us/step - loss: 0.0174 - acc: 0.9951\n",
      "Epoch 29/50\n",
      "2056/2056 [==============================] - 1s 549us/step - loss: 0.0191 - acc: 0.9946\n",
      "Epoch 30/50\n",
      "2056/2056 [==============================] - 1s 553us/step - loss: 0.0184 - acc: 0.9946\n",
      "Epoch 31/50\n",
      "2056/2056 [==============================] - 1s 569us/step - loss: 0.0188 - acc: 0.9937\n",
      "Epoch 32/50\n",
      "2056/2056 [==============================] - 1s 564us/step - loss: 0.0185 - acc: 0.9951\n",
      "Epoch 33/50\n",
      "2056/2056 [==============================] - 1s 661us/step - loss: 0.0186 - acc: 0.9937\n",
      "Epoch 34/50\n",
      "2056/2056 [==============================] - 1s 663us/step - loss: 0.0183 - acc: 0.9942\n",
      "Epoch 35/50\n",
      "2056/2056 [==============================] - 1s 621us/step - loss: 0.0189 - acc: 0.9946\n",
      "Epoch 36/50\n",
      "2056/2056 [==============================] - 1s 591us/step - loss: 0.0182 - acc: 0.9937\n",
      "Epoch 37/50\n",
      "2056/2056 [==============================] - 1s 641us/step - loss: 0.0179 - acc: 0.9946\n",
      "Epoch 38/50\n",
      "2056/2056 [==============================] - 1s 676us/step - loss: 0.0171 - acc: 0.9946\n",
      "Epoch 39/50\n",
      "2056/2056 [==============================] - 1s 669us/step - loss: 0.0204 - acc: 0.9942\n",
      "Epoch 40/50\n",
      "2056/2056 [==============================] - 1s 669us/step - loss: 0.0179 - acc: 0.9942\n",
      "Epoch 41/50\n",
      "2056/2056 [==============================] - 1s 672us/step - loss: 0.0182 - acc: 0.9946\n",
      "Epoch 42/50\n",
      "2056/2056 [==============================] - 1s 653us/step - loss: 0.0177 - acc: 0.9951\n",
      "Epoch 43/50\n",
      "2056/2056 [==============================] - 1s 672us/step - loss: 0.0174 - acc: 0.9951\n",
      "Epoch 44/50\n",
      "2056/2056 [==============================] - 1s 670us/step - loss: 0.0182 - acc: 0.9946\n",
      "Epoch 45/50\n",
      "2056/2056 [==============================] - 1s 655us/step - loss: 0.0175 - acc: 0.9942\n",
      "Epoch 46/50\n",
      "2056/2056 [==============================] - 1s 686us/step - loss: 0.0201 - acc: 0.9942\n",
      "Epoch 47/50\n",
      "2056/2056 [==============================] - 1s 658us/step - loss: 0.0214 - acc: 0.9946\n",
      "Epoch 48/50\n",
      "2056/2056 [==============================] - 1s 623us/step - loss: 0.0392 - acc: 0.9917\n",
      "Epoch 49/50\n",
      "2056/2056 [==============================] - 1s 604us/step - loss: 0.0386 - acc: 0.9908\n",
      "Epoch 50/50\n",
      "2056/2056 [==============================] - 1s 658us/step - loss: 0.0408 - acc: 0.9903\n",
      "228/228 [==============================] - 0s 798us/step\n",
      "Epoch 1/50\n",
      "2056/2056 [==============================] - 2s 1ms/step - loss: 0.2586 - acc: 0.9105\n",
      "Epoch 2/50\n",
      "2056/2056 [==============================] - 1s 635us/step - loss: 0.0909 - acc: 0.9698\n",
      "Epoch 3/50\n",
      "2056/2056 [==============================] - 1s 661us/step - loss: 0.0579 - acc: 0.9830\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2056/2056 [==============================] - 1s 625us/step - loss: 0.0484 - acc: 0.9849\n",
      "Epoch 5/50\n",
      "2056/2056 [==============================] - 1s 670us/step - loss: 0.0397 - acc: 0.9878\n",
      "Epoch 6/50\n",
      "2056/2056 [==============================] - 1s 660us/step - loss: 0.0395 - acc: 0.9883\n",
      "Epoch 7/50\n",
      "2056/2056 [==============================] - 1s 671us/step - loss: 0.0345 - acc: 0.9898\n",
      "Epoch 8/50\n",
      "2056/2056 [==============================] - 1s 655us/step - loss: 0.0384 - acc: 0.9888\n",
      "Epoch 9/50\n",
      "2056/2056 [==============================] - 1s 711us/step - loss: 0.0345 - acc: 0.9874\n",
      "Epoch 10/50\n",
      "2056/2056 [==============================] - 1s 729us/step - loss: 0.0284 - acc: 0.9917\n",
      "Epoch 11/50\n",
      "2056/2056 [==============================] - 1s 669us/step - loss: 0.0295 - acc: 0.9912\n",
      "Epoch 12/50\n",
      "2056/2056 [==============================] - 2s 755us/step - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 13/50\n",
      "2056/2056 [==============================] - 2s 750us/step - loss: 0.0239 - acc: 0.9927\n",
      "Epoch 14/50\n",
      "2056/2056 [==============================] - 2s 746us/step - loss: 0.0243 - acc: 0.9922\n",
      "Epoch 15/50\n",
      "2056/2056 [==============================] - 2s 745us/step - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 16/50\n",
      "2056/2056 [==============================] - 1s 680us/step - loss: 0.0226 - acc: 0.9917\n",
      "Epoch 17/50\n",
      "2056/2056 [==============================] - 1s 613us/step - loss: 0.0251 - acc: 0.9912\n",
      "Epoch 18/50\n",
      "2056/2056 [==============================] - 1s 645us/step - loss: 0.0234 - acc: 0.9932\n",
      "Epoch 19/50\n",
      "2056/2056 [==============================] - 1s 655us/step - loss: 0.0226 - acc: 0.9927\n",
      "Epoch 20/50\n",
      "2056/2056 [==============================] - 1s 646us/step - loss: 0.0224 - acc: 0.9927\n",
      "Epoch 21/50\n",
      "2056/2056 [==============================] - 1s 663us/step - loss: 0.0225 - acc: 0.9922\n",
      "Epoch 22/50\n",
      "2056/2056 [==============================] - 1s 668us/step - loss: 0.0240 - acc: 0.9922\n",
      "Epoch 23/50\n",
      "2056/2056 [==============================] - 1s 675us/step - loss: 0.0249 - acc: 0.9922 0s - loss: 0.0182 - a\n",
      "Epoch 24/50\n",
      "2056/2056 [==============================] - 1s 667us/step - loss: 0.0223 - acc: 0.9922\n",
      "Epoch 25/50\n",
      "2056/2056 [==============================] - 1s 697us/step - loss: 0.0214 - acc: 0.9917\n",
      "Epoch 26/50\n",
      "2056/2056 [==============================] - 1s 652us/step - loss: 0.0213 - acc: 0.9922\n",
      "Epoch 27/50\n",
      "2056/2056 [==============================] - 1s 687us/step - loss: 0.0220 - acc: 0.9927\n",
      "Epoch 28/50\n",
      "2056/2056 [==============================] - 1s 594us/step - loss: 0.0227 - acc: 0.9922\n",
      "Epoch 29/50\n",
      "2056/2056 [==============================] - 1s 596us/step - loss: 0.0208 - acc: 0.9937\n",
      "Epoch 30/50\n",
      "2056/2056 [==============================] - 1s 657us/step - loss: 0.0212 - acc: 0.9932\n",
      "Epoch 31/50\n",
      "2056/2056 [==============================] - 1s 657us/step - loss: 0.0221 - acc: 0.9927\n",
      "Epoch 32/50\n",
      "2056/2056 [==============================] - 1s 675us/step - loss: 0.0221 - acc: 0.9922\n",
      "Epoch 33/50\n",
      "2056/2056 [==============================] - 1s 657us/step - loss: 0.0207 - acc: 0.9927\n",
      "Epoch 34/50\n",
      "2056/2056 [==============================] - 1s 647us/step - loss: 0.0212 - acc: 0.9932\n",
      "Epoch 35/50\n",
      "2056/2056 [==============================] - 1s 661us/step - loss: 0.0201 - acc: 0.9932\n",
      "Epoch 36/50\n",
      "2056/2056 [==============================] - 1s 553us/step - loss: 0.0204 - acc: 0.9932\n",
      "Epoch 37/50\n",
      "2056/2056 [==============================] - 1s 547us/step - loss: 0.0214 - acc: 0.9937\n",
      "Epoch 38/50\n",
      "2056/2056 [==============================] - 1s 528us/step - loss: 0.0205 - acc: 0.9937\n",
      "Epoch 39/50\n",
      "2056/2056 [==============================] - 1s 565us/step - loss: 0.0200 - acc: 0.9927\n",
      "Epoch 40/50\n",
      "2056/2056 [==============================] - 2s 910us/step - loss: 0.0197 - acc: 0.9927\n",
      "Epoch 41/50\n",
      "2056/2056 [==============================] - 2s 956us/step - loss: 0.0221 - acc: 0.9922\n",
      "Epoch 42/50\n",
      "2056/2056 [==============================] - 2s 979us/step - loss: 0.0203 - acc: 0.9932\n",
      "Epoch 43/50\n",
      "2056/2056 [==============================] - 2s 965us/step - loss: 0.0205 - acc: 0.9937\n",
      "Epoch 44/50\n",
      "2056/2056 [==============================] - 2s 813us/step - loss: 0.0221 - acc: 0.9927\n",
      "Epoch 45/50\n",
      "2056/2056 [==============================] - 1s 683us/step - loss: 0.0208 - acc: 0.9927\n",
      "Epoch 46/50\n",
      "2056/2056 [==============================] - 1s 689us/step - loss: 0.0204 - acc: 0.9932\n",
      "Epoch 47/50\n",
      "2056/2056 [==============================] - 1s 687us/step - loss: 0.0202 - acc: 0.9927\n",
      "Epoch 48/50\n",
      "2056/2056 [==============================] - 1s 639us/step - loss: 0.0204 - acc: 0.9932\n",
      "Epoch 49/50\n",
      "2056/2056 [==============================] - 1s 591us/step - loss: 0.0210 - acc: 0.9932\n",
      "Epoch 50/50\n",
      "2056/2056 [==============================] - 1s 652us/step - loss: 0.0197 - acc: 0.9937\n",
      "228/228 [==============================] - 0s 965us/step\n",
      "Epoch 1/50\n",
      "2056/2056 [==============================] - 2s 1ms/step - loss: 0.2320 - acc: 0.9202\n",
      "Epoch 2/50\n",
      "2056/2056 [==============================] - 2s 784us/step - loss: 0.0767 - acc: 0.9776\n",
      "Epoch 3/50\n",
      "2056/2056 [==============================] - 1s 700us/step - loss: 0.0483 - acc: 0.9830\n",
      "Epoch 4/50\n",
      "2056/2056 [==============================] - 2s 805us/step - loss: 0.0423 - acc: 0.9854\n",
      "Epoch 5/50\n",
      "2056/2056 [==============================] - 2s 777us/step - loss: 0.0339 - acc: 0.9898\n",
      "Epoch 6/50\n",
      "2056/2056 [==============================] - 2s 754us/step - loss: 0.0299 - acc: 0.9898\n",
      "Epoch 7/50\n",
      "2056/2056 [==============================] - 1s 603us/step - loss: 0.0254 - acc: 0.9937\n",
      "Epoch 8/50\n",
      "2056/2056 [==============================] - 1s 597us/step - loss: 0.0226 - acc: 0.9922\n",
      "Epoch 9/50\n",
      "2056/2056 [==============================] - 1s 652us/step - loss: 0.0229 - acc: 0.9932\n",
      "Epoch 10/50\n",
      "2056/2056 [==============================] - 1s 651us/step - loss: 0.0215 - acc: 0.9937\n",
      "Epoch 11/50\n",
      "2056/2056 [==============================] - 1s 660us/step - loss: 0.0196 - acc: 0.9927\n",
      "Epoch 12/50\n",
      "2056/2056 [==============================] - 1s 675us/step - loss: 0.0191 - acc: 0.9937\n",
      "Epoch 13/50\n",
      "2056/2056 [==============================] - 1s 666us/step - loss: 0.0185 - acc: 0.9942\n",
      "Epoch 14/50\n",
      "2056/2056 [==============================] - 1s 674us/step - loss: 0.0181 - acc: 0.9951\n",
      "Epoch 15/50\n",
      "2056/2056 [==============================] - 1s 631us/step - loss: 0.0178 - acc: 0.9951\n",
      "Epoch 16/50\n",
      "2056/2056 [==============================] - 1s 651us/step - loss: 0.0175 - acc: 0.9937\n",
      "Epoch 17/50\n",
      "2056/2056 [==============================] - 1s 644us/step - loss: 0.0174 - acc: 0.9946\n",
      "Epoch 18/50\n",
      "2056/2056 [==============================] - 1s 645us/step - loss: 0.0190 - acc: 0.9942 1s - loss: 0.0142 \n",
      "Epoch 19/50\n",
      "2056/2056 [==============================] - 1s 690us/step - loss: 0.0167 - acc: 0.9937\n",
      "Epoch 20/50\n",
      "2056/2056 [==============================] - 1s 664us/step - loss: 0.0176 - acc: 0.9946\n",
      "Epoch 21/50\n",
      "2056/2056 [==============================] - 1s 667us/step - loss: 0.0155 - acc: 0.9946\n",
      "Epoch 22/50\n",
      "2056/2056 [==============================] - 1s 660us/step - loss: 0.0171 - acc: 0.9946\n",
      "Epoch 23/50\n",
      "2056/2056 [==============================] - 1s 651us/step - loss: 0.0167 - acc: 0.9951\n",
      "Epoch 24/50\n",
      "2056/2056 [==============================] - 1s 662us/step - loss: 0.0182 - acc: 0.9946\n",
      "Epoch 25/50\n",
      "2056/2056 [==============================] - 1s 654us/step - loss: 0.0183 - acc: 0.9942\n",
      "Epoch 26/50\n",
      "2056/2056 [==============================] - 1s 654us/step - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 27/50\n",
      "2056/2056 [==============================] - 1s 624us/step - loss: 0.0182 - acc: 0.9937\n",
      "Epoch 28/50\n",
      "2056/2056 [==============================] - 1s 643us/step - loss: 0.0176 - acc: 0.9942\n",
      "Epoch 29/50\n",
      "2056/2056 [==============================] - 1s 656us/step - loss: 0.0178 - acc: 0.9942\n",
      "Epoch 30/50\n",
      "2056/2056 [==============================] - 1s 669us/step - loss: 0.0181 - acc: 0.9946\n",
      "Epoch 31/50\n",
      "2056/2056 [==============================] - 1s 640us/step - loss: 0.0221 - acc: 0.9937\n",
      "Epoch 32/50\n",
      "2056/2056 [==============================] - 1s 664us/step - loss: 0.0179 - acc: 0.9946\n",
      "Epoch 33/50\n",
      "2056/2056 [==============================] - 1s 669us/step - loss: 0.0176 - acc: 0.9946 1s - loss: 0.01\n",
      "Epoch 34/50\n",
      "2056/2056 [==============================] - 1s 662us/step - loss: 0.0166 - acc: 0.9951\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2056/2056 [==============================] - 1s 675us/step - loss: 0.0155 - acc: 0.9951\n",
      "Epoch 36/50\n",
      "2056/2056 [==============================] - 1s 656us/step - loss: 0.0158 - acc: 0.9951\n",
      "Epoch 37/50\n",
      "2056/2056 [==============================] - 1s 643us/step - loss: 0.0156 - acc: 0.9942\n",
      "Epoch 38/50\n",
      "2056/2056 [==============================] - 1s 670us/step - loss: 0.0165 - acc: 0.9942\n",
      "Epoch 39/50\n",
      "2056/2056 [==============================] - 1s 571us/step - loss: 0.0155 - acc: 0.9951\n",
      "Epoch 40/50\n",
      "2056/2056 [==============================] - 1s 663us/step - loss: 0.0161 - acc: 0.9946\n",
      "Epoch 41/50\n",
      "2056/2056 [==============================] - 1s 609us/step - loss: 0.0160 - acc: 0.9951\n",
      "Epoch 42/50\n",
      "2056/2056 [==============================] - 1s 673us/step - loss: 0.0156 - acc: 0.9951\n",
      "Epoch 43/50\n",
      "2056/2056 [==============================] - 1s 674us/step - loss: 0.0154 - acc: 0.9946\n",
      "Epoch 44/50\n",
      "2056/2056 [==============================] - 1s 695us/step - loss: 0.0167 - acc: 0.9951\n",
      "Epoch 45/50\n",
      "2056/2056 [==============================] - 2s 743us/step - loss: 0.0153 - acc: 0.9951\n",
      "Epoch 46/50\n",
      "2056/2056 [==============================] - 1s 722us/step - loss: 0.0154 - acc: 0.9951\n",
      "Epoch 47/50\n",
      "2056/2056 [==============================] - 2s 760us/step - loss: 0.0159 - acc: 0.9951\n",
      "Epoch 48/50\n",
      "2056/2056 [==============================] - 2s 786us/step - loss: 0.0153 - acc: 0.9942 1s - loss\n",
      "Epoch 49/50\n",
      "2056/2056 [==============================] - 2s 770us/step - loss: 0.0148 - acc: 0.9951\n",
      "Epoch 50/50\n",
      "2056/2056 [==============================] - 2s 749us/step - loss: 0.0150 - acc: 0.9942\n",
      "228/228 [==============================] - 0s 615us/step\n",
      "Accuracy mean: 0.964086799969\n",
      "Accuracy variance: 0.0101696879142\n",
      "(' Time ', '689.441', ' seconds')\n",
      "[[651 209]\n",
      " [  6 114]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.76      0.86       860\n",
      "        1.0       0.35      0.95      0.51       120\n",
      "\n",
      "avg / total       0.91      0.78      0.82       980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# estimators \n",
    "# Evaluating the ANN\n",
    "t0 = time()\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 1024, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n",
    "    classifier.add(Dense(units = 512, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 50)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
