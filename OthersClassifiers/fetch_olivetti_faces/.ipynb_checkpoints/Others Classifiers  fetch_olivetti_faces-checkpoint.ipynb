{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt \n",
    "from pprint import pprint\n",
    "from numpy import array\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = fetch_olivetti_faces()\n",
    "X = data.images\n",
    "y = data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# reshape data\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GcForeest\n",
    "import argparse\n",
    "import sys\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "sys.path.insert(0, \"lib\")\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.utils.config_utils import load_json\n",
    "config = load_json(\"./examples/olivetti.json\") \n",
    "gc = GCForest(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of class\n",
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 17:37:14,746][cascade_classifier.fit_transform] X_groups_train.shape=[(280, 4096)],y_train.shape=(280,),X_groups_test.shape=[(120, 4096)],y_test.shape=(120,)\n",
      "[ 2018-07-31 17:37:14,748][cascade_classifier.fit_transform] group_dims=[4096]\n",
      "[ 2018-07-31 17:37:14,749][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-31 17:37:14,750][cascade_classifier.fit_transform] group_ends=[4096]\n",
      "[ 2018-07-31 17:37:14,751][cascade_classifier.fit_transform] X_train.shape=(280, 4096),X_test.shape=(120, 4096)\n",
      "[ 2018-07-31 17:37:14,755][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(280, 4096), X_cur_test.shape=(120, 4096)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[ 2018-07-31 17:37:15,669][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=96.43%\n",
      "[ 2018-07-31 17:37:16,494][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=93.10%\n",
      "[ 2018-07-31 17:37:17,488][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=89.66%\n",
      "[ 2018-07-31 17:37:18,415][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=90.00%\n",
      "[ 2018-07-31 17:37:19,230][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=87.10%\n",
      "[ 2018-07-31 17:37:20,060][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=92.86%\n",
      "[ 2018-07-31 17:37:20,991][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=90.00%\n",
      "[ 2018-07-31 17:37:21,813][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=95.83%\n",
      "[ 2018-07-31 17:37:22,758][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=90.91%\n",
      "[ 2018-07-31 17:37:23,697][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=82.76%\n",
      "[ 2018-07-31 17:37:23,917][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=90.71%\n",
      "[ 2018-07-31 17:37:23,918][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=85.83%\n",
      "[ 2018-07-31 17:37:24,430][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_0.predict)=92.00%\n",
      "[ 2018-07-31 17:37:25,039][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_1.predict)=96.15%\n",
      "[ 2018-07-31 17:37:25,647][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_2.predict)=93.33%\n",
      "[ 2018-07-31 17:37:26,377][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_3.predict)=93.33%\n",
      "[ 2018-07-31 17:37:27,121][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_4.predict)=85.71%\n",
      "[ 2018-07-31 17:37:27,845][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_5.predict)=89.66%\n",
      "[ 2018-07-31 17:37:28,452][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_6.predict)=89.66%\n",
      "[ 2018-07-31 17:37:29,341][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_7.predict)=87.50%\n",
      "[ 2018-07-31 17:37:29,947][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_8.predict)=92.31%\n",
      "[ 2018-07-31 17:37:30,678][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_9.predict)=92.31%\n",
      "[ 2018-07-31 17:37:30,786][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_cv.predict)=91.07%\n",
      "[ 2018-07-31 17:37:30,788][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.test.predict)=88.33%\n",
      "[ 2018-07-31 17:37:35,493][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_0.predict)=92.31%\n",
      "[ 2018-07-31 17:37:39,975][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_1.predict)=92.59%\n",
      "[ 2018-07-31 17:37:44,345][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_2.predict)=96.30%\n",
      "[ 2018-07-31 17:37:48,683][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_3.predict)=100.00%\n",
      "[ 2018-07-31 17:37:53,255][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_4.predict)=91.30%\n",
      "[ 2018-07-31 17:37:57,743][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_5.predict)=92.31%\n",
      "[ 2018-07-31 17:38:02,487][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_6.predict)=100.00%\n",
      "[ 2018-07-31 17:38:07,228][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_7.predict)=90.62%\n",
      "[ 2018-07-31 17:38:11,610][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_8.predict)=93.10%\n",
      "[ 2018-07-31 17:38:16,084][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_9.predict)=90.62%\n",
      "[ 2018-07-31 17:38:16,087][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_cv.predict)=93.93%\n",
      "[ 2018-07-31 17:38:16,088][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.test.predict)=89.17%\n",
      "[ 2018-07-31 17:38:16,089][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=94.64%\n",
      "[ 2018-07-31 17:38:16,090][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=92.50%\n",
      "[ 2018-07-31 17:38:16,093][cascade_classifier.fit_transform] [layer=1] look_indexs=[0], X_cur_train.shape=(280, 4216), X_cur_test.shape=(120, 4216)\n",
      "[ 2018-07-31 17:38:16,805][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_0.predict)=95.83%\n",
      "[ 2018-07-31 17:38:17,729][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_1.predict)=89.66%\n",
      "[ 2018-07-31 17:38:18,763][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_2.predict)=92.59%\n",
      "[ 2018-07-31 17:38:19,795][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_3.predict)=92.31%\n",
      "[ 2018-07-31 17:38:20,725][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_4.predict)=96.30%\n",
      "[ 2018-07-31 17:38:21,758][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_5.predict)=93.75%\n",
      "[ 2018-07-31 17:38:22,683][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_6.predict)=93.33%\n",
      "[ 2018-07-31 17:38:23,612][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_7.predict)=86.67%\n",
      "[ 2018-07-31 17:38:24,542][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_8.predict)=96.00%\n",
      "[ 2018-07-31 17:38:25,468][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_9.predict)=96.67%\n",
      "[ 2018-07-31 17:38:25,689][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_cv.predict)=93.21%\n",
      "[ 2018-07-31 17:38:25,690][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.test.predict)=87.50%\n",
      "[ 2018-07-31 17:38:26,203][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_0.predict)=93.10%\n",
      "[ 2018-07-31 17:38:26,930][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_1.predict)=96.67%\n",
      "[ 2018-07-31 17:38:27,642][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_2.predict)=89.66%\n",
      "[ 2018-07-31 17:38:28,365][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_3.predict)=96.43%\n",
      "[ 2018-07-31 17:38:29,094][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_4.predict)=96.55%\n",
      "[ 2018-07-31 17:38:29,824][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_5.predict)=89.29%\n",
      "[ 2018-07-31 17:38:30,547][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_6.predict)=93.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 17:38:31,159][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_7.predict)=100.00%\n",
      "[ 2018-07-31 17:38:31,886][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_8.predict)=96.00%\n",
      "[ 2018-07-31 17:38:32,615][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_9.predict)=84.00%\n",
      "[ 2018-07-31 17:38:32,836][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_cv.predict)=93.57%\n",
      "[ 2018-07-31 17:38:32,837][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.test.predict)=90.83%\n",
      "[ 2018-07-31 17:38:37,637][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_0.predict)=96.15%\n",
      "[ 2018-07-31 17:38:42,243][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_1.predict)=93.33%\n",
      "[ 2018-07-31 17:38:46,886][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_2.predict)=93.10%\n",
      "[ 2018-07-31 17:38:51,583][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_3.predict)=88.89%\n",
      "[ 2018-07-31 17:38:56,288][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_4.predict)=95.65%\n",
      "[ 2018-07-31 17:39:00,891][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_5.predict)=85.19%\n",
      "[ 2018-07-31 17:39:06,805][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_6.predict)=93.33%\n",
      "[ 2018-07-31 17:39:12,045][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_7.predict)=96.55%\n",
      "[ 2018-07-31 17:39:16,488][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_8.predict)=90.00%\n",
      "[ 2018-07-31 17:39:21,095][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_9.predict)=100.00%\n",
      "[ 2018-07-31 17:39:21,098][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_cv.predict)=93.21%\n",
      "[ 2018-07-31 17:39:21,099][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.test.predict)=90.00%\n",
      "[ 2018-07-31 17:39:21,101][cascade_classifier.calc_accuracy] Accuracy(layer_1 - train.classifier_average)=95.00%\n",
      "[ 2018-07-31 17:39:21,102][cascade_classifier.calc_accuracy] Accuracy(layer_1 - test.classifier_average)=92.50%\n",
      "[ 2018-07-31 17:39:21,105][cascade_classifier.fit_transform] [layer=2] look_indexs=[0], X_cur_train.shape=(280, 4216), X_cur_test.shape=(120, 4216)\n",
      "[ 2018-07-31 17:39:21,814][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_0.predict)=96.43%\n",
      "[ 2018-07-31 17:39:22,615][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_1.predict)=87.50%\n",
      "[ 2018-07-31 17:39:23,541][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_2.predict)=90.00%\n",
      "[ 2018-07-31 17:39:24,346][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_3.predict)=96.43%\n",
      "[ 2018-07-31 17:39:25,277][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_4.predict)=92.00%\n",
      "[ 2018-07-31 17:39:26,193][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_5.predict)=90.91%\n",
      "[ 2018-07-31 17:39:27,120][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_6.predict)=96.30%\n",
      "[ 2018-07-31 17:39:28,050][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_7.predict)=92.59%\n",
      "[ 2018-07-31 17:39:29,084][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_8.predict)=92.59%\n",
      "[ 2018-07-31 17:39:30,080][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_9.predict)=88.24%\n",
      "[ 2018-07-31 17:39:30,301][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_cv.predict)=92.14%\n",
      "[ 2018-07-31 17:39:30,302][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.test.predict)=90.00%\n",
      "[ 2018-07-31 17:39:30,819][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_0.predict)=88.89%\n",
      "[ 2018-07-31 17:39:31,544][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_1.predict)=93.55%\n",
      "[ 2018-07-31 17:39:32,277][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_2.predict)=100.00%\n",
      "[ 2018-07-31 17:39:33,001][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_3.predict)=100.00%\n",
      "[ 2018-07-31 17:39:33,612][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_4.predict)=93.55%\n",
      "[ 2018-07-31 17:39:34,336][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_5.predict)=89.29%\n",
      "[ 2018-07-31 17:39:35,068][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_6.predict)=92.00%\n",
      "[ 2018-07-31 17:39:35,798][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_7.predict)=87.88%\n",
      "[ 2018-07-31 17:39:36,412][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_8.predict)=91.67%\n",
      "[ 2018-07-31 17:39:37,137][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_9.predict)=93.75%\n",
      "[ 2018-07-31 17:39:37,358][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_cv.predict)=92.86%\n",
      "[ 2018-07-31 17:39:37,359][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.test.predict)=91.67%\n",
      "[ 2018-07-31 17:39:41,978][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_0.predict)=92.86%\n",
      "[ 2018-07-31 17:39:46,495][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_1.predict)=96.15%\n",
      "[ 2018-07-31 17:39:50,974][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_2.predict)=90.00%\n",
      "[ 2018-07-31 17:39:55,701][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_3.predict)=95.83%\n",
      "[ 2018-07-31 17:40:00,254][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_4.predict)=100.00%\n",
      "[ 2018-07-31 17:40:05,248][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_5.predict)=93.55%\n",
      "[ 2018-07-31 17:40:09,957][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_6.predict)=89.29%\n",
      "[ 2018-07-31 17:40:14,717][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_7.predict)=92.86%\n",
      "[ 2018-07-31 17:40:20,191][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_8.predict)=96.67%\n",
      "[ 2018-07-31 17:40:27,533][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_9.predict)=88.46%\n",
      "[ 2018-07-31 17:40:27,536][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_cv.predict)=93.57%\n",
      "[ 2018-07-31 17:40:27,538][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.test.predict)=90.00%\n",
      "[ 2018-07-31 17:40:27,539][cascade_classifier.calc_accuracy] Accuracy(layer_2 - train.classifier_average)=94.29%\n",
      "[ 2018-07-31 17:40:27,540][cascade_classifier.calc_accuracy] Accuracy(layer_2 - test.classifier_average)=92.50%\n",
      "[ 2018-07-31 17:40:27,543][cascade_classifier.fit_transform] [layer=3] look_indexs=[0], X_cur_train.shape=(280, 4216), X_cur_test.shape=(120, 4216)\n",
      "[ 2018-07-31 17:40:28,389][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_0.predict)=93.10%\n",
      "[ 2018-07-31 17:40:29,206][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_1.predict)=96.00%\n",
      "[ 2018-07-31 17:40:30,122][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_2.predict)=89.47%\n",
      "[ 2018-07-31 17:40:31,052][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_3.predict)=100.00%\n",
      "[ 2018-07-31 17:40:31,855][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_4.predict)=93.75%\n",
      "[ 2018-07-31 17:40:32,781][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_5.predict)=89.66%\n",
      "[ 2018-07-31 17:40:33,696][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_6.predict)=96.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 17:40:34,617][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_7.predict)=83.33%\n",
      "[ 2018-07-31 17:40:35,425][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_8.predict)=86.67%\n",
      "[ 2018-07-31 17:40:36,359][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_9.predict)=93.55%\n",
      "[ 2018-07-31 17:40:36,581][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_cv.predict)=92.14%\n",
      "[ 2018-07-31 17:40:36,583][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.test.predict)=90.00%\n",
      "[ 2018-07-31 17:40:37,094][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_0.predict)=92.86%\n",
      "[ 2018-07-31 17:40:37,936][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_1.predict)=96.77%\n",
      "[ 2018-07-31 17:40:38,783][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_2.predict)=90.62%\n",
      "[ 2018-07-31 17:40:39,520][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_3.predict)=96.00%\n",
      "[ 2018-07-31 17:40:40,252][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_4.predict)=96.43%\n",
      "[ 2018-07-31 17:40:40,978][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_5.predict)=89.29%\n",
      "[ 2018-07-31 17:40:41,835][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_6.predict)=84.00%\n",
      "[ 2018-07-31 17:40:42,793][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_7.predict)=96.67%\n",
      "[ 2018-07-31 17:40:43,965][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_8.predict)=88.46%\n",
      "[ 2018-07-31 17:40:44,967][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_9.predict)=88.89%\n",
      "[ 2018-07-31 17:40:45,218][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_cv.predict)=92.14%\n",
      "[ 2018-07-31 17:40:45,220][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.test.predict)=92.50%\n",
      "[ 2018-07-31 17:40:49,886][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_0.predict)=96.30%\n",
      "[ 2018-07-31 17:40:54,375][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_1.predict)=88.00%\n",
      "[ 2018-07-31 17:40:59,034][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_2.predict)=92.86%\n",
      "[ 2018-07-31 17:41:05,326][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_3.predict)=96.77%\n",
      "[ 2018-07-31 17:41:09,996][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_4.predict)=89.66%\n",
      "[ 2018-07-31 17:41:14,641][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_5.predict)=84.85%\n",
      "[ 2018-07-31 17:41:19,464][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_6.predict)=96.77%\n",
      "[ 2018-07-31 17:41:25,382][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_7.predict)=100.00%\n",
      "[ 2018-07-31 17:41:30,007][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_8.predict)=92.00%\n",
      "[ 2018-07-31 17:41:34,967][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_9.predict)=100.00%\n",
      "[ 2018-07-31 17:41:34,971][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_cv.predict)=93.57%\n",
      "[ 2018-07-31 17:41:34,972][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.test.predict)=90.00%\n",
      "[ 2018-07-31 17:41:34,974][cascade_classifier.calc_accuracy] Accuracy(layer_3 - train.classifier_average)=95.36%\n",
      "[ 2018-07-31 17:41:34,974][cascade_classifier.calc_accuracy] Accuracy(layer_3 - test.classifier_average)=92.50%\n",
      "[ 2018-07-31 17:41:34,977][cascade_classifier.fit_transform] [layer=4] look_indexs=[0], X_cur_train.shape=(280, 4216), X_cur_test.shape=(120, 4216)\n",
      "[ 2018-07-31 17:41:35,683][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_0.predict)=92.31%\n",
      "[ 2018-07-31 17:41:36,606][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_1.predict)=88.46%\n",
      "[ 2018-07-31 17:41:37,563][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_2.predict)=96.00%\n",
      "[ 2018-07-31 17:41:38,605][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_3.predict)=90.91%\n",
      "[ 2018-07-31 17:41:39,655][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_4.predict)=93.33%\n",
      "[ 2018-07-31 17:41:40,852][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_5.predict)=88.89%\n",
      "[ 2018-07-31 17:41:42,237][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_6.predict)=93.33%\n",
      "[ 2018-07-31 17:41:43,689][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_7.predict)=92.59%\n",
      "[ 2018-07-31 17:41:44,807][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_8.predict)=91.67%\n",
      "[ 2018-07-31 17:41:45,853][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_9.predict)=87.50%\n",
      "[ 2018-07-31 17:41:46,076][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_cv.predict)=91.43%\n",
      "[ 2018-07-31 17:41:46,078][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.test.predict)=90.00%\n",
      "[ 2018-07-31 17:41:46,605][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_0.predict)=96.00%\n",
      "[ 2018-07-31 17:41:47,335][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_1.predict)=96.15%\n",
      "[ 2018-07-31 17:41:48,063][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_2.predict)=100.00%\n",
      "[ 2018-07-31 17:41:48,911][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_3.predict)=92.86%\n",
      "[ 2018-07-31 17:41:49,645][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_4.predict)=78.57%\n",
      "[ 2018-07-31 17:41:50,372][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_5.predict)=100.00%\n",
      "[ 2018-07-31 17:41:51,111][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_6.predict)=93.75%\n",
      "[ 2018-07-31 17:41:51,874][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_7.predict)=93.10%\n",
      "[ 2018-07-31 17:41:52,721][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_8.predict)=92.59%\n",
      "[ 2018-07-31 17:41:53,567][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_9.predict)=92.31%\n",
      "[ 2018-07-31 17:41:53,788][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_cv.predict)=93.57%\n",
      "[ 2018-07-31 17:41:53,790][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.test.predict)=90.00%\n",
      "[ 2018-07-31 17:41:58,921][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_0.predict)=91.67%\n",
      "[ 2018-07-31 17:42:06,321][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_1.predict)=89.66%\n",
      "[ 2018-07-31 17:42:11,564][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_2.predict)=88.57%\n",
      "[ 2018-07-31 17:42:16,129][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_3.predict)=89.66%\n",
      "[ 2018-07-31 17:42:21,483][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_4.predict)=100.00%\n",
      "[ 2018-07-31 17:42:27,381][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_5.predict)=88.46%\n",
      "[ 2018-07-31 17:42:32,981][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_6.predict)=96.55%\n",
      "[ 2018-07-31 17:42:37,870][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_7.predict)=95.45%\n",
      "[ 2018-07-31 17:42:44,861][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_8.predict)=92.86%\n",
      "[ 2018-07-31 17:42:49,852][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_9.predict)=100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 17:42:49,855][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_cv.predict)=93.21%\n",
      "[ 2018-07-31 17:42:49,856][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.test.predict)=90.00%\n",
      "[ 2018-07-31 17:42:49,857][cascade_classifier.calc_accuracy] Accuracy(layer_4 - train.classifier_average)=95.36%\n",
      "[ 2018-07-31 17:42:49,858][cascade_classifier.calc_accuracy] Accuracy(layer_4 - test.classifier_average)=92.50%\n",
      "[ 2018-07-31 17:42:49,861][cascade_classifier.fit_transform] [layer=5] look_indexs=[0], X_cur_train.shape=(280, 4216), X_cur_test.shape=(120, 4216)\n",
      "[ 2018-07-31 17:42:50,746][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_0.predict)=90.00%\n",
      "[ 2018-07-31 17:42:51,784][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_1.predict)=87.10%\n",
      "[ 2018-07-31 17:42:52,715][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_2.predict)=93.33%\n",
      "[ 2018-07-31 17:42:53,754][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_3.predict)=92.59%\n",
      "[ 2018-07-31 17:42:54,679][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_4.predict)=91.30%\n",
      "[ 2018-07-31 17:42:55,607][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_5.predict)=90.00%\n",
      "[ 2018-07-31 17:42:56,416][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_6.predict)=90.32%\n",
      "[ 2018-07-31 17:42:57,229][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_7.predict)=88.00%\n",
      "[ 2018-07-31 17:42:58,388][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_8.predict)=95.65%\n",
      "[ 2018-07-31 17:42:59,536][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_9.predict)=96.67%\n",
      "[ 2018-07-31 17:42:59,761][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_cv.predict)=91.43%\n",
      "[ 2018-07-31 17:42:59,762][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.test.predict)=87.50%\n",
      "[ 2018-07-31 17:43:00,398][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_0.predict)=100.00%\n",
      "[ 2018-07-31 17:43:01,260][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-31 17:43:02,265][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_2.predict)=100.00%\n",
      "[ 2018-07-31 17:43:03,133][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_3.predict)=86.21%\n",
      "[ 2018-07-31 17:43:03,982][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_4.predict)=86.21%\n",
      "[ 2018-07-31 17:43:04,848][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_5.predict)=95.65%\n",
      "[ 2018-07-31 17:43:05,659][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_6.predict)=96.30%\n",
      "[ 2018-07-31 17:43:06,378][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_7.predict)=90.00%\n",
      "[ 2018-07-31 17:43:07,269][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_8.predict)=90.00%\n",
      "[ 2018-07-31 17:43:07,997][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_9.predict)=93.55%\n",
      "[ 2018-07-31 17:43:08,221][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_cv.predict)=93.57%\n",
      "[ 2018-07-31 17:43:08,222][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.test.predict)=90.83%\n",
      "[ 2018-07-31 17:43:12,832][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_0.predict)=96.55%\n",
      "[ 2018-07-31 17:43:17,666][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_1.predict)=84.62%\n",
      "[ 2018-07-31 17:43:22,489][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_2.predict)=93.10%\n",
      "[ 2018-07-31 17:43:27,317][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_3.predict)=96.15%\n",
      "[ 2018-07-31 17:43:31,966][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_4.predict)=100.00%\n",
      "[ 2018-07-31 17:43:36,623][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_5.predict)=96.77%\n",
      "[ 2018-07-31 17:43:41,259][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_6.predict)=89.66%\n",
      "[ 2018-07-31 17:43:46,084][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_7.predict)=92.59%\n",
      "[ 2018-07-31 17:43:50,945][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_8.predict)=89.29%\n",
      "[ 2018-07-31 17:43:55,723][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_9.predict)=96.30%\n",
      "[ 2018-07-31 17:43:55,727][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_cv.predict)=93.57%\n",
      "[ 2018-07-31 17:43:55,728][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.test.predict)=90.00%\n",
      "[ 2018-07-31 17:43:55,729][cascade_classifier.calc_accuracy] Accuracy(layer_5 - train.classifier_average)=95.00%\n",
      "[ 2018-07-31 17:43:55,730][cascade_classifier.calc_accuracy] Accuracy(layer_5 - test.classifier_average)=92.50%\n",
      "[ 2018-07-31 17:43:55,734][cascade_classifier.fit_transform] [layer=6] look_indexs=[0], X_cur_train.shape=(280, 4216), X_cur_test.shape=(120, 4216)\n",
      "[ 2018-07-31 17:43:56,456][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_0.predict)=96.00%\n",
      "[ 2018-07-31 17:43:57,388][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_1.predict)=96.43%\n",
      "[ 2018-07-31 17:43:58,460][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_2.predict)=89.66%\n",
      "[ 2018-07-31 17:43:59,591][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_3.predict)=90.91%\n",
      "[ 2018-07-31 17:44:00,512][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_4.predict)=95.83%\n",
      "[ 2018-07-31 17:44:01,659][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_5.predict)=96.55%\n",
      "[ 2018-07-31 17:44:02,811][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_6.predict)=96.00%\n",
      "[ 2018-07-31 17:44:03,994][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_7.predict)=77.27%\n",
      "[ 2018-07-31 17:44:05,166][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_8.predict)=87.88%\n",
      "[ 2018-07-31 17:44:06,508][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_9.predict)=87.50%\n",
      "[ 2018-07-31 17:44:06,740][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_cv.predict)=91.43%\n",
      "[ 2018-07-31 17:44:06,741][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.test.predict)=89.17%\n",
      "[ 2018-07-31 17:44:07,259][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_0.predict)=93.10%\n",
      "[ 2018-07-31 17:44:07,987][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_1.predict)=89.29%\n",
      "[ 2018-07-31 17:44:08,825][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_2.predict)=96.55%\n",
      "[ 2018-07-31 17:44:09,553][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_3.predict)=92.59%\n",
      "[ 2018-07-31 17:44:10,399][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_4.predict)=91.30%\n",
      "[ 2018-07-31 17:44:11,127][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_5.predict)=93.33%\n",
      "[ 2018-07-31 17:44:11,910][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_6.predict)=90.00%\n",
      "[ 2018-07-31 17:44:12,638][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_7.predict)=92.59%\n",
      "[ 2018-07-31 17:44:13,368][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_8.predict)=100.00%\n",
      "[ 2018-07-31 17:44:14,105][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_9.predict)=86.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 17:44:14,328][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_cv.predict)=92.50%\n",
      "[ 2018-07-31 17:44:14,329][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.test.predict)=90.83%\n",
      "[ 2018-07-31 17:44:18,989][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_0.predict)=90.00%\n",
      "[ 2018-07-31 17:44:23,666][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_1.predict)=96.43%\n",
      "[ 2018-07-31 17:44:28,394][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_2.predict)=88.24%\n",
      "[ 2018-07-31 17:44:33,176][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_3.predict)=89.29%\n",
      "[ 2018-07-31 17:44:37,800][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_4.predict)=91.18%\n",
      "[ 2018-07-31 17:44:42,495][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_5.predict)=92.00%\n",
      "[ 2018-07-31 17:44:47,180][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_6.predict)=100.00%\n",
      "[ 2018-07-31 17:44:51,985][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_7.predict)=92.00%\n",
      "[ 2018-07-31 17:44:56,951][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_8.predict)=100.00%\n",
      "[ 2018-07-31 17:45:02,362][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_9.predict)=96.55%\n",
      "[ 2018-07-31 17:45:02,366][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_cv.predict)=93.21%\n",
      "[ 2018-07-31 17:45:02,367][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.test.predict)=90.00%\n",
      "[ 2018-07-31 17:45:02,368][cascade_classifier.calc_accuracy] Accuracy(layer_6 - train.classifier_average)=94.29%\n",
      "[ 2018-07-31 17:45:02,369][cascade_classifier.calc_accuracy] Accuracy(layer_6 - test.classifier_average)=92.50%\n",
      "[ 2018-07-31 17:45:02,370][cascade_classifier.fit_transform] [Result][Optimal Level Detected] opt_layer_num=4, accuracy_train=95.36%, accuracy_test=92.50%\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "# X_enc is the concatenated predict_proba result of each estimators of the last layer of the GCForest model\n",
    "    # X_enc.shape =\n",
    "    #   (n_datas, n_estimators * n_classes): If cascade is provided\n",
    "    #   (n_datas, n_estimators * n_classes, dimX, dimY): If only finegrained part is provided\n",
    "    # You can also pass X_test, y_test to fit_transform method, then the accracy on test data will be logged when training.\n",
    "X_train_enc, X_test_enc = gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test)\n",
    "    # WARNING: if you set gc.set_keep_model_in_mem(True), you would have to use\n",
    "    # gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test) to evaluate your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 17:45:02,397][cascade_classifier.transform] X_groups_test.shape=[(120, 4096)]\n",
      "[ 2018-07-31 17:45:02,399][cascade_classifier.transform] group_dims=[4096]\n",
      "[ 2018-07-31 17:45:02,401][cascade_classifier.transform] X_test.shape=(120, 4096)\n",
      "[ 2018-07-31 17:45:02,402][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(120, 4096)\n",
      "[ 2018-07-31 17:45:07,072][cascade_classifier.transform] [layer=1] look_indexs=[0], X_cur_test.shape=(120, 4216)\n",
      "[ 2018-07-31 17:45:11,153][cascade_classifier.transform] [layer=2] look_indexs=[0], X_cur_test.shape=(120, 4216)\n",
      "[ 2018-07-31 17:45:15,393][cascade_classifier.transform] [layer=3] look_indexs=[0], X_cur_test.shape=(120, 4216)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GCForest = 92.500000 %\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "y_pred = gc.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy of GCForest = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' Time ', '484.443', ' seconds')\n",
      "[[3 0 0 ..., 0 0 0]\n",
      " [0 3 0 ..., 0 0 0]\n",
      " [0 0 2 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 2 0 0]\n",
      " [0 0 0 ..., 0 3 0]\n",
      " [0 0 0 ..., 0 0 3]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         3\n",
      "          1       1.00      1.00      1.00         3\n",
      "          2       1.00      1.00      1.00         2\n",
      "          3       1.00      1.00      1.00         4\n",
      "          4       0.80      1.00      0.89         4\n",
      "          5       1.00      1.00      1.00         1\n",
      "          6       1.00      1.00      1.00         3\n",
      "          7       1.00      0.83      0.91         6\n",
      "          8       0.00      0.00      0.00         0\n",
      "          9       1.00      0.80      0.89         5\n",
      "         10       1.00      1.00      1.00         5\n",
      "         11       1.00      1.00      1.00         1\n",
      "         12       1.00      1.00      1.00         1\n",
      "         14       1.00      1.00      1.00         4\n",
      "         15       1.00      1.00      1.00         3\n",
      "         16       0.50      1.00      0.67         1\n",
      "         17       0.80      1.00      0.89         4\n",
      "         18       1.00      1.00      1.00         3\n",
      "         19       1.00      1.00      1.00         3\n",
      "         20       1.00      1.00      1.00         2\n",
      "         21       1.00      0.75      0.86         4\n",
      "         22       1.00      1.00      1.00         3\n",
      "         23       1.00      1.00      1.00         5\n",
      "         24       1.00      1.00      1.00         4\n",
      "         25       1.00      1.00      1.00         1\n",
      "         26       1.00      1.00      1.00         2\n",
      "         27       1.00      1.00      1.00         5\n",
      "         28       1.00      1.00      1.00         3\n",
      "         29       1.00      1.00      1.00         1\n",
      "         30       1.00      1.00      1.00         2\n",
      "         31       1.00      1.00      1.00         5\n",
      "         32       1.00      1.00      1.00         2\n",
      "         33       1.00      1.00      1.00         4\n",
      "         34       1.00      0.50      0.67         6\n",
      "         35       1.00      1.00      1.00         2\n",
      "         36       1.00      1.00      1.00         2\n",
      "         37       1.00      1.00      1.00         2\n",
      "         38       0.60      1.00      0.75         3\n",
      "         39       0.60      0.50      0.55         6\n",
      "\n",
      "avg / total       0.95      0.93      0.93       120\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "252/252 [==============================] - 1s 5ms/step - loss: -241.9712 - acc: 0.0278\n",
      "Epoch 2/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 3/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 4/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 5/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 6/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 7/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 8/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 9/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 10/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 11/50\n",
      "252/252 [==============================] - 1s 2ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 12/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 13/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 14/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 15/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 16/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 17/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 18/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 19/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278: 0s - loss: -281.4827 - acc: \n",
      "Epoch 20/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 21/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 22/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 23/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 24/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 25/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 26/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 27/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 28/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 29/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 30/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 31/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 32/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 33/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 34/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 35/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 36/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 37/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 38/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 39/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 40/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 41/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 42/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 43/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 44/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 45/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 46/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 47/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 48/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 49/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "Epoch 50/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.2160 - acc: 0.0278\n",
      "28/28 [==============================] - 0s 675us/step\n",
      "Epoch 1/50\n",
      "252/252 [==============================] - 1s 3ms/step - loss: -237.3513 - acc: 0.0278\n",
      "Epoch 2/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 3/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 4/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 5/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 6/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 7/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 8/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 9/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 10/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 11/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 12/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 13/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 14/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 15/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 16/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 17/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 18/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 19/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 20/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 21/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 22/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 23/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 24/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 25/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 26/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 27/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 28/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 29/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 30/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 31/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 32/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252/252 [==============================] - 0s 2ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 34/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 35/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 36/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 37/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 38/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 39/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 40/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 41/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 42/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 43/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 44/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 45/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 46/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 47/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 48/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 49/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "Epoch 50/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -287.0894 - acc: 0.0238\n",
      "28/28 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "252/252 [==============================] - 1s 3ms/step - loss: -242.0499 - acc: 0.0278\n",
      "Epoch 2/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 3/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 4/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 5/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 6/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 7/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 8/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 9/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 10/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 11/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 12/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 13/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 14/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 15/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 16/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 17/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 18/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 19/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 20/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 21/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 22/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 23/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 24/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 25/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 26/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 27/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 28/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 29/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 30/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 31/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 32/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 33/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 34/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 35/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 36/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 37/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 38/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 39/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 40/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 41/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 42/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 43/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 44/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 45/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 46/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 47/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 48/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 49/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "Epoch 50/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -289.3669 - acc: 0.0238\n",
      "28/28 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "252/252 [==============================] - 1s 3ms/step - loss: -242.0893 - acc: 0.0278\n",
      "Epoch 2/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 3/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 4/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 5/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 6/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 7/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 8/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 9/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 10/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 11/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 12/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 13/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 15/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 16/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 17/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 18/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 19/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 20/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 21/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 22/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 23/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278: 0s - loss: -300.9125 - acc: \n",
      "Epoch 24/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 25/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 26/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 27/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 28/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 29/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 30/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 31/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 32/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 33/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 34/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 35/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 36/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 37/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 38/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 39/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 40/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 41/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 42/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 43/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 44/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 45/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 46/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 47/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 48/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 49/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "Epoch 50/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7832 - acc: 0.0278\n",
      "28/28 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "252/252 [==============================] - 1s 3ms/step - loss: -239.4063 - acc: 0.0238\n",
      "Epoch 2/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 3/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 4/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 5/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 6/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 7/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 8/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 9/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 10/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 11/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 12/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 13/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 14/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 15/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 16/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 17/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 18/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 19/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 20/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 21/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 22/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 23/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 24/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 25/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 26/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 27/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 28/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 29/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 30/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 31/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 32/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 33/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 34/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 35/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 36/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 37/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 38/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 39/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 40/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 41/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 42/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 43/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 44/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 45/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 47/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 48/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 49/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "Epoch 50/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.8464 - acc: 0.0238\n",
      "28/28 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "252/252 [==============================] - 1s 4ms/step - loss: -250.5691 - acc: 0.0278\n",
      "Epoch 2/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 3/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 4/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 5/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 6/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 7/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 8/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 9/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 10/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 11/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 12/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 13/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 14/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 15/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 16/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 17/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 18/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 19/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278 ETA: 0s - loss: -303.7024 - acc: 0.\n",
      "Epoch 20/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 21/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 22/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 23/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 24/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 25/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 26/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 27/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 28/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 29/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 30/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 31/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 32/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 33/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 34/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 35/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 36/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 37/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 38/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 39/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 40/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 41/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 42/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 43/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 44/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 45/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 46/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 47/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 48/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 49/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "Epoch 50/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -291.1383 - acc: 0.0278\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "252/252 [==============================] - 1s 3ms/step - loss: -254.6550 - acc: 0.0278\n",
      "Epoch 2/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 3/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 4/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 5/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 6/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 7/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 8/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 9/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 10/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 11/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 12/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 13/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 14/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 15/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 16/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 17/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 18/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 19/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 20/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 21/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 22/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 23/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 24/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 25/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 26/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 28/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 29/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 30/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 31/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 32/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 33/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 34/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 35/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 36/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 37/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 38/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 39/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 40/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 41/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 42/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 43/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 44/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 45/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 46/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 47/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 48/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 49/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "Epoch 50/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -292.7199 - acc: 0.0278\n",
      "28/28 [==============================] - 0s 3ms/step\n",
      "Epoch 1/50\n",
      "252/252 [==============================] - 1s 5ms/step - loss: -243.7971 - acc: 0.0198\n",
      "Epoch 2/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 3/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 4/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 5/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 6/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 7/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 8/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 9/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 10/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 11/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 12/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 13/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 14/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 15/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 16/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 17/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 18/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 19/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 20/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 21/50\n",
      "252/252 [==============================] - 1s 2ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 22/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 23/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 24/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 25/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 26/50\n",
      "252/252 [==============================] - 1s 2ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 27/50\n",
      "252/252 [==============================] - 1s 2ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 28/50\n",
      "252/252 [==============================] - 1s 2ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 29/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 30/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 31/50\n",
      "252/252 [==============================] - 1s 2ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 32/50\n",
      "252/252 [==============================] - 1s 2ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 33/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 34/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 35/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 36/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 37/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 38/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 39/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 40/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 41/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 42/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 43/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 44/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 45/50\n",
      "252/252 [==============================] - 1s 2ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 46/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 47/50\n",
      "252/252 [==============================] - 1s 2ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 48/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 49/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.2915 - acc: 0.0278\n",
      "Epoch 50/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.2915 - acc: 0.0278\n",
      "28/28 [==============================] - 0s 6ms/step\n",
      "Epoch 1/50\n",
      "252/252 [==============================] - 1s 3ms/step - loss: -242.0919 - acc: 0.0238\n",
      "Epoch 2/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 3/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 4/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 5/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 6/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 7/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 8/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 10/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 11/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 12/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 13/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 14/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 15/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 16/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 17/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 18/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 19/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 20/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 21/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 22/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 23/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 24/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 25/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 26/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 27/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 28/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 29/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 30/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 31/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 32/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 33/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 34/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 35/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 36/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 37/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 38/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 39/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 40/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 41/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 42/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 43/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 44/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 45/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 46/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 47/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 48/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 49/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "Epoch 50/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -288.6710 - acc: 0.0278\n",
      "28/28 [==============================] - 0s 4ms/step\n",
      "Epoch 1/50\n",
      "252/252 [==============================] - 1s 5ms/step - loss: -247.4872 - acc: 0.0159\n",
      "Epoch 2/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 3/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 4/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 5/50\n",
      "252/252 [==============================] - 1s 2ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 6/50\n",
      "252/252 [==============================] - 1s 2ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 7/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 8/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 9/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 10/50\n",
      "252/252 [==============================] - 1s 2ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 11/50\n",
      "252/252 [==============================] - 1s 2ms/step - loss: -294.2382 - acc: 0.0119 ETA: 0s - loss: -297.1760 - acc\n",
      "Epoch 12/50\n",
      "252/252 [==============================] - 1s 2ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 13/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 14/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 15/50\n",
      "252/252 [==============================] - 1s 3ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 16/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 17/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 18/50\n",
      "252/252 [==============================] - 0s 2ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 19/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 20/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 21/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 22/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 23/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 24/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 25/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 26/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 27/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 28/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 29/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 30/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 31/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 32/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 33/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 34/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 35/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 36/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 37/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 38/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 39/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 40/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 42/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 43/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 44/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 45/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 46/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 47/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 48/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 49/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "Epoch 50/50\n",
      "252/252 [==============================] - 0s 1ms/step - loss: -294.2382 - acc: 0.0119\n",
      "28/28 [==============================] - 0s 5ms/step\n",
      "Accuracy mean: 0.0250000011176\n",
      "Accuracy variance: 0.0424083664924\n",
      "(' Time ', '179.823', ' seconds')\n",
      "[[3 0 0 ..., 0 0 0]\n",
      " [0 3 0 ..., 0 0 0]\n",
      " [0 0 2 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 2 0 0]\n",
      " [0 0 0 ..., 0 3 0]\n",
      " [0 0 0 ..., 0 0 3]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         3\n",
      "          1       1.00      1.00      1.00         3\n",
      "          2       1.00      1.00      1.00         2\n",
      "          3       1.00      1.00      1.00         4\n",
      "          4       0.80      1.00      0.89         4\n",
      "          5       1.00      1.00      1.00         1\n",
      "          6       1.00      1.00      1.00         3\n",
      "          7       1.00      0.83      0.91         6\n",
      "          8       0.00      0.00      0.00         0\n",
      "          9       1.00      0.80      0.89         5\n",
      "         10       1.00      1.00      1.00         5\n",
      "         11       1.00      1.00      1.00         1\n",
      "         12       1.00      1.00      1.00         1\n",
      "         14       1.00      1.00      1.00         4\n",
      "         15       1.00      1.00      1.00         3\n",
      "         16       0.50      1.00      0.67         1\n",
      "         17       0.80      1.00      0.89         4\n",
      "         18       1.00      1.00      1.00         3\n",
      "         19       1.00      1.00      1.00         3\n",
      "         20       1.00      1.00      1.00         2\n",
      "         21       1.00      0.75      0.86         4\n",
      "         22       1.00      1.00      1.00         3\n",
      "         23       1.00      1.00      1.00         5\n",
      "         24       1.00      1.00      1.00         4\n",
      "         25       1.00      1.00      1.00         1\n",
      "         26       1.00      1.00      1.00         2\n",
      "         27       1.00      1.00      1.00         5\n",
      "         28       1.00      1.00      1.00         3\n",
      "         29       1.00      1.00      1.00         1\n",
      "         30       1.00      1.00      1.00         2\n",
      "         31       1.00      1.00      1.00         5\n",
      "         32       1.00      1.00      1.00         2\n",
      "         33       1.00      1.00      1.00         4\n",
      "         34       1.00      0.50      0.67         6\n",
      "         35       1.00      1.00      1.00         2\n",
      "         36       1.00      1.00      1.00         2\n",
      "         37       1.00      1.00      1.00         2\n",
      "         38       0.60      1.00      0.75         3\n",
      "         39       0.60      0.50      0.55         6\n",
      "\n",
      "avg / total       0.95      0.93      0.93       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# estimators \n",
    "# Evaluating the ANN\n",
    "t0 = time()\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 1024, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n",
    "    classifier.add(Dense(units = 512, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 50)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of DecisionTreeClassifier = 47.500000 %\n",
      "(' Time ', '1.993', ' seconds')\n",
      "[[2 0 0 ..., 0 0 0]\n",
      " [0 1 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 2 0 0]\n",
      " [0 0 0 ..., 0 3 0]\n",
      " [0 0 1 ..., 0 0 2]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.67      0.67         3\n",
      "          1       0.25      0.33      0.29         3\n",
      "          2       0.00      0.00      0.00         2\n",
      "          3       0.00      0.00      0.00         4\n",
      "          4       0.12      0.25      0.17         4\n",
      "          5       1.00      1.00      1.00         1\n",
      "          6       1.00      0.67      0.80         3\n",
      "          7       0.50      0.17      0.25         6\n",
      "          8       0.00      0.00      0.00         0\n",
      "          9       0.00      0.00      0.00         5\n",
      "         10       0.75      0.60      0.67         5\n",
      "         11       1.00      1.00      1.00         1\n",
      "         12       0.00      0.00      0.00         1\n",
      "         13       0.00      0.00      0.00         0\n",
      "         14       1.00      0.25      0.40         4\n",
      "         15       0.33      0.33      0.33         3\n",
      "         16       0.00      0.00      0.00         1\n",
      "         17       0.67      1.00      0.80         4\n",
      "         18       1.00      0.67      0.80         3\n",
      "         19       0.29      0.67      0.40         3\n",
      "         20       0.50      1.00      0.67         2\n",
      "         21       1.00      0.75      0.86         4\n",
      "         22       0.75      1.00      0.86         3\n",
      "         23       1.00      0.60      0.75         5\n",
      "         24       0.67      0.50      0.57         4\n",
      "         25       0.33      1.00      0.50         1\n",
      "         26       1.00      0.50      0.67         2\n",
      "         27       0.00      0.00      0.00         5\n",
      "         28       0.00      0.00      0.00         3\n",
      "         29       0.33      1.00      0.50         1\n",
      "         30       1.00      1.00      1.00         2\n",
      "         31       1.00      0.20      0.33         5\n",
      "         32       1.00      1.00      1.00         2\n",
      "         33       1.00      0.75      0.86         4\n",
      "         34       0.00      0.00      0.00         6\n",
      "         35       0.50      1.00      0.67         2\n",
      "         36       0.33      1.00      0.50         2\n",
      "         37       0.50      1.00      0.67         2\n",
      "         38       0.60      1.00      0.75         3\n",
      "         39       1.00      0.33      0.50         6\n",
      "\n",
      "avg / total       0.56      0.47      0.47       120\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of DecisionTreeClassifier = {:.6f} %\".format(acc * 100))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of RandomForestClassifier = 85.000000 %\n",
      "(' Time ', '2.095', ' seconds')\n",
      "[[3 0 0 ..., 0 0 0]\n",
      " [0 3 0 ..., 0 0 0]\n",
      " [0 0 2 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 2 0 0]\n",
      " [0 0 0 ..., 0 3 0]\n",
      " [0 0 0 ..., 0 0 3]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         3\n",
      "          1       0.75      1.00      0.86         3\n",
      "          2       0.67      1.00      0.80         2\n",
      "          3       1.00      0.50      0.67         4\n",
      "          4       0.67      0.50      0.57         4\n",
      "          5       1.00      1.00      1.00         1\n",
      "          6       0.60      1.00      0.75         3\n",
      "          7       1.00      0.50      0.67         6\n",
      "          8       0.00      0.00      0.00         0\n",
      "          9       1.00      0.80      0.89         5\n",
      "         10       1.00      1.00      1.00         5\n",
      "         11       1.00      1.00      1.00         1\n",
      "         12       0.33      1.00      0.50         1\n",
      "         14       1.00      1.00      1.00         4\n",
      "         15       1.00      1.00      1.00         3\n",
      "         16       0.50      1.00      0.67         1\n",
      "         17       0.80      1.00      0.89         4\n",
      "         18       1.00      1.00      1.00         3\n",
      "         19       1.00      1.00      1.00         3\n",
      "         20       1.00      1.00      1.00         2\n",
      "         21       1.00      1.00      1.00         4\n",
      "         22       1.00      1.00      1.00         3\n",
      "         23       1.00      1.00      1.00         5\n",
      "         24       1.00      1.00      1.00         4\n",
      "         25       1.00      1.00      1.00         1\n",
      "         26       1.00      1.00      1.00         2\n",
      "         27       1.00      0.80      0.89         5\n",
      "         28       1.00      1.00      1.00         3\n",
      "         29       0.33      1.00      0.50         1\n",
      "         30       1.00      1.00      1.00         2\n",
      "         31       1.00      1.00      1.00         5\n",
      "         32       1.00      1.00      1.00         2\n",
      "         33       1.00      1.00      1.00         4\n",
      "         34       1.00      0.33      0.50         6\n",
      "         35       0.00      0.00      0.00         2\n",
      "         36       1.00      1.00      1.00         2\n",
      "         37       0.67      1.00      0.80         2\n",
      "         38       0.50      1.00      0.67         3\n",
      "         39       1.00      0.50      0.67         6\n",
      "\n",
      "avg / total       0.91      0.85      0.85       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of RandomForestClassifier = {:.6f} %\".format(acc * 100))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of ExtraTreesClassifier = 86.666667 %\n",
      "(' Time ', '0.629', ' seconds')\n",
      "[[2 0 0 ..., 0 0 0]\n",
      " [0 3 0 ..., 0 0 0]\n",
      " [0 0 2 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 2 0 0]\n",
      " [0 0 0 ..., 0 3 0]\n",
      " [0 0 0 ..., 0 0 3]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.67      0.80         3\n",
      "          1       1.00      1.00      1.00         3\n",
      "          2       1.00      1.00      1.00         2\n",
      "          3       1.00      0.50      0.67         4\n",
      "          4       0.33      0.50      0.40         4\n",
      "          5       1.00      1.00      1.00         1\n",
      "          6       0.60      1.00      0.75         3\n",
      "          7       1.00      0.83      0.91         6\n",
      "          8       0.00      0.00      0.00         0\n",
      "          9       1.00      1.00      1.00         5\n",
      "         10       1.00      1.00      1.00         5\n",
      "         11       1.00      1.00      1.00         1\n",
      "         12       0.25      1.00      0.40         1\n",
      "         14       0.80      1.00      0.89         4\n",
      "         15       1.00      1.00      1.00         3\n",
      "         16       1.00      1.00      1.00         1\n",
      "         17       0.80      1.00      0.89         4\n",
      "         18       1.00      1.00      1.00         3\n",
      "         19       1.00      1.00      1.00         3\n",
      "         20       1.00      1.00      1.00         2\n",
      "         21       1.00      0.75      0.86         4\n",
      "         22       1.00      1.00      1.00         3\n",
      "         23       1.00      1.00      1.00         5\n",
      "         24       1.00      0.75      0.86         4\n",
      "         25       1.00      1.00      1.00         1\n",
      "         26       1.00      1.00      1.00         2\n",
      "         27       1.00      1.00      1.00         5\n",
      "         28       1.00      1.00      1.00         3\n",
      "         29       1.00      1.00      1.00         1\n",
      "         30       1.00      1.00      1.00         2\n",
      "         31       1.00      1.00      1.00         5\n",
      "         32       1.00      1.00      1.00         2\n",
      "         33       1.00      1.00      1.00         4\n",
      "         34       1.00      0.50      0.67         6\n",
      "         35       0.00      0.00      0.00         2\n",
      "         36       1.00      1.00      1.00         2\n",
      "         37       0.50      1.00      0.67         2\n",
      "         38       0.60      1.00      0.75         3\n",
      "         39       1.00      0.50      0.67         6\n",
      "\n",
      "avg / total       0.91      0.87      0.87       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of ExtraTreesClassifier = {:.6f} %\".format(acc * 100))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of AdaBoostClassifier = 14.166667 %\n",
      "(' Time ', '11.333', ' seconds')\n",
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 3 0]\n",
      " [0 0 0 ..., 0 0 0]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         3\n",
      "          1       0.00      0.00      0.00         3\n",
      "          2       0.00      0.00      0.00         2\n",
      "          3       0.00      0.00      0.00         4\n",
      "          4       0.00      0.00      0.00         4\n",
      "          5       1.00      1.00      1.00         1\n",
      "          6       0.00      0.00      0.00         3\n",
      "          7       1.00      0.33      0.50         6\n",
      "          8       0.00      0.00      0.00         0\n",
      "          9       0.00      0.00      0.00         5\n",
      "         10       1.00      0.20      0.33         5\n",
      "         11       0.00      0.00      0.00         1\n",
      "         12       0.00      0.00      0.00         1\n",
      "         14       0.00      0.00      0.00         4\n",
      "         15       0.00      0.00      0.00         3\n",
      "         16       0.00      0.00      0.00         1\n",
      "         17       0.00      0.00      0.00         4\n",
      "         18       0.00      0.00      0.00         3\n",
      "         19       0.50      0.67      0.57         3\n",
      "         20       0.00      0.00      0.00         2\n",
      "         21       0.50      0.50      0.50         4\n",
      "         22       0.00      0.00      0.00         3\n",
      "         23       0.00      0.00      0.00         5\n",
      "         24       0.00      0.00      0.00         4\n",
      "         25       0.00      0.00      0.00         1\n",
      "         26       0.00      0.00      0.00         2\n",
      "         27       0.00      0.00      0.00         5\n",
      "         28       0.00      0.00      0.00         3\n",
      "         29       0.00      0.00      0.00         1\n",
      "         30       0.00      0.00      0.00         2\n",
      "         31       0.00      0.00      0.00         5\n",
      "         32       1.00      1.00      1.00         2\n",
      "         33       1.00      1.00      1.00         4\n",
      "         34       0.00      0.00      0.00         6\n",
      "         35       0.00      0.00      0.00         2\n",
      "         36       0.00      0.00      0.00         2\n",
      "         37       0.00      0.00      0.00         2\n",
      "         38       0.60      1.00      0.75         3\n",
      "         39       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.19      0.14      0.15       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of AdaBoostClassifier = {:.6f} %\".format(acc * 100))\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Naive_bayes  GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GaussianNB = 74.166667 %\n",
      "(' Time ', '0.124', ' seconds')\n",
      "[[3 0 0 ..., 0 0 0]\n",
      " [0 3 0 ..., 0 0 0]\n",
      " [0 0 2 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 2 0 0]\n",
      " [0 0 0 ..., 0 3 0]\n",
      " [1 0 1 ..., 0 0 1]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      1.00      0.60         3\n",
      "          1       1.00      1.00      1.00         3\n",
      "          2       0.18      1.00      0.31         2\n",
      "          3       1.00      0.50      0.67         4\n",
      "          4       0.67      0.50      0.57         4\n",
      "          5       1.00      1.00      1.00         1\n",
      "          6       1.00      0.67      0.80         3\n",
      "          7       1.00      0.50      0.67         6\n",
      "          8       0.00      0.00      0.00         0\n",
      "          9       0.67      0.80      0.73         5\n",
      "         10       1.00      0.80      0.89         5\n",
      "         11       1.00      1.00      1.00         1\n",
      "         12       0.14      1.00      0.25         1\n",
      "         14       1.00      0.75      0.86         4\n",
      "         15       1.00      0.33      0.50         3\n",
      "         16       0.20      1.00      0.33         1\n",
      "         17       1.00      1.00      1.00         4\n",
      "         18       1.00      0.67      0.80         3\n",
      "         19       1.00      1.00      1.00         3\n",
      "         20       1.00      1.00      1.00         2\n",
      "         21       1.00      0.50      0.67         4\n",
      "         22       0.75      1.00      0.86         3\n",
      "         23       1.00      1.00      1.00         5\n",
      "         24       1.00      0.50      0.67         4\n",
      "         25       1.00      1.00      1.00         1\n",
      "         26       1.00      1.00      1.00         2\n",
      "         27       1.00      0.80      0.89         5\n",
      "         28       1.00      0.33      0.50         3\n",
      "         29       1.00      1.00      1.00         1\n",
      "         30       1.00      1.00      1.00         2\n",
      "         31       1.00      1.00      1.00         5\n",
      "         32       1.00      1.00      1.00         2\n",
      "         33       1.00      1.00      1.00         4\n",
      "         34       1.00      0.50      0.67         6\n",
      "         35       0.00      0.00      0.00         2\n",
      "         36       1.00      1.00      1.00         2\n",
      "         37       1.00      1.00      1.00         2\n",
      "         38       0.50      1.00      0.67         3\n",
      "         39       1.00      0.17      0.29         6\n",
      "\n",
      "avg / total       0.90      0.74      0.76       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred= gnb.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of GaussianNB = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
