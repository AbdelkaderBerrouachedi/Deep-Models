{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt \n",
    "from pprint import pprint\n",
    "from numpy import array\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3072)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data \n",
    "from keras.datasets import cifar10\n",
    "\n",
    "cls_names = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\"\"\"\n",
    "X_train.shape: (50000, 3, 32, 32)\n",
    "X_test.shape: (10000, 3, 32, 32)\n",
    "y: 10 labels\n",
    "\"\"\"\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "y_train = y_train.reshape((y_train.shape[0]))\n",
    "y_test = y_test.reshape((y_test.shape[0]))\n",
    "\n",
    "# rechape data (..,...)\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "\n",
    "# new train reshape \n",
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GcForeest\n",
    "import argparse\n",
    "import sys\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "sys.path.insert(0, \"lib\")\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.utils.config_utils import load_json\n",
    "config = load_json(\"./examples/cifar10.json\")  # layer = 1   k=10   Extree + DTree\n",
    "gc = GCForest(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of class\n",
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-12-05 11:59:30,975][cascade_classifier.fit_transform] X_groups_train.shape=[(50000, 3072)],y_train.shape=(50000,),X_groups_test.shape=[(10000, 3072)],y_test.shape=(10000,)\n",
      "[ 2018-12-05 11:59:31,097][cascade_classifier.fit_transform] group_dims=[3072]\n",
      "[ 2018-12-05 11:59:31,098][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-12-05 11:59:31,099][cascade_classifier.fit_transform] group_ends=[3072]\n",
      "[ 2018-12-05 11:59:31,100][cascade_classifier.fit_transform] X_train.shape=(50000, 3072),X_test.shape=(10000, 3072)\n",
      "[ 2018-12-05 11:59:31,405][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(50000, 3072), X_cur_test.shape=(10000, 3072)\n",
      "[ 2018-12-05 12:01:13,446][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=46.00%\n",
      "[ 2018-12-05 12:03:09,500][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=46.06%\n",
      "[ 2018-12-05 12:05:04,390][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=45.84%\n",
      "[ 2018-12-05 12:06:50,205][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=47.22%\n",
      "[ 2018-12-05 12:08:57,045][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=46.66%\n",
      "[ 2018-12-05 12:11:07,577][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=46.88%\n",
      "[ 2018-12-05 12:13:28,907][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=47.50%\n",
      "[ 2018-12-05 12:15:43,281][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=45.68%\n",
      "[ 2018-12-05 12:18:07,025][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=47.06%\n",
      "[ 2018-12-05 12:20:33,739][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=46.04%\n",
      "[ 2018-12-05 12:20:34,404][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=46.49%\n",
      "[ 2018-12-05 12:20:34,406][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=49.14%\n",
      "[ 2018-12-05 12:21:51,851][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_0.predict)=44.88%\n",
      "[ 2018-12-05 12:23:11,850][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_1.predict)=47.26%\n",
      "[ 2018-12-05 12:25:17,008][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_2.predict)=47.02%\n",
      "[ 2018-12-05 12:27:01,941][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_3.predict)=47.38%\n",
      "[ 2018-12-05 12:28:01,377][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_4.predict)=47.18%\n",
      "[ 2018-12-05 12:29:00,416][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_5.predict)=45.84%\n",
      "[ 2018-12-05 12:30:09,442][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_6.predict)=46.68%\n",
      "[ 2018-12-05 12:31:11,522][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_7.predict)=46.46%\n",
      "[ 2018-12-05 12:32:12,059][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_8.predict)=45.92%\n",
      "[ 2018-12-05 12:33:16,058][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_9.predict)=47.04%\n",
      "[ 2018-12-05 12:33:16,839][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_cv.predict)=46.57%\n",
      "[ 2018-12-05 12:33:16,919][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.test.predict)=49.73%\n",
      "[ 2018-12-05 12:33:20,030][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=47.83%\n",
      "[ 2018-12-05 12:33:20,124][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=49.90%\n",
      "[ 2018-12-05 12:33:38,219][cascade_classifier.fit_transform] [layer=1] look_indexs=[0], X_cur_train.shape=(50000, 3092), X_cur_test.shape=(10000, 3092)\n",
      "[ 2018-12-05 12:35:46,946][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_0.predict)=48.14%\n",
      "[ 2018-12-05 12:37:39,415][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_1.predict)=48.04%\n",
      "[ 2018-12-05 12:39:32,351][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_2.predict)=47.66%\n",
      "[ 2018-12-05 12:41:25,176][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_3.predict)=48.00%\n",
      "[ 2018-12-05 12:43:16,027][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_4.predict)=48.38%\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "# X_enc is the concatenated predict_proba result of each estimators of the last layer of the GCForest model\n",
    "    # X_enc.shape =\n",
    "    #   (n_datas, n_estimators * n_classes): If cascade is provided\n",
    "    #   (n_datas, n_estimators * n_classes, dimX, dimY): If only finegrained part is provided\n",
    "    # You can also pass X_test, y_test to fit_transform method, then the accracy on test data will be logged when training.\n",
    "X_train_enc, X_test_enc = gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test)\n",
    "    # WARNING: if you set gc.set_keep_model_in_mem(True), you would have to use\n",
    "    # gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test) to evaluate your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred = gc.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy of GCForest = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# estimators \n",
    "# Evaluating the ANN\n",
    "t0 = time()\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 1024, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n",
    "    classifier.add(Dense(units = 512, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 50)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of DecisionTreeClassifier = 26.520000 %\n",
      "[[340  74  96  59  61  58  42  50 161  59]\n",
      " [ 74 274  70  92  57  55  47  67 106 158]\n",
      " [100  50 214  98 149 120 102  74  42  51]\n",
      " [ 63  60 115 196 100 137 133  93  49  54]\n",
      " [ 62  38 166  80 227 118 116 101  40  52]\n",
      " [ 54  52 107 174  83 210 105  99  55  61]\n",
      " [ 45  39 127 129 147 102 271  66  31  43]\n",
      " [ 79  93  83  91 115 110  59 243  58  69]\n",
      " [153 108  55  47  41  45  31  44 387  89]\n",
      " [ 83 166  70  71  39  54  47  82  98 290]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.32      0.34      0.33      1000\n",
      "          1       0.29      0.27      0.28      1000\n",
      "          2       0.19      0.21      0.20      1000\n",
      "          3       0.19      0.20      0.19      1000\n",
      "          4       0.22      0.23      0.22      1000\n",
      "          5       0.21      0.21      0.21      1000\n",
      "          6       0.28      0.27      0.28      1000\n",
      "          7       0.26      0.24      0.25      1000\n",
      "          8       0.38      0.39      0.38      1000\n",
      "          9       0.31      0.29      0.30      1000\n",
      "\n",
      "avg / total       0.27      0.27      0.27     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of DecisionTreeClassifier = {:.6f} %\".format(acc * 100))\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of RandomForestClassifier = 46.980000 %\n",
      "(' Time ', '309.923', ' seconds')\n",
      "[[569  36  52  17  37  21  25  29 166  48]\n",
      " [ 32 550  21  38  23  31  33  31  67 174]\n",
      " [105  44 317  93 143  67 116  60  28  27]\n",
      " [ 53  42  70 279  83 184 133  61  21  74]\n",
      " [ 55  22 155  56 402  43 144  80  23  20]\n",
      " [ 39  28  82 164  81 390  76  89  22  29]\n",
      " [ 11  35  83  69 104  56 568  26  12  36]\n",
      " [ 51  47  47  58  93  82  56 451  19  96]\n",
      " [ 92  91  21  23  22  34   8  24 609  76]\n",
      " [ 46 160  17  36  20  21  24  39  74 563]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.57      0.55      1000\n",
      "          1       0.52      0.55      0.54      1000\n",
      "          2       0.37      0.32      0.34      1000\n",
      "          3       0.33      0.28      0.30      1000\n",
      "          4       0.40      0.40      0.40      1000\n",
      "          5       0.42      0.39      0.40      1000\n",
      "          6       0.48      0.57      0.52      1000\n",
      "          7       0.51      0.45      0.48      1000\n",
      "          8       0.59      0.61      0.60      1000\n",
      "          9       0.49      0.56      0.53      1000\n",
      "\n",
      "avg / total       0.46      0.47      0.47     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of RandomForestClassifier = {:.6f} %\".format(acc * 100))\n",
    " \n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of ExtraTreesClassifier = 47.320000 %\n",
      "(' Time ', '133.711', ' seconds')\n",
      "[[558  29  56  13  32  25  19  28 182  58]\n",
      " [ 35 554  11  37  20  30  39  33  61 180]\n",
      " [102  42 341  71 146  67 123  55  23  30]\n",
      " [ 58  47  73 284  84 177 121  59  19  78]\n",
      " [ 48  18 165  56 388  42 147  80  30  26]\n",
      " [ 43  25  87 153  82 389  85  76  23  37]\n",
      " [ 11  23  82  73 127  50 561  26   7  40]\n",
      " [ 44  45  43  58 109  85  42 448  30  96]\n",
      " [ 87  78  17  30  17  27  12  17 644  71]\n",
      " [ 39 161  13  32  14  24  30  36  86 565]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.56      0.55      1000\n",
      "          1       0.54      0.55      0.55      1000\n",
      "          2       0.38      0.34      0.36      1000\n",
      "          3       0.35      0.28      0.31      1000\n",
      "          4       0.38      0.39      0.38      1000\n",
      "          5       0.42      0.39      0.41      1000\n",
      "          6       0.48      0.56      0.51      1000\n",
      "          7       0.52      0.45      0.48      1000\n",
      "          8       0.58      0.64      0.61      1000\n",
      "          9       0.48      0.56      0.52      1000\n",
      "\n",
      "avg / total       0.47      0.47      0.47     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of ExtraTreesClassifier = {:.6f} %\".format(acc * 100))\n",
    " \n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of AdaBoostClassifier = 33.080000 %\n",
      "(' Time ', '1338.971', ' seconds')\n",
      "[[336  35  50  42  33  35  38  53 302  76]\n",
      " [ 61 323  32  35  33  47  65  34 130 240]\n",
      " [ 80  72 121  71 185  90 196  81  74  30]\n",
      " [ 68  74  66 126  81 139 256  79  51  60]\n",
      " [ 49  42  81  44 258  77 299  85  39  26]\n",
      " [ 80  49  48 103  89 246 168  90  89  38]\n",
      " [ 10  45  48  77 119  55 560  40  22  24]\n",
      " [ 79  46  48  56 114  91 114 335  33  84]\n",
      " [105  67  23  16  24  35  21  20 521 168]\n",
      " [ 69 134  22  26  22  16  60  57 112 482]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.36      0.34      0.35      1000\n",
      "          1       0.36      0.32      0.34      1000\n",
      "          2       0.22      0.12      0.16      1000\n",
      "          3       0.21      0.13      0.16      1000\n",
      "          4       0.27      0.26      0.26      1000\n",
      "          5       0.30      0.25      0.27      1000\n",
      "          6       0.32      0.56      0.40      1000\n",
      "          7       0.38      0.34      0.36      1000\n",
      "          8       0.38      0.52      0.44      1000\n",
      "          9       0.39      0.48      0.43      1000\n",
      "\n",
      "avg / total       0.32      0.33      0.32     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of AdaBoostClassifier = {:.6f} %\".format(acc * 100))\n",
    " \n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Naive_bayes  GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GaussianNB = 29.760000 %\n",
      "(' Time ', '6.382', ' seconds')\n",
      "[[494  20  39  10  84  34  50   9 200  60]\n",
      " [141 166  24  31  66  72 192  19 121 168]\n",
      " [225  24  83  15 292  48 209  21  54  29]\n",
      " [163  36  54  76 151 129 262  26  34  69]\n",
      " [ 86   8  57  26 417  38 265  22  50  31]\n",
      " [156  17  55  51 167 264 159  36  57  38]\n",
      " [106   2  60  18 228  46 467  15  19  39]\n",
      " [134  24  36  41 228  94 102 131  72 138]\n",
      " [168  41  18  17  56  83  39   8 471  99]\n",
      " [144  67  17  20  48  32 101  23 141 407]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.27      0.49      0.35      1000\n",
      "          1       0.41      0.17      0.24      1000\n",
      "          2       0.19      0.08      0.12      1000\n",
      "          3       0.25      0.08      0.12      1000\n",
      "          4       0.24      0.42      0.30      1000\n",
      "          5       0.31      0.26      0.29      1000\n",
      "          6       0.25      0.47      0.33      1000\n",
      "          7       0.42      0.13      0.20      1000\n",
      "          8       0.39      0.47      0.42      1000\n",
      "          9       0.38      0.41      0.39      1000\n",
      "\n",
      "avg / total       0.31      0.30      0.28     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred= gnb.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of GaussianNB = {:.6f} %\".format(acc * 100)) \n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
