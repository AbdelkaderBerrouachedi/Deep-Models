{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt \n",
    "from pprint import pprint\n",
    "from numpy import array\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>att1</th>\n",
       "      <th>att2</th>\n",
       "      <th>att3</th>\n",
       "      <th>att4</th>\n",
       "      <th>att5</th>\n",
       "      <th>att6</th>\n",
       "      <th>att7</th>\n",
       "      <th>att8</th>\n",
       "      <th>att9</th>\n",
       "      <th>att10</th>\n",
       "      <th>...</th>\n",
       "      <th>att49</th>\n",
       "      <th>att50</th>\n",
       "      <th>att51</th>\n",
       "      <th>att52</th>\n",
       "      <th>att53</th>\n",
       "      <th>att54</th>\n",
       "      <th>att55</th>\n",
       "      <th>att56</th>\n",
       "      <th>att57</th>\n",
       "      <th>outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044818</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.006007</td>\n",
       "      <td>0.017487</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.046256</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.028886</td>\n",
       "      <td>0.006301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011454</td>\n",
       "      <td>0.029985</td>\n",
       "      <td>0.002421</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.010012</td>\n",
       "      <td>0.064836</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.032313</td>\n",
       "      <td>0.026135</td>\n",
       "      <td>0.010801</td>\n",
       "      <td>0.121673</td>\n",
       "      <td>0.013751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002281</td>\n",
       "      <td>0.014664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.030651</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.008008</td>\n",
       "      <td>0.048458</td>\n",
       "      <td>0.142551</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042641</td>\n",
       "      <td>0.056706</td>\n",
       "      <td>0.058935</td>\n",
       "      <td>0.034653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>0.003905</td>\n",
       "      <td>0.011995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042641</td>\n",
       "      <td>0.056706</td>\n",
       "      <td>0.058935</td>\n",
       "      <td>0.034653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>0.003905</td>\n",
       "      <td>0.011995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       att1      att2      att3  att4   att5      att6      att7      att8  \\\n",
       "0  0.000000  0.044818  0.125490   0.0  0.032  0.000000  0.000000  0.000000   \n",
       "1  0.046256  0.019608  0.098039   0.0  0.014  0.047619  0.028886  0.006301   \n",
       "2  0.013216  0.000000  0.139216   0.0  0.123  0.032313  0.026135  0.010801   \n",
       "3  0.000000  0.000000  0.000000   0.0  0.063  0.000000  0.042641  0.056706   \n",
       "4  0.000000  0.000000  0.000000   0.0  0.063  0.000000  0.042641  0.056706   \n",
       "\n",
       "       att9     att10   ...        att49     att50  att51     att52     att53  \\\n",
       "0  0.000000  0.000000   ...     0.000000  0.000000    0.0  0.023955  0.000000   \n",
       "1  0.000000  0.051705   ...     0.000000  0.013536    0.0  0.011454  0.029985   \n",
       "2  0.121673  0.013751   ...     0.002281  0.014664    0.0  0.008498  0.030651   \n",
       "3  0.058935  0.034653   ...     0.000000  0.014048    0.0  0.004218  0.000000   \n",
       "4  0.058935  0.034653   ...     0.000000  0.013843    0.0  0.004157  0.000000   \n",
       "\n",
       "      att54     att55     att56     att57  outlier  \n",
       "0  0.000000  0.002502  0.006007  0.017487        1  \n",
       "1  0.002421  0.003735  0.010012  0.064836        1  \n",
       "2  0.000504  0.008008  0.048458  0.142551        1  \n",
       "3  0.000000  0.002303  0.003905  0.011995        1  \n",
       "4  0.000000  0.002303  0.003905  0.011995        1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df=pd.read_csv('SpamBase_withoutdupl_norm_40.csv')  \n",
    "\n",
    "del df['id']\n",
    "del df['Unnamed: 0']\n",
    "df['outlier'] = df.outlier.apply(lambda label: 1 if label == \"'yes'\" else 0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df to values\n",
    "df = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GC Forest\n",
    "import argparse\n",
    "import sys\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "sys.path.insert(0, \"lib\")\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.utils.config_utils import load_json\n",
    "config = load_json(\"./examples/SpamBase.json\")   \n",
    "gc = GCForest(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# train test \n",
    "from sklearn.cross_validation import train_test_split\n",
    "y = df[:,57]\n",
    "X = df[:,0:57]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of class\n",
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:11:46,388][cascade_classifier.fit_transform] X_groups_train.shape=[(2944, 57)],y_train.shape=(2944,),X_groups_test.shape=[(1263, 57)],y_test.shape=(1263,)\n",
      "[ 2018-07-31 22:11:46,391][cascade_classifier.fit_transform] group_dims=[57]\n",
      "[ 2018-07-31 22:11:46,392][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-31 22:11:46,393][cascade_classifier.fit_transform] group_ends=[57]\n",
      "[ 2018-07-31 22:11:46,394][cascade_classifier.fit_transform] X_train.shape=(2944, 57),X_test.shape=(1263, 57)\n",
      "[ 2018-07-31 22:11:46,396][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(2944, 57), X_cur_test.shape=(1263, 57)\n",
      "[ 2018-07-31 22:11:47,451][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=93.22%\n",
      "[ 2018-07-31 22:11:48,695][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=94.24%\n",
      "[ 2018-07-31 22:11:49,878][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=96.27%\n",
      "[ 2018-07-31 22:11:51,288][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=94.58%\n",
      "[ 2018-07-31 22:11:52,712][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=93.20%\n",
      "[ 2018-07-31 22:11:53,812][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=96.26%\n",
      "[ 2018-07-31 22:11:55,115][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=96.60%\n",
      "[ 2018-07-31 22:11:56,317][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=92.52%\n",
      "[ 2018-07-31 22:11:57,532][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=95.24%\n",
      "[ 2018-07-31 22:11:58,718][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=94.90%\n",
      "[ 2018-07-31 22:11:58,976][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=94.70%\n",
      "[ 2018-07-31 22:11:58,981][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=94.22%\n",
      "[ 2018-07-31 22:11:59,954][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_0.predict)=94.24%\n",
      "[ 2018-07-31 22:12:01,403][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_1.predict)=94.24%\n",
      "[ 2018-07-31 22:12:02,774][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_2.predict)=96.27%\n",
      "[ 2018-07-31 22:12:04,386][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_3.predict)=95.93%\n",
      "[ 2018-07-31 22:12:05,719][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_4.predict)=94.56%\n",
      "[ 2018-07-31 22:12:08,280][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_5.predict)=92.86%\n",
      "[ 2018-07-31 22:12:10,117][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_6.predict)=96.26%\n",
      "[ 2018-07-31 22:12:11,992][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_7.predict)=94.22%\n",
      "[ 2018-07-31 22:12:13,383][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_8.predict)=97.62%\n",
      "[ 2018-07-31 22:12:15,024][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_9.predict)=95.24%\n",
      "[ 2018-07-31 22:12:15,237][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_cv.predict)=95.14%\n",
      "[ 2018-07-31 22:12:15,239][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.test.predict)=94.93%\n",
      "[ 2018-07-31 22:12:15,325][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_0.predict)=89.15%\n",
      "[ 2018-07-31 22:12:15,370][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_1.predict)=87.46%\n",
      "[ 2018-07-31 22:12:15,430][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_2.predict)=88.14%\n",
      "[ 2018-07-31 22:12:15,449][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_3.predict)=86.44%\n",
      "[ 2018-07-31 22:12:15,465][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_4.predict)=90.14%\n",
      "[ 2018-07-31 22:12:15,480][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_5.predict)=86.73%\n",
      "[ 2018-07-31 22:12:15,497][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_6.predict)=92.18%\n",
      "[ 2018-07-31 22:12:15,521][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_7.predict)=88.44%\n",
      "[ 2018-07-31 22:12:15,545][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_8.predict)=87.07%\n",
      "[ 2018-07-31 22:12:15,564][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_9.predict)=88.78%\n",
      "[ 2018-07-31 22:12:15,567][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_cv.predict)=88.45%\n",
      "[ 2018-07-31 22:12:15,568][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.test.predict)=88.36%\n",
      "[ 2018-07-31 22:12:15,570][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=94.74%\n",
      "[ 2018-07-31 22:12:15,571][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=94.77%\n",
      "[ 2018-07-31 22:12:15,574][cascade_classifier.fit_transform] [layer=1] look_indexs=[0], X_cur_train.shape=(2944, 63), X_cur_test.shape=(1263, 63)\n",
      "[ 2018-07-31 22:12:16,971][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_0.predict)=96.95%\n",
      "[ 2018-07-31 22:12:18,353][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_1.predict)=97.97%\n",
      "[ 2018-07-31 22:12:19,838][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_2.predict)=94.92%\n",
      "[ 2018-07-31 22:12:21,859][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_3.predict)=95.59%\n",
      "[ 2018-07-31 22:12:23,296][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_4.predict)=95.58%\n",
      "[ 2018-07-31 22:12:24,835][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_5.predict)=93.20%\n",
      "[ 2018-07-31 22:12:26,264][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_6.predict)=94.56%\n",
      "[ 2018-07-31 22:12:27,686][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_7.predict)=93.88%\n",
      "[ 2018-07-31 22:12:29,029][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_8.predict)=96.94%\n",
      "[ 2018-07-31 22:12:30,430][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_9.predict)=93.88%\n",
      "[ 2018-07-31 22:12:30,664][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_cv.predict)=95.35%\n",
      "[ 2018-07-31 22:12:30,666][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.test.predict)=94.93%\n",
      "[ 2018-07-31 22:12:32,102][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_0.predict)=96.27%\n",
      "[ 2018-07-31 22:12:33,425][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_1.predict)=95.93%\n",
      "[ 2018-07-31 22:12:34,581][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_2.predict)=93.90%\n",
      "[ 2018-07-31 22:12:35,962][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_3.predict)=94.92%\n",
      "[ 2018-07-31 22:12:37,247][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_4.predict)=94.56%\n",
      "[ 2018-07-31 22:12:38,935][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_5.predict)=96.26%\n",
      "[ 2018-07-31 22:12:40,872][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_6.predict)=95.92%\n",
      "[ 2018-07-31 22:12:42,386][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_7.predict)=94.22%\n",
      "[ 2018-07-31 22:12:43,973][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_8.predict)=94.56%\n",
      "[ 2018-07-31 22:12:45,712][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_9.predict)=96.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:12:45,945][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_cv.predict)=95.35%\n",
      "[ 2018-07-31 22:12:45,946][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.test.predict)=94.54%\n",
      "[ 2018-07-31 22:12:46,003][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_0.predict)=95.93%\n",
      "[ 2018-07-31 22:12:46,066][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_1.predict)=93.56%\n",
      "[ 2018-07-31 22:12:46,119][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_2.predict)=95.59%\n",
      "[ 2018-07-31 22:12:46,170][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_3.predict)=95.25%\n",
      "[ 2018-07-31 22:12:46,208][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_4.predict)=93.88%\n",
      "[ 2018-07-31 22:12:46,245][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_5.predict)=94.56%\n",
      "[ 2018-07-31 22:12:46,282][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_6.predict)=95.24%\n",
      "[ 2018-07-31 22:12:46,317][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_7.predict)=96.26%\n",
      "[ 2018-07-31 22:12:46,353][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_8.predict)=94.22%\n",
      "[ 2018-07-31 22:12:46,388][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_9.predict)=96.26%\n",
      "[ 2018-07-31 22:12:46,390][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_cv.predict)=95.07%\n",
      "[ 2018-07-31 22:12:46,396][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.test.predict)=95.25%\n",
      "[ 2018-07-31 22:12:46,397][cascade_classifier.calc_accuracy] Accuracy(layer_1 - train.classifier_average)=95.24%\n",
      "[ 2018-07-31 22:12:46,398][cascade_classifier.calc_accuracy] Accuracy(layer_1 - test.classifier_average)=95.17%\n",
      "[ 2018-07-31 22:12:46,404][cascade_classifier.fit_transform] [layer=2] look_indexs=[0], X_cur_train.shape=(2944, 63), X_cur_test.shape=(1263, 63)\n",
      "[ 2018-07-31 22:12:47,804][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_0.predict)=94.92%\n",
      "[ 2018-07-31 22:12:49,184][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_1.predict)=93.22%\n",
      "[ 2018-07-31 22:12:50,351][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_2.predict)=95.25%\n",
      "[ 2018-07-31 22:12:51,597][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_3.predict)=95.25%\n",
      "[ 2018-07-31 22:12:53,072][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_4.predict)=95.92%\n",
      "[ 2018-07-31 22:12:54,418][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_5.predict)=96.60%\n",
      "[ 2018-07-31 22:12:56,028][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_6.predict)=95.92%\n",
      "[ 2018-07-31 22:12:57,459][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_7.predict)=94.90%\n",
      "[ 2018-07-31 22:12:58,723][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_8.predict)=93.88%\n",
      "[ 2018-07-31 22:13:00,071][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_9.predict)=96.26%\n",
      "[ 2018-07-31 22:13:00,430][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_cv.predict)=95.21%\n",
      "[ 2018-07-31 22:13:00,431][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.test.predict)=94.46%\n",
      "[ 2018-07-31 22:13:01,479][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_0.predict)=95.59%\n",
      "[ 2018-07-31 22:13:02,858][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_1.predict)=93.90%\n",
      "[ 2018-07-31 22:13:04,096][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_2.predict)=95.93%\n",
      "[ 2018-07-31 22:13:05,365][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_3.predict)=94.92%\n",
      "[ 2018-07-31 22:13:06,525][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_4.predict)=95.92%\n",
      "[ 2018-07-31 22:13:07,729][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_5.predict)=96.94%\n",
      "[ 2018-07-31 22:13:09,272][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_6.predict)=95.58%\n",
      "[ 2018-07-31 22:13:10,913][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_7.predict)=93.20%\n",
      "[ 2018-07-31 22:13:12,282][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_8.predict)=94.56%\n",
      "[ 2018-07-31 22:13:13,618][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_9.predict)=96.26%\n",
      "[ 2018-07-31 22:13:13,840][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_cv.predict)=95.28%\n",
      "[ 2018-07-31 22:13:13,842][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.test.predict)=94.62%\n",
      "[ 2018-07-31 22:13:13,873][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_0.predict)=95.25%\n",
      "[ 2018-07-31 22:13:13,904][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_1.predict)=94.58%\n",
      "[ 2018-07-31 22:13:13,977][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_2.predict)=96.27%\n",
      "[ 2018-07-31 22:13:14,024][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_3.predict)=94.58%\n",
      "[ 2018-07-31 22:13:14,056][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_4.predict)=94.56%\n",
      "[ 2018-07-31 22:13:14,084][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_5.predict)=96.60%\n",
      "[ 2018-07-31 22:13:14,125][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_6.predict)=95.24%\n",
      "[ 2018-07-31 22:13:14,168][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_7.predict)=95.92%\n",
      "[ 2018-07-31 22:13:14,192][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_8.predict)=96.60%\n",
      "[ 2018-07-31 22:13:14,241][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_9.predict)=93.54%\n",
      "[ 2018-07-31 22:13:14,244][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_cv.predict)=95.31%\n",
      "[ 2018-07-31 22:13:14,247][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.test.predict)=94.77%\n",
      "[ 2018-07-31 22:13:14,248][cascade_classifier.calc_accuracy] Accuracy(layer_2 - train.classifier_average)=95.38%\n",
      "[ 2018-07-31 22:13:14,251][cascade_classifier.calc_accuracy] Accuracy(layer_2 - test.classifier_average)=94.70%\n",
      "[ 2018-07-31 22:13:14,254][cascade_classifier.fit_transform] [layer=3] look_indexs=[0], X_cur_train.shape=(2944, 63), X_cur_test.shape=(1263, 63)\n",
      "[ 2018-07-31 22:13:15,451][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_0.predict)=93.56%\n",
      "[ 2018-07-31 22:13:16,724][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_1.predict)=94.92%\n",
      "[ 2018-07-31 22:13:18,026][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_2.predict)=95.93%\n",
      "[ 2018-07-31 22:13:19,348][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_3.predict)=94.92%\n",
      "[ 2018-07-31 22:13:20,927][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_4.predict)=94.22%\n",
      "[ 2018-07-31 22:13:22,608][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_5.predict)=96.60%\n",
      "[ 2018-07-31 22:13:24,133][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_6.predict)=94.90%\n",
      "[ 2018-07-31 22:13:25,732][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_7.predict)=94.90%\n",
      "[ 2018-07-31 22:13:27,480][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_8.predict)=96.94%\n",
      "[ 2018-07-31 22:13:29,228][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_9.predict)=96.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:13:29,601][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_cv.predict)=95.31%\n",
      "[ 2018-07-31 22:13:29,602][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.test.predict)=94.70%\n",
      "[ 2018-07-31 22:13:30,872][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_0.predict)=95.93%\n",
      "[ 2018-07-31 22:13:32,398][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_1.predict)=95.59%\n",
      "[ 2018-07-31 22:13:34,148][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_2.predict)=95.59%\n",
      "[ 2018-07-31 22:13:35,796][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_3.predict)=95.93%\n",
      "[ 2018-07-31 22:13:37,436][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_4.predict)=95.24%\n",
      "[ 2018-07-31 22:13:39,181][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_5.predict)=95.58%\n",
      "[ 2018-07-31 22:13:40,844][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_6.predict)=95.24%\n",
      "[ 2018-07-31 22:13:42,514][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_7.predict)=95.92%\n",
      "[ 2018-07-31 22:13:44,106][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_8.predict)=94.22%\n",
      "[ 2018-07-31 22:13:46,181][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_9.predict)=95.24%\n",
      "[ 2018-07-31 22:13:46,454][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_cv.predict)=95.45%\n",
      "[ 2018-07-31 22:13:46,456][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.test.predict)=94.54%\n",
      "[ 2018-07-31 22:13:46,521][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_0.predict)=95.25%\n",
      "[ 2018-07-31 22:13:46,568][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_1.predict)=95.59%\n",
      "[ 2018-07-31 22:13:46,612][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_2.predict)=93.22%\n",
      "[ 2018-07-31 22:13:46,657][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_3.predict)=93.22%\n",
      "[ 2018-07-31 22:13:46,715][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_4.predict)=94.22%\n",
      "[ 2018-07-31 22:13:46,808][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_5.predict)=96.60%\n",
      "[ 2018-07-31 22:13:46,856][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_6.predict)=95.92%\n",
      "[ 2018-07-31 22:13:46,900][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_7.predict)=95.92%\n",
      "[ 2018-07-31 22:13:46,949][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_8.predict)=96.94%\n",
      "[ 2018-07-31 22:13:47,096][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_9.predict)=94.90%\n",
      "[ 2018-07-31 22:13:47,107][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_cv.predict)=95.18%\n",
      "[ 2018-07-31 22:13:47,116][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.test.predict)=94.46%\n",
      "[ 2018-07-31 22:13:47,127][cascade_classifier.calc_accuracy] Accuracy(layer_3 - train.classifier_average)=95.41%\n",
      "[ 2018-07-31 22:13:47,130][cascade_classifier.calc_accuracy] Accuracy(layer_3 - test.classifier_average)=94.54%\n",
      "[ 2018-07-31 22:13:47,136][cascade_classifier.fit_transform] [layer=4] look_indexs=[0], X_cur_train.shape=(2944, 63), X_cur_test.shape=(1263, 63)\n",
      "[ 2018-07-31 22:13:48,450][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_0.predict)=96.27%\n",
      "[ 2018-07-31 22:13:50,240][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_1.predict)=94.58%\n",
      "[ 2018-07-31 22:13:51,761][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_2.predict)=95.59%\n",
      "[ 2018-07-31 22:13:53,378][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_3.predict)=95.93%\n",
      "[ 2018-07-31 22:13:54,867][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_4.predict)=93.88%\n",
      "[ 2018-07-31 22:13:56,463][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_5.predict)=94.90%\n",
      "[ 2018-07-31 22:13:58,351][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_6.predict)=95.92%\n",
      "[ 2018-07-31 22:14:00,306][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_7.predict)=96.26%\n",
      "[ 2018-07-31 22:14:02,238][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_8.predict)=95.24%\n",
      "[ 2018-07-31 22:14:04,275][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_9.predict)=94.22%\n",
      "[ 2018-07-31 22:14:04,521][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_cv.predict)=95.28%\n",
      "[ 2018-07-31 22:14:04,531][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.test.predict)=94.62%\n",
      "[ 2018-07-31 22:14:06,458][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_0.predict)=97.29%\n",
      "[ 2018-07-31 22:14:08,353][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_1.predict)=96.61%\n",
      "[ 2018-07-31 22:14:10,314][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_2.predict)=95.93%\n",
      "[ 2018-07-31 22:14:12,512][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_3.predict)=95.25%\n",
      "[ 2018-07-31 22:14:14,219][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_4.predict)=95.92%\n",
      "[ 2018-07-31 22:14:15,908][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_5.predict)=93.88%\n",
      "[ 2018-07-31 22:14:17,700][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_6.predict)=94.90%\n",
      "[ 2018-07-31 22:14:19,649][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_7.predict)=95.92%\n",
      "[ 2018-07-31 22:14:21,817][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_8.predict)=93.54%\n",
      "[ 2018-07-31 22:14:23,947][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_9.predict)=95.58%\n",
      "[ 2018-07-31 22:14:24,186][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_cv.predict)=95.48%\n",
      "[ 2018-07-31 22:14:24,188][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.test.predict)=94.54%\n",
      "[ 2018-07-31 22:14:24,241][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_0.predict)=95.93%\n",
      "[ 2018-07-31 22:14:24,318][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_1.predict)=97.29%\n",
      "[ 2018-07-31 22:14:24,378][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_2.predict)=94.92%\n",
      "[ 2018-07-31 22:14:24,456][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_3.predict)=95.93%\n",
      "[ 2018-07-31 22:14:24,605][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_4.predict)=96.94%\n",
      "[ 2018-07-31 22:14:24,701][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_5.predict)=94.56%\n",
      "[ 2018-07-31 22:14:24,817][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_6.predict)=95.92%\n",
      "[ 2018-07-31 22:14:24,870][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_7.predict)=94.22%\n",
      "[ 2018-07-31 22:14:24,974][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_8.predict)=93.88%\n",
      "[ 2018-07-31 22:14:25,041][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_9.predict)=94.90%\n",
      "[ 2018-07-31 22:14:25,061][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_cv.predict)=95.45%\n",
      "[ 2018-07-31 22:14:25,069][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.test.predict)=94.62%\n",
      "[ 2018-07-31 22:14:25,071][cascade_classifier.calc_accuracy] Accuracy(layer_4 - train.classifier_average)=95.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:14:25,073][cascade_classifier.calc_accuracy] Accuracy(layer_4 - test.classifier_average)=94.54%\n",
      "[ 2018-07-31 22:14:25,076][cascade_classifier.fit_transform] [layer=5] look_indexs=[0], X_cur_train.shape=(2944, 63), X_cur_test.shape=(1263, 63)\n",
      "[ 2018-07-31 22:14:26,591][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_0.predict)=94.58%\n",
      "[ 2018-07-31 22:14:28,615][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_1.predict)=96.95%\n",
      "[ 2018-07-31 22:14:31,027][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_2.predict)=94.92%\n",
      "[ 2018-07-31 22:14:33,982][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_3.predict)=94.92%\n",
      "[ 2018-07-31 22:14:36,750][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_4.predict)=95.58%\n",
      "[ 2018-07-31 22:14:38,526][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_5.predict)=96.26%\n",
      "[ 2018-07-31 22:14:41,471][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_6.predict)=93.54%\n",
      "[ 2018-07-31 22:14:45,276][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_7.predict)=96.94%\n",
      "[ 2018-07-31 22:14:48,507][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_8.predict)=95.58%\n",
      "[ 2018-07-31 22:14:51,164][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_9.predict)=96.60%\n",
      "[ 2018-07-31 22:14:51,375][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_cv.predict)=95.58%\n",
      "[ 2018-07-31 22:14:51,377][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.test.predict)=94.62%\n",
      "[ 2018-07-31 22:14:54,071][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_0.predict)=96.27%\n",
      "[ 2018-07-31 22:14:56,705][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_1.predict)=95.25%\n",
      "[ 2018-07-31 22:14:59,425][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_2.predict)=95.25%\n",
      "[ 2018-07-31 22:15:01,199][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_3.predict)=94.24%\n",
      "[ 2018-07-31 22:15:03,032][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_4.predict)=96.60%\n",
      "[ 2018-07-31 22:15:04,905][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_5.predict)=94.56%\n",
      "[ 2018-07-31 22:15:07,203][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_6.predict)=95.24%\n",
      "[ 2018-07-31 22:15:11,003][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_7.predict)=96.94%\n",
      "[ 2018-07-31 22:15:14,914][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_8.predict)=94.22%\n",
      "[ 2018-07-31 22:15:18,552][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_9.predict)=96.26%\n",
      "[ 2018-07-31 22:15:19,019][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_cv.predict)=95.48%\n",
      "[ 2018-07-31 22:15:19,021][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.test.predict)=94.70%\n",
      "[ 2018-07-31 22:15:19,203][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_0.predict)=93.90%\n",
      "[ 2018-07-31 22:15:19,422][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_1.predict)=95.25%\n",
      "[ 2018-07-31 22:15:19,546][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_2.predict)=95.59%\n",
      "[ 2018-07-31 22:15:19,665][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_3.predict)=96.95%\n",
      "[ 2018-07-31 22:15:19,768][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_4.predict)=94.90%\n",
      "[ 2018-07-31 22:15:19,899][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_5.predict)=94.56%\n",
      "[ 2018-07-31 22:15:20,002][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_6.predict)=95.24%\n",
      "[ 2018-07-31 22:15:20,107][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_7.predict)=94.90%\n",
      "[ 2018-07-31 22:15:20,207][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_8.predict)=95.92%\n",
      "[ 2018-07-31 22:15:20,345][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_9.predict)=96.94%\n",
      "[ 2018-07-31 22:15:20,352][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_cv.predict)=95.41%\n",
      "[ 2018-07-31 22:15:20,357][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.test.predict)=94.54%\n",
      "[ 2018-07-31 22:15:20,362][cascade_classifier.calc_accuracy] Accuracy(layer_5 - train.classifier_average)=95.48%\n",
      "[ 2018-07-31 22:15:20,366][cascade_classifier.calc_accuracy] Accuracy(layer_5 - test.classifier_average)=94.62%\n",
      "[ 2018-07-31 22:15:20,371][cascade_classifier.fit_transform] [layer=6] look_indexs=[0], X_cur_train.shape=(2944, 63), X_cur_test.shape=(1263, 63)\n",
      "[ 2018-07-31 22:15:23,855][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_0.predict)=95.25%\n",
      "[ 2018-07-31 22:15:27,918][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_1.predict)=97.29%\n",
      "[ 2018-07-31 22:15:32,014][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_2.predict)=94.92%\n",
      "[ 2018-07-31 22:15:34,511][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_3.predict)=97.29%\n",
      "[ 2018-07-31 22:15:38,063][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_4.predict)=94.56%\n",
      "[ 2018-07-31 22:15:41,274][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_5.predict)=95.92%\n",
      "[ 2018-07-31 22:15:44,729][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_6.predict)=93.54%\n",
      "[ 2018-07-31 22:15:48,578][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_7.predict)=94.56%\n",
      "[ 2018-07-31 22:15:52,082][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_8.predict)=94.22%\n",
      "[ 2018-07-31 22:15:56,360][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_9.predict)=96.94%\n",
      "[ 2018-07-31 22:15:56,939][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_cv.predict)=95.45%\n",
      "[ 2018-07-31 22:15:56,942][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.test.predict)=94.70%\n",
      "[ 2018-07-31 22:15:59,949][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_0.predict)=95.25%\n",
      "[ 2018-07-31 22:16:03,432][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_1.predict)=95.59%\n",
      "[ 2018-07-31 22:16:06,601][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_2.predict)=95.59%\n",
      "[ 2018-07-31 22:16:09,647][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_3.predict)=93.90%\n",
      "[ 2018-07-31 22:16:11,859][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_4.predict)=96.60%\n",
      "[ 2018-07-31 22:16:14,393][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_5.predict)=96.26%\n",
      "[ 2018-07-31 22:16:17,272][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_6.predict)=96.94%\n",
      "[ 2018-07-31 22:16:20,805][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_7.predict)=93.54%\n",
      "[ 2018-07-31 22:16:23,432][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_8.predict)=96.26%\n",
      "[ 2018-07-31 22:16:26,448][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_9.predict)=93.88%\n",
      "[ 2018-07-31 22:16:27,280][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_cv.predict)=95.38%\n",
      "[ 2018-07-31 22:16:27,288][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.test.predict)=94.62%\n",
      "[ 2018-07-31 22:16:27,476][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_0.predict)=96.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:16:27,767][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_1.predict)=95.93%\n",
      "[ 2018-07-31 22:16:27,826][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_2.predict)=96.95%\n",
      "[ 2018-07-31 22:16:27,963][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_3.predict)=95.93%\n",
      "[ 2018-07-31 22:16:28,051][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_4.predict)=94.22%\n",
      "[ 2018-07-31 22:16:28,188][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_5.predict)=95.24%\n",
      "[ 2018-07-31 22:16:28,321][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_6.predict)=94.56%\n",
      "[ 2018-07-31 22:16:28,418][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_7.predict)=94.56%\n",
      "[ 2018-07-31 22:16:28,533][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_8.predict)=96.60%\n",
      "[ 2018-07-31 22:16:28,648][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_9.predict)=94.56%\n",
      "[ 2018-07-31 22:16:28,662][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_cv.predict)=95.48%\n",
      "[ 2018-07-31 22:16:28,663][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.test.predict)=94.70%\n",
      "[ 2018-07-31 22:16:28,664][cascade_classifier.calc_accuracy] Accuracy(layer_6 - train.classifier_average)=95.48%\n",
      "[ 2018-07-31 22:16:28,673][cascade_classifier.calc_accuracy] Accuracy(layer_6 - test.classifier_average)=94.62%\n",
      "[ 2018-07-31 22:16:28,692][cascade_classifier.fit_transform] [layer=7] look_indexs=[0], X_cur_train.shape=(2944, 63), X_cur_test.shape=(1263, 63)\n",
      "[ 2018-07-31 22:16:31,343][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_0.predict)=95.59%\n",
      "[ 2018-07-31 22:16:33,786][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_1.predict)=96.27%\n",
      "[ 2018-07-31 22:16:37,274][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_2.predict)=93.56%\n",
      "[ 2018-07-31 22:16:40,863][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_3.predict)=95.25%\n",
      "[ 2018-07-31 22:16:44,305][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_4.predict)=96.26%\n",
      "[ 2018-07-31 22:16:48,221][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_5.predict)=96.60%\n",
      "[ 2018-07-31 22:16:52,539][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_6.predict)=96.60%\n",
      "[ 2018-07-31 22:16:55,996][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_7.predict)=94.22%\n",
      "[ 2018-07-31 22:16:58,807][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_8.predict)=94.56%\n",
      "[ 2018-07-31 22:17:01,832][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_9.predict)=95.92%\n",
      "[ 2018-07-31 22:17:02,451][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_cv.predict)=95.48%\n",
      "[ 2018-07-31 22:17:02,454][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.test.predict)=94.62%\n",
      "[ 2018-07-31 22:17:04,707][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_0.predict)=95.93%\n",
      "[ 2018-07-31 22:17:08,034][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_1.predict)=94.58%\n",
      "[ 2018-07-31 22:17:11,448][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_2.predict)=93.90%\n",
      "[ 2018-07-31 22:17:14,704][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_3.predict)=94.92%\n",
      "[ 2018-07-31 22:17:17,635][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_4.predict)=95.58%\n",
      "[ 2018-07-31 22:17:20,528][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_5.predict)=97.28%\n",
      "[ 2018-07-31 22:17:23,937][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_6.predict)=97.62%\n",
      "[ 2018-07-31 22:17:26,618][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_7.predict)=96.94%\n",
      "[ 2018-07-31 22:17:29,065][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_8.predict)=94.56%\n",
      "[ 2018-07-31 22:17:32,618][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_9.predict)=93.88%\n",
      "[ 2018-07-31 22:17:33,039][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_cv.predict)=95.52%\n",
      "[ 2018-07-31 22:17:33,042][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.test.predict)=94.62%\n",
      "[ 2018-07-31 22:17:33,184][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_0.predict)=97.63%\n",
      "[ 2018-07-31 22:17:33,295][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_1.predict)=95.59%\n",
      "[ 2018-07-31 22:17:33,612][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_2.predict)=93.90%\n",
      "[ 2018-07-31 22:17:33,854][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_3.predict)=95.93%\n",
      "[ 2018-07-31 22:17:34,064][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_4.predict)=94.22%\n",
      "[ 2018-07-31 22:17:34,321][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_5.predict)=93.54%\n",
      "[ 2018-07-31 22:17:34,454][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_6.predict)=96.26%\n",
      "[ 2018-07-31 22:17:34,571][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_7.predict)=95.92%\n",
      "[ 2018-07-31 22:17:34,729][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_8.predict)=96.26%\n",
      "[ 2018-07-31 22:17:34,900][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_9.predict)=96.26%\n",
      "[ 2018-07-31 22:17:34,913][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_cv.predict)=95.55%\n",
      "[ 2018-07-31 22:17:34,914][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.test.predict)=94.62%\n",
      "[ 2018-07-31 22:17:34,916][cascade_classifier.calc_accuracy] Accuracy(layer_7 - train.classifier_average)=95.52%\n",
      "[ 2018-07-31 22:17:34,964][cascade_classifier.calc_accuracy] Accuracy(layer_7 - test.classifier_average)=94.62%\n",
      "[ 2018-07-31 22:17:34,967][cascade_classifier.fit_transform] [layer=8] look_indexs=[0], X_cur_train.shape=(2944, 63), X_cur_test.shape=(1263, 63)\n",
      "[ 2018-07-31 22:17:38,088][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_0.predict)=94.58%\n",
      "[ 2018-07-31 22:17:41,328][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_1.predict)=96.27%\n",
      "[ 2018-07-31 22:17:44,752][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_2.predict)=96.61%\n",
      "[ 2018-07-31 22:17:48,722][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_3.predict)=95.25%\n",
      "[ 2018-07-31 22:17:52,267][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_4.predict)=94.56%\n",
      "[ 2018-07-31 22:17:56,230][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_5.predict)=95.24%\n",
      "[ 2018-07-31 22:17:59,238][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_6.predict)=95.92%\n",
      "[ 2018-07-31 22:18:02,757][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_7.predict)=94.56%\n",
      "[ 2018-07-31 22:18:06,258][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_8.predict)=95.58%\n",
      "[ 2018-07-31 22:18:09,522][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_9.predict)=95.92%\n",
      "[ 2018-07-31 22:18:10,039][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_cv.predict)=95.45%\n",
      "[ 2018-07-31 22:18:10,040][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.test.predict)=94.62%\n",
      "[ 2018-07-31 22:18:13,562][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_0.predict)=94.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:18:18,101][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_1.predict)=94.58%\n",
      "[ 2018-07-31 22:18:23,350][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_2.predict)=96.27%\n",
      "[ 2018-07-31 22:18:27,556][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_3.predict)=93.90%\n",
      "[ 2018-07-31 22:18:31,426][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_4.predict)=95.58%\n",
      "[ 2018-07-31 22:18:34,663][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_5.predict)=97.96%\n",
      "[ 2018-07-31 22:18:38,694][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_6.predict)=94.90%\n",
      "[ 2018-07-31 22:18:41,396][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_7.predict)=96.94%\n",
      "[ 2018-07-31 22:18:45,361][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_8.predict)=95.58%\n",
      "[ 2018-07-31 22:18:49,083][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_9.predict)=95.24%\n",
      "[ 2018-07-31 22:18:50,024][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_cv.predict)=95.58%\n",
      "[ 2018-07-31 22:18:50,027][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.test.predict)=94.62%\n",
      "[ 2018-07-31 22:18:50,155][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_0.predict)=95.93%\n",
      "[ 2018-07-31 22:18:50,345][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_1.predict)=93.56%\n",
      "[ 2018-07-31 22:18:50,526][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_2.predict)=95.93%\n",
      "[ 2018-07-31 22:18:50,745][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_3.predict)=97.63%\n",
      "[ 2018-07-31 22:18:50,978][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_4.predict)=92.18%\n",
      "[ 2018-07-31 22:18:51,162][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_5.predict)=95.24%\n",
      "[ 2018-07-31 22:18:51,349][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_6.predict)=96.94%\n",
      "[ 2018-07-31 22:18:51,569][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_7.predict)=96.94%\n",
      "[ 2018-07-31 22:18:51,809][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_8.predict)=95.58%\n",
      "[ 2018-07-31 22:18:51,872][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_9.predict)=95.58%\n",
      "[ 2018-07-31 22:18:51,889][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_cv.predict)=95.55%\n",
      "[ 2018-07-31 22:18:51,903][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.test.predict)=94.62%\n",
      "[ 2018-07-31 22:18:51,919][cascade_classifier.calc_accuracy] Accuracy(layer_8 - train.classifier_average)=95.52%\n",
      "[ 2018-07-31 22:18:51,934][cascade_classifier.calc_accuracy] Accuracy(layer_8 - test.classifier_average)=94.62%\n",
      "[ 2018-07-31 22:18:51,936][cascade_classifier.fit_transform] [layer=9] look_indexs=[0], X_cur_train.shape=(2944, 63), X_cur_test.shape=(1263, 63)\n",
      "[ 2018-07-31 22:18:54,406][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_0 - 10_folds.train_0.predict)=96.95%\n",
      "[ 2018-07-31 22:18:56,747][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_0 - 10_folds.train_1.predict)=95.93%\n",
      "[ 2018-07-31 22:18:59,633][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_0 - 10_folds.train_2.predict)=96.61%\n",
      "[ 2018-07-31 22:19:02,761][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_0 - 10_folds.train_3.predict)=96.61%\n",
      "[ 2018-07-31 22:19:05,642][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_0 - 10_folds.train_4.predict)=96.26%\n",
      "[ 2018-07-31 22:19:08,420][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_0 - 10_folds.train_5.predict)=93.88%\n",
      "[ 2018-07-31 22:19:11,161][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_0 - 10_folds.train_6.predict)=94.90%\n",
      "[ 2018-07-31 22:19:14,012][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_0 - 10_folds.train_7.predict)=93.88%\n",
      "[ 2018-07-31 22:19:16,599][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_0 - 10_folds.train_8.predict)=96.94%\n",
      "[ 2018-07-31 22:19:19,653][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_0 - 10_folds.train_9.predict)=93.54%\n",
      "[ 2018-07-31 22:19:19,894][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_0 - 10_folds.train_cv.predict)=95.55%\n",
      "[ 2018-07-31 22:19:19,897][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_0 - 10_folds.test.predict)=94.62%\n",
      "[ 2018-07-31 22:19:22,010][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_1 - 10_folds.train_0.predict)=96.95%\n",
      "[ 2018-07-31 22:19:24,354][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_1 - 10_folds.train_1.predict)=95.25%\n",
      "[ 2018-07-31 22:19:27,281][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_1 - 10_folds.train_2.predict)=94.24%\n",
      "[ 2018-07-31 22:19:29,422][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_1 - 10_folds.train_3.predict)=95.25%\n",
      "[ 2018-07-31 22:19:31,876][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_1 - 10_folds.train_4.predict)=96.94%\n",
      "[ 2018-07-31 22:19:34,616][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_1 - 10_folds.train_5.predict)=95.58%\n",
      "[ 2018-07-31 22:19:36,934][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_1 - 10_folds.train_6.predict)=94.22%\n",
      "[ 2018-07-31 22:19:39,829][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_1 - 10_folds.train_7.predict)=95.24%\n",
      "[ 2018-07-31 22:19:43,905][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_1 - 10_folds.train_8.predict)=96.94%\n",
      "[ 2018-07-31 22:19:47,151][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_1 - 10_folds.train_9.predict)=95.58%\n",
      "[ 2018-07-31 22:19:47,701][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_1 - 10_folds.train_cv.predict)=95.62%\n",
      "[ 2018-07-31 22:19:47,707][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_1 - 10_folds.test.predict)=94.62%\n",
      "[ 2018-07-31 22:19:47,858][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_2 - 10_folds.train_0.predict)=95.93%\n",
      "[ 2018-07-31 22:19:48,024][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_2 - 10_folds.train_1.predict)=94.24%\n",
      "[ 2018-07-31 22:19:48,250][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_2 - 10_folds.train_2.predict)=96.95%\n",
      "[ 2018-07-31 22:19:48,453][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_2 - 10_folds.train_3.predict)=96.27%\n",
      "[ 2018-07-31 22:19:48,617][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_2 - 10_folds.train_4.predict)=96.26%\n",
      "[ 2018-07-31 22:19:48,793][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_2 - 10_folds.train_5.predict)=94.56%\n",
      "[ 2018-07-31 22:19:48,898][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_2 - 10_folds.train_6.predict)=93.54%\n",
      "[ 2018-07-31 22:19:49,046][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_2 - 10_folds.train_7.predict)=94.90%\n",
      "[ 2018-07-31 22:19:49,189][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_2 - 10_folds.train_8.predict)=95.92%\n",
      "[ 2018-07-31 22:19:49,304][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_2 - 10_folds.train_9.predict)=96.60%\n",
      "[ 2018-07-31 22:19:49,306][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_2 - 10_folds.train_cv.predict)=95.52%\n",
      "[ 2018-07-31 22:19:49,313][kfold_wrapper.log_eval_metrics] Accuracy(layer_9 - estimator_2 - 10_folds.test.predict)=94.62%\n",
      "[ 2018-07-31 22:19:49,328][cascade_classifier.calc_accuracy] Accuracy(layer_9 - train.classifier_average)=95.52%\n",
      "[ 2018-07-31 22:19:49,330][cascade_classifier.calc_accuracy] Accuracy(layer_9 - test.classifier_average)=94.62%\n",
      "[ 2018-07-31 22:19:49,367][cascade_classifier.fit_transform] [layer=10] look_indexs=[0], X_cur_train.shape=(2944, 63), X_cur_test.shape=(1263, 63)\n",
      "[ 2018-07-31 22:19:52,166][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_0 - 10_folds.train_0.predict)=93.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:19:55,600][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_0 - 10_folds.train_1.predict)=96.61%\n",
      "[ 2018-07-31 22:19:57,939][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_0 - 10_folds.train_2.predict)=95.93%\n",
      "[ 2018-07-31 22:20:01,133][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_0 - 10_folds.train_3.predict)=94.24%\n",
      "[ 2018-07-31 22:20:03,188][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_0 - 10_folds.train_4.predict)=96.94%\n",
      "[ 2018-07-31 22:20:05,237][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_0 - 10_folds.train_5.predict)=95.92%\n",
      "[ 2018-07-31 22:20:07,347][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_0 - 10_folds.train_6.predict)=95.92%\n",
      "[ 2018-07-31 22:20:09,801][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_0 - 10_folds.train_7.predict)=95.92%\n",
      "[ 2018-07-31 22:20:12,736][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_0 - 10_folds.train_8.predict)=94.22%\n",
      "[ 2018-07-31 22:20:15,369][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_0 - 10_folds.train_9.predict)=96.60%\n",
      "[ 2018-07-31 22:20:15,804][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_0 - 10_folds.train_cv.predict)=95.58%\n",
      "[ 2018-07-31 22:20:15,805][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_0 - 10_folds.test.predict)=94.62%\n",
      "[ 2018-07-31 22:20:18,660][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_1 - 10_folds.train_0.predict)=95.93%\n",
      "[ 2018-07-31 22:20:21,509][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_1 - 10_folds.train_1.predict)=96.27%\n",
      "[ 2018-07-31 22:20:24,384][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_1 - 10_folds.train_2.predict)=93.90%\n",
      "[ 2018-07-31 22:20:27,234][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_1 - 10_folds.train_3.predict)=93.90%\n",
      "[ 2018-07-31 22:20:29,869][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_1 - 10_folds.train_4.predict)=96.60%\n",
      "[ 2018-07-31 22:20:32,990][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_1 - 10_folds.train_5.predict)=96.94%\n",
      "[ 2018-07-31 22:20:35,850][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_1 - 10_folds.train_6.predict)=96.94%\n",
      "[ 2018-07-31 22:20:39,010][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_1 - 10_folds.train_7.predict)=93.20%\n",
      "[ 2018-07-31 22:20:42,273][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_1 - 10_folds.train_8.predict)=96.94%\n",
      "[ 2018-07-31 22:20:45,263][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_1 - 10_folds.train_9.predict)=94.56%\n",
      "[ 2018-07-31 22:20:45,857][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_1 - 10_folds.train_cv.predict)=95.52%\n",
      "[ 2018-07-31 22:20:45,859][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_1 - 10_folds.test.predict)=94.62%\n",
      "[ 2018-07-31 22:20:45,949][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_2 - 10_folds.train_0.predict)=95.93%\n",
      "[ 2018-07-31 22:20:46,180][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_2 - 10_folds.train_1.predict)=95.25%\n",
      "[ 2018-07-31 22:20:46,399][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_2 - 10_folds.train_2.predict)=96.27%\n",
      "[ 2018-07-31 22:20:46,482][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_2 - 10_folds.train_3.predict)=96.27%\n",
      "[ 2018-07-31 22:20:46,788][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_2 - 10_folds.train_4.predict)=95.24%\n",
      "[ 2018-07-31 22:20:46,995][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_2 - 10_folds.train_5.predict)=95.92%\n",
      "[ 2018-07-31 22:20:47,235][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_2 - 10_folds.train_6.predict)=95.24%\n",
      "[ 2018-07-31 22:20:47,411][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_2 - 10_folds.train_7.predict)=94.56%\n",
      "[ 2018-07-31 22:20:47,543][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_2 - 10_folds.train_8.predict)=95.24%\n",
      "[ 2018-07-31 22:20:47,630][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_2 - 10_folds.train_9.predict)=95.92%\n",
      "[ 2018-07-31 22:20:47,644][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_2 - 10_folds.train_cv.predict)=95.58%\n",
      "[ 2018-07-31 22:20:47,646][kfold_wrapper.log_eval_metrics] Accuracy(layer_10 - estimator_2 - 10_folds.test.predict)=94.62%\n",
      "[ 2018-07-31 22:20:47,651][cascade_classifier.calc_accuracy] Accuracy(layer_10 - train.classifier_average)=95.62%\n",
      "[ 2018-07-31 22:20:47,652][cascade_classifier.calc_accuracy] Accuracy(layer_10 - test.classifier_average)=94.62%\n",
      "[ 2018-07-31 22:20:47,655][cascade_classifier.fit_transform] [layer=11] look_indexs=[0], X_cur_train.shape=(2944, 63), X_cur_test.shape=(1263, 63)\n",
      "[ 2018-07-31 22:20:49,466][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_0 - 10_folds.train_0.predict)=95.93%\n",
      "[ 2018-07-31 22:20:51,603][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_0 - 10_folds.train_1.predict)=95.25%\n",
      "[ 2018-07-31 22:20:54,083][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_0 - 10_folds.train_2.predict)=95.59%\n",
      "[ 2018-07-31 22:20:56,791][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_0 - 10_folds.train_3.predict)=94.92%\n",
      "[ 2018-07-31 22:20:59,750][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_0 - 10_folds.train_4.predict)=93.88%\n",
      "[ 2018-07-31 22:21:01,648][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_0 - 10_folds.train_5.predict)=95.24%\n",
      "[ 2018-07-31 22:21:04,295][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_0 - 10_folds.train_6.predict)=95.24%\n",
      "[ 2018-07-31 22:21:07,802][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_0 - 10_folds.train_7.predict)=96.60%\n",
      "[ 2018-07-31 22:21:10,671][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_0 - 10_folds.train_8.predict)=96.94%\n",
      "[ 2018-07-31 22:21:14,404][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_0 - 10_folds.train_9.predict)=96.26%\n",
      "[ 2018-07-31 22:21:15,164][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_0 - 10_folds.train_cv.predict)=95.58%\n",
      "[ 2018-07-31 22:21:15,166][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_0 - 10_folds.test.predict)=94.62%\n",
      "[ 2018-07-31 22:21:18,509][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_1 - 10_folds.train_0.predict)=96.61%\n",
      "[ 2018-07-31 22:21:21,781][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_1 - 10_folds.train_1.predict)=96.27%\n",
      "[ 2018-07-31 22:21:25,745][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_1 - 10_folds.train_2.predict)=96.27%\n",
      "[ 2018-07-31 22:21:29,406][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_1 - 10_folds.train_3.predict)=94.24%\n",
      "[ 2018-07-31 22:21:32,675][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_1 - 10_folds.train_4.predict)=96.60%\n",
      "[ 2018-07-31 22:21:35,181][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_1 - 10_folds.train_5.predict)=94.90%\n",
      "[ 2018-07-31 22:21:37,551][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_1 - 10_folds.train_6.predict)=95.58%\n",
      "[ 2018-07-31 22:21:40,876][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_1 - 10_folds.train_7.predict)=95.24%\n",
      "[ 2018-07-31 22:21:43,524][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_1 - 10_folds.train_8.predict)=95.92%\n",
      "[ 2018-07-31 22:21:46,844][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_1 - 10_folds.train_9.predict)=94.22%\n",
      "[ 2018-07-31 22:21:47,461][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_1 - 10_folds.train_cv.predict)=95.58%\n",
      "[ 2018-07-31 22:21:47,463][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_1 - 10_folds.test.predict)=94.62%\n",
      "[ 2018-07-31 22:21:47,541][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_2 - 10_folds.train_0.predict)=94.92%\n",
      "[ 2018-07-31 22:21:47,744][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_2 - 10_folds.train_1.predict)=96.27%\n",
      "[ 2018-07-31 22:21:47,959][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_2 - 10_folds.train_2.predict)=94.92%\n",
      "[ 2018-07-31 22:21:48,273][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_2 - 10_folds.train_3.predict)=95.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:21:48,444][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_2 - 10_folds.train_4.predict)=96.60%\n",
      "[ 2018-07-31 22:21:48,595][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_2 - 10_folds.train_5.predict)=94.90%\n",
      "[ 2018-07-31 22:21:48,757][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_2 - 10_folds.train_6.predict)=95.58%\n",
      "[ 2018-07-31 22:21:48,963][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_2 - 10_folds.train_7.predict)=95.58%\n",
      "[ 2018-07-31 22:21:49,133][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_2 - 10_folds.train_8.predict)=94.90%\n",
      "[ 2018-07-31 22:21:49,338][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_2 - 10_folds.train_9.predict)=96.26%\n",
      "[ 2018-07-31 22:21:49,364][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_2 - 10_folds.train_cv.predict)=95.58%\n",
      "[ 2018-07-31 22:21:49,365][kfold_wrapper.log_eval_metrics] Accuracy(layer_11 - estimator_2 - 10_folds.test.predict)=94.62%\n",
      "[ 2018-07-31 22:21:49,371][cascade_classifier.calc_accuracy] Accuracy(layer_11 - train.classifier_average)=95.62%\n",
      "[ 2018-07-31 22:21:49,382][cascade_classifier.calc_accuracy] Accuracy(layer_11 - test.classifier_average)=94.62%\n",
      "[ 2018-07-31 22:21:49,384][cascade_classifier.fit_transform] [layer=12] look_indexs=[0], X_cur_train.shape=(2944, 63), X_cur_test.shape=(1263, 63)\n",
      "[ 2018-07-31 22:21:52,134][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_0 - 10_folds.train_0.predict)=93.90%\n",
      "[ 2018-07-31 22:21:54,442][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_0 - 10_folds.train_1.predict)=93.56%\n",
      "[ 2018-07-31 22:21:57,286][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_0 - 10_folds.train_2.predict)=97.29%\n",
      "[ 2018-07-31 22:21:59,409][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_0 - 10_folds.train_3.predict)=95.93%\n",
      "[ 2018-07-31 22:22:02,109][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_0 - 10_folds.train_4.predict)=96.26%\n",
      "[ 2018-07-31 22:22:04,986][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_0 - 10_folds.train_5.predict)=96.26%\n",
      "[ 2018-07-31 22:22:07,128][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_0 - 10_folds.train_6.predict)=95.92%\n",
      "[ 2018-07-31 22:22:09,850][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_0 - 10_folds.train_7.predict)=96.26%\n",
      "[ 2018-07-31 22:22:12,152][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_0 - 10_folds.train_8.predict)=95.24%\n",
      "[ 2018-07-31 22:22:15,095][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_0 - 10_folds.train_9.predict)=95.58%\n",
      "[ 2018-07-31 22:22:15,673][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_0 - 10_folds.train_cv.predict)=95.62%\n",
      "[ 2018-07-31 22:22:15,674][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_0 - 10_folds.test.predict)=94.70%\n",
      "[ 2018-07-31 22:22:17,849][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_1 - 10_folds.train_0.predict)=95.59%\n",
      "[ 2018-07-31 22:22:20,786][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_1 - 10_folds.train_1.predict)=97.29%\n",
      "[ 2018-07-31 22:22:23,320][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_1 - 10_folds.train_2.predict)=96.95%\n",
      "[ 2018-07-31 22:22:26,878][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_1 - 10_folds.train_3.predict)=96.95%\n",
      "[ 2018-07-31 22:22:29,158][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_1 - 10_folds.train_4.predict)=94.22%\n",
      "[ 2018-07-31 22:22:32,599][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_1 - 10_folds.train_5.predict)=93.88%\n",
      "[ 2018-07-31 22:22:34,779][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_1 - 10_folds.train_6.predict)=95.92%\n",
      "[ 2018-07-31 22:22:37,637][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_1 - 10_folds.train_7.predict)=95.92%\n",
      "[ 2018-07-31 22:22:40,527][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_1 - 10_folds.train_8.predict)=94.22%\n",
      "[ 2018-07-31 22:22:43,054][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_1 - 10_folds.train_9.predict)=95.58%\n",
      "[ 2018-07-31 22:22:43,846][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_1 - 10_folds.train_cv.predict)=95.65%\n",
      "[ 2018-07-31 22:22:43,849][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_1 - 10_folds.test.predict)=94.70%\n",
      "[ 2018-07-31 22:22:44,003][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_2 - 10_folds.train_0.predict)=93.22%\n",
      "[ 2018-07-31 22:22:44,093][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_2 - 10_folds.train_1.predict)=96.27%\n",
      "[ 2018-07-31 22:22:44,341][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_2 - 10_folds.train_2.predict)=97.63%\n",
      "[ 2018-07-31 22:22:44,591][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_2 - 10_folds.train_3.predict)=94.58%\n",
      "[ 2018-07-31 22:22:44,820][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_2 - 10_folds.train_4.predict)=97.62%\n",
      "[ 2018-07-31 22:22:45,017][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_2 - 10_folds.train_5.predict)=96.26%\n",
      "[ 2018-07-31 22:22:45,240][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_2 - 10_folds.train_6.predict)=93.20%\n",
      "[ 2018-07-31 22:22:45,471][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_2 - 10_folds.train_7.predict)=95.24%\n",
      "[ 2018-07-31 22:22:45,678][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_2 - 10_folds.train_8.predict)=96.26%\n",
      "[ 2018-07-31 22:22:45,875][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_2 - 10_folds.train_9.predict)=95.58%\n",
      "[ 2018-07-31 22:22:45,924][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_2 - 10_folds.train_cv.predict)=95.58%\n",
      "[ 2018-07-31 22:22:45,925][kfold_wrapper.log_eval_metrics] Accuracy(layer_12 - estimator_2 - 10_folds.test.predict)=94.54%\n",
      "[ 2018-07-31 22:22:45,926][cascade_classifier.calc_accuracy] Accuracy(layer_12 - train.classifier_average)=95.62%\n",
      "[ 2018-07-31 22:22:45,928][cascade_classifier.calc_accuracy] Accuracy(layer_12 - test.classifier_average)=94.62%\n",
      "[ 2018-07-31 22:22:45,930][cascade_classifier.fit_transform] [layer=13] look_indexs=[0], X_cur_train.shape=(2944, 63), X_cur_test.shape=(1263, 63)\n",
      "[ 2018-07-31 22:22:48,607][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_0 - 10_folds.train_0.predict)=94.92%\n",
      "[ 2018-07-31 22:22:51,199][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_0 - 10_folds.train_1.predict)=94.92%\n",
      "[ 2018-07-31 22:22:53,445][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_0 - 10_folds.train_2.predict)=95.25%\n",
      "[ 2018-07-31 22:22:56,236][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_0 - 10_folds.train_3.predict)=97.97%\n",
      "[ 2018-07-31 22:22:58,725][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_0 - 10_folds.train_4.predict)=95.58%\n",
      "[ 2018-07-31 22:23:01,934][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_0 - 10_folds.train_5.predict)=95.92%\n",
      "[ 2018-07-31 22:23:04,603][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_0 - 10_folds.train_6.predict)=95.92%\n",
      "[ 2018-07-31 22:23:07,108][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_0 - 10_folds.train_7.predict)=95.92%\n",
      "[ 2018-07-31 22:23:10,586][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_0 - 10_folds.train_8.predict)=95.58%\n",
      "[ 2018-07-31 22:23:14,141][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_0 - 10_folds.train_9.predict)=94.22%\n",
      "[ 2018-07-31 22:23:14,620][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_0 - 10_folds.train_cv.predict)=95.62%\n",
      "[ 2018-07-31 22:23:14,623][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_0 - 10_folds.test.predict)=94.70%\n",
      "[ 2018-07-31 22:23:17,286][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_1 - 10_folds.train_0.predict)=95.59%\n",
      "[ 2018-07-31 22:23:19,778][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_1 - 10_folds.train_1.predict)=93.90%\n",
      "[ 2018-07-31 22:23:22,479][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_1 - 10_folds.train_2.predict)=97.63%\n",
      "[ 2018-07-31 22:23:25,052][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_1 - 10_folds.train_3.predict)=96.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:23:26,638][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_1 - 10_folds.train_4.predict)=95.58%\n",
      "[ 2018-07-31 22:23:29,092][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_1 - 10_folds.train_5.predict)=94.56%\n",
      "[ 2018-07-31 22:23:31,850][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_1 - 10_folds.train_6.predict)=95.24%\n",
      "[ 2018-07-31 22:23:34,160][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_1 - 10_folds.train_7.predict)=96.94%\n",
      "[ 2018-07-31 22:23:36,847][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_1 - 10_folds.train_8.predict)=93.88%\n",
      "[ 2018-07-31 22:23:39,498][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_1 - 10_folds.train_9.predict)=96.26%\n",
      "[ 2018-07-31 22:23:39,894][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_1 - 10_folds.train_cv.predict)=95.62%\n",
      "[ 2018-07-31 22:23:39,896][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_1 - 10_folds.test.predict)=94.62%\n",
      "[ 2018-07-31 22:23:40,005][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_2 - 10_folds.train_0.predict)=95.59%\n",
      "[ 2018-07-31 22:23:40,122][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_2 - 10_folds.train_1.predict)=95.25%\n",
      "[ 2018-07-31 22:23:40,202][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_2 - 10_folds.train_2.predict)=95.25%\n",
      "[ 2018-07-31 22:23:40,309][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_2 - 10_folds.train_3.predict)=97.29%\n",
      "[ 2018-07-31 22:23:40,457][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_2 - 10_folds.train_4.predict)=95.24%\n",
      "[ 2018-07-31 22:23:40,575][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_2 - 10_folds.train_5.predict)=95.92%\n",
      "[ 2018-07-31 22:23:40,709][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_2 - 10_folds.train_6.predict)=95.24%\n",
      "[ 2018-07-31 22:23:40,872][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_2 - 10_folds.train_7.predict)=96.60%\n",
      "[ 2018-07-31 22:23:41,061][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_2 - 10_folds.train_8.predict)=92.86%\n",
      "[ 2018-07-31 22:23:41,206][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_2 - 10_folds.train_9.predict)=96.94%\n",
      "[ 2018-07-31 22:23:41,213][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_2 - 10_folds.train_cv.predict)=95.62%\n",
      "[ 2018-07-31 22:23:41,225][kfold_wrapper.log_eval_metrics] Accuracy(layer_13 - estimator_2 - 10_folds.test.predict)=94.70%\n",
      "[ 2018-07-31 22:23:41,246][cascade_classifier.calc_accuracy] Accuracy(layer_13 - train.classifier_average)=95.62%\n",
      "[ 2018-07-31 22:23:41,261][cascade_classifier.calc_accuracy] Accuracy(layer_13 - test.classifier_average)=94.70%\n",
      "[ 2018-07-31 22:23:41,263][cascade_classifier.fit_transform] [Result][Optimal Level Detected] opt_layer_num=11, accuracy_train=95.62%, accuracy_test=94.62%\n"
     ]
    }
   ],
   "source": [
    "t0=time()\n",
    "# X_enc is the concatenated predict_proba result of each estimators of the last layer of the GCForest model\n",
    "    # X_enc.shape =\n",
    "    #   (n_datas, n_estimators * n_classes): If cascade is provided\n",
    "    #   (n_datas, n_estimators * n_classes, dimX, dimY): If only finegrained part is provided\n",
    "    # You can also pass X_test, y_test to fit_transform method, then the accracy on test data will be logged when training.\n",
    "X_train_enc, X_test_enc = gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test)\n",
    "    # WARNING: if you set gc.set_keep_model_in_mem(True), you would have to use\n",
    "    # gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test) to evaluate your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 22:23:41,399][cascade_classifier.transform] X_groups_test.shape=[(1263, 57)]\n",
      "[ 2018-07-31 22:23:41,407][cascade_classifier.transform] group_dims=[57]\n",
      "[ 2018-07-31 22:23:41,409][cascade_classifier.transform] X_test.shape=(1263, 57)\n",
      "[ 2018-07-31 22:23:41,410][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(1263, 57)\n",
      "[ 2018-07-31 22:23:52,208][cascade_classifier.transform] [layer=1] look_indexs=[0], X_cur_test.shape=(1263, 63)\n",
      "[ 2018-07-31 22:24:01,639][cascade_classifier.transform] [layer=2] look_indexs=[0], X_cur_test.shape=(1263, 63)\n",
      "[ 2018-07-31 22:24:13,446][cascade_classifier.transform] [layer=3] look_indexs=[0], X_cur_test.shape=(1263, 63)\n",
      "[ 2018-07-31 22:24:25,002][cascade_classifier.transform] [layer=4] look_indexs=[0], X_cur_test.shape=(1263, 63)\n",
      "[ 2018-07-31 22:24:34,744][cascade_classifier.transform] [layer=5] look_indexs=[0], X_cur_test.shape=(1263, 63)\n",
      "[ 2018-07-31 22:24:41,989][cascade_classifier.transform] [layer=6] look_indexs=[0], X_cur_test.shape=(1263, 63)\n",
      "[ 2018-07-31 22:24:49,843][cascade_classifier.transform] [layer=7] look_indexs=[0], X_cur_test.shape=(1263, 63)\n",
      "[ 2018-07-31 22:24:59,056][cascade_classifier.transform] [layer=8] look_indexs=[0], X_cur_test.shape=(1263, 63)\n",
      "[ 2018-07-31 22:25:07,550][cascade_classifier.transform] [layer=9] look_indexs=[0], X_cur_test.shape=(1263, 63)\n",
      "[ 2018-07-31 22:25:16,374][cascade_classifier.transform] [layer=10] look_indexs=[0], X_cur_test.shape=(1263, 63)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GCForest = 94.615994 %\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "y_pred = gc.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy of GCForest = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' Time ', '818.646', ' seconds')\n",
      "[[701  37]\n",
      " [ 31 494]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      0.95      0.95       738\n",
      "        1.0       0.93      0.94      0.94       525\n",
      "\n",
      "avg / total       0.95      0.95      0.95      1263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2649/2649 [==============================] - 4s 2ms/step - loss: 0.3502 - acc: 0.8784\n",
      "Epoch 2/50\n",
      "2649/2649 [==============================] - 2s 854us/step - loss: 0.2020 - acc: 0.9290\n",
      "Epoch 3/50\n",
      "2649/2649 [==============================] - 2s 877us/step - loss: 0.1893 - acc: 0.9298\n",
      "Epoch 4/50\n",
      "2649/2649 [==============================] - 2s 899us/step - loss: 0.1794 - acc: 0.9324\n",
      "Epoch 5/50\n",
      "2649/2649 [==============================] - 2s 921us/step - loss: 0.1623 - acc: 0.9404\n",
      "Epoch 6/50\n",
      "2649/2649 [==============================] - 2s 752us/step - loss: 0.1597 - acc: 0.9373\n",
      "Epoch 7/50\n",
      "2649/2649 [==============================] - 2s 786us/step - loss: 0.1466 - acc: 0.9449\n",
      "Epoch 8/50\n",
      "2649/2649 [==============================] - 2s 782us/step - loss: 0.1363 - acc: 0.9498 1s - l\n",
      "Epoch 9/50\n",
      "2649/2649 [==============================] - 2s 768us/step - loss: 0.1246 - acc: 0.9517\n",
      "Epoch 10/50\n",
      "2649/2649 [==============================] - 2s 689us/step - loss: 0.1176 - acc: 0.9558\n",
      "Epoch 11/50\n",
      "2649/2649 [==============================] - 2s 598us/step - loss: 0.1213 - acc: 0.9521\n",
      "Epoch 12/50\n",
      "2649/2649 [==============================] - 2s 680us/step - loss: 0.1265 - acc: 0.9524\n",
      "Epoch 13/50\n",
      "2649/2649 [==============================] - 2s 749us/step - loss: 0.1007 - acc: 0.9634\n",
      "Epoch 14/50\n",
      "2649/2649 [==============================] - 2s 687us/step - loss: 0.0919 - acc: 0.9656\n",
      "Epoch 15/50\n",
      "2649/2649 [==============================] - 2s 663us/step - loss: 0.0911 - acc: 0.9664\n",
      "Epoch 16/50\n",
      "2649/2649 [==============================] - 2s 740us/step - loss: 0.0825 - acc: 0.9675\n",
      "Epoch 17/50\n",
      "2649/2649 [==============================] - 2s 728us/step - loss: 0.0794 - acc: 0.9717\n",
      "Epoch 18/50\n",
      "2649/2649 [==============================] - 2s 744us/step - loss: 0.0848 - acc: 0.9679\n",
      "Epoch 19/50\n",
      "2649/2649 [==============================] - 2s 616us/step - loss: 0.0786 - acc: 0.9724\n",
      "Epoch 20/50\n",
      "2649/2649 [==============================] - 2s 676us/step - loss: 0.0734 - acc: 0.9743\n",
      "Epoch 21/50\n",
      "2649/2649 [==============================] - 2s 767us/step - loss: 0.0694 - acc: 0.9728 1s -\n",
      "Epoch 22/50\n",
      "2649/2649 [==============================] - 2s 657us/step - loss: 0.0654 - acc: 0.9770\n",
      "Epoch 23/50\n",
      "2649/2649 [==============================] - 2s 655us/step - loss: 0.0565 - acc: 0.9796\n",
      "Epoch 24/50\n",
      "2649/2649 [==============================] - 2s 642us/step - loss: 0.0616 - acc: 0.9758\n",
      "Epoch 25/50\n",
      "2649/2649 [==============================] - 2s 642us/step - loss: 0.0550 - acc: 0.9815\n",
      "Epoch 26/50\n",
      "2649/2649 [==============================] - 2s 725us/step - loss: 0.0516 - acc: 0.9819\n",
      "Epoch 27/50\n",
      "2649/2649 [==============================] - 2s 753us/step - loss: 0.0574 - acc: 0.9792\n",
      "Epoch 28/50\n",
      "2649/2649 [==============================] - 2s 695us/step - loss: 0.0485 - acc: 0.9830\n",
      "Epoch 29/50\n",
      "2649/2649 [==============================] - 2s 704us/step - loss: 0.0436 - acc: 0.9830\n",
      "Epoch 30/50\n",
      "2649/2649 [==============================] - 2s 693us/step - loss: 0.0406 - acc: 0.9864\n",
      "Epoch 31/50\n",
      "2649/2649 [==============================] - 2s 690us/step - loss: 0.0423 - acc: 0.9841\n",
      "Epoch 32/50\n",
      "2649/2649 [==============================] - 2s 756us/step - loss: 0.0433 - acc: 0.9838\n",
      "Epoch 33/50\n",
      "2649/2649 [==============================] - 2s 860us/step - loss: 0.0331 - acc: 0.9894\n",
      "Epoch 34/50\n",
      "2649/2649 [==============================] - 3s 966us/step - loss: 0.0297 - acc: 0.9894\n",
      "Epoch 35/50\n",
      "2649/2649 [==============================] - 3s 944us/step - loss: 0.0386 - acc: 0.9875\n",
      "Epoch 36/50\n",
      "2649/2649 [==============================] - 3s 978us/step - loss: 0.0319 - acc: 0.9875\n",
      "Epoch 37/50\n",
      "2649/2649 [==============================] - 2s 795us/step - loss: 0.0405 - acc: 0.9875\n",
      "Epoch 38/50\n",
      "2649/2649 [==============================] - 2s 674us/step - loss: 0.0329 - acc: 0.9891\n",
      "Epoch 39/50\n",
      "2649/2649 [==============================] - 2s 655us/step - loss: 0.0279 - acc: 0.9909\n",
      "Epoch 40/50\n",
      "2649/2649 [==============================] - 2s 785us/step - loss: 0.0277 - acc: 0.9891\n",
      "Epoch 41/50\n",
      "2649/2649 [==============================] - 2s 773us/step - loss: 0.0288 - acc: 0.9898\n",
      "Epoch 42/50\n",
      "2649/2649 [==============================] - 2s 768us/step - loss: 0.0346 - acc: 0.9883\n",
      "Epoch 43/50\n",
      "2649/2649 [==============================] - 2s 717us/step - loss: 0.0277 - acc: 0.9894\n",
      "Epoch 44/50\n",
      "2649/2649 [==============================] - 2s 630us/step - loss: 0.0258 - acc: 0.9909\n",
      "Epoch 45/50\n",
      "2649/2649 [==============================] - 2s 682us/step - loss: 0.0327 - acc: 0.9879\n",
      "Epoch 46/50\n",
      "2649/2649 [==============================] - 2s 763us/step - loss: 0.0231 - acc: 0.9928\n",
      "Epoch 47/50\n",
      "2649/2649 [==============================] - 2s 787us/step - loss: 0.0218 - acc: 0.9924\n",
      "Epoch 48/50\n",
      "2649/2649 [==============================] - 2s 768us/step - loss: 0.0219 - acc: 0.9932\n",
      "Epoch 49/50\n",
      "2649/2649 [==============================] - 2s 866us/step - loss: 0.0200 - acc: 0.9928\n",
      "Epoch 50/50\n",
      "2649/2649 [==============================] - 2s 842us/step - loss: 0.0200 - acc: 0.9928\n",
      "295/295 [==============================] - 0s 641us/step\n",
      "Epoch 1/50\n",
      "2649/2649 [==============================] - 6s 2ms/step - loss: 0.3473 - acc: 0.8683\n",
      "Epoch 2/50\n",
      "2649/2649 [==============================] - 1s 513us/step - loss: 0.2073 - acc: 0.9264\n",
      "Epoch 3/50\n",
      "2649/2649 [==============================] - 2s 629us/step - loss: 0.1850 - acc: 0.9336\n",
      "Epoch 4/50\n",
      "2649/2649 [==============================] - 2s 635us/step - loss: 0.1742 - acc: 0.9336\n",
      "Epoch 5/50\n",
      "2649/2649 [==============================] - 2s 594us/step - loss: 0.1658 - acc: 0.9366\n",
      "Epoch 6/50\n",
      "2649/2649 [==============================] - 2s 656us/step - loss: 0.1558 - acc: 0.9385\n",
      "Epoch 7/50\n",
      "2649/2649 [==============================] - 2s 782us/step - loss: 0.1548 - acc: 0.9396\n",
      "Epoch 8/50\n",
      "2649/2649 [==============================] - 2s 788us/step - loss: 0.1433 - acc: 0.9453\n",
      "Epoch 9/50\n",
      "2649/2649 [==============================] - 2s 788us/step - loss: 0.1313 - acc: 0.9487\n",
      "Epoch 10/50\n",
      "2649/2649 [==============================] - 2s 858us/step - loss: 0.1215 - acc: 0.9558\n",
      "Epoch 11/50\n",
      "2649/2649 [==============================] - 3s 972us/step - loss: 0.1180 - acc: 0.9585\n",
      "Epoch 12/50\n",
      "2649/2649 [==============================] - 2s 923us/step - loss: 0.1046 - acc: 0.9607\n",
      "Epoch 13/50\n",
      "2649/2649 [==============================] - 2s 846us/step - loss: 0.1012 - acc: 0.9630\n",
      "Epoch 14/50\n",
      "2649/2649 [==============================] - 2s 721us/step - loss: 0.0907 - acc: 0.9664\n",
      "Epoch 15/50\n",
      "2649/2649 [==============================] - 2s 713us/step - loss: 0.0957 - acc: 0.9641\n",
      "Epoch 16/50\n",
      "2649/2649 [==============================] - 2s 764us/step - loss: 0.0830 - acc: 0.9687\n",
      "Epoch 17/50\n",
      "2649/2649 [==============================] - 2s 752us/step - loss: 0.0795 - acc: 0.9724\n",
      "Epoch 18/50\n",
      "2649/2649 [==============================] - 2s 742us/step - loss: 0.0692 - acc: 0.9747\n",
      "Epoch 19/50\n",
      "2649/2649 [==============================] - 2s 751us/step - loss: 0.0668 - acc: 0.9755\n",
      "Epoch 20/50\n",
      "2649/2649 [==============================] - 2s 747us/step - loss: 0.0639 - acc: 0.9762\n",
      "Epoch 21/50\n",
      "2649/2649 [==============================] - 2s 829us/step - loss: 0.0655 - acc: 0.9736\n",
      "Epoch 22/50\n",
      "2649/2649 [==============================] - 2s 776us/step - loss: 0.0627 - acc: 0.9766\n",
      "Epoch 23/50\n",
      "2649/2649 [==============================] - 2s 768us/step - loss: 0.0538 - acc: 0.9811\n",
      "Epoch 24/50\n",
      "2649/2649 [==============================] - 2s 713us/step - loss: 0.0495 - acc: 0.9830\n",
      "Epoch 25/50\n",
      "2649/2649 [==============================] - 2s 783us/step - loss: 0.0469 - acc: 0.9830\n",
      "Epoch 26/50\n",
      "2649/2649 [==============================] - 2s 735us/step - loss: 0.0506 - acc: 0.9811\n",
      "Epoch 27/50\n",
      "2649/2649 [==============================] - 2s 651us/step - loss: 0.0487 - acc: 0.9815\n",
      "Epoch 28/50\n",
      "2649/2649 [==============================] - 2s 639us/step - loss: 0.0473 - acc: 0.9849\n",
      "Epoch 29/50\n",
      "2649/2649 [==============================] - 2s 663us/step - loss: 0.0358 - acc: 0.9883\n",
      "Epoch 30/50\n",
      "2649/2649 [==============================] - 2s 777us/step - loss: 0.0434 - acc: 0.9834\n",
      "Epoch 31/50\n",
      "2649/2649 [==============================] - 2s 725us/step - loss: 0.0440 - acc: 0.9830\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2649/2649 [==============================] - 2s 666us/step - loss: 0.0388 - acc: 0.9841\n",
      "Epoch 33/50\n",
      "2649/2649 [==============================] - 2s 773us/step - loss: 0.0323 - acc: 0.9894\n",
      "Epoch 34/50\n",
      "2649/2649 [==============================] - 2s 812us/step - loss: 0.0288 - acc: 0.9902\n",
      "Epoch 35/50\n",
      "2649/2649 [==============================] - 2s 794us/step - loss: 0.0303 - acc: 0.9868 1s -\n",
      "Epoch 36/50\n",
      "2649/2649 [==============================] - 2s 776us/step - loss: 0.0328 - acc: 0.9887\n",
      "Epoch 37/50\n",
      "2649/2649 [==============================] - 2s 747us/step - loss: 0.0247 - acc: 0.9909 0s - loss: 0.0246 - acc: 0.\n",
      "Epoch 38/50\n",
      "2649/2649 [==============================] - 2s 878us/step - loss: 0.0259 - acc: 0.9921\n",
      "Epoch 39/50\n",
      "2649/2649 [==============================] - 2s 754us/step - loss: 0.0303 - acc: 0.9894\n",
      "Epoch 40/50\n",
      "2649/2649 [==============================] - 2s 898us/step - loss: 0.0285 - acc: 0.9909\n",
      "Epoch 41/50\n",
      "2649/2649 [==============================] - 2s 837us/step - loss: 0.0215 - acc: 0.9932\n",
      "Epoch 42/50\n",
      "2649/2649 [==============================] - 2s 819us/step - loss: 0.0290 - acc: 0.9909\n",
      "Epoch 43/50\n",
      "2649/2649 [==============================] - 2s 737us/step - loss: 0.0241 - acc: 0.9924\n",
      "Epoch 44/50\n",
      "2649/2649 [==============================] - 2s 741us/step - loss: 0.0256 - acc: 0.9913\n",
      "Epoch 45/50\n",
      "2649/2649 [==============================] - 2s 780us/step - loss: 0.0232 - acc: 0.9906\n",
      "Epoch 46/50\n",
      "2649/2649 [==============================] - 2s 703us/step - loss: 0.0297 - acc: 0.9909\n",
      "Epoch 47/50\n",
      "2649/2649 [==============================] - 2s 728us/step - loss: 0.0280 - acc: 0.9902\n",
      "Epoch 48/50\n",
      "2649/2649 [==============================] - 2s 660us/step - loss: 0.0282 - acc: 0.9898\n",
      "Epoch 49/50\n",
      "2649/2649 [==============================] - 2s 702us/step - loss: 0.0398 - acc: 0.9868\n",
      "Epoch 50/50\n",
      "2649/2649 [==============================] - 2s 652us/step - loss: 0.0202 - acc: 0.9936 0s - loss: 0.0201 - acc: \n",
      "295/295 [==============================] - 0s 295us/step\n",
      "Epoch 1/50\n",
      "2649/2649 [==============================] - 3s 1ms/step - loss: 0.3453 - acc: 0.8482\n",
      "Epoch 2/50\n",
      "2649/2649 [==============================] - 2s 607us/step - loss: 0.2156 - acc: 0.9234\n",
      "Epoch 3/50\n",
      "2649/2649 [==============================] - 2s 669us/step - loss: 0.1923 - acc: 0.9305\n",
      "Epoch 4/50\n",
      "2649/2649 [==============================] - 2s 661us/step - loss: 0.1719 - acc: 0.9385\n",
      "Epoch 5/50\n",
      "2649/2649 [==============================] - 2s 570us/step - loss: 0.1591 - acc: 0.9426\n",
      "Epoch 6/50\n",
      "2649/2649 [==============================] - 2s 606us/step - loss: 0.1560 - acc: 0.9411\n",
      "Epoch 7/50\n",
      "2649/2649 [==============================] - 2s 578us/step - loss: 0.1462 - acc: 0.9468\n",
      "Epoch 8/50\n",
      "2649/2649 [==============================] - 1s 533us/step - loss: 0.1372 - acc: 0.9464\n",
      "Epoch 9/50\n",
      "2649/2649 [==============================] - 2s 568us/step - loss: 0.1274 - acc: 0.9562\n",
      "Epoch 10/50\n",
      "2649/2649 [==============================] - 1s 560us/step - loss: 0.1256 - acc: 0.9517\n",
      "Epoch 11/50\n",
      "2649/2649 [==============================] - 2s 580us/step - loss: 0.1231 - acc: 0.9532\n",
      "Epoch 12/50\n",
      "2649/2649 [==============================] - 1s 566us/step - loss: 0.1136 - acc: 0.9566\n",
      "Epoch 13/50\n",
      "2649/2649 [==============================] - 2s 650us/step - loss: 0.0938 - acc: 0.9664\n",
      "Epoch 14/50\n",
      "2649/2649 [==============================] - 1s 546us/step - loss: 0.0906 - acc: 0.9687\n",
      "Epoch 15/50\n",
      "2649/2649 [==============================] - 2s 626us/step - loss: 0.0854 - acc: 0.9694\n",
      "Epoch 16/50\n",
      "2649/2649 [==============================] - 2s 683us/step - loss: 0.0776 - acc: 0.9736\n",
      "Epoch 17/50\n",
      "2649/2649 [==============================] - 2s 607us/step - loss: 0.0723 - acc: 0.9721\n",
      "Epoch 18/50\n",
      "2649/2649 [==============================] - 2s 668us/step - loss: 0.0821 - acc: 0.9694 1s - \n",
      "Epoch 19/50\n",
      "2649/2649 [==============================] - 2s 768us/step - loss: 0.0720 - acc: 0.9713\n",
      "Epoch 20/50\n",
      "2649/2649 [==============================] - 2s 680us/step - loss: 0.0601 - acc: 0.9819\n",
      "Epoch 21/50\n",
      "2649/2649 [==============================] - 2s 660us/step - loss: 0.0606 - acc: 0.9777\n",
      "Epoch 22/50\n",
      "2649/2649 [==============================] - 2s 808us/step - loss: 0.0547 - acc: 0.9800\n",
      "Epoch 23/50\n",
      "2649/2649 [==============================] - 2s 748us/step - loss: 0.0505 - acc: 0.9815\n",
      "Epoch 24/50\n",
      "2649/2649 [==============================] - 2s 718us/step - loss: 0.0453 - acc: 0.9860\n",
      "Epoch 25/50\n",
      "2649/2649 [==============================] - 2s 718us/step - loss: 0.0431 - acc: 0.9872\n",
      "Epoch 26/50\n",
      "2649/2649 [==============================] - 2s 632us/step - loss: 0.0409 - acc: 0.9879\n",
      "Epoch 27/50\n",
      "2649/2649 [==============================] - 2s 656us/step - loss: 0.0403 - acc: 0.9887\n",
      "Epoch 28/50\n",
      "2649/2649 [==============================] - 2s 677us/step - loss: 0.0483 - acc: 0.9838\n",
      "Epoch 29/50\n",
      "2649/2649 [==============================] - 2s 616us/step - loss: 0.0445 - acc: 0.9838\n",
      "Epoch 30/50\n",
      "2649/2649 [==============================] - 2s 569us/step - loss: 0.0346 - acc: 0.9872\n",
      "Epoch 31/50\n",
      "2649/2649 [==============================] - 1s 551us/step - loss: 0.0323 - acc: 0.9906\n",
      "Epoch 32/50\n",
      "2649/2649 [==============================] - 2s 664us/step - loss: 0.0284 - acc: 0.9913\n",
      "Epoch 33/50\n",
      "2649/2649 [==============================] - 2s 635us/step - loss: 0.0359 - acc: 0.9887\n",
      "Epoch 34/50\n",
      "2649/2649 [==============================] - 1s 547us/step - loss: 0.0278 - acc: 0.9921\n",
      "Epoch 35/50\n",
      "2649/2649 [==============================] - 1s 562us/step - loss: 0.0312 - acc: 0.9872\n",
      "Epoch 36/50\n",
      "2649/2649 [==============================] - 2s 581us/step - loss: 0.0343 - acc: 0.9883\n",
      "Epoch 37/50\n",
      "2649/2649 [==============================] - 2s 612us/step - loss: 0.0267 - acc: 0.9917\n",
      "Epoch 38/50\n",
      "2649/2649 [==============================] - 2s 653us/step - loss: 0.0295 - acc: 0.9909\n",
      "Epoch 39/50\n",
      "2649/2649 [==============================] - 2s 735us/step - loss: 0.0291 - acc: 0.9921\n",
      "Epoch 40/50\n",
      "2649/2649 [==============================] - 2s 721us/step - loss: 0.0252 - acc: 0.9932 1s - loss: 0.0286 - ETA: 0s - loss: 0.0263 - acc: 0.\n",
      "Epoch 41/50\n",
      "2649/2649 [==============================] - 2s 762us/step - loss: 0.0238 - acc: 0.9936\n",
      "Epoch 42/50\n",
      "2649/2649 [==============================] - 2s 775us/step - loss: 0.0219 - acc: 0.9928\n",
      "Epoch 43/50\n",
      "2649/2649 [==============================] - 2s 676us/step - loss: 0.0260 - acc: 0.9913\n",
      "Epoch 44/50\n",
      "2649/2649 [==============================] - 2s 629us/step - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 45/50\n",
      "2649/2649 [==============================] - 2s 707us/step - loss: 0.0379 - acc: 0.9853\n",
      "Epoch 46/50\n",
      "2649/2649 [==============================] - 2s 693us/step - loss: 0.0300 - acc: 0.9921\n",
      "Epoch 47/50\n",
      "2649/2649 [==============================] - 2s 606us/step - loss: 0.0268 - acc: 0.9928\n",
      "Epoch 48/50\n",
      "2649/2649 [==============================] - 2s 662us/step - loss: 0.0224 - acc: 0.9943\n",
      "Epoch 49/50\n",
      "2649/2649 [==============================] - 2s 629us/step - loss: 0.0233 - acc: 0.9928 0s - loss: 0.0302 - ac\n",
      "Epoch 50/50\n",
      "2649/2649 [==============================] - 1s 544us/step - loss: 0.0239 - acc: 0.9917\n",
      "295/295 [==============================] - 0s 437us/step\n",
      "Epoch 1/50\n",
      "2649/2649 [==============================] - 3s 946us/step - loss: 0.3857 - acc: 0.8214\n",
      "Epoch 2/50\n",
      "2649/2649 [==============================] - 2s 739us/step - loss: 0.2059 - acc: 0.9264\n",
      "Epoch 3/50\n",
      "2649/2649 [==============================] - 2s 739us/step - loss: 0.1982 - acc: 0.9249\n",
      "Epoch 4/50\n",
      "2649/2649 [==============================] - 2s 712us/step - loss: 0.1835 - acc: 0.9309\n",
      "Epoch 5/50\n",
      "2649/2649 [==============================] - 2s 725us/step - loss: 0.1742 - acc: 0.9354\n",
      "Epoch 6/50\n",
      "2649/2649 [==============================] - 2s 751us/step - loss: 0.1690 - acc: 0.9381\n",
      "Epoch 7/50\n",
      "2649/2649 [==============================] - 2s 691us/step - loss: 0.1516 - acc: 0.9415\n",
      "Epoch 8/50\n",
      "2649/2649 [==============================] - 2s 607us/step - loss: 0.1409 - acc: 0.9449\n",
      "Epoch 9/50\n",
      "2649/2649 [==============================] - 2s 669us/step - loss: 0.1409 - acc: 0.9411\n",
      "Epoch 10/50\n",
      "2649/2649 [==============================] - 2s 662us/step - loss: 0.1330 - acc: 0.9464\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2649/2649 [==============================] - 2s 614us/step - loss: 0.1179 - acc: 0.9570\n",
      "Epoch 12/50\n",
      "2649/2649 [==============================] - 2s 607us/step - loss: 0.1112 - acc: 0.9592\n",
      "Epoch 13/50\n",
      "2649/2649 [==============================] - 2s 708us/step - loss: 0.0995 - acc: 0.9641\n",
      "Epoch 14/50\n",
      "2649/2649 [==============================] - 2s 643us/step - loss: 0.0962 - acc: 0.9604\n",
      "Epoch 15/50\n",
      "2649/2649 [==============================] - 2s 661us/step - loss: 0.0919 - acc: 0.9656\n",
      "Epoch 16/50\n",
      "2649/2649 [==============================] - 1s 538us/step - loss: 0.0863 - acc: 0.9706\n",
      "Epoch 17/50\n",
      "2649/2649 [==============================] - 1s 512us/step - loss: 0.0755 - acc: 0.9728\n",
      "Epoch 18/50\n",
      "2649/2649 [==============================] - 1s 566us/step - loss: 0.0706 - acc: 0.9777\n",
      "Epoch 19/50\n",
      "2649/2649 [==============================] - 2s 567us/step - loss: 0.0851 - acc: 0.9713\n",
      "Epoch 20/50\n",
      "2649/2649 [==============================] - 2s 619us/step - loss: 0.0658 - acc: 0.9758\n",
      "Epoch 21/50\n",
      "2649/2649 [==============================] - 2s 669us/step - loss: 0.0658 - acc: 0.9781\n",
      "Epoch 22/50\n",
      "2649/2649 [==============================] - 2s 602us/step - loss: 0.0692 - acc: 0.9755\n",
      "Epoch 23/50\n",
      "2649/2649 [==============================] - 2s 590us/step - loss: 0.0594 - acc: 0.9800\n",
      "Epoch 24/50\n",
      "2649/2649 [==============================] - 2s 642us/step - loss: 0.0551 - acc: 0.9815\n",
      "Epoch 25/50\n",
      "2649/2649 [==============================] - 2s 671us/step - loss: 0.0479 - acc: 0.9819\n",
      "Epoch 26/50\n",
      "2649/2649 [==============================] - 2s 604us/step - loss: 0.0468 - acc: 0.9841\n",
      "Epoch 27/50\n",
      "2649/2649 [==============================] - 2s 651us/step - loss: 0.0440 - acc: 0.9830\n",
      "Epoch 28/50\n",
      "2649/2649 [==============================] - 2s 629us/step - loss: 0.0422 - acc: 0.9849\n",
      "Epoch 29/50\n",
      "2649/2649 [==============================] - 2s 622us/step - loss: 0.0360 - acc: 0.9891 1s \n",
      "Epoch 30/50\n",
      "2649/2649 [==============================] - 2s 593us/step - loss: 0.0402 - acc: 0.9868\n",
      "Epoch 31/50\n",
      "2649/2649 [==============================] - 2s 671us/step - loss: 0.0376 - acc: 0.9864\n",
      "Epoch 32/50\n",
      "2649/2649 [==============================] - 2s 622us/step - loss: 0.0337 - acc: 0.9891\n",
      "Epoch 33/50\n",
      "2649/2649 [==============================] - 1s 556us/step - loss: 0.0352 - acc: 0.9891\n",
      "Epoch 34/50\n",
      "2649/2649 [==============================] - 2s 593us/step - loss: 0.0341 - acc: 0.9891\n",
      "Epoch 35/50\n",
      "2649/2649 [==============================] - 2s 646us/step - loss: 0.0354 - acc: 0.9883\n",
      "Epoch 36/50\n",
      "2649/2649 [==============================] - 2s 654us/step - loss: 0.0321 - acc: 0.9887\n",
      "Epoch 37/50\n",
      "2649/2649 [==============================] - 2s 737us/step - loss: 0.0334 - acc: 0.9894\n",
      "Epoch 38/50\n",
      "2649/2649 [==============================] - 2s 712us/step - loss: 0.0362 - acc: 0.9868\n",
      "Epoch 39/50\n",
      "2649/2649 [==============================] - 2s 758us/step - loss: 0.0398 - acc: 0.9841\n",
      "Epoch 40/50\n",
      "2649/2649 [==============================] - 2s 720us/step - loss: 0.0357 - acc: 0.9864\n",
      "Epoch 41/50\n",
      "2649/2649 [==============================] - 2s 791us/step - loss: 0.0296 - acc: 0.9909\n",
      "Epoch 42/50\n",
      "2649/2649 [==============================] - 2s 597us/step - loss: 0.0276 - acc: 0.9917\n",
      "Epoch 43/50\n",
      "2649/2649 [==============================] - 2s 591us/step - loss: 0.0274 - acc: 0.9894\n",
      "Epoch 44/50\n",
      "2649/2649 [==============================] - 2s 574us/step - loss: 0.0264 - acc: 0.9898\n",
      "Epoch 45/50\n",
      "2649/2649 [==============================] - 2s 625us/step - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 46/50\n",
      "2649/2649 [==============================] - 2s 641us/step - loss: 0.0289 - acc: 0.9894\n",
      "Epoch 47/50\n",
      "2649/2649 [==============================] - 2s 682us/step - loss: 0.0295 - acc: 0.9894\n",
      "Epoch 48/50\n",
      "2649/2649 [==============================] - 2s 664us/step - loss: 0.0289 - acc: 0.9909\n",
      "Epoch 49/50\n",
      "2649/2649 [==============================] - 2s 642us/step - loss: 0.0289 - acc: 0.9898\n",
      "Epoch 50/50\n",
      "2649/2649 [==============================] - 2s 605us/step - loss: 0.0323 - acc: 0.9891\n",
      "295/295 [==============================] - 0s 487us/step\n",
      "Epoch 1/50\n",
      "2650/2650 [==============================] - 4s 1ms/step - loss: 0.3399 - acc: 0.8528\n",
      "Epoch 2/50\n",
      "2650/2650 [==============================] - 2s 647us/step - loss: 0.1973 - acc: 0.9249\n",
      "Epoch 3/50\n",
      "2650/2650 [==============================] - 2s 629us/step - loss: 0.1799 - acc: 0.9336\n",
      "Epoch 4/50\n",
      "2650/2650 [==============================] - 2s 574us/step - loss: 0.1694 - acc: 0.9351\n",
      "Epoch 5/50\n",
      "2650/2650 [==============================] - 2s 640us/step - loss: 0.1629 - acc: 0.9396\n",
      "Epoch 6/50\n",
      "2650/2650 [==============================] - 2s 607us/step - loss: 0.1489 - acc: 0.9442\n",
      "Epoch 7/50\n",
      "2650/2650 [==============================] - 2s 589us/step - loss: 0.1411 - acc: 0.9438\n",
      "Epoch 8/50\n",
      "2650/2650 [==============================] - 2s 627us/step - loss: 0.1312 - acc: 0.9502\n",
      "Epoch 9/50\n",
      "2650/2650 [==============================] - 2s 595us/step - loss: 0.1191 - acc: 0.9551\n",
      "Epoch 10/50\n",
      "2650/2650 [==============================] - 2s 667us/step - loss: 0.1177 - acc: 0.9566\n",
      "Epoch 11/50\n",
      "2650/2650 [==============================] - 1s 540us/step - loss: 0.1049 - acc: 0.9608\n",
      "Epoch 12/50\n",
      "2650/2650 [==============================] - 2s 603us/step - loss: 0.0991 - acc: 0.9615\n",
      "Epoch 13/50\n",
      "2650/2650 [==============================] - 2s 624us/step - loss: 0.0938 - acc: 0.9623\n",
      "Epoch 14/50\n",
      "2650/2650 [==============================] - 2s 574us/step - loss: 0.0894 - acc: 0.9668\n",
      "Epoch 15/50\n",
      "2650/2650 [==============================] - 2s 618us/step - loss: 0.0893 - acc: 0.9668\n",
      "Epoch 16/50\n",
      "2650/2650 [==============================] - 1s 554us/step - loss: 0.0710 - acc: 0.9770\n",
      "Epoch 17/50\n",
      "2650/2650 [==============================] - 2s 570us/step - loss: 0.0703 - acc: 0.9755\n",
      "Epoch 18/50\n",
      "2650/2650 [==============================] - 2s 659us/step - loss: 0.0666 - acc: 0.9774\n",
      "Epoch 19/50\n",
      "2650/2650 [==============================] - 2s 636us/step - loss: 0.0692 - acc: 0.9751\n",
      "Epoch 20/50\n",
      "2650/2650 [==============================] - 2s 686us/step - loss: 0.0562 - acc: 0.9811\n",
      "Epoch 21/50\n",
      "2650/2650 [==============================] - 2s 719us/step - loss: 0.0536 - acc: 0.9808\n",
      "Epoch 22/50\n",
      "2650/2650 [==============================] - 2s 617us/step - loss: 0.0494 - acc: 0.9830\n",
      "Epoch 23/50\n",
      "2650/2650 [==============================] - 2s 696us/step - loss: 0.0515 - acc: 0.9830\n",
      "Epoch 24/50\n",
      "2650/2650 [==============================] - 2s 719us/step - loss: 0.0463 - acc: 0.9853\n",
      "Epoch 25/50\n",
      "2650/2650 [==============================] - 2s 681us/step - loss: 0.0408 - acc: 0.9879\n",
      "Epoch 26/50\n",
      "2650/2650 [==============================] - 2s 630us/step - loss: 0.0441 - acc: 0.9849\n",
      "Epoch 27/50\n",
      "2650/2650 [==============================] - 2s 581us/step - loss: 0.0374 - acc: 0.9875\n",
      "Epoch 28/50\n",
      "2650/2650 [==============================] - 1s 526us/step - loss: 0.0534 - acc: 0.9830\n",
      "Epoch 29/50\n",
      "2650/2650 [==============================] - 1s 543us/step - loss: 0.0353 - acc: 0.9887\n",
      "Epoch 30/50\n",
      "2650/2650 [==============================] - 1s 527us/step - loss: 0.0339 - acc: 0.9887\n",
      "Epoch 31/50\n",
      "2650/2650 [==============================] - 1s 514us/step - loss: 0.0320 - acc: 0.9883\n",
      "Epoch 32/50\n",
      "2650/2650 [==============================] - 1s 515us/step - loss: 0.0363 - acc: 0.9875\n",
      "Epoch 33/50\n",
      "2650/2650 [==============================] - 1s 516us/step - loss: 0.0384 - acc: 0.9849\n",
      "Epoch 34/50\n",
      "2650/2650 [==============================] - 2s 574us/step - loss: 0.0389 - acc: 0.9868\n",
      "Epoch 35/50\n",
      "2650/2650 [==============================] - 1s 548us/step - loss: 0.0315 - acc: 0.9894\n",
      "Epoch 36/50\n",
      "2650/2650 [==============================] - 2s 587us/step - loss: 0.0268 - acc: 0.9917\n",
      "Epoch 37/50\n",
      "2650/2650 [==============================] - 1s 549us/step - loss: 0.0288 - acc: 0.9909\n",
      "Epoch 38/50\n",
      "2650/2650 [==============================] - 2s 599us/step - loss: 0.0277 - acc: 0.9913\n",
      "Epoch 39/50\n",
      "2650/2650 [==============================] - 2s 586us/step - loss: 0.0270 - acc: 0.9928\n",
      "Epoch 40/50\n",
      "2650/2650 [==============================] - 2s 619us/step - loss: 0.0236 - acc: 0.9913\n",
      "Epoch 41/50\n",
      "2650/2650 [==============================] - 2s 645us/step - loss: 0.0252 - acc: 0.9906\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2650/2650 [==============================] - 2s 619us/step - loss: 0.0245 - acc: 0.9925\n",
      "Epoch 43/50\n",
      "2650/2650 [==============================] - 1s 564us/step - loss: 0.0202 - acc: 0.9936\n",
      "Epoch 44/50\n",
      "2650/2650 [==============================] - 2s 598us/step - loss: 0.0231 - acc: 0.9928\n",
      "Epoch 45/50\n",
      "2650/2650 [==============================] - 1s 551us/step - loss: 0.0226 - acc: 0.9943\n",
      "Epoch 46/50\n",
      "2650/2650 [==============================] - 1s 566us/step - loss: 0.0223 - acc: 0.9932\n",
      "Epoch 47/50\n",
      "2650/2650 [==============================] - 1s 488us/step - loss: 0.0248 - acc: 0.9921\n",
      "Epoch 48/50\n",
      "2650/2650 [==============================] - 1s 463us/step - loss: 0.0331 - acc: 0.9883\n",
      "Epoch 49/50\n",
      "2650/2650 [==============================] - 1s 453us/step - loss: 0.0228 - acc: 0.9936\n",
      "Epoch 50/50\n",
      "2650/2650 [==============================] - 1s 457us/step - loss: 0.0210 - acc: 0.9932\n",
      "294/294 [==============================] - 0s 517us/step\n",
      "Epoch 1/50\n",
      "2650/2650 [==============================] - 2s 688us/step - loss: 0.3361 - acc: 0.8528\n",
      "Epoch 2/50\n",
      "2650/2650 [==============================] - 1s 402us/step - loss: 0.2057 - acc: 0.9234\n",
      "Epoch 3/50\n",
      "2650/2650 [==============================] - 1s 398us/step - loss: 0.1809 - acc: 0.9325\n",
      "Epoch 4/50\n",
      "2650/2650 [==============================] - ETA: 0s - loss: 0.1716 - acc: 0.934 - 1s 422us/step - loss: 0.1694 - acc: 0.9362\n",
      "Epoch 5/50\n",
      "2650/2650 [==============================] - 1s 402us/step - loss: 0.1686 - acc: 0.9366\n",
      "Epoch 6/50\n",
      "2650/2650 [==============================] - 1s 425us/step - loss: 0.1492 - acc: 0.9449\n",
      "Epoch 7/50\n",
      "2650/2650 [==============================] - 1s 366us/step - loss: 0.1479 - acc: 0.9468\n",
      "Epoch 8/50\n",
      "2650/2650 [==============================] - 1s 325us/step - loss: 0.1352 - acc: 0.9475\n",
      "Epoch 9/50\n",
      "2650/2650 [==============================] - 1s 333us/step - loss: 0.1281 - acc: 0.9528\n",
      "Epoch 10/50\n",
      "2650/2650 [==============================] - 1s 411us/step - loss: 0.1191 - acc: 0.9570\n",
      "Epoch 11/50\n",
      "2650/2650 [==============================] - 1s 412us/step - loss: 0.1083 - acc: 0.9592\n",
      "Epoch 12/50\n",
      "2650/2650 [==============================] - 1s 445us/step - loss: 0.1006 - acc: 0.9615\n",
      "Epoch 13/50\n",
      "2650/2650 [==============================] - 1s 459us/step - loss: 0.1000 - acc: 0.9645\n",
      "Epoch 14/50\n",
      "2650/2650 [==============================] - 1s 434us/step - loss: 0.0914 - acc: 0.9660\n",
      "Epoch 15/50\n",
      "2650/2650 [==============================] - 1s 462us/step - loss: 0.0818 - acc: 0.9694\n",
      "Epoch 16/50\n",
      "2650/2650 [==============================] - 1s 473us/step - loss: 0.0745 - acc: 0.9758\n",
      "Epoch 17/50\n",
      "2650/2650 [==============================] - 1s 479us/step - loss: 0.0708 - acc: 0.9740\n",
      "Epoch 18/50\n",
      "2650/2650 [==============================] - 1s 462us/step - loss: 0.0645 - acc: 0.9789\n",
      "Epoch 19/50\n",
      "2650/2650 [==============================] - 1s 466us/step - loss: 0.0672 - acc: 0.9762\n",
      "Epoch 20/50\n",
      "2650/2650 [==============================] - 1s 475us/step - loss: 0.0672 - acc: 0.9766\n",
      "Epoch 21/50\n",
      "2650/2650 [==============================] - 1s 418us/step - loss: 0.0637 - acc: 0.9762\n",
      "Epoch 22/50\n",
      "2650/2650 [==============================] - 1s 400us/step - loss: 0.0514 - acc: 0.9823\n",
      "Epoch 23/50\n",
      "2650/2650 [==============================] - 1s 406us/step - loss: 0.0570 - acc: 0.9800\n",
      "Epoch 24/50\n",
      "2650/2650 [==============================] - 1s 421us/step - loss: 0.0494 - acc: 0.9842\n",
      "Epoch 25/50\n",
      "2650/2650 [==============================] - 1s 397us/step - loss: 0.0443 - acc: 0.9845\n",
      "Epoch 26/50\n",
      "2650/2650 [==============================] - 1s 406us/step - loss: 0.0428 - acc: 0.9853\n",
      "Epoch 27/50\n",
      "2650/2650 [==============================] - 1s 409us/step - loss: 0.0447 - acc: 0.9849\n",
      "Epoch 28/50\n",
      "2650/2650 [==============================] - 1s 403us/step - loss: 0.0389 - acc: 0.9879\n",
      "Epoch 29/50\n",
      "2650/2650 [==============================] - 1s 404us/step - loss: 0.0349 - acc: 0.9879\n",
      "Epoch 30/50\n",
      "2650/2650 [==============================] - 1s 403us/step - loss: 0.0364 - acc: 0.9875\n",
      "Epoch 31/50\n",
      "2650/2650 [==============================] - 1s 442us/step - loss: 0.0375 - acc: 0.9853\n",
      "Epoch 32/50\n",
      "2650/2650 [==============================] - 1s 413us/step - loss: 0.0342 - acc: 0.9868\n",
      "Epoch 33/50\n",
      "2650/2650 [==============================] - 1s 407us/step - loss: 0.0341 - acc: 0.9872\n",
      "Epoch 34/50\n",
      "2650/2650 [==============================] - 1s 400us/step - loss: 0.0285 - acc: 0.9898\n",
      "Epoch 35/50\n",
      "2650/2650 [==============================] - 1s 413us/step - loss: 0.0313 - acc: 0.9902\n",
      "Epoch 36/50\n",
      "2650/2650 [==============================] - 1s 417us/step - loss: 0.0321 - acc: 0.9887\n",
      "Epoch 37/50\n",
      "2650/2650 [==============================] - 1s 406us/step - loss: 0.0420 - acc: 0.9879\n",
      "Epoch 38/50\n",
      "2650/2650 [==============================] - 1s 429us/step - loss: 0.0310 - acc: 0.9879\n",
      "Epoch 39/50\n",
      "2650/2650 [==============================] - 1s 408us/step - loss: 0.0255 - acc: 0.9913\n",
      "Epoch 40/50\n",
      "2650/2650 [==============================] - 1s 395us/step - loss: 0.0241 - acc: 0.9913\n",
      "Epoch 41/50\n",
      "2650/2650 [==============================] - 1s 410us/step - loss: 0.0223 - acc: 0.9928\n",
      "Epoch 42/50\n",
      "2650/2650 [==============================] - 1s 404us/step - loss: 0.0212 - acc: 0.9932\n",
      "Epoch 43/50\n",
      "2650/2650 [==============================] - 1s 416us/step - loss: 0.0279 - acc: 0.9921\n",
      "Epoch 44/50\n",
      "2650/2650 [==============================] - 1s 405us/step - loss: 0.0198 - acc: 0.9936\n",
      "Epoch 45/50\n",
      "2650/2650 [==============================] - 1s 405us/step - loss: 0.0281 - acc: 0.9909\n",
      "Epoch 46/50\n",
      "2650/2650 [==============================] - 1s 407us/step - loss: 0.0221 - acc: 0.9925\n",
      "Epoch 47/50\n",
      "2650/2650 [==============================] - 1s 396us/step - loss: 0.0209 - acc: 0.9932\n",
      "Epoch 48/50\n",
      "2650/2650 [==============================] - 1s 405us/step - loss: 0.0246 - acc: 0.9921\n",
      "Epoch 49/50\n",
      "2650/2650 [==============================] - 1s 412us/step - loss: 0.0266 - acc: 0.9909\n",
      "Epoch 50/50\n",
      "2650/2650 [==============================] - 1s 417us/step - loss: 0.0300 - acc: 0.9913\n",
      "294/294 [==============================] - 0s 541us/step\n",
      "Epoch 1/50\n",
      "2650/2650 [==============================] - 2s 718us/step - loss: 0.3436 - acc: 0.8547\n",
      "Epoch 2/50\n",
      "2650/2650 [==============================] - 1s 421us/step - loss: 0.2000 - acc: 0.9287\n",
      "Epoch 3/50\n",
      "2650/2650 [==============================] - 1s 409us/step - loss: 0.1876 - acc: 0.9249\n",
      "Epoch 4/50\n",
      "2650/2650 [==============================] - 1s 405us/step - loss: 0.1716 - acc: 0.9358\n",
      "Epoch 5/50\n",
      "2650/2650 [==============================] - 1s 413us/step - loss: 0.1633 - acc: 0.9423\n",
      "Epoch 6/50\n",
      "2650/2650 [==============================] - 1s 400us/step - loss: 0.1561 - acc: 0.9415\n",
      "Epoch 7/50\n",
      "2650/2650 [==============================] - 1s 413us/step - loss: 0.1473 - acc: 0.9457\n",
      "Epoch 8/50\n",
      "2650/2650 [==============================] - 1s 404us/step - loss: 0.1440 - acc: 0.9457\n",
      "Epoch 9/50\n",
      "2650/2650 [==============================] - 1s 407us/step - loss: 0.1352 - acc: 0.9509\n",
      "Epoch 10/50\n",
      "2650/2650 [==============================] - 1s 409us/step - loss: 0.1268 - acc: 0.9498\n",
      "Epoch 11/50\n",
      "2650/2650 [==============================] - 1s 399us/step - loss: 0.1153 - acc: 0.9581\n",
      "Epoch 12/50\n",
      "2650/2650 [==============================] - 1s 399us/step - loss: 0.1068 - acc: 0.9596\n",
      "Epoch 13/50\n",
      "2650/2650 [==============================] - 1s 403us/step - loss: 0.1068 - acc: 0.9574\n",
      "Epoch 14/50\n",
      "2650/2650 [==============================] - 1s 462us/step - loss: 0.0962 - acc: 0.9581\n",
      "Epoch 15/50\n",
      "2650/2650 [==============================] - 1s 455us/step - loss: 0.0895 - acc: 0.9642\n",
      "Epoch 16/50\n",
      "2650/2650 [==============================] - 1s 459us/step - loss: 0.0868 - acc: 0.9653\n",
      "Epoch 17/50\n",
      "2650/2650 [==============================] - 1s 461us/step - loss: 0.0877 - acc: 0.9675\n",
      "Epoch 18/50\n",
      "2650/2650 [==============================] - 1s 467us/step - loss: 0.0792 - acc: 0.9702\n",
      "Epoch 19/50\n",
      "2650/2650 [==============================] - 1s 482us/step - loss: 0.0718 - acc: 0.9725\n",
      "Epoch 20/50\n",
      "2650/2650 [==============================] - 1s 476us/step - loss: 0.0678 - acc: 0.9751\n",
      "Epoch 21/50\n",
      "2650/2650 [==============================] - 1s 466us/step - loss: 0.0653 - acc: 0.9740\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2650/2650 [==============================] - 1s 418us/step - loss: 0.0562 - acc: 0.9792\n",
      "Epoch 23/50\n",
      "2650/2650 [==============================] - 1s 424us/step - loss: 0.0596 - acc: 0.9758\n",
      "Epoch 24/50\n",
      "2650/2650 [==============================] - 1s 414us/step - loss: 0.0523 - acc: 0.9811\n",
      "Epoch 25/50\n",
      "2650/2650 [==============================] - 1s 403us/step - loss: 0.0505 - acc: 0.9819\n",
      "Epoch 26/50\n",
      "2650/2650 [==============================] - 1s 419us/step - loss: 0.0463 - acc: 0.9849\n",
      "Epoch 27/50\n",
      "2650/2650 [==============================] - 1s 414us/step - loss: 0.0458 - acc: 0.9823\n",
      "Epoch 28/50\n",
      "2650/2650 [==============================] - 1s 412us/step - loss: 0.0457 - acc: 0.9838\n",
      "Epoch 29/50\n",
      "2650/2650 [==============================] - 1s 406us/step - loss: 0.0440 - acc: 0.9849\n",
      "Epoch 30/50\n",
      "2650/2650 [==============================] - 1s 415us/step - loss: 0.0387 - acc: 0.9887\n",
      "Epoch 31/50\n",
      "2650/2650 [==============================] - 1s 408us/step - loss: 0.0393 - acc: 0.9879\n",
      "Epoch 32/50\n",
      "2650/2650 [==============================] - 1s 405us/step - loss: 0.0357 - acc: 0.9875\n",
      "Epoch 33/50\n",
      "2650/2650 [==============================] - 1s 436us/step - loss: 0.0343 - acc: 0.9898\n",
      "Epoch 34/50\n",
      "2650/2650 [==============================] - 1s 418us/step - loss: 0.0317 - acc: 0.9894\n",
      "Epoch 35/50\n",
      "2650/2650 [==============================] - 1s 427us/step - loss: 0.0334 - acc: 0.9898\n",
      "Epoch 36/50\n",
      "2650/2650 [==============================] - 1s 424us/step - loss: 0.0398 - acc: 0.9875\n",
      "Epoch 37/50\n",
      "2650/2650 [==============================] - 1s 419us/step - loss: 0.0349 - acc: 0.9906\n",
      "Epoch 38/50\n",
      "2650/2650 [==============================] - 1s 416us/step - loss: 0.0351 - acc: 0.9898\n",
      "Epoch 39/50\n",
      "2650/2650 [==============================] - 1s 431us/step - loss: 0.0273 - acc: 0.9913\n",
      "Epoch 40/50\n",
      "2650/2650 [==============================] - 1s 417us/step - loss: 0.0344 - acc: 0.9883\n",
      "Epoch 41/50\n",
      "2650/2650 [==============================] - 1s 406us/step - loss: 0.0233 - acc: 0.9932\n",
      "Epoch 42/50\n",
      "2650/2650 [==============================] - 1s 416us/step - loss: 0.0331 - acc: 0.9902\n",
      "Epoch 43/50\n",
      "2650/2650 [==============================] - 1s 413us/step - loss: 0.0344 - acc: 0.9875\n",
      "Epoch 44/50\n",
      "2650/2650 [==============================] - 1s 399us/step - loss: 0.0283 - acc: 0.9913\n",
      "Epoch 45/50\n",
      "2650/2650 [==============================] - 1s 406us/step - loss: 0.0247 - acc: 0.9928\n",
      "Epoch 46/50\n",
      "2650/2650 [==============================] - 1s 410us/step - loss: 0.0287 - acc: 0.9917\n",
      "Epoch 47/50\n",
      "2650/2650 [==============================] - 1s 402us/step - loss: 0.0219 - acc: 0.9925\n",
      "Epoch 48/50\n",
      "2650/2650 [==============================] - 1s 400us/step - loss: 0.0236 - acc: 0.9925\n",
      "Epoch 49/50\n",
      "2650/2650 [==============================] - 1s 395us/step - loss: 0.0261 - acc: 0.9909\n",
      "Epoch 50/50\n",
      "2650/2650 [==============================] - 1s 411us/step - loss: 0.0220 - acc: 0.9936\n",
      "294/294 [==============================] - 0s 664us/step\n",
      "Epoch 1/50\n",
      "2650/2650 [==============================] - 2s 846us/step - loss: 0.3557 - acc: 0.8528\n",
      "Epoch 2/50\n",
      "2650/2650 [==============================] - 1s 410us/step - loss: 0.2000 - acc: 0.9219\n",
      "Epoch 3/50\n",
      "2650/2650 [==============================] - 1s 414us/step - loss: 0.1891 - acc: 0.9294\n",
      "Epoch 4/50\n",
      "2650/2650 [==============================] - 1s 414us/step - loss: 0.1683 - acc: 0.9389\n",
      "Epoch 5/50\n",
      "2650/2650 [==============================] - 1s 408us/step - loss: 0.1698 - acc: 0.9370\n",
      "Epoch 6/50\n",
      "2650/2650 [==============================] - 1s 421us/step - loss: 0.1491 - acc: 0.9434\n",
      "Epoch 7/50\n",
      "2650/2650 [==============================] - 1s 404us/step - loss: 0.1406 - acc: 0.9483\n",
      "Epoch 8/50\n",
      "2650/2650 [==============================] - 1s 401us/step - loss: 0.1452 - acc: 0.9445\n",
      "Epoch 9/50\n",
      "2650/2650 [==============================] - 1s 415us/step - loss: 0.1265 - acc: 0.9532\n",
      "Epoch 10/50\n",
      "2650/2650 [==============================] - 1s 418us/step - loss: 0.1123 - acc: 0.9608\n",
      "Epoch 11/50\n",
      "2650/2650 [==============================] - 1s 408us/step - loss: 0.1066 - acc: 0.9608\n",
      "Epoch 12/50\n",
      "2650/2650 [==============================] - 1s 401us/step - loss: 0.1088 - acc: 0.9596\n",
      "Epoch 13/50\n",
      "2650/2650 [==============================] - 1s 402us/step - loss: 0.0914 - acc: 0.9691\n",
      "Epoch 14/50\n",
      "2650/2650 [==============================] - 1s 333us/step - loss: 0.0940 - acc: 0.9645\n",
      "Epoch 15/50\n",
      "2650/2650 [==============================] - 1s 328us/step - loss: 0.0822 - acc: 0.9713\n",
      "Epoch 16/50\n",
      "2650/2650 [==============================] - 1s 427us/step - loss: 0.0718 - acc: 0.9740\n",
      "Epoch 17/50\n",
      "2650/2650 [==============================] - 1s 455us/step - loss: 0.0788 - acc: 0.9706\n",
      "Epoch 18/50\n",
      "2650/2650 [==============================] - 1s 427us/step - loss: 0.0701 - acc: 0.9770\n",
      "Epoch 19/50\n",
      "2650/2650 [==============================] - 1s 441us/step - loss: 0.0600 - acc: 0.9823\n",
      "Epoch 20/50\n",
      "2650/2650 [==============================] - 1s 488us/step - loss: 0.0616 - acc: 0.9777\n",
      "Epoch 21/50\n",
      "2650/2650 [==============================] - 1s 485us/step - loss: 0.0646 - acc: 0.9766\n",
      "Epoch 22/50\n",
      "2650/2650 [==============================] - 1s 475us/step - loss: 0.0567 - acc: 0.9804\n",
      "Epoch 23/50\n",
      "2650/2650 [==============================] - 1s 475us/step - loss: 0.0489 - acc: 0.9849\n",
      "Epoch 24/50\n",
      "2650/2650 [==============================] - 1s 460us/step - loss: 0.0491 - acc: 0.9849\n",
      "Epoch 25/50\n",
      "2650/2650 [==============================] - 1s 439us/step - loss: 0.0484 - acc: 0.9811\n",
      "Epoch 26/50\n",
      "2650/2650 [==============================] - 1s 413us/step - loss: 0.0425 - acc: 0.9857\n",
      "Epoch 27/50\n",
      "2650/2650 [==============================] - 1s 412us/step - loss: 0.0481 - acc: 0.9845\n",
      "Epoch 28/50\n",
      "2650/2650 [==============================] - 1s 409us/step - loss: 0.0403 - acc: 0.9849\n",
      "Epoch 29/50\n",
      "2650/2650 [==============================] - 1s 399us/step - loss: 0.0388 - acc: 0.9864\n",
      "Epoch 30/50\n",
      "2650/2650 [==============================] - 1s 401us/step - loss: 0.0366 - acc: 0.9872\n",
      "Epoch 31/50\n",
      "2650/2650 [==============================] - 1s 433us/step - loss: 0.0343 - acc: 0.9898\n",
      "Epoch 32/50\n",
      "2650/2650 [==============================] - 1s 423us/step - loss: 0.0304 - acc: 0.9902\n",
      "Epoch 33/50\n",
      "2650/2650 [==============================] - 1s 412us/step - loss: 0.0304 - acc: 0.9891\n",
      "Epoch 34/50\n",
      "2650/2650 [==============================] - 1s 399us/step - loss: 0.0290 - acc: 0.9883\n",
      "Epoch 35/50\n",
      "2650/2650 [==============================] - 1s 492us/step - loss: 0.0298 - acc: 0.9902\n",
      "Epoch 36/50\n",
      "2650/2650 [==============================] - 1s 507us/step - loss: 0.0359 - acc: 0.9860\n",
      "Epoch 37/50\n",
      "2650/2650 [==============================] - 1s 472us/step - loss: 0.0304 - acc: 0.9906\n",
      "Epoch 38/50\n",
      "2650/2650 [==============================] - 1s 536us/step - loss: 0.0272 - acc: 0.9902\n",
      "Epoch 39/50\n",
      "2650/2650 [==============================] - 1s 509us/step - loss: 0.0233 - acc: 0.9917\n",
      "Epoch 40/50\n",
      "2650/2650 [==============================] - 1s 502us/step - loss: 0.0236 - acc: 0.9921\n",
      "Epoch 41/50\n",
      "2650/2650 [==============================] - 1s 490us/step - loss: 0.0289 - acc: 0.9898 0s - loss: 0.0261 - acc: 0\n",
      "Epoch 42/50\n",
      "2650/2650 [==============================] - 1s 511us/step - loss: 0.0344 - acc: 0.9902\n",
      "Epoch 43/50\n",
      "2650/2650 [==============================] - 1s 519us/step - loss: 0.0224 - acc: 0.9928\n",
      "Epoch 44/50\n",
      "2650/2650 [==============================] - 1s 500us/step - loss: 0.0199 - acc: 0.9932\n",
      "Epoch 45/50\n",
      "2650/2650 [==============================] - 1s 413us/step - loss: 0.0204 - acc: 0.9940\n",
      "Epoch 46/50\n",
      "2650/2650 [==============================] - 1s 403us/step - loss: 0.0200 - acc: 0.9936\n",
      "Epoch 47/50\n",
      "2650/2650 [==============================] - 1s 428us/step - loss: 0.0204 - acc: 0.9932\n",
      "Epoch 48/50\n",
      "2650/2650 [==============================] - 1s 419us/step - loss: 0.0291 - acc: 0.9894\n",
      "Epoch 49/50\n",
      "2650/2650 [==============================] - 1s 399us/step - loss: 0.0300 - acc: 0.9906\n",
      "Epoch 50/50\n",
      "2650/2650 [==============================] - 1s 412us/step - loss: 0.0262 - acc: 0.9902\n",
      "294/294 [==============================] - 0s 667us/step\n",
      "Epoch 1/50\n",
      "2650/2650 [==============================] - 2s 738us/step - loss: 0.3449 - acc: 0.8642\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2650/2650 [==============================] - 1s 405us/step - loss: 0.2001 - acc: 0.9291\n",
      "Epoch 3/50\n",
      "2650/2650 [==============================] - 1s 406us/step - loss: 0.1856 - acc: 0.9309\n",
      "Epoch 4/50\n",
      "2650/2650 [==============================] - 1s 406us/step - loss: 0.1742 - acc: 0.9411\n",
      "Epoch 5/50\n",
      "2650/2650 [==============================] - 1s 415us/step - loss: 0.1654 - acc: 0.9404\n",
      "Epoch 6/50\n",
      "2650/2650 [==============================] - 1s 410us/step - loss: 0.1523 - acc: 0.9419\n",
      "Epoch 7/50\n",
      "2650/2650 [==============================] - 1s 408us/step - loss: 0.1495 - acc: 0.9434\n",
      "Epoch 8/50\n",
      "2650/2650 [==============================] - 1s 405us/step - loss: 0.1412 - acc: 0.9464\n",
      "Epoch 9/50\n",
      "2650/2650 [==============================] - 1s 407us/step - loss: 0.1317 - acc: 0.9464\n",
      "Epoch 10/50\n",
      "2650/2650 [==============================] - 1s 419us/step - loss: 0.1252 - acc: 0.9547\n",
      "Epoch 11/50\n",
      "2650/2650 [==============================] - 1s 423us/step - loss: 0.1127 - acc: 0.9589\n",
      "Epoch 12/50\n",
      "2650/2650 [==============================] - 1s 405us/step - loss: 0.1108 - acc: 0.9623\n",
      "Epoch 13/50\n",
      "2650/2650 [==============================] - 1s 400us/step - loss: 0.1025 - acc: 0.9611\n",
      "Epoch 14/50\n",
      "2650/2650 [==============================] - 1s 409us/step - loss: 0.0901 - acc: 0.9672\n",
      "Epoch 15/50\n",
      "2650/2650 [==============================] - 1s 423us/step - loss: 0.0843 - acc: 0.9683\n",
      "Epoch 16/50\n",
      "2650/2650 [==============================] - 1s 450us/step - loss: 0.0858 - acc: 0.9698\n",
      "Epoch 17/50\n",
      "2650/2650 [==============================] - 1s 464us/step - loss: 0.0883 - acc: 0.9672\n",
      "Epoch 18/50\n",
      "2650/2650 [==============================] - 1s 473us/step - loss: 0.0761 - acc: 0.9736\n",
      "Epoch 19/50\n",
      "2650/2650 [==============================] - 1s 460us/step - loss: 0.0711 - acc: 0.9740\n",
      "Epoch 20/50\n",
      "2650/2650 [==============================] - 1s 471us/step - loss: 0.0763 - acc: 0.9709\n",
      "Epoch 21/50\n",
      "2650/2650 [==============================] - 1s 470us/step - loss: 0.0706 - acc: 0.9721\n",
      "Epoch 22/50\n",
      "2650/2650 [==============================] - 1s 491us/step - loss: 0.0652 - acc: 0.9751\n",
      "Epoch 23/50\n",
      "2650/2650 [==============================] - 1s 454us/step - loss: 0.0543 - acc: 0.9804\n",
      "Epoch 24/50\n",
      "2650/2650 [==============================] - 1s 416us/step - loss: 0.0508 - acc: 0.9804\n",
      "Epoch 25/50\n",
      "2650/2650 [==============================] - 1s 446us/step - loss: 0.0452 - acc: 0.9860\n",
      "Epoch 26/50\n",
      "2650/2650 [==============================] - 1s 413us/step - loss: 0.0461 - acc: 0.9845\n",
      "Epoch 27/50\n",
      "2650/2650 [==============================] - 1s 412us/step - loss: 0.0494 - acc: 0.9819\n",
      "Epoch 28/50\n",
      "2650/2650 [==============================] - 1s 415us/step - loss: 0.0411 - acc: 0.9842\n",
      "Epoch 29/50\n",
      "2650/2650 [==============================] - 1s 422us/step - loss: 0.0472 - acc: 0.9834\n",
      "Epoch 30/50\n",
      "2650/2650 [==============================] - 1s 417us/step - loss: 0.0490 - acc: 0.9845\n",
      "Epoch 31/50\n",
      "2650/2650 [==============================] - 1s 410us/step - loss: 0.0373 - acc: 0.9872\n",
      "Epoch 32/50\n",
      "2650/2650 [==============================] - 1s 411us/step - loss: 0.0415 - acc: 0.9879\n",
      "Epoch 33/50\n",
      "2650/2650 [==============================] - 1s 427us/step - loss: 0.0323 - acc: 0.9883\n",
      "Epoch 34/50\n",
      "2650/2650 [==============================] - 1s 415us/step - loss: 0.0301 - acc: 0.9921\n",
      "Epoch 35/50\n",
      "2650/2650 [==============================] - 1s 442us/step - loss: 0.0309 - acc: 0.9898\n",
      "Epoch 36/50\n",
      "2650/2650 [==============================] - 1s 420us/step - loss: 0.0311 - acc: 0.9913\n",
      "Epoch 37/50\n",
      "2650/2650 [==============================] - 1s 410us/step - loss: 0.0289 - acc: 0.9898\n",
      "Epoch 38/50\n",
      "2650/2650 [==============================] - 1s 403us/step - loss: 0.0300 - acc: 0.9883\n",
      "Epoch 39/50\n",
      "2650/2650 [==============================] - 1s 413us/step - loss: 0.0410 - acc: 0.9838\n",
      "Epoch 40/50\n",
      "2650/2650 [==============================] - 1s 401us/step - loss: 0.0309 - acc: 0.9898\n",
      "Epoch 41/50\n",
      "2650/2650 [==============================] - 1s 426us/step - loss: 0.0385 - acc: 0.9864\n",
      "Epoch 42/50\n",
      "2650/2650 [==============================] - 1s 412us/step - loss: 0.0288 - acc: 0.9902\n",
      "Epoch 43/50\n",
      "2650/2650 [==============================] - 1s 414us/step - loss: 0.0264 - acc: 0.9909\n",
      "Epoch 44/50\n",
      "2650/2650 [==============================] - 1s 408us/step - loss: 0.0274 - acc: 0.9913\n",
      "Epoch 45/50\n",
      "2650/2650 [==============================] - 1s 410us/step - loss: 0.0265 - acc: 0.9894\n",
      "Epoch 46/50\n",
      "2650/2650 [==============================] - 1s 411us/step - loss: 0.0232 - acc: 0.9921\n",
      "Epoch 47/50\n",
      "2650/2650 [==============================] - 1s 411us/step - loss: 0.0226 - acc: 0.9921\n",
      "Epoch 48/50\n",
      "2650/2650 [==============================] - 1s 408us/step - loss: 0.0255 - acc: 0.9913\n",
      "Epoch 49/50\n",
      "2650/2650 [==============================] - 1s 408us/step - loss: 0.0251 - acc: 0.9917\n",
      "Epoch 50/50\n",
      "2650/2650 [==============================] - 1s 415us/step - loss: 0.0270 - acc: 0.9902\n",
      "294/294 [==============================] - 0s 715us/step\n",
      "Epoch 1/50\n",
      "2650/2650 [==============================] - 2s 759us/step - loss: 0.3505 - acc: 0.8479\n",
      "Epoch 2/50\n",
      "2650/2650 [==============================] - 1s 410us/step - loss: 0.2068 - acc: 0.9242\n",
      "Epoch 3/50\n",
      "2650/2650 [==============================] - 1s 402us/step - loss: 0.1951 - acc: 0.9253\n",
      "Epoch 4/50\n",
      "2650/2650 [==============================] - 1s 405us/step - loss: 0.1822 - acc: 0.9325\n",
      "Epoch 5/50\n",
      "2650/2650 [==============================] - 1s 413us/step - loss: 0.1696 - acc: 0.9404\n",
      "Epoch 6/50\n",
      "2650/2650 [==============================] - 1s 398us/step - loss: 0.1561 - acc: 0.9445\n",
      "Epoch 7/50\n",
      "2650/2650 [==============================] - 1s 405us/step - loss: 0.1560 - acc: 0.9426\n",
      "Epoch 8/50\n",
      "2650/2650 [==============================] - 1s 403us/step - loss: 0.1414 - acc: 0.9464\n",
      "Epoch 9/50\n",
      "2650/2650 [==============================] - 1s 406us/step - loss: 0.1319 - acc: 0.9525\n",
      "Epoch 10/50\n",
      "2650/2650 [==============================] - 1s 411us/step - loss: 0.1234 - acc: 0.9528\n",
      "Epoch 11/50\n",
      "2650/2650 [==============================] - 1s 411us/step - loss: 0.1122 - acc: 0.9600\n",
      "Epoch 12/50\n",
      "2650/2650 [==============================] - 1s 426us/step - loss: 0.1114 - acc: 0.9600\n",
      "Epoch 13/50\n",
      "2650/2650 [==============================] - 1s 411us/step - loss: 0.0973 - acc: 0.9660\n",
      "Epoch 14/50\n",
      "2650/2650 [==============================] - 1s 413us/step - loss: 0.0909 - acc: 0.9668\n",
      "Epoch 15/50\n",
      "2650/2650 [==============================] - 1s 397us/step - loss: 0.0822 - acc: 0.9691\n",
      "Epoch 16/50\n",
      "2650/2650 [==============================] - 1s 401us/step - loss: 0.0876 - acc: 0.9706\n",
      "Epoch 17/50\n",
      "2650/2650 [==============================] - 1s 450us/step - loss: 0.0768 - acc: 0.9732\n",
      "Epoch 18/50\n",
      "2650/2650 [==============================] - 1s 462us/step - loss: 0.0712 - acc: 0.9751\n",
      "Epoch 19/50\n",
      "2650/2650 [==============================] - 1s 423us/step - loss: 0.0653 - acc: 0.9781\n",
      "Epoch 20/50\n",
      "2650/2650 [==============================] - 1s 325us/step - loss: 0.0623 - acc: 0.9789\n",
      "Epoch 21/50\n",
      "2650/2650 [==============================] - 1s 361us/step - loss: 0.0640 - acc: 0.9792\n",
      "Epoch 22/50\n",
      "2650/2650 [==============================] - 1s 479us/step - loss: 0.0564 - acc: 0.9789\n",
      "Epoch 23/50\n",
      "2650/2650 [==============================] - 1s 455us/step - loss: 0.0503 - acc: 0.9845\n",
      "Epoch 24/50\n",
      "2650/2650 [==============================] - 1s 482us/step - loss: 0.0471 - acc: 0.9857\n",
      "Epoch 25/50\n",
      "2650/2650 [==============================] - 1s 484us/step - loss: 0.0477 - acc: 0.9838\n",
      "Epoch 26/50\n",
      "2650/2650 [==============================] - 1s 454us/step - loss: 0.0475 - acc: 0.9838\n",
      "Epoch 27/50\n",
      "2650/2650 [==============================] - 1s 412us/step - loss: 0.0441 - acc: 0.9834\n",
      "Epoch 28/50\n",
      "2650/2650 [==============================] - 1s 422us/step - loss: 0.0425 - acc: 0.9830\n",
      "Epoch 29/50\n",
      "2650/2650 [==============================] - 1s 411us/step - loss: 0.0487 - acc: 0.9808\n",
      "Epoch 30/50\n",
      "2650/2650 [==============================] - 1s 418us/step - loss: 0.0470 - acc: 0.9845\n",
      "Epoch 31/50\n",
      "2650/2650 [==============================] - 1s 406us/step - loss: 0.0418 - acc: 0.9875\n",
      "Epoch 32/50\n",
      "2650/2650 [==============================] - 1s 401us/step - loss: 0.0357 - acc: 0.9879\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2650/2650 [==============================] - 1s 404us/step - loss: 0.0424 - acc: 0.9842\n",
      "Epoch 34/50\n",
      "2650/2650 [==============================] - 1s 419us/step - loss: 0.0394 - acc: 0.9864\n",
      "Epoch 35/50\n",
      "2650/2650 [==============================] - 1s 405us/step - loss: 0.0273 - acc: 0.9917\n",
      "Epoch 36/50\n",
      "2650/2650 [==============================] - 1s 405us/step - loss: 0.0308 - acc: 0.9891\n",
      "Epoch 37/50\n",
      "2650/2650 [==============================] - 1s 429us/step - loss: 0.0269 - acc: 0.9898\n",
      "Epoch 38/50\n",
      "2650/2650 [==============================] - 1s 417us/step - loss: 0.0235 - acc: 0.9921\n",
      "Epoch 39/50\n",
      "2650/2650 [==============================] - 1s 420us/step - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 40/50\n",
      "2650/2650 [==============================] - 1s 405us/step - loss: 0.0302 - acc: 0.9906\n",
      "Epoch 41/50\n",
      "2650/2650 [==============================] - 1s 404us/step - loss: 0.0362 - acc: 0.9864\n",
      "Epoch 42/50\n",
      "2650/2650 [==============================] - 1s 418us/step - loss: 0.0263 - acc: 0.9921\n",
      "Epoch 43/50\n",
      "2650/2650 [==============================] - 1s 413us/step - loss: 0.0282 - acc: 0.9902\n",
      "Epoch 44/50\n",
      "2650/2650 [==============================] - 1s 398us/step - loss: 0.0257 - acc: 0.9921\n",
      "Epoch 45/50\n",
      "2650/2650 [==============================] - 1s 398us/step - loss: 0.0245 - acc: 0.9906\n",
      "Epoch 46/50\n",
      "2650/2650 [==============================] - 1s 412us/step - loss: 0.0251 - acc: 0.9913\n",
      "Epoch 47/50\n",
      "2650/2650 [==============================] - 1s 416us/step - loss: 0.0242 - acc: 0.9932\n",
      "Epoch 48/50\n",
      "2650/2650 [==============================] - 1s 413us/step - loss: 0.0212 - acc: 0.9928\n",
      "Epoch 49/50\n",
      "2650/2650 [==============================] - 1s 404us/step - loss: 0.0214 - acc: 0.9928\n",
      "Epoch 50/50\n",
      "2650/2650 [==============================] - 1s 409us/step - loss: 0.0243 - acc: 0.9936\n",
      "294/294 [==============================] - 0s 860us/step\n",
      "Accuracy mean: 0.939192897457\n",
      "Accuracy variance: 0.0098210944133\n",
      "(' Time ', '772.246', ' seconds')\n",
      "[[701  37]\n",
      " [ 31 494]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      0.95      0.95       738\n",
      "        1.0       0.93      0.94      0.94       525\n",
      "\n",
      "avg / total       0.95      0.95      0.95      1263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "# estimators \n",
    "# Evaluating the ANN\n",
    "t0 = time()\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 1024, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n",
    "    classifier.add(Dense(units = 512, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 50)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of DecisionTreeClassifier = 90.419636 %\n",
      "(' Time ', '0.081', ' seconds')\n",
      "[[672  66]\n",
      " [ 55 470]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.91      0.92       738\n",
      "        1.0       0.88      0.90      0.89       525\n",
      "\n",
      "avg / total       0.90      0.90      0.90      1263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of DecisionTreeClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of RandomForestClassifier = 94.457641 %\n",
      "(' Time ', '1.119', ' seconds')\n",
      "[[708  30]\n",
      " [ 40 485]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.96      0.95       738\n",
      "        1.0       0.94      0.92      0.93       525\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of RandomForestClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of ExtraTreesClassifier = 95.011876 %\n",
      "(' Time ', '1.118', ' seconds')\n",
      "[[707  31]\n",
      " [ 32 493]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      0.96      0.96       738\n",
      "        1.0       0.94      0.94      0.94       525\n",
      "\n",
      "avg / total       0.95      0.95      0.95      1263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of ExtraTreesClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of AdaBoostClassifier = 94.378464 %\n",
      "(' Time ', '1.07', ' seconds')\n",
      "[[706  32]\n",
      " [ 39 486]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.96      0.95       738\n",
      "        1.0       0.94      0.93      0.93       525\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of AdaBoostClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Naive_bayes  GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GaussianNB = 81.631037 %\n",
      "(' Time ', '0.008', ' seconds')\n",
      "[[526 212]\n",
      " [ 20 505]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      0.71      0.82       738\n",
      "        1.0       0.70      0.96      0.81       525\n",
      "\n",
      "avg / total       0.86      0.82      0.82      1263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred= gnb.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of GaussianNB = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
