{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt \n",
    "from pprint import pprint\n",
    "from numpy import array\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(494021, 42)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "import constants\n",
    "df = pd.read_csv(\"kddcup.data_10_percent.gz\", names = constants.names)\n",
    "\n",
    "#https://github.com/chinskiy/KDD-99\n",
    "# Categorical features to numeric labels\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le_dicts = {}\n",
    "\n",
    "for categorical_name in constants.categorical_names:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(df[categorical_name])\n",
    "    le_dicts[categorical_name] = dict(zip(le.transform(le.classes_), le.classes_))\n",
    "    df[categorical_name + '_num'] = le.fit_transform(df[categorical_name])\n",
    "\n",
    "df['cible'] = df.label.apply(lambda label: 1 if label == 'normal.' else 0)\n",
    "df['label_four'] = df.label.apply(lambda label: constants.label_to_four_attack_class[label])\n",
    "df['label_four_num'] = df.label_four.apply(lambda label: constants.five_classes_to_num[label])\n",
    "df.drop(constants.categorical_names + ['label','label_four_num','label_four'], axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>protocol_type_num</th>\n",
       "      <th>service_num</th>\n",
       "      <th>flag_num</th>\n",
       "      <th>cible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>5450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>235</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
       "0         0        181       5450     0               0       0    0   \n",
       "1         0        239        486     0               0       0    0   \n",
       "2         0        235       1337     0               0       0    0   \n",
       "3         0        219       1337     0               0       0    0   \n",
       "4         0        217       2032     0               0       0    0   \n",
       "\n",
       "   num_failed_logins  logged_in  num_compromised  ...    \\\n",
       "0                  0          1                0  ...     \n",
       "1                  0          1                0  ...     \n",
       "2                  0          1                0  ...     \n",
       "3                  0          1                0  ...     \n",
       "4                  0          1                0  ...     \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.11                          0.0   \n",
       "1                         0.05                          0.0   \n",
       "2                         0.03                          0.0   \n",
       "3                         0.03                          0.0   \n",
       "4                         0.02                          0.0   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                   0.0                       0.0                   0.0   \n",
       "1                   0.0                       0.0                   0.0   \n",
       "2                   0.0                       0.0                   0.0   \n",
       "3                   0.0                       0.0                   0.0   \n",
       "4                   0.0                       0.0                   0.0   \n",
       "\n",
       "   dst_host_srv_rerror_rate  protocol_type_num  service_num  flag_num  cible  \n",
       "0                       0.0                  1           22         9      1  \n",
       "1                       0.0                  1           22         9      1  \n",
       "2                       0.0                  1           22         9      1  \n",
       "3                       0.0                  1           22         9      1  \n",
       "4                       0.0                  1           22         9      1  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 5 \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df to values\n",
    "df = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GC Forest\n",
    "import argparse\n",
    "import sys\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "sys.path.insert(0, \"lib\")\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.utils.config_utils import load_json\n",
    "config = load_json(\"./examples/kdd.json\")  # layer = 1   k=10   Extree + DTree\n",
    "gc = GCForest(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# train test \n",
    "from sklearn.cross_validation import train_test_split\n",
    "y = df[:,41]\n",
    "X = df[:,0:41]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of class\n",
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 20:39:27,437][cascade_classifier.fit_transform] X_groups_train.shape=[(330994, 41)],y_train.shape=(330994,),X_groups_test.shape=[(163027, 41)],y_test.shape=(163027,)\n",
      "[ 2018-07-31 20:39:27,505][cascade_classifier.fit_transform] group_dims=[41]\n",
      "[ 2018-07-31 20:39:27,507][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-31 20:39:27,508][cascade_classifier.fit_transform] group_ends=[41]\n",
      "[ 2018-07-31 20:39:27,509][cascade_classifier.fit_transform] X_train.shape=(330994, 41),X_test.shape=(163027, 41)\n",
      "[ 2018-07-31 20:39:27,583][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(330994, 41), X_cur_test.shape=(163027, 41)\n",
      "[ 2018-07-31 20:39:35,469][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=99.98%\n",
      "[ 2018-07-31 20:39:42,738][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=99.98%\n",
      "[ 2018-07-31 20:39:49,829][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=99.99%\n",
      "[ 2018-07-31 20:39:57,192][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=99.98%\n",
      "[ 2018-07-31 20:40:04,975][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=99.96%\n",
      "[ 2018-07-31 20:40:12,297][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=99.97%\n",
      "[ 2018-07-31 20:40:19,285][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=99.98%\n",
      "[ 2018-07-31 20:40:26,937][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=99.97%\n",
      "[ 2018-07-31 20:40:34,253][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=99.98%\n",
      "[ 2018-07-31 20:40:43,127][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=99.99%\n",
      "[ 2018-07-31 20:40:43,848][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=99.98%\n",
      "[ 2018-07-31 20:40:43,854][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=99.98%\n",
      "[ 2018-07-31 20:40:54,387][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_0.predict)=99.98%\n",
      "[ 2018-07-31 20:41:02,326][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_1.predict)=99.97%\n",
      "[ 2018-07-31 20:41:10,119][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_2.predict)=99.97%\n",
      "[ 2018-07-31 20:41:19,880][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_3.predict)=99.98%\n",
      "[ 2018-07-31 20:41:27,825][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_4.predict)=99.97%\n",
      "[ 2018-07-31 20:41:35,172][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_5.predict)=99.97%\n",
      "[ 2018-07-31 20:41:45,113][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_6.predict)=99.97%\n",
      "[ 2018-07-31 20:41:53,018][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_7.predict)=99.98%\n",
      "[ 2018-07-31 20:42:00,149][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_8.predict)=99.98%\n",
      "[ 2018-07-31 20:42:11,224][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_9.predict)=99.99%\n",
      "[ 2018-07-31 20:42:12,017][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_cv.predict)=99.98%\n",
      "[ 2018-07-31 20:42:12,024][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.test.predict)=99.98%\n",
      "[ 2018-07-31 20:42:19,581][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_0.predict)=98.45%\n",
      "[ 2018-07-31 20:42:36,137][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_1.predict)=98.49%\n",
      "[ 2018-07-31 20:42:56,713][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_2.predict)=98.40%\n",
      "[ 2018-07-31 20:43:13,769][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_3.predict)=97.72%\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/base.py:352: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n",
      "[ 2018-07-31 20:43:41,845][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_4.predict)=99.10%\n",
      "[ 2018-07-31 20:43:51,419][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_5.predict)=98.65%\n",
      "[ 2018-07-31 20:44:10,498][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_6.predict)=98.96%\n",
      "[ 2018-07-31 20:44:23,390][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_7.predict)=98.68%\n",
      "[ 2018-07-31 20:44:42,057][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_8.predict)=98.45%\n",
      "[ 2018-07-31 20:44:51,155][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_9.predict)=98.53%\n",
      "[ 2018-07-31 20:44:51,193][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_cv.predict)=98.54%\n",
      "[ 2018-07-31 20:44:51,202][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.test.predict)=98.67%\n",
      "[ 2018-07-31 20:44:51,219][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=99.97%\n",
      "[ 2018-07-31 20:44:51,226][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=99.97%\n",
      "[ 2018-07-31 20:44:51,328][cascade_classifier.fit_transform] [layer=1] look_indexs=[0], X_cur_train.shape=(330994, 47), X_cur_test.shape=(163027, 47)\n",
      "[ 2018-07-31 20:44:57,581][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_0.predict)=99.98%\n",
      "[ 2018-07-31 20:45:04,696][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_1.predict)=99.97%\n",
      "[ 2018-07-31 20:45:13,030][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_2.predict)=99.99%\n",
      "[ 2018-07-31 20:45:19,521][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_3.predict)=99.98%\n",
      "[ 2018-07-31 20:45:26,430][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_4.predict)=99.99%\n",
      "[ 2018-07-31 20:45:33,899][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_5.predict)=99.98%\n",
      "[ 2018-07-31 20:45:40,935][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_6.predict)=99.97%\n",
      "[ 2018-07-31 20:45:47,979][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_7.predict)=99.99%\n",
      "[ 2018-07-31 20:45:57,655][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_8.predict)=99.99%\n",
      "[ 2018-07-31 20:46:06,199][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_9.predict)=99.98%\n",
      "[ 2018-07-31 20:46:06,598][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_cv.predict)=99.98%\n",
      "[ 2018-07-31 20:46:06,606][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.test.predict)=99.98%\n",
      "[ 2018-07-31 20:46:13,205][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_0.predict)=99.97%\n",
      "[ 2018-07-31 20:46:19,861][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_1.predict)=99.99%\n",
      "[ 2018-07-31 20:46:29,097][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_2.predict)=99.98%\n",
      "[ 2018-07-31 20:46:36,160][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_3.predict)=99.98%\n",
      "[ 2018-07-31 20:46:42,363][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_4.predict)=99.98%\n",
      "[ 2018-07-31 20:46:49,932][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_5.predict)=100.00%\n",
      "[ 2018-07-31 20:46:57,985][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_6.predict)=99.98%\n",
      "[ 2018-07-31 20:47:04,528][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_7.predict)=99.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 20:47:11,199][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_8.predict)=99.96%\n",
      "[ 2018-07-31 20:47:19,643][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_9.predict)=99.98%\n",
      "[ 2018-07-31 20:47:20,502][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_cv.predict)=99.98%\n",
      "[ 2018-07-31 20:47:20,509][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.test.predict)=99.98%\n",
      "[ 2018-07-31 20:47:46,690][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_0.predict)=99.97%\n",
      "[ 2018-07-31 20:48:13,012][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_1.predict)=99.36%\n",
      "[ 2018-07-31 20:48:37,277][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_2.predict)=99.26%\n",
      "[ 2018-07-31 20:49:01,674][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_3.predict)=98.98%\n",
      "[ 2018-07-31 20:49:19,956][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_4.predict)=98.92%\n",
      "[ 2018-07-31 20:49:37,265][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_5.predict)=98.27%\n",
      "[ 2018-07-31 20:49:58,524][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_6.predict)=98.60%\n",
      "[ 2018-07-31 20:50:20,626][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_7.predict)=99.78%\n",
      "[ 2018-07-31 20:50:39,374][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_8.predict)=98.69%\n",
      "[ 2018-07-31 20:51:01,019][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_9.predict)=99.31%\n",
      "[ 2018-07-31 20:51:01,040][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_cv.predict)=99.11%\n",
      "[ 2018-07-31 20:51:01,043][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.test.predict)=99.17%\n",
      "[ 2018-07-31 20:51:01,055][cascade_classifier.calc_accuracy] Accuracy(layer_1 - train.classifier_average)=99.98%\n",
      "[ 2018-07-31 20:51:01,058][cascade_classifier.calc_accuracy] Accuracy(layer_1 - test.classifier_average)=99.98%\n",
      "[ 2018-07-31 20:51:01,154][cascade_classifier.fit_transform] [layer=2] look_indexs=[0], X_cur_train.shape=(330994, 47), X_cur_test.shape=(163027, 47)\n",
      "[ 2018-07-31 20:51:07,588][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_0.predict)=99.97%\n",
      "[ 2018-07-31 20:51:14,336][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_1.predict)=99.98%\n",
      "[ 2018-07-31 20:51:21,506][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_2.predict)=99.96%\n",
      "[ 2018-07-31 20:51:27,400][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_3.predict)=99.97%\n",
      "[ 2018-07-31 20:51:33,083][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_4.predict)=99.98%\n",
      "[ 2018-07-31 20:51:38,852][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_5.predict)=99.99%\n",
      "[ 2018-07-31 20:51:45,805][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_6.predict)=99.99%\n",
      "[ 2018-07-31 20:51:51,453][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_7.predict)=99.99%\n",
      "[ 2018-07-31 20:51:56,989][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_8.predict)=99.99%\n",
      "[ 2018-07-31 20:52:02,828][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_9.predict)=99.98%\n",
      "[ 2018-07-31 20:52:03,437][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_cv.predict)=99.98%\n",
      "[ 2018-07-31 20:52:03,441][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.test.predict)=99.98%\n",
      "[ 2018-07-31 20:52:10,325][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_0.predict)=99.99%\n",
      "[ 2018-07-31 20:52:15,850][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_1.predict)=99.98%\n",
      "[ 2018-07-31 20:52:21,471][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_2.predict)=99.99%\n",
      "[ 2018-07-31 20:52:27,256][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_3.predict)=99.98%\n",
      "[ 2018-07-31 20:52:34,635][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_4.predict)=99.98%\n",
      "[ 2018-07-31 20:52:40,178][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_5.predict)=99.98%\n",
      "[ 2018-07-31 20:52:45,712][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_6.predict)=99.98%\n",
      "[ 2018-07-31 20:52:51,247][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_7.predict)=99.97%\n",
      "[ 2018-07-31 20:52:59,197][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_8.predict)=99.97%\n",
      "[ 2018-07-31 20:53:06,098][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_9.predict)=99.97%\n",
      "[ 2018-07-31 20:53:06,492][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_cv.predict)=99.98%\n",
      "[ 2018-07-31 20:53:06,495][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.test.predict)=99.98%\n",
      "[ 2018-07-31 20:53:30,644][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_0.predict)=99.31%\n",
      "[ 2018-07-31 20:53:54,208][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_1.predict)=99.73%\n",
      "[ 2018-07-31 20:54:13,145][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_2.predict)=98.97%\n",
      "[ 2018-07-31 20:54:35,044][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_3.predict)=99.37%\n",
      "[ 2018-07-31 20:54:53,495][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_4.predict)=97.54%\n",
      "[ 2018-07-31 20:55:15,079][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_5.predict)=99.18%\n",
      "[ 2018-07-31 20:55:36,793][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_6.predict)=99.14%\n",
      "[ 2018-07-31 20:55:56,557][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_7.predict)=98.36%\n",
      "[ 2018-07-31 20:56:12,548][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_8.predict)=98.64%\n",
      "[ 2018-07-31 20:56:29,664][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_9.predict)=99.11%\n",
      "[ 2018-07-31 20:56:29,684][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_cv.predict)=98.94%\n",
      "[ 2018-07-31 20:56:29,688][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.test.predict)=99.08%\n",
      "[ 2018-07-31 20:56:29,701][cascade_classifier.calc_accuracy] Accuracy(layer_2 - train.classifier_average)=99.98%\n",
      "[ 2018-07-31 20:56:29,704][cascade_classifier.calc_accuracy] Accuracy(layer_2 - test.classifier_average)=99.98%\n",
      "[ 2018-07-31 20:56:29,800][cascade_classifier.fit_transform] [layer=3] look_indexs=[0], X_cur_train.shape=(330994, 47), X_cur_test.shape=(163027, 47)\n",
      "[ 2018-07-31 20:56:35,023][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_0.predict)=99.97%\n",
      "[ 2018-07-31 20:56:40,299][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_1.predict)=99.98%\n",
      "[ 2018-07-31 20:56:46,174][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_2.predict)=99.97%\n",
      "[ 2018-07-31 20:56:52,890][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_3.predict)=99.97%\n",
      "[ 2018-07-31 20:56:58,565][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_4.predict)=99.98%\n",
      "[ 2018-07-31 20:57:04,449][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_5.predict)=99.98%\n",
      "[ 2018-07-31 20:57:12,594][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_6.predict)=99.98%\n",
      "[ 2018-07-31 20:57:19,079][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_7.predict)=99.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 20:57:24,525][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_8.predict)=99.98%\n",
      "[ 2018-07-31 20:57:30,445][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_9.predict)=99.98%\n",
      "[ 2018-07-31 20:57:30,816][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_cv.predict)=99.98%\n",
      "[ 2018-07-31 20:57:30,819][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.test.predict)=99.98%\n",
      "[ 2018-07-31 20:57:37,399][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_0.predict)=99.98%\n",
      "[ 2018-07-31 20:57:43,925][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_1.predict)=99.98%\n",
      "[ 2018-07-31 20:57:49,463][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_2.predict)=99.97%\n",
      "[ 2018-07-31 20:57:55,096][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_3.predict)=99.99%\n",
      "[ 2018-07-31 20:58:02,220][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_4.predict)=99.98%\n",
      "[ 2018-07-31 20:58:09,070][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_5.predict)=99.99%\n",
      "[ 2018-07-31 20:58:16,116][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_6.predict)=99.99%\n",
      "[ 2018-07-31 20:58:22,755][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_7.predict)=99.97%\n",
      "[ 2018-07-31 20:58:31,190][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_8.predict)=99.99%\n",
      "[ 2018-07-31 20:58:37,443][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_9.predict)=99.96%\n",
      "[ 2018-07-31 20:58:37,833][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_cv.predict)=99.98%\n",
      "[ 2018-07-31 20:58:37,836][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.test.predict)=99.98%\n",
      "[ 2018-07-31 20:58:54,692][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_0.predict)=99.13%\n",
      "[ 2018-07-31 20:59:15,238][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_1.predict)=97.90%\n",
      "[ 2018-07-31 20:59:37,247][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_2.predict)=99.75%\n",
      "[ 2018-07-31 20:59:56,810][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_3.predict)=98.93%\n",
      "[ 2018-07-31 21:00:19,913][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_4.predict)=98.96%\n",
      "[ 2018-07-31 21:00:38,632][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_5.predict)=98.85%\n",
      "[ 2018-07-31 21:01:01,172][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_6.predict)=97.93%\n",
      "[ 2018-07-31 21:01:19,243][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_7.predict)=98.51%\n",
      "[ 2018-07-31 21:01:42,628][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_8.predict)=99.28%\n",
      "[ 2018-07-31 21:02:02,724][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_9.predict)=98.76%\n",
      "[ 2018-07-31 21:02:02,746][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_cv.predict)=98.80%\n",
      "[ 2018-07-31 21:02:02,750][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.test.predict)=99.00%\n",
      "[ 2018-07-31 21:02:02,762][cascade_classifier.calc_accuracy] Accuracy(layer_3 - train.classifier_average)=99.98%\n",
      "[ 2018-07-31 21:02:02,765][cascade_classifier.calc_accuracy] Accuracy(layer_3 - test.classifier_average)=99.98%\n",
      "[ 2018-07-31 21:02:02,863][cascade_classifier.fit_transform] [layer=4] look_indexs=[0], X_cur_train.shape=(330994, 47), X_cur_test.shape=(163027, 47)\n",
      "[ 2018-07-31 21:02:09,104][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_0.predict)=99.98%\n",
      "[ 2018-07-31 21:02:15,464][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_1.predict)=99.98%\n",
      "[ 2018-07-31 21:02:21,043][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_2.predict)=99.99%\n",
      "[ 2018-07-31 21:02:26,635][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_3.predict)=99.98%\n",
      "[ 2018-07-31 21:02:33,305][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_4.predict)=99.98%\n",
      "[ 2018-07-31 21:02:39,103][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_5.predict)=99.97%\n",
      "[ 2018-07-31 21:02:44,662][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_6.predict)=99.98%\n",
      "[ 2018-07-31 21:02:50,104][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_7.predict)=99.98%\n",
      "[ 2018-07-31 21:02:56,777][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_8.predict)=99.97%\n",
      "[ 2018-07-31 21:03:02,817][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_9.predict)=99.98%\n",
      "[ 2018-07-31 21:03:03,405][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_cv.predict)=99.98%\n",
      "[ 2018-07-31 21:03:03,408][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.test.predict)=99.98%\n",
      "[ 2018-07-31 21:03:11,218][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_0.predict)=99.99%\n",
      "[ 2018-07-31 21:03:19,787][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_1.predict)=99.98%\n",
      "[ 2018-07-31 21:03:27,345][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_2.predict)=99.97%\n",
      "[ 2018-07-31 21:03:34,217][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_3.predict)=99.98%\n",
      "[ 2018-07-31 21:03:40,597][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_4.predict)=99.98%\n",
      "[ 2018-07-31 21:03:46,517][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_5.predict)=99.97%\n",
      "[ 2018-07-31 21:03:51,972][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_6.predict)=99.97%\n",
      "[ 2018-07-31 21:03:57,893][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_7.predict)=99.98%\n",
      "[ 2018-07-31 21:04:04,069][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_8.predict)=99.98%\n",
      "[ 2018-07-31 21:04:09,790][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_9.predict)=99.98%\n",
      "[ 2018-07-31 21:04:10,174][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_cv.predict)=99.98%\n",
      "[ 2018-07-31 21:04:10,177][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.test.predict)=99.98%\n",
      "[ 2018-07-31 21:04:25,523][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_0.predict)=98.95%\n",
      "[ 2018-07-31 21:04:42,687][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_1.predict)=99.21%\n",
      "[ 2018-07-31 21:05:01,997][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_2.predict)=98.99%\n",
      "[ 2018-07-31 21:05:28,363][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_3.predict)=99.21%\n",
      "[ 2018-07-31 21:05:53,832][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_4.predict)=99.13%\n",
      "[ 2018-07-31 21:06:16,068][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_5.predict)=98.49%\n",
      "[ 2018-07-31 21:06:33,772][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_6.predict)=97.68%\n",
      "[ 2018-07-31 21:06:54,886][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_7.predict)=98.90%\n",
      "[ 2018-07-31 21:07:16,898][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_8.predict)=99.35%\n",
      "[ 2018-07-31 21:07:35,718][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_9.predict)=98.02%\n",
      "[ 2018-07-31 21:07:35,738][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_cv.predict)=98.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 21:07:35,742][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.test.predict)=99.03%\n",
      "[ 2018-07-31 21:07:35,754][cascade_classifier.calc_accuracy] Accuracy(layer_4 - train.classifier_average)=99.98%\n",
      "[ 2018-07-31 21:07:35,757][cascade_classifier.calc_accuracy] Accuracy(layer_4 - test.classifier_average)=99.98%\n",
      "[ 2018-07-31 21:07:35,853][cascade_classifier.fit_transform] [layer=5] look_indexs=[0], X_cur_train.shape=(330994, 47), X_cur_test.shape=(163027, 47)\n",
      "[ 2018-07-31 21:07:41,251][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_0.predict)=99.98%\n",
      "[ 2018-07-31 21:07:47,485][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_1.predict)=99.98%\n",
      "[ 2018-07-31 21:07:54,268][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_2.predict)=99.99%\n",
      "[ 2018-07-31 21:07:59,700][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_3.predict)=99.98%\n",
      "[ 2018-07-31 21:08:05,481][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_4.predict)=99.98%\n",
      "[ 2018-07-31 21:08:12,031][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_5.predict)=99.98%\n",
      "[ 2018-07-31 21:08:20,707][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_6.predict)=99.99%\n",
      "[ 2018-07-31 21:08:27,086][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_7.predict)=99.98%\n",
      "[ 2018-07-31 21:08:33,879][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_8.predict)=99.98%\n",
      "[ 2018-07-31 21:08:39,946][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_9.predict)=99.97%\n",
      "[ 2018-07-31 21:08:40,360][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_cv.predict)=99.98%\n",
      "[ 2018-07-31 21:08:40,362][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.test.predict)=99.98%\n",
      "[ 2018-07-31 21:08:45,967][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_0.predict)=99.98%\n",
      "[ 2018-07-31 21:08:51,813][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_1.predict)=99.98%\n",
      "[ 2018-07-31 21:08:57,459][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_2.predict)=99.97%\n",
      "[ 2018-07-31 21:09:03,390][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_3.predict)=99.98%\n",
      "[ 2018-07-31 21:09:10,727][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_4.predict)=99.98%\n",
      "[ 2018-07-31 21:09:16,464][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_5.predict)=99.98%\n",
      "[ 2018-07-31 21:09:22,508][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_6.predict)=99.99%\n",
      "[ 2018-07-31 21:09:28,540][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_7.predict)=99.97%\n",
      "[ 2018-07-31 21:09:34,556][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_8.predict)=99.97%\n",
      "[ 2018-07-31 21:09:40,602][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_9.predict)=99.98%\n",
      "[ 2018-07-31 21:09:40,976][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_cv.predict)=99.98%\n",
      "[ 2018-07-31 21:09:40,979][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.test.predict)=99.98%\n",
      "[ 2018-07-31 21:10:01,558][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_0.predict)=98.73%\n",
      "[ 2018-07-31 21:10:17,674][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_1.predict)=98.83%\n",
      "[ 2018-07-31 21:10:36,550][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_2.predict)=98.56%\n",
      "[ 2018-07-31 21:10:53,972][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_3.predict)=99.03%\n",
      "[ 2018-07-31 21:11:17,398][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_4.predict)=99.13%\n",
      "[ 2018-07-31 21:11:38,811][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_5.predict)=99.28%\n",
      "[ 2018-07-31 21:11:59,700][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_6.predict)=98.45%\n",
      "[ 2018-07-31 21:12:21,088][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_7.predict)=98.92%\n",
      "[ 2018-07-31 21:12:41,345][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_8.predict)=99.04%\n",
      "[ 2018-07-31 21:13:00,784][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_9.predict)=98.43%\n",
      "[ 2018-07-31 21:13:00,805][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_cv.predict)=98.84%\n",
      "[ 2018-07-31 21:13:00,810][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.test.predict)=98.93%\n",
      "[ 2018-07-31 21:13:00,822][cascade_classifier.calc_accuracy] Accuracy(layer_5 - train.classifier_average)=99.98%\n",
      "[ 2018-07-31 21:13:00,825][cascade_classifier.calc_accuracy] Accuracy(layer_5 - test.classifier_average)=99.98%\n",
      "[ 2018-07-31 21:13:00,921][cascade_classifier.fit_transform] [layer=6] look_indexs=[0], X_cur_train.shape=(330994, 47), X_cur_test.shape=(163027, 47)\n",
      "[ 2018-07-31 21:13:06,463][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_0.predict)=99.97%\n",
      "[ 2018-07-31 21:13:12,323][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_1.predict)=99.99%\n",
      "[ 2018-07-31 21:13:18,146][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_2.predict)=99.98%\n",
      "[ 2018-07-31 21:13:23,822][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_3.predict)=99.98%\n",
      "[ 2018-07-31 21:13:29,333][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_4.predict)=99.97%\n",
      "[ 2018-07-31 21:13:35,468][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_5.predict)=99.97%\n",
      "[ 2018-07-31 21:13:41,064][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_6.predict)=99.97%\n",
      "[ 2018-07-31 21:13:46,959][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_7.predict)=99.98%\n",
      "[ 2018-07-31 21:13:52,560][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_8.predict)=99.98%\n",
      "[ 2018-07-31 21:13:58,306][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_9.predict)=99.98%\n",
      "[ 2018-07-31 21:13:58,679][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_cv.predict)=99.98%\n",
      "[ 2018-07-31 21:13:58,682][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.test.predict)=99.98%\n",
      "[ 2018-07-31 21:14:04,491][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_0.predict)=99.98%\n",
      "[ 2018-07-31 21:14:10,339][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_1.predict)=99.99%\n",
      "[ 2018-07-31 21:14:15,989][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_2.predict)=99.97%\n",
      "[ 2018-07-31 21:14:21,738][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_3.predict)=99.98%\n",
      "[ 2018-07-31 21:14:27,475][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_4.predict)=99.98%\n",
      "[ 2018-07-31 21:14:33,611][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_5.predict)=99.97%\n",
      "[ 2018-07-31 21:14:39,966][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_6.predict)=99.98%\n",
      "[ 2018-07-31 21:14:45,700][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_7.predict)=99.96%\n",
      "[ 2018-07-31 21:14:51,543][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_8.predict)=99.97%\n",
      "[ 2018-07-31 21:14:57,401][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_9.predict)=99.98%\n",
      "[ 2018-07-31 21:14:57,795][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_cv.predict)=99.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 21:14:57,798][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.test.predict)=99.98%\n",
      "[ 2018-07-31 21:15:18,155][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_0.predict)=98.96%\n",
      "[ 2018-07-31 21:15:40,797][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_1.predict)=98.92%\n",
      "[ 2018-07-31 21:16:01,579][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_2.predict)=99.12%\n",
      "[ 2018-07-31 21:16:31,724][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_3.predict)=99.97%\n",
      "[ 2018-07-31 21:16:50,171][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_4.predict)=98.86%\n",
      "[ 2018-07-31 21:17:09,950][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_5.predict)=97.78%\n",
      "[ 2018-07-31 21:17:24,514][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_6.predict)=98.72%\n",
      "[ 2018-07-31 21:17:46,521][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_7.predict)=98.93%\n",
      "[ 2018-07-31 21:18:07,990][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_8.predict)=98.96%\n",
      "[ 2018-07-31 21:18:25,363][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_9.predict)=98.48%\n",
      "[ 2018-07-31 21:18:25,384][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_cv.predict)=98.87%\n",
      "[ 2018-07-31 21:18:25,387][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.test.predict)=99.00%\n",
      "[ 2018-07-31 21:18:25,399][cascade_classifier.calc_accuracy] Accuracy(layer_6 - train.classifier_average)=99.98%\n",
      "[ 2018-07-31 21:18:25,402][cascade_classifier.calc_accuracy] Accuracy(layer_6 - test.classifier_average)=99.98%\n",
      "[ 2018-07-31 21:18:25,403][cascade_classifier.fit_transform] [Result][Optimal Level Detected] opt_layer_num=4, accuracy_train=99.98%, accuracy_test=99.98%\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "# X_enc is the concatenated predict_proba result of each estimators of the last layer of the GCForest model\n",
    "    # X_enc.shape =\n",
    "    #   (n_datas, n_estimators * n_classes): If cascade is provided\n",
    "    #   (n_datas, n_estimators * n_classes, dimX, dimY): If only finegrained part is provided\n",
    "    # You can also pass X_test, y_test to fit_transform method, then the accracy on test data will be logged when training.\n",
    "X_train_enc, X_test_enc = gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test)\n",
    "    # WARNING: if you set gc.set_keep_model_in_mem(True), you would have to use\n",
    "    # gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test) to evaluate your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 21:18:25,422][cascade_classifier.transform] X_groups_test.shape=[(163027, 41)]\n",
      "[ 2018-07-31 21:18:25,430][cascade_classifier.transform] group_dims=[41]\n",
      "[ 2018-07-31 21:18:25,431][cascade_classifier.transform] X_test.shape=(163027, 41)\n",
      "[ 2018-07-31 21:18:25,454][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(163027, 41)\n",
      "[ 2018-07-31 21:18:34,268][cascade_classifier.transform] [layer=1] look_indexs=[0], X_cur_test.shape=(163027, 47)\n",
      "[ 2018-07-31 21:18:42,324][cascade_classifier.transform] [layer=2] look_indexs=[0], X_cur_test.shape=(163027, 47)\n",
      "[ 2018-07-31 21:18:50,231][cascade_classifier.transform] [layer=3] look_indexs=[0], X_cur_test.shape=(163027, 47)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GCForest = 99.982825 %\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "y_pred = gc.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy of GCForest = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' Time ', '2370.741', ' seconds')\n",
      "[[130846     14]\n",
      " [    14  32153]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00    130860\n",
      "        1.0       1.00      1.00      1.00     32167\n",
      "\n",
      "avg / total       1.00      1.00      1.00    163027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "297894/297894 [==============================] - 53s 177us/step - loss: 0.2757 - acc: 0.9823\n",
      "Epoch 2/50\n",
      "297894/297894 [==============================] - 52s 175us/step - loss: 0.8862 - acc: 0.9443\n",
      "Epoch 3/50\n",
      "297894/297894 [==============================] - 55s 184us/step - loss: 0.1600 - acc: 0.9899\n",
      "Epoch 4/50\n",
      "297894/297894 [==============================] - 51s 172us/step - loss: 0.2721 - acc: 0.9830\n",
      "Epoch 5/50\n",
      "297894/297894 [==============================] - 52s 175us/step - loss: 2.1968 - acc: 0.8623\n",
      "Epoch 6/50\n",
      "297894/297894 [==============================] - 54s 183us/step - loss: 1.4159 - acc: 0.9112\n",
      "Epoch 7/50\n",
      "297894/297894 [==============================] - 52s 175us/step - loss: 3.0191 - acc: 0.8106\n",
      "Epoch 8/50\n",
      "297894/297894 [==============================] - 52s 175us/step - loss: 4.0308 - acc: 0.7472\n",
      "Epoch 9/50\n",
      "297894/297894 [==============================] - 52s 174us/step - loss: 0.6895 - acc: 0.9568\n",
      "Epoch 10/50\n",
      "297894/297894 [==============================] - 54s 181us/step - loss: 4.4948 - acc: 0.7181\n",
      "Epoch 11/50\n",
      "297894/297894 [==============================] - 52s 176us/step - loss: 0.1532 - acc: 0.9904\n",
      "Epoch 12/50\n",
      "297894/297894 [==============================] - 52s 175us/step - loss: 0.9693 - acc: 0.9392\n",
      "Epoch 13/50\n",
      "297894/297894 [==============================] - 55s 184us/step - loss: 4.1287 - acc: 0.7410\n",
      "Epoch 14/50\n",
      "297894/297894 [==============================] - 53s 178us/step - loss: 2.4005 - acc: 0.8494\n",
      "Epoch 15/50\n",
      "297894/297894 [==============================] - 53s 178us/step - loss: 3.4847 - acc: 0.7815\n",
      "Epoch 16/50\n",
      "297894/297894 [==============================] - 55s 183us/step - loss: 7.6303 - acc: 0.5214\n",
      "Epoch 17/50\n",
      "297894/297894 [==============================] - 53s 177us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 18/50\n",
      "297894/297894 [==============================] - 52s 176us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 19/50\n",
      "297894/297894 [==============================] - 53s 177us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 20/50\n",
      "297894/297894 [==============================] - 54s 182us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 21/50\n",
      "297894/297894 [==============================] - 52s 174us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 22/50\n",
      "297894/297894 [==============================] - 52s 174us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 23/50\n",
      "297894/297894 [==============================] - 54s 181us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 24/50\n",
      "297894/297894 [==============================] - 52s 174us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 25/50\n",
      "297894/297894 [==============================] - 57s 193us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 26/50\n",
      "297894/297894 [==============================] - 56s 190us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 27/50\n",
      "297894/297894 [==============================] - 61s 204us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 28/50\n",
      "297894/297894 [==============================] - 52s 174us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 29/50\n",
      "297894/297894 [==============================] - 52s 174us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 30/50\n",
      "297894/297894 [==============================] - 54s 181us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 31/50\n",
      "297894/297894 [==============================] - 59s 198us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 32/50\n",
      "297894/297894 [==============================] - 56s 189us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 33/50\n",
      "297894/297894 [==============================] - 58s 195us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 34/50\n",
      "297894/297894 [==============================] - 52s 173us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 35/50\n",
      "297894/297894 [==============================] - 52s 174us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 36/50\n",
      "297894/297894 [==============================] - 59s 197us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 37/50\n",
      "297894/297894 [==============================] - 57s 190us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 38/50\n",
      "297894/297894 [==============================] - 58s 196us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 39/50\n",
      "297894/297894 [==============================] - 55s 184us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 40/50\n",
      "297894/297894 [==============================] - 52s 176us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 41/50\n",
      "297894/297894 [==============================] - 53s 177us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 42/50\n",
      "297894/297894 [==============================] - 57s 193us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 43/50\n",
      "297894/297894 [==============================] - 58s 196us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 44/50\n",
      "297894/297894 [==============================] - 58s 196us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 45/50\n",
      "297894/297894 [==============================] - 51s 171us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 46/50\n",
      "297894/297894 [==============================] - 53s 179us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 47/50\n",
      "297894/297894 [==============================] - 56s 188us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 48/50\n",
      "297894/297894 [==============================] - 56s 188us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 49/50\n",
      "297894/297894 [==============================] - 60s 202us/step - loss: 7.4944 - acc: 0.5299\n",
      "Epoch 50/50\n",
      "297894/297894 [==============================] - 53s 179us/step - loss: 7.4944 - acc: 0.5299\n",
      "33100/33100 [==============================] - 2s 46us/step\n",
      "Epoch 1/50\n",
      "297894/297894 [==============================] - 53s 178us/step - loss: 0.1580 - acc: 0.9894\n",
      "Epoch 2/50\n",
      "297894/297894 [==============================] - 54s 181us/step - loss: 0.1802 - acc: 0.9885\n",
      "Epoch 3/50\n",
      "297894/297894 [==============================] - 60s 200us/step - loss: 1.5951 - acc: 0.8998\n",
      "Epoch 4/50\n",
      "297894/297894 [==============================] - 56s 189us/step - loss: 0.1512 - acc: 0.9904\n",
      "Epoch 5/50\n",
      "297894/297894 [==============================] - 59s 199us/step - loss: 7.1941 - acc: 0.5487\n",
      "Epoch 6/50\n",
      "297894/297894 [==============================] - 54s 182us/step - loss: 5.5419 - acc: 0.6523\n",
      "Epoch 7/50\n",
      "297894/297894 [==============================] - 52s 175us/step - loss: 0.6464 - acc: 0.9594\n",
      "Epoch 8/50\n",
      "297894/297894 [==============================] - 64s 216us/step - loss: 0.1485 - acc: 0.9907\n",
      "Epoch 9/50\n",
      "297894/297894 [==============================] - 121s 407us/step - loss: 0.1439 - acc: 0.9910\n",
      "Epoch 10/50\n",
      "297894/297894 [==============================] - 190s 637us/step - loss: 0.1412 - acc: 0.9911\n",
      "Epoch 11/50\n",
      "297894/297894 [==============================] - 207s 696us/step - loss: 0.2418 - acc: 0.9848\n",
      "Epoch 12/50\n",
      "297894/297894 [==============================] - 197s 662us/step - loss: 0.1401 - acc: 0.9912\n",
      "Epoch 13/50\n",
      "297894/297894 [==============================] - 207s 696us/step - loss: 0.1863 - acc: 0.9883\n",
      "Epoch 14/50\n",
      "297894/297894 [==============================] - 200s 673us/step - loss: 1.7262 - acc: 0.8917\n",
      "Epoch 15/50\n",
      "297894/297894 [==============================] - 176s 589us/step - loss: 0.4524 - acc: 0.9716\n",
      "Epoch 16/50\n",
      "297894/297894 [==============================] - 118s 396us/step - loss: 0.1433 - acc: 0.9910\n",
      "Epoch 17/50\n",
      "297894/297894 [==============================] - 120s 403us/step - loss: 0.2524 - acc: 0.9842\n",
      "Epoch 18/50\n",
      "297894/297894 [==============================] - 100s 335us/step - loss: 0.3329 - acc: 0.9791\n",
      "Epoch 19/50\n",
      "297894/297894 [==============================] - 83s 279us/step - loss: 0.2344 - acc: 0.9853\n",
      "Epoch 20/50\n",
      "297894/297894 [==============================] - 65s 219us/step - loss: 0.1448 - acc: 0.9909\n",
      "Epoch 21/50\n",
      "297894/297894 [==============================] - 57s 192us/step - loss: 0.1404 - acc: 0.9912\n",
      "Epoch 22/50\n",
      "297894/297894 [==============================] - 57s 192us/step - loss: 0.1385 - acc: 0.9913\n",
      "Epoch 23/50\n",
      "297894/297894 [==============================] - 51s 172us/step - loss: 0.5737 - acc: 0.9640\n",
      "Epoch 24/50\n",
      "297894/297894 [==============================] - 54s 180us/step - loss: 0.2095 - acc: 0.9869\n",
      "Epoch 25/50\n",
      "297894/297894 [==============================] - 55s 184us/step - loss: 0.2249 - acc: 0.9860\n",
      "Epoch 26/50\n",
      "297894/297894 [==============================] - 54s 180us/step - loss: 0.1499 - acc: 0.9906\n",
      "Epoch 27/50\n",
      "297894/297894 [==============================] - 56s 187us/step - loss: 0.1389 - acc: 0.9913\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297894/297894 [==============================] - 59s 197us/step - loss: 0.1758 - acc: 0.9890\n",
      "Epoch 29/50\n",
      "297894/297894 [==============================] - 52s 173us/step - loss: 0.2042 - acc: 0.9873\n",
      "Epoch 30/50\n",
      "297894/297894 [==============================] - 51s 170us/step - loss: 0.1834 - acc: 0.9885\n",
      "Epoch 31/50\n",
      "297894/297894 [==============================] - 60s 201us/step - loss: 0.1629 - acc: 0.9898\n",
      "Epoch 32/50\n",
      "297894/297894 [==============================] - 56s 187us/step - loss: 0.1643 - acc: 0.9897\n",
      "Epoch 33/50\n",
      "297894/297894 [==============================] - 57s 192us/step - loss: 0.1479 - acc: 0.9907\n",
      "Epoch 34/50\n",
      "297894/297894 [==============================] - 54s 180us/step - loss: 0.1462 - acc: 0.9908\n",
      "Epoch 35/50\n",
      "297894/297894 [==============================] - 52s 174us/step - loss: 0.1545 - acc: 0.9903\n",
      "Epoch 36/50\n",
      "297894/297894 [==============================] - 52s 175us/step - loss: 0.1422 - acc: 0.9911\n",
      "Epoch 37/50\n",
      "297894/297894 [==============================] - 60s 202us/step - loss: 0.1417 - acc: 0.9911\n",
      "Epoch 38/50\n",
      "297894/297894 [==============================] - 55s 186us/step - loss: 3.0756 - acc: 0.8071\n",
      "Epoch 39/50\n",
      "297894/297894 [==============================] - 56s 189us/step - loss: 1.5629 - acc: 0.9020\n",
      "Epoch 40/50\n",
      "297894/297894 [==============================] - 51s 171us/step - loss: 0.1359 - acc: 0.9915\n",
      "Epoch 41/50\n",
      "297894/297894 [==============================] - 52s 175us/step - loss: 0.1377 - acc: 0.9914\n",
      "Epoch 42/50\n",
      "297894/297894 [==============================] - 56s 188us/step - loss: 0.1403 - acc: 0.9912\n",
      "Epoch 43/50\n",
      "297894/297894 [==============================] - 55s 183us/step - loss: 0.1410 - acc: 0.9912\n",
      "Epoch 44/50\n",
      "297894/297894 [==============================] - 61s 203us/step - loss: 0.6415 - acc: 0.9598\n",
      "Epoch 45/50\n",
      "297894/297894 [==============================] - 52s 174us/step - loss: 2.4733 - acc: 0.8449\n",
      "Epoch 46/50\n",
      "297894/297894 [==============================] - 52s 174us/step - loss: 2.8200 - acc: 0.8231\n",
      "Epoch 47/50\n",
      "297894/297894 [==============================] - 54s 182us/step - loss: 0.1448 - acc: 0.9909\n",
      "Epoch 48/50\n",
      "297894/297894 [==============================] - 57s 193us/step - loss: 0.4100 - acc: 0.9743\n",
      "Epoch 49/50\n",
      "297894/297894 [==============================] - 55s 185us/step - loss: 0.3273 - acc: 0.9795\n",
      "Epoch 50/50\n",
      "297894/297894 [==============================] - 61s 206us/step - loss: 0.1443 - acc: 0.9909\n",
      "33100/33100 [==============================] - 2s 48us/step\n",
      "Epoch 1/50\n",
      "297894/297894 [==============================] - 52s 175us/step - loss: 1.1600 - acc: 0.9267\n",
      "Epoch 2/50\n",
      "297894/297894 [==============================] - 52s 173us/step - loss: 0.9221 - acc: 0.9420\n",
      "Epoch 3/50\n",
      "297894/297894 [==============================] - 51s 172us/step - loss: 0.1489 - acc: 0.9906\n",
      "Epoch 4/50\n",
      "297894/297894 [==============================] - 54s 182us/step - loss: 0.1566 - acc: 0.9902\n",
      "Epoch 5/50\n",
      "297894/297894 [==============================] - 52s 174us/step - loss: 0.8528 - acc: 0.9465\n",
      "Epoch 6/50\n",
      "297894/297894 [==============================] - 52s 174us/step - loss: 0.1873 - acc: 0.9882\n",
      "Epoch 7/50\n",
      "297894/297894 [==============================] - 54s 182us/step - loss: 0.1487 - acc: 0.9907\n",
      "Epoch 8/50\n",
      "297894/297894 [==============================] - 51s 173us/step - loss: 0.1504 - acc: 0.9906\n",
      "Epoch 9/50\n",
      "297894/297894 [==============================] - 52s 175us/step - loss: 0.1409 - acc: 0.9912\n",
      "Epoch 10/50\n",
      "297894/297894 [==============================] - 52s 175us/step - loss: 1.2105 - acc: 0.9241\n",
      "Epoch 11/50\n",
      "297894/297894 [==============================] - 53s 179us/step - loss: 1.0670 - acc: 0.9331\n",
      "Epoch 12/50\n",
      "297894/297894 [==============================] - 52s 174us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 13/50\n",
      "297894/297894 [==============================] - 52s 174us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 14/50\n",
      "297894/297894 [==============================] - 54s 181us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 15/50\n",
      "297894/297894 [==============================] - 52s 174us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 16/50\n",
      "297894/297894 [==============================] - 52s 173us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 17/50\n",
      "297894/297894 [==============================] - 52s 173us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 18/50\n",
      "297894/297894 [==============================] - 53s 177us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 19/50\n",
      "297894/297894 [==============================] - 51s 171us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 20/50\n",
      "297894/297894 [==============================] - 51s 173us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 21/50\n",
      "297894/297894 [==============================] - 53s 179us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 22/50\n",
      "297894/297894 [==============================] - 51s 172us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 23/50\n",
      "297894/297894 [==============================] - 51s 172us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 24/50\n",
      "297894/297894 [==============================] - 51s 170us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 25/50\n",
      "297894/297894 [==============================] - 53s 176us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 26/50\n",
      "297894/297894 [==============================] - 50s 169us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 27/50\n",
      "297894/297894 [==============================] - 51s 172us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 28/50\n",
      "297894/297894 [==============================] - 53s 179us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 29/50\n",
      "297894/297894 [==============================] - 51s 170us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 30/50\n",
      "297894/297894 [==============================] - 51s 172us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 31/50\n",
      "297894/297894 [==============================] - 51s 171us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 32/50\n",
      "297894/297894 [==============================] - 52s 175us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 33/50\n",
      "297894/297894 [==============================] - 51s 170us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 34/50\n",
      "297894/297894 [==============================] - 50s 169us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 35/50\n",
      "297894/297894 [==============================] - 53s 177us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 36/50\n",
      "297894/297894 [==============================] - 51s 171us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 37/50\n",
      "297894/297894 [==============================] - 55s 186us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 38/50\n",
      "297894/297894 [==============================] - 56s 189us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 39/50\n",
      "297894/297894 [==============================] - 56s 190us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 40/50\n",
      "297894/297894 [==============================] - 52s 173us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 41/50\n",
      "297894/297894 [==============================] - 49s 166us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 42/50\n",
      "297894/297894 [==============================] - 53s 177us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 43/50\n",
      "297894/297894 [==============================] - 55s 186us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 44/50\n",
      "297894/297894 [==============================] - 55s 184us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 45/50\n",
      "297894/297894 [==============================] - 59s 197us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 46/50\n",
      "297894/297894 [==============================] - 50s 169us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 47/50\n",
      "297894/297894 [==============================] - 50s 169us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 48/50\n",
      "297894/297894 [==============================] - 54s 181us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 49/50\n",
      "297894/297894 [==============================] - 56s 187us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 50/50\n",
      "297894/297894 [==============================] - 57s 190us/step - loss: 0.1449 - acc: 0.9909\n",
      "33100/33100 [==============================] - 2s 48us/step\n",
      "Epoch 1/50\n",
      "297894/297894 [==============================] - 56s 188us/step - loss: 0.1586 - acc: 0.9894\n",
      "Epoch 2/50\n",
      "297894/297894 [==============================] - 51s 173us/step - loss: 0.1648 - acc: 0.9894\n",
      "Epoch 3/50\n",
      "297894/297894 [==============================] - 50s 167us/step - loss: 0.1619 - acc: 0.9897\n",
      "Epoch 4/50\n",
      "297894/297894 [==============================] - 53s 179us/step - loss: 0.1602 - acc: 0.9899\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297894/297894 [==============================] - 56s 188us/step - loss: 0.1370 - acc: 0.9913\n",
      "Epoch 6/50\n",
      "297894/297894 [==============================] - 56s 187us/step - loss: 0.1445 - acc: 0.9909\n",
      "Epoch 7/50\n",
      "297894/297894 [==============================] - 51s 173us/step - loss: 0.1555 - acc: 0.9902\n",
      "Epoch 8/50\n",
      "297894/297894 [==============================] - 50s 166us/step - loss: 0.1387 - acc: 0.9913\n",
      "Epoch 9/50\n",
      "297894/297894 [==============================] - 51s 172us/step - loss: 0.1419 - acc: 0.9911\n",
      "Epoch 10/50\n",
      "297894/297894 [==============================] - 56s 188us/step - loss: 0.1362 - acc: 0.9914\n",
      "Epoch 11/50\n",
      "297894/297894 [==============================] - 53s 177us/step - loss: 2.6187 - acc: 0.8357\n",
      "Epoch 12/50\n",
      "297894/297894 [==============================] - 60s 200us/step - loss: 4.8551 - acc: 0.6955\n",
      "Epoch 13/50\n",
      "297894/297894 [==============================] - 50s 168us/step - loss: 0.1369 - acc: 0.9914\n",
      "Epoch 14/50\n",
      "297894/297894 [==============================] - 50s 168us/step - loss: 0.1351 - acc: 0.9915\n",
      "Epoch 15/50\n",
      "297894/297894 [==============================] - 52s 175us/step - loss: 0.1354 - acc: 0.9915\n",
      "Epoch 16/50\n",
      "297894/297894 [==============================] - 57s 191us/step - loss: 0.1387 - acc: 0.9913\n",
      "Epoch 17/50\n",
      "297894/297894 [==============================] - 53s 177us/step - loss: 0.1357 - acc: 0.9915\n",
      "Epoch 18/50\n",
      "297894/297894 [==============================] - 56s 187us/step - loss: 0.1350 - acc: 0.9915\n",
      "Epoch 19/50\n",
      "297894/297894 [==============================] - 52s 173us/step - loss: 0.1384 - acc: 0.9913\n",
      "Epoch 20/50\n",
      "297894/297894 [==============================] - 50s 168us/step - loss: 0.1403 - acc: 0.9912\n",
      "Epoch 21/50\n",
      "297894/297894 [==============================] - 50s 167us/step - loss: 0.1948 - acc: 0.9878\n",
      "Epoch 22/50\n",
      "297894/297894 [==============================] - 52s 174us/step - loss: 0.1780 - acc: 0.9888\n",
      "Epoch 23/50\n",
      "297894/297894 [==============================] - 50s 167us/step - loss: 0.1412 - acc: 0.9911\n",
      "Epoch 24/50\n",
      "297894/297894 [==============================] - 49s 165us/step - loss: 0.1377 - acc: 0.9913\n",
      "Epoch 25/50\n",
      "297894/297894 [==============================] - 49s 164us/step - loss: 0.1369 - acc: 0.9914\n",
      "Epoch 26/50\n",
      "297894/297894 [==============================] - 52s 174us/step - loss: 0.1354 - acc: 0.9915\n",
      "Epoch 27/50\n",
      "297894/297894 [==============================] - 50s 166us/step - loss: 0.1419 - acc: 0.9911\n",
      "Epoch 28/50\n",
      "297894/297894 [==============================] - 50s 166us/step - loss: 0.1364 - acc: 0.9914\n",
      "Epoch 29/50\n",
      "297894/297894 [==============================] - 51s 173us/step - loss: 0.1370 - acc: 0.9914\n",
      "Epoch 30/50\n",
      "297894/297894 [==============================] - 49s 166us/step - loss: 0.1418 - acc: 0.9911\n",
      "Epoch 31/50\n",
      "297894/297894 [==============================] - 49s 166us/step - loss: 0.1783 - acc: 0.9888\n",
      "Epoch 32/50\n",
      "297894/297894 [==============================] - 50s 168us/step - loss: 0.1361 - acc: 0.9914\n",
      "Epoch 33/50\n",
      "297894/297894 [==============================] - 52s 175us/step - loss: 0.1345 - acc: 0.9916\n",
      "Epoch 34/50\n",
      "297894/297894 [==============================] - 50s 167us/step - loss: 0.1374 - acc: 0.9914\n",
      "Epoch 35/50\n",
      "297894/297894 [==============================] - 50s 168us/step - loss: 0.1325 - acc: 0.9917\n",
      "Epoch 36/50\n",
      "297894/297894 [==============================] - 50s 168us/step - loss: 0.1403 - acc: 0.9912\n",
      "Epoch 37/50\n",
      "297894/297894 [==============================] - 51s 173us/step - loss: 0.1415 - acc: 0.9911\n",
      "Epoch 38/50\n",
      "297894/297894 [==============================] - 50s 166us/step - loss: 0.1384 - acc: 0.9913\n",
      "Epoch 39/50\n",
      "297894/297894 [==============================] - 50s 167us/step - loss: 0.1643 - acc: 0.9897\n",
      "Epoch 40/50\n",
      "297894/297894 [==============================] - 52s 174us/step - loss: 0.1340 - acc: 0.9916\n",
      "Epoch 41/50\n",
      "297894/297894 [==============================] - 50s 167us/step - loss: 0.1353 - acc: 0.9915\n",
      "Epoch 42/50\n",
      "297894/297894 [==============================] - 50s 167us/step - loss: 0.1319 - acc: 0.9917\n",
      "Epoch 43/50\n",
      "297894/297894 [==============================] - 49s 164us/step - loss: 0.1386 - acc: 0.9913\n",
      "Epoch 44/50\n",
      "297894/297894 [==============================] - 52s 175us/step - loss: 0.1360 - acc: 0.9915\n",
      "Epoch 45/50\n",
      "297894/297894 [==============================] - 50s 167us/step - loss: 0.1395 - acc: 0.9912\n",
      "Epoch 46/50\n",
      "297894/297894 [==============================] - 50s 166us/step - loss: 0.1367 - acc: 0.9914\n",
      "Epoch 47/50\n",
      "297894/297894 [==============================] - 52s 174us/step - loss: 0.1369 - acc: 0.9914\n",
      "Epoch 48/50\n",
      "297894/297894 [==============================] - 50s 167us/step - loss: 0.1336 - acc: 0.9916\n",
      "Epoch 49/50\n",
      "297894/297894 [==============================] - 49s 164us/step - loss: 0.1336 - acc: 0.9916\n",
      "Epoch 50/50\n",
      "297894/297894 [==============================] - 50s 168us/step - loss: 0.1336 - acc: 0.9916\n",
      "33100/33100 [==============================] - 2s 48us/step\n",
      "Epoch 1/50\n",
      "297895/297895 [==============================] - 53s 178us/step - loss: 0.4600 - acc: 0.9710\n",
      "Epoch 2/50\n",
      "297895/297895 [==============================] - 50s 169us/step - loss: 0.2494 - acc: 0.9844\n",
      "Epoch 3/50\n",
      "297895/297895 [==============================] - 50s 168us/step - loss: 0.1776 - acc: 0.9888\n",
      "Epoch 4/50\n",
      "297895/297895 [==============================] - 52s 176us/step - loss: 0.1902 - acc: 0.9881\n",
      "Epoch 5/50\n",
      "297895/297895 [==============================] - 49s 166us/step - loss: 0.2014 - acc: 0.9874\n",
      "Epoch 6/50\n",
      "297895/297895 [==============================] - 50s 167us/step - loss: 0.5646 - acc: 0.9646\n",
      "Epoch 7/50\n",
      "297895/297895 [==============================] - 56s 189us/step - loss: 0.2158 - acc: 0.9865\n",
      "Epoch 8/50\n",
      "297895/297895 [==============================] - 56s 187us/step - loss: 0.2236 - acc: 0.9860\n",
      "Epoch 9/50\n",
      "297895/297895 [==============================] - 56s 188us/step - loss: 0.1708 - acc: 0.9893\n",
      "Epoch 10/50\n",
      "297895/297895 [==============================] - 50s 169us/step - loss: 0.2178 - acc: 0.9864\n",
      "Epoch 11/50\n",
      "297895/297895 [==============================] - 53s 177us/step - loss: 0.1717 - acc: 0.9892\n",
      "Epoch 12/50\n",
      "297895/297895 [==============================] - 54s 181us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 13/50\n",
      "297895/297895 [==============================] - 55s 184us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 14/50\n",
      "297895/297895 [==============================] - 55s 184us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 15/50\n",
      "297895/297895 [==============================] - 55s 186us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 16/50\n",
      "297895/297895 [==============================] - 50s 169us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 17/50\n",
      "297895/297895 [==============================] - 51s 171us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 18/50\n",
      "297895/297895 [==============================] - 58s 196us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 19/50\n",
      "297895/297895 [==============================] - 55s 184us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 20/50\n",
      "297895/297895 [==============================] - 57s 190us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 21/50\n",
      "297895/297895 [==============================] - 53s 177us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 22/50\n",
      "297895/297895 [==============================] - 50s 168us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 23/50\n",
      "297895/297895 [==============================] - 50s 168us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 24/50\n",
      "297895/297895 [==============================] - 57s 192us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 25/50\n",
      "297895/297895 [==============================] - 55s 184us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 26/50\n",
      "297895/297895 [==============================] - 56s 187us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 27/50\n",
      "297895/297895 [==============================] - 50s 168us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 28/50\n",
      "297895/297895 [==============================] - 53s 176us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 29/50\n",
      "297895/297895 [==============================] - 52s 174us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 30/50\n",
      "297895/297895 [==============================] - 56s 187us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 31/50\n",
      "297895/297895 [==============================] - 57s 190us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297895/297895 [==============================] - 55s 184us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 33/50\n",
      "297895/297895 [==============================] - 50s 168us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 34/50\n",
      "297895/297895 [==============================] - 50s 168us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 35/50\n",
      "297895/297895 [==============================] - 57s 192us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 36/50\n",
      "297895/297895 [==============================] - 54s 183us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 37/50\n",
      "297895/297895 [==============================] - 58s 193us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 38/50\n",
      "297895/297895 [==============================] - 53s 180us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 39/50\n",
      "297895/297895 [==============================] - 50s 169us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 40/50\n",
      "297895/297895 [==============================] - 50s 169us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 41/50\n",
      "297895/297895 [==============================] - 53s 177us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 42/50\n",
      "297895/297895 [==============================] - 49s 166us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 43/50\n",
      "297895/297895 [==============================] - 50s 169us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 44/50\n",
      "297895/297895 [==============================] - 50s 169us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 45/50\n",
      "297895/297895 [==============================] - 53s 177us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 46/50\n",
      "297895/297895 [==============================] - 50s 169us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 47/50\n",
      "297895/297895 [==============================] - 50s 168us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 48/50\n",
      "297895/297895 [==============================] - 50s 169us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 49/50\n",
      "297895/297895 [==============================] - 52s 174us/step - loss: 0.1683 - acc: 0.9895\n",
      "Epoch 50/50\n",
      "297895/297895 [==============================] - 51s 171us/step - loss: 0.1683 - acc: 0.9895\n",
      "33099/33099 [==============================] - 2s 49us/step\n",
      "Epoch 1/50\n",
      "297895/297895 [==============================] - 52s 175us/step - loss: 0.1873 - acc: 0.9877\n",
      "Epoch 2/50\n",
      "297895/297895 [==============================] - 54s 180us/step - loss: 0.1797 - acc: 0.9887\n",
      "Epoch 3/50\n",
      "297895/297895 [==============================] - 51s 172us/step - loss: 0.2140 - acc: 0.9866\n",
      "Epoch 4/50\n",
      "297895/297895 [==============================] - 51s 170us/step - loss: 0.7602 - acc: 0.9523\n",
      "Epoch 5/50\n",
      "297895/297895 [==============================] - 53s 177us/step - loss: 0.1795 - acc: 0.9887\n",
      "Epoch 6/50\n",
      "297895/297895 [==============================] - 51s 170us/step - loss: 0.1611 - acc: 0.9899\n",
      "Epoch 7/50\n",
      "297895/297895 [==============================] - 51s 171us/step - loss: 0.8044 - acc: 0.9495\n",
      "Epoch 8/50\n",
      "297895/297895 [==============================] - 51s 172us/step - loss: 6.1450 - acc: 0.6145\n",
      "Epoch 9/50\n",
      "297895/297895 [==============================] - 53s 179us/step - loss: 1.2849 - acc: 0.9194\n",
      "Epoch 10/50\n",
      "297895/297895 [==============================] - 51s 171us/step - loss: 0.2193 - acc: 0.9863\n",
      "Epoch 11/50\n",
      "297895/297895 [==============================] - 51s 171us/step - loss: 0.1879 - acc: 0.9883\n",
      "Epoch 12/50\n",
      "297895/297895 [==============================] - 53s 179us/step - loss: 0.1560 - acc: 0.9902\n",
      "Epoch 13/50\n",
      "297895/297895 [==============================] - 51s 171us/step - loss: 0.2133 - acc: 0.9867\n",
      "Epoch 14/50\n",
      "297895/297895 [==============================] - 52s 173us/step - loss: 0.1621 - acc: 0.9898\n",
      "Epoch 15/50\n",
      "297895/297895 [==============================] - 51s 172us/step - loss: 0.2035 - acc: 0.9873\n",
      "Epoch 16/50\n",
      "297895/297895 [==============================] - 54s 182us/step - loss: 0.2950 - acc: 0.9817\n",
      "Epoch 17/50\n",
      "297895/297895 [==============================] - 52s 175us/step - loss: 0.1716 - acc: 0.9892\n",
      "Epoch 18/50\n",
      "297895/297895 [==============================] - 52s 176us/step - loss: 0.1633 - acc: 0.9898\n",
      "Epoch 19/50\n",
      "297895/297895 [==============================] - 54s 183us/step - loss: 0.1639 - acc: 0.9897\n",
      "Epoch 20/50\n",
      "297895/297895 [==============================] - 52s 173us/step - loss: 0.1640 - acc: 0.9897\n",
      "Epoch 21/50\n",
      "297895/297895 [==============================] - 51s 172us/step - loss: 0.1640 - acc: 0.9897\n",
      "Epoch 22/50\n",
      "297895/297895 [==============================] - 51s 173us/step - loss: 0.1640 - acc: 0.9897\n",
      "Epoch 23/50\n",
      "297895/297895 [==============================] - 54s 182us/step - loss: 0.1640 - acc: 0.9897\n",
      "Epoch 24/50\n",
      "297895/297895 [==============================] - 52s 175us/step - loss: 0.1640 - acc: 0.9897\n",
      "Epoch 25/50\n",
      "297895/297895 [==============================] - 58s 195us/step - loss: 0.1640 - acc: 0.9897\n",
      "Epoch 26/50\n",
      "297895/297895 [==============================] - 59s 197us/step - loss: 0.1640 - acc: 0.9897\n",
      "Epoch 27/50\n",
      "297895/297895 [==============================] - 58s 195us/step - loss: 0.1640 - acc: 0.9897\n",
      "Epoch 28/50\n",
      "297895/297895 [==============================] - 53s 177us/step - loss: 0.1640 - acc: 0.9897\n",
      "Epoch 29/50\n",
      "297895/297895 [==============================] - 55s 185us/step - loss: 0.1640 - acc: 0.9897\n",
      "Epoch 30/50\n",
      "297895/297895 [==============================] - 56s 188us/step - loss: 0.1640 - acc: 0.9897\n",
      "Epoch 31/50\n",
      "297895/297895 [==============================] - 55s 185us/step - loss: 0.1640 - acc: 0.9897\n",
      "Epoch 32/50\n",
      "297895/297895 [==============================] - 59s 198us/step - loss: 0.1640 - acc: 0.9897\n",
      "Epoch 33/50\n",
      "297895/297895 [==============================] - 56s 189us/step - loss: 0.1640 - acc: 0.9897\n",
      "Epoch 34/50\n",
      "297895/297895 [==============================] - 52s 176us/step - loss: 0.1640 - acc: 0.9897\n",
      "Epoch 35/50\n",
      "297895/297895 [==============================] - 53s 177us/step - loss: 0.1640 - acc: 0.9897\n",
      "Epoch 36/50\n",
      "297895/297895 [==============================] - 60s 202us/step - loss: 0.1640 - acc: 0.9897\n",
      "Epoch 37/50\n",
      "297895/297895 [==============================] - 57s 191us/step - loss: 0.1640 - acc: 0.9897\n",
      "Epoch 38/50\n",
      "297895/297895 [==============================] - 58s 196us/step - loss: 0.1640 - acc: 0.9897\n",
      "Epoch 39/50\n",
      "297895/297895 [==============================] - 55s 185us/step - loss: 0.1640 - acc: 0.9897\n",
      "Epoch 40/50\n",
      "297895/297895 [==============================] - 53s 177us/step - loss: 0.1640 - acc: 0.9897\n",
      "Epoch 41/50\n",
      "297895/297895 [==============================] - 53s 179us/step - loss: 0.1640 - acc: 0.9897\n",
      "Epoch 42/50\n",
      "297895/297895 [==============================] - 61s 205us/step - loss: 0.1640 - acc: 0.9897\n",
      "Epoch 43/50\n",
      "297895/297895 [==============================] - 57s 190us/step - loss: 0.1640 - acc: 0.9897\n",
      "Epoch 44/50\n",
      "297895/297895 [==============================] - 57s 192us/step - loss: 0.1640 - acc: 0.9897\n",
      "Epoch 45/50\n",
      "297895/297895 [==============================] - 54s 182us/step - loss: 0.1640 - acc: 0.9897\n",
      "Epoch 46/50\n",
      "297895/297895 [==============================] - 52s 173us/step - loss: 0.1640 - acc: 0.9897\n",
      "Epoch 47/50\n",
      "297895/297895 [==============================] - 58s 193us/step - loss: 0.1640 - acc: 0.9897\n",
      "Epoch 48/50\n",
      "297895/297895 [==============================] - 58s 195us/step - loss: 0.1640 - acc: 0.9897\n",
      "Epoch 49/50\n",
      "297895/297895 [==============================] - 62s 207us/step - loss: 0.1640 - acc: 0.9897\n",
      "Epoch 50/50\n",
      "297895/297895 [==============================] - 53s 178us/step - loss: 0.1640 - acc: 0.9897\n",
      "33099/33099 [==============================] - 2s 53us/step\n",
      "Epoch 1/50\n",
      "297895/297895 [==============================] - 53s 179us/step - loss: 0.1771 - acc: 0.9882\n",
      "Epoch 2/50\n",
      "297895/297895 [==============================] - 59s 199us/step - loss: 0.1729 - acc: 0.9889\n",
      "Epoch 3/50\n",
      "297895/297895 [==============================] - 58s 195us/step - loss: 7.1772 - acc: 0.5497\n",
      "Epoch 4/50\n",
      "297895/297895 [==============================] - 59s 199us/step - loss: 7.8851 - acc: 0.5054\n",
      "Epoch 5/50\n",
      "297895/297895 [==============================] - 57s 192us/step - loss: 0.1509 - acc: 0.9905\n",
      "Epoch 6/50\n",
      "297895/297895 [==============================] - 53s 178us/step - loss: 0.1802 - acc: 0.9887\n",
      "Epoch 7/50\n",
      "297895/297895 [==============================] - 54s 180us/step - loss: 1.2517 - acc: 0.9214\n",
      "Epoch 8/50\n",
      "297895/297895 [==============================] - 55s 185us/step - loss: 0.1661 - acc: 0.9896\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297895/297895 [==============================] - 53s 178us/step - loss: 0.2015 - acc: 0.9874\n",
      "Epoch 10/50\n",
      "297895/297895 [==============================] - 53s 178us/step - loss: 0.1449 - acc: 0.9909\n",
      "Epoch 11/50\n",
      "297895/297895 [==============================] - 54s 183us/step - loss: 0.1357 - acc: 0.9915\n",
      "Epoch 12/50\n",
      "297895/297895 [==============================] - 52s 176us/step - loss: 0.1411 - acc: 0.9911\n",
      "Epoch 13/50\n",
      "297895/297895 [==============================] - 53s 176us/step - loss: 0.1504 - acc: 0.9906\n",
      "Epoch 14/50\n",
      "297895/297895 [==============================] - 53s 176us/step - loss: 0.1410 - acc: 0.9912\n",
      "Epoch 15/50\n",
      "297895/297895 [==============================] - 55s 184us/step - loss: 0.1572 - acc: 0.9901\n",
      "Epoch 16/50\n",
      "297895/297895 [==============================] - 53s 178us/step - loss: 0.1679 - acc: 0.9895\n",
      "Epoch 17/50\n",
      "297895/297895 [==============================] - 54s 181us/step - loss: 7.2830 - acc: 0.5431\n",
      "Epoch 18/50\n",
      "297895/297895 [==============================] - 56s 187us/step - loss: 6.1928 - acc: 0.6115\n",
      "Epoch 19/50\n",
      "297895/297895 [==============================] - 53s 177us/step - loss: 0.1436 - acc: 0.9910\n",
      "Epoch 20/50\n",
      "297895/297895 [==============================] - 52s 174us/step - loss: 0.1415 - acc: 0.9911\n",
      "Epoch 21/50\n",
      "297895/297895 [==============================] - 54s 182us/step - loss: 0.1473 - acc: 0.9908\n",
      "Epoch 22/50\n",
      "297895/297895 [==============================] - 53s 178us/step - loss: 0.1431 - acc: 0.9910\n",
      "Epoch 23/50\n",
      "297895/297895 [==============================] - 53s 179us/step - loss: 0.1430 - acc: 0.9910\n",
      "Epoch 24/50\n",
      "297895/297895 [==============================] - 53s 178us/step - loss: 0.2113 - acc: 0.9868\n",
      "Epoch 25/50\n",
      "297895/297895 [==============================] - 55s 184us/step - loss: 0.1447 - acc: 0.9909\n",
      "Epoch 26/50\n",
      "297895/297895 [==============================] - 53s 177us/step - loss: 0.1371 - acc: 0.9914\n",
      "Epoch 27/50\n",
      "297895/297895 [==============================] - 53s 178us/step - loss: 0.1374 - acc: 0.9914\n",
      "Epoch 28/50\n",
      "297895/297895 [==============================] - 54s 182us/step - loss: 0.1425 - acc: 0.9911\n",
      "Epoch 29/50\n",
      "297895/297895 [==============================] - 52s 175us/step - loss: 0.1399 - acc: 0.9912\n",
      "Epoch 30/50\n",
      "297895/297895 [==============================] - 53s 177us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 31/50\n",
      "297895/297895 [==============================] - 53s 177us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 32/50\n",
      "297895/297895 [==============================] - 55s 186us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 33/50\n",
      "297895/297895 [==============================] - 54s 180us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 34/50\n",
      "297895/297895 [==============================] - 53s 178us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 35/50\n",
      "297895/297895 [==============================] - 55s 186us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 36/50\n",
      "297895/297895 [==============================] - 53s 179us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 37/50\n",
      "297895/297895 [==============================] - 53s 178us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 38/50\n",
      "297895/297895 [==============================] - 55s 185us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 39/50\n",
      "297895/297895 [==============================] - 53s 176us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 40/50\n",
      "297895/297895 [==============================] - 53s 178us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 41/50\n",
      "297895/297895 [==============================] - 59s 197us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 42/50\n",
      "297895/297895 [==============================] - 59s 199us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 43/50\n",
      "297895/297895 [==============================] - 57s 192us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 44/50\n",
      "297895/297895 [==============================] - 53s 178us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 45/50\n",
      "297895/297895 [==============================] - 55s 183us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 46/50\n",
      "297895/297895 [==============================] - 58s 195us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 47/50\n",
      "297895/297895 [==============================] - 57s 191us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 48/50\n",
      "297895/297895 [==============================] - 61s 204us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 49/50\n",
      "297895/297895 [==============================] - 53s 179us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 50/50\n",
      "297895/297895 [==============================] - 53s 179us/step - loss: 0.1381 - acc: 0.9913\n",
      "33099/33099 [==============================] - 2s 51us/step\n",
      "Epoch 1/50\n",
      "297895/297895 [==============================] - 59s 198us/step - loss: 0.3865 - acc: 0.9751\n",
      "Epoch 2/50\n",
      "297895/297895 [==============================] - 57s 192us/step - loss: 0.9282 - acc: 0.9416\n",
      "Epoch 3/50\n",
      "297895/297895 [==============================] - 55s 186us/step - loss: 0.1499 - acc: 0.9905\n",
      "Epoch 4/50\n",
      "297895/297895 [==============================] - 59s 200us/step - loss: 0.2208 - acc: 0.9861\n",
      "Epoch 5/50\n",
      "297895/297895 [==============================] - 52s 175us/step - loss: 0.1733 - acc: 0.9891\n",
      "Epoch 6/50\n",
      "297895/297895 [==============================] - 52s 175us/step - loss: 0.1757 - acc: 0.9890\n",
      "Epoch 7/50\n",
      "297895/297895 [==============================] - 58s 196us/step - loss: 0.1407 - acc: 0.9912\n",
      "Epoch 8/50\n",
      "297895/297895 [==============================] - 58s 195us/step - loss: 0.3489 - acc: 0.9781\n",
      "Epoch 9/50\n",
      "297895/297895 [==============================] - 58s 194us/step - loss: 0.1602 - acc: 0.9900\n",
      "Epoch 10/50\n",
      "297895/297895 [==============================] - 52s 174us/step - loss: 0.1644 - acc: 0.9897\n",
      "Epoch 11/50\n",
      "297895/297895 [==============================] - 54s 182us/step - loss: 0.1484 - acc: 0.9907\n",
      "Epoch 12/50\n",
      "297895/297895 [==============================] - 56s 186us/step - loss: 0.1589 - acc: 0.9900\n",
      "Epoch 13/50\n",
      "297895/297895 [==============================] - 57s 191us/step - loss: 0.1419 - acc: 0.9911\n",
      "Epoch 14/50\n",
      "297895/297895 [==============================] - 62s 208us/step - loss: 0.1442 - acc: 0.9909\n",
      "Epoch 15/50\n",
      "297895/297895 [==============================] - 53s 177us/step - loss: 0.1416 - acc: 0.9911\n",
      "Epoch 16/50\n",
      "297895/297895 [==============================] - 52s 175us/step - loss: 0.6663 - acc: 0.9582\n",
      "Epoch 17/50\n",
      "297895/297895 [==============================] - 53s 179us/step - loss: 0.1392 - acc: 0.9913\n",
      "Epoch 18/50\n",
      "297895/297895 [==============================] - 58s 194us/step - loss: 0.1420 - acc: 0.9911\n",
      "Epoch 19/50\n",
      "297895/297895 [==============================] - 55s 185us/step - loss: 0.1581 - acc: 0.9901\n",
      "Epoch 20/50\n",
      "297895/297895 [==============================] - 60s 200us/step - loss: 0.1503 - acc: 0.9906\n",
      "Epoch 21/50\n",
      "297895/297895 [==============================] - 52s 175us/step - loss: 0.1500 - acc: 0.9906\n",
      "Epoch 22/50\n",
      "297895/297895 [==============================] - 51s 172us/step - loss: 0.1387 - acc: 0.9913\n",
      "Epoch 23/50\n",
      "297895/297895 [==============================] - 52s 173us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 24/50\n",
      "297895/297895 [==============================] - 54s 180us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 25/50\n",
      "297895/297895 [==============================] - 52s 174us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 26/50\n",
      "297895/297895 [==============================] - 52s 174us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 27/50\n",
      "297895/297895 [==============================] - 54s 182us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 28/50\n",
      "297895/297895 [==============================] - 52s 174us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 29/50\n",
      "297895/297895 [==============================] - 52s 174us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 30/50\n",
      "297895/297895 [==============================] - 51s 173us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 31/50\n",
      "297895/297895 [==============================] - 54s 181us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 32/50\n",
      "297895/297895 [==============================] - 52s 175us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 33/50\n",
      "297895/297895 [==============================] - 53s 177us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 34/50\n",
      "297895/297895 [==============================] - 55s 183us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 35/50\n",
      "297895/297895 [==============================] - 51s 173us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297895/297895 [==============================] - 52s 174us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 37/50\n",
      "297895/297895 [==============================] - 51s 171us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 38/50\n",
      "297895/297895 [==============================] - 54s 181us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 39/50\n",
      "297895/297895 [==============================] - 52s 173us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 40/50\n",
      "297895/297895 [==============================] - 52s 173us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 41/50\n",
      "297895/297895 [==============================] - 54s 180us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 42/50\n",
      "297895/297895 [==============================] - 51s 172us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 43/50\n",
      "297895/297895 [==============================] - 52s 176us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 44/50\n",
      "297895/297895 [==============================] - 54s 182us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 45/50\n",
      "297895/297895 [==============================] - 53s 177us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 46/50\n",
      "297895/297895 [==============================] - 52s 174us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 47/50\n",
      "297895/297895 [==============================] - 52s 173us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 48/50\n",
      "297895/297895 [==============================] - 54s 182us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 49/50\n",
      "297895/297895 [==============================] - 52s 174us/step - loss: 0.1381 - acc: 0.9913\n",
      "Epoch 50/50\n",
      "297895/297895 [==============================] - 52s 174us/step - loss: 0.1381 - acc: 0.9913\n",
      "33099/33099 [==============================] - 2s 54us/step\n",
      "Epoch 1/50\n",
      "297895/297895 [==============================] - 55s 186us/step - loss: 0.5170 - acc: 0.9673\n",
      "Epoch 2/50\n",
      "297895/297895 [==============================] - 53s 177us/step - loss: 0.5723 - acc: 0.9642\n",
      "Epoch 3/50\n",
      "297895/297895 [==============================] - 53s 179us/step - loss: 1.9500 - acc: 0.8777\n",
      "Epoch 4/50\n",
      "297895/297895 [==============================] - 53s 177us/step - loss: 0.1987 - acc: 0.9875\n",
      "Epoch 5/50\n",
      "297895/297895 [==============================] - 55s 183us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 6/50\n",
      "297895/297895 [==============================] - 53s 177us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 7/50\n",
      "297895/297895 [==============================] - 58s 195us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 8/50\n",
      "297895/297895 [==============================] - 59s 198us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 9/50\n",
      "297895/297895 [==============================] - 59s 199us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 10/50\n",
      "297895/297895 [==============================] - 54s 180us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 11/50\n",
      "297895/297895 [==============================] - 55s 185us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 12/50\n",
      "297895/297895 [==============================] - 53s 177us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 13/50\n",
      "297895/297895 [==============================] - 60s 200us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 14/50\n",
      "297895/297895 [==============================] - 59s 198us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 15/50\n",
      "297895/297895 [==============================] - 57s 191us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 16/50\n",
      "297895/297895 [==============================] - 54s 180us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 17/50\n",
      "297895/297895 [==============================] - 55s 185us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 18/50\n",
      "297895/297895 [==============================] - 58s 195us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 19/50\n",
      "297895/297895 [==============================] - 58s 196us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 20/50\n",
      "297895/297895 [==============================] - 61s 206us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 21/50\n",
      "297895/297895 [==============================] - 54s 180us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 22/50\n",
      "297895/297895 [==============================] - 53s 179us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 23/50\n",
      "297895/297895 [==============================] - 57s 191us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 24/50\n",
      "297895/297895 [==============================] - 59s 200us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 25/50\n",
      "297895/297895 [==============================] - 61s 206us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 26/50\n",
      "297895/297895 [==============================] - 53s 179us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 27/50\n",
      "297895/297895 [==============================] - 55s 185us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 28/50\n",
      "297895/297895 [==============================] - 57s 193us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 29/50\n",
      "297895/297895 [==============================] - 57s 192us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 30/50\n",
      "297895/297895 [==============================] - 60s 200us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 31/50\n",
      "297895/297895 [==============================] - 57s 192us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 32/50\n",
      "297895/297895 [==============================] - 53s 178us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 33/50\n",
      "297895/297895 [==============================] - 56s 188us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 34/50\n",
      "297895/297895 [==============================] - 59s 196us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 35/50\n",
      "297895/297895 [==============================] - 58s 196us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 36/50\n",
      "297895/297895 [==============================] - 62s 209us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 37/50\n",
      "297895/297895 [==============================] - 54s 182us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 38/50\n",
      "297895/297895 [==============================] - 54s 182us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 39/50\n",
      "297895/297895 [==============================] - 54s 182us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 40/50\n",
      "297895/297895 [==============================] - 56s 187us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 41/50\n",
      "297895/297895 [==============================] - 53s 178us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 42/50\n",
      "297895/297895 [==============================] - 53s 179us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 43/50\n",
      "297895/297895 [==============================] - 55s 184us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 44/50\n",
      "297895/297895 [==============================] - 52s 174us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 45/50\n",
      "297895/297895 [==============================] - 53s 177us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 46/50\n",
      "297895/297895 [==============================] - 55s 185us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 47/50\n",
      "297895/297895 [==============================] - 52s 176us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 48/50\n",
      "297895/297895 [==============================] - 52s 175us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 49/50\n",
      "297895/297895 [==============================] - 52s 174us/step - loss: 0.1841 - acc: 0.9885\n",
      "Epoch 50/50\n",
      "297895/297895 [==============================] - 54s 180us/step - loss: 0.1841 - acc: 0.9885\n",
      "33099/33099 [==============================] - 2s 51us/step\n",
      "Epoch 1/50\n",
      "297895/297895 [==============================] - 52s 176us/step - loss: 2.0144 - acc: 0.8732\n",
      "Epoch 2/50\n",
      "297895/297895 [==============================] - 52s 175us/step - loss: 0.4766 - acc: 0.9701\n",
      "Epoch 3/50\n",
      "297895/297895 [==============================] - 54s 180us/step - loss: 1.1124 - acc: 0.9302\n",
      "Epoch 4/50\n",
      "297895/297895 [==============================] - 52s 175us/step - loss: 0.1965 - acc: 0.9877\n",
      "Epoch 5/50\n",
      "297895/297895 [==============================] - 52s 175us/step - loss: 4.1915 - acc: 0.7371\n",
      "Epoch 6/50\n",
      "297895/297895 [==============================] - 54s 183us/step - loss: 3.9000 - acc: 0.7554\n",
      "Epoch 7/50\n",
      "297895/297895 [==============================] - 52s 175us/step - loss: 4.7993 - acc: 0.6990\n",
      "Epoch 8/50\n",
      "297895/297895 [==============================] - 52s 174us/step - loss: 8.8888 - acc: 0.4424\n",
      "Epoch 9/50\n",
      "297895/297895 [==============================] - 52s 175us/step - loss: 7.5448 - acc: 0.5268\n",
      "Epoch 10/50\n",
      "297895/297895 [==============================] - 54s 182us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 11/50\n",
      "297895/297895 [==============================] - 51s 173us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 12/50\n",
      "297895/297895 [==============================] - 53s 178us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297895/297895 [==============================] - 55s 185us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 14/50\n",
      "297895/297895 [==============================] - 53s 179us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 15/50\n",
      "297895/297895 [==============================] - 52s 175us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 16/50\n",
      "297895/297895 [==============================] - 52s 176us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 17/50\n",
      "297895/297895 [==============================] - 54s 182us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 18/50\n",
      "297895/297895 [==============================] - 52s 173us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 19/50\n",
      "297895/297895 [==============================] - 51s 172us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 20/50\n",
      "297895/297895 [==============================] - 54s 180us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 21/50\n",
      "297895/297895 [==============================] - 51s 172us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 22/50\n",
      "297895/297895 [==============================] - 52s 174us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 23/50\n",
      "297895/297895 [==============================] - 61s 205us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 24/50\n",
      "297895/297895 [==============================] - 55s 185us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 25/50\n",
      "297895/297895 [==============================] - 59s 198us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 26/50\n",
      "297895/297895 [==============================] - 53s 178us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 27/50\n",
      "297895/297895 [==============================] - 55s 183us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 28/50\n",
      "297895/297895 [==============================] - 58s 195us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 29/50\n",
      "297895/297895 [==============================] - 55s 186us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 30/50\n",
      "297895/297895 [==============================] - 63s 213us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 31/50\n",
      "297895/297895 [==============================] - 53s 176us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 32/50\n",
      "297895/297895 [==============================] - 52s 174us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 33/50\n",
      "297895/297895 [==============================] - 55s 184us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 34/50\n",
      "297895/297895 [==============================] - 59s 198us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 35/50\n",
      "297895/297895 [==============================] - 56s 189us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 36/50\n",
      "297895/297895 [==============================] - 58s 195us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 37/50\n",
      "297895/297895 [==============================] - 52s 175us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 38/50\n",
      "297895/297895 [==============================] - 52s 173us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 39/50\n",
      "297895/297895 [==============================] - 55s 185us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 40/50\n",
      "297895/297895 [==============================] - 59s 197us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 41/50\n",
      "297895/297895 [==============================] - 58s 196us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 42/50\n",
      "297895/297895 [==============================] - 54s 181us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 43/50\n",
      "297895/297895 [==============================] - 54s 180us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 44/50\n",
      "297895/297895 [==============================] - 51s 172us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 45/50\n",
      "297895/297895 [==============================] - 59s 199us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 46/50\n",
      "297895/297895 [==============================] - 59s 199us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 47/50\n",
      "297895/297895 [==============================] - 58s 194us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 48/50\n",
      "297895/297895 [==============================] - 53s 177us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 49/50\n",
      "297895/297895 [==============================] - 55s 186us/step - loss: 7.5442 - acc: 0.5268\n",
      "Epoch 50/50\n",
      "297895/297895 [==============================] - 58s 195us/step - loss: 7.5442 - acc: 0.5268\n",
      "33099/33099 [==============================] - 2s 52us/step\n",
      "Accuracy mean: 0.897835279663\n",
      "Accuracy variance: 0.185179198638\n",
      "(' Time ', '28103.287', ' seconds')\n",
      "[[130846     14]\n",
      " [    14  32153]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00    130860\n",
      "        1.0       1.00      1.00      1.00     32167\n",
      "\n",
      "avg / total       1.00      1.00      1.00    163027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# estimators \n",
    "# Evaluating the ANN\n",
    "t0 = time()\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 1024, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n",
    "    classifier.add(Dense(units = 512, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 50)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of DecisionTreeClassifier = 99.968103 %\n",
      "(' Time ', '1.432', ' seconds')\n",
      "[[130835     25]\n",
      " [    27  32140]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00    130860\n",
      "        1.0       1.00      1.00      1.00     32167\n",
      "\n",
      "avg / total       1.00      1.00      1.00    163027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of DecisionTreeClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of RandomForestClassifier = 99.979145 %\n",
      "(' Time ', '20.167', ' seconds')\n",
      "[[130836     24]\n",
      " [    10  32157]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00    130860\n",
      "        1.0       1.00      1.00      1.00     32167\n",
      "\n",
      "avg / total       1.00      1.00      1.00    163027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of RandomForestClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of ExtraTreesClassifier = 99.974237 %\n",
      "(' Time ', '22.932', ' seconds')\n",
      "[[130827     33]\n",
      " [     9  32158]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00    130860\n",
      "        1.0       1.00      1.00      1.00     32167\n",
      "\n",
      "avg / total       1.00      1.00      1.00    163027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of ExtraTreesClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of AdaBoostClassifier = 99.929460 %\n",
      "(' Time ', '39.391', ' seconds')\n",
      "[[130792     68]\n",
      " [    47  32120]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00    130860\n",
      "        1.0       1.00      1.00      1.00     32167\n",
      "\n",
      "avg / total       1.00      1.00      1.00    163027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of AdaBoostClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Naive_bayes  GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GaussianNB = 91.964521 %\n",
      "(' Time ', '0.504', ' seconds')\n",
      "[[118004  12856]\n",
      " [   244  31923]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.90      0.95    130860\n",
      "        1.0       0.71      0.99      0.83     32167\n",
      "\n",
      "avg / total       0.94      0.92      0.92    163027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred= gnb.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of GaussianNB = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
