{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt \n",
    "from pprint import pprint\n",
    "from numpy import array\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>att1</th>\n",
       "      <th>att2</th>\n",
       "      <th>att3</th>\n",
       "      <th>att4</th>\n",
       "      <th>att5</th>\n",
       "      <th>att6</th>\n",
       "      <th>att7</th>\n",
       "      <th>att8</th>\n",
       "      <th>att9</th>\n",
       "      <th>att10</th>\n",
       "      <th>...</th>\n",
       "      <th>att13</th>\n",
       "      <th>att14</th>\n",
       "      <th>att15</th>\n",
       "      <th>att16</th>\n",
       "      <th>att17</th>\n",
       "      <th>att18</th>\n",
       "      <th>att19</th>\n",
       "      <th>att20</th>\n",
       "      <th>att21</th>\n",
       "      <th>outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00025</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00190</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00090</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00025</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   att1  att2  att3  att4  att5  att6  att7  att8  att9  att10   ...     \\\n",
       "0  0.73   0.0   1.0   0.0   0.0   0.0   0.0   0.0   1.0    0.0   ...      \n",
       "1  0.24   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   ...      \n",
       "2  0.47   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   ...      \n",
       "3  0.64   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   ...      \n",
       "4  0.23   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    0.0   ...      \n",
       "\n",
       "   att13  att14  att15  att16    att17  att18  att19  att20  att21  outlier  \n",
       "0    0.0    0.0    0.0    0.0  0.00060  0.015  0.120  0.082  0.146        0  \n",
       "1    0.0    0.0    0.0    0.0  0.00025  0.030  0.143  0.133  0.108        0  \n",
       "2    0.0    0.0    0.0    0.0  0.00190  0.024  0.102  0.131  0.078        0  \n",
       "3    0.0    0.0    0.0    0.0  0.00090  0.017  0.077  0.090  0.085        0  \n",
       "4    0.0    0.0    0.0    0.0  0.00025  0.026  0.139  0.090  0.153        0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df=pd.read_csv('Annthyroid_02_v01.csv')  \n",
    "\n",
    "del df['id']\n",
    "del df['Unnamed: 0']\n",
    "df['outlier'] = df.outlier.apply(lambda label: 1 if label == \"'yes'\" else 0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df to values\n",
    "df = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GC Forest\n",
    "import argparse\n",
    "import sys\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "sys.path.insert(0, \"lib\")\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.utils.config_utils import load_json\n",
    "config = load_json(\"./examples/Annthyroid.json\")   \n",
    "gc = GCForest(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# train test \n",
    "from sklearn.cross_validation import train_test_split\n",
    "y = df[:,21]\n",
    "X = df[:,0:21]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of class\n",
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 16:39:34,038][cascade_classifier.fit_transform] X_groups_train.shape=[(4761, 21)],y_train.shape=(4761,),X_groups_test.shape=[(2041, 21)],y_test.shape=(2041,)\n",
      "[ 2018-07-31 16:39:34,040][cascade_classifier.fit_transform] group_dims=[21]\n",
      "[ 2018-07-31 16:39:34,041][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-07-31 16:39:34,042][cascade_classifier.fit_transform] group_ends=[21]\n",
      "[ 2018-07-31 16:39:34,043][cascade_classifier.fit_transform] X_train.shape=(4761, 21),X_test.shape=(2041, 21)\n",
      "[ 2018-07-31 16:39:34,045][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(4761, 21), X_cur_test.shape=(2041, 21)\n",
      "[ 2018-07-31 16:39:34,603][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=99.16%\n",
      "[ 2018-07-31 16:39:35,437][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-07-31 16:39:36,063][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=99.37%\n",
      "[ 2018-07-31 16:39:36,921][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=99.58%\n",
      "[ 2018-07-31 16:39:37,637][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=99.16%\n",
      "[ 2018-07-31 16:39:38,377][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=99.79%\n",
      "[ 2018-07-31 16:39:38,977][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=98.95%\n",
      "[ 2018-07-31 16:39:39,723][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=99.37%\n",
      "[ 2018-07-31 16:39:40,438][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=98.95%\n",
      "[ 2018-07-31 16:39:41,153][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=99.16%\n",
      "[ 2018-07-31 16:39:41,374][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=99.35%\n",
      "[ 2018-07-31 16:39:41,375][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=99.56%\n",
      "[ 2018-07-31 16:39:41,879][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_0.predict)=98.74%\n",
      "[ 2018-07-31 16:39:42,605][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_1.predict)=99.16%\n",
      "[ 2018-07-31 16:39:43,331][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_2.predict)=98.53%\n",
      "[ 2018-07-31 16:39:44,170][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_3.predict)=98.74%\n",
      "[ 2018-07-31 16:39:45,013][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_4.predict)=99.16%\n",
      "[ 2018-07-31 16:39:45,856][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_5.predict)=98.74%\n",
      "[ 2018-07-31 16:39:46,590][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_6.predict)=98.74%\n",
      "[ 2018-07-31 16:39:47,366][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_7.predict)=98.74%\n",
      "[ 2018-07-31 16:39:48,094][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_8.predict)=98.53%\n",
      "[ 2018-07-31 16:39:48,965][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_9.predict)=99.58%\n",
      "[ 2018-07-31 16:39:49,212][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_cv.predict)=98.87%\n",
      "[ 2018-07-31 16:39:49,213][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.test.predict)=98.97%\n",
      "[ 2018-07-31 16:39:49,241][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_0.predict)=97.90%\n",
      "[ 2018-07-31 16:39:49,255][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_1.predict)=97.90%\n",
      "[ 2018-07-31 16:39:49,267][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_2.predict)=97.90%\n",
      "[ 2018-07-31 16:39:49,282][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_3.predict)=97.90%\n",
      "[ 2018-07-31 16:39:49,301][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_4.predict)=97.90%\n",
      "[ 2018-07-31 16:39:49,318][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_5.predict)=97.90%\n",
      "[ 2018-07-31 16:39:49,337][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_6.predict)=97.90%\n",
      "[ 2018-07-31 16:39:49,354][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_7.predict)=98.11%\n",
      "[ 2018-07-31 16:39:49,371][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_8.predict)=98.11%\n",
      "[ 2018-07-31 16:39:49,390][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_9.predict)=98.11%\n",
      "[ 2018-07-31 16:39:49,392][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_cv.predict)=97.96%\n",
      "[ 2018-07-31 16:39:49,393][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.test.predict)=98.09%\n",
      "[ 2018-07-31 16:39:49,394][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=98.51%\n",
      "[ 2018-07-31 16:39:49,395][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=98.38%\n",
      "[ 2018-07-31 16:39:49,397][cascade_classifier.fit_transform] [layer=1] look_indexs=[0], X_cur_train.shape=(4761, 27), X_cur_test.shape=(2041, 27)\n",
      "[ 2018-07-31 16:39:49,974][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_0.predict)=99.79%\n",
      "[ 2018-07-31 16:39:50,718][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_1.predict)=99.58%\n",
      "[ 2018-07-31 16:39:51,598][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_2.predict)=99.79%\n",
      "[ 2018-07-31 16:39:52,453][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_3.predict)=99.37%\n",
      "[ 2018-07-31 16:39:53,304][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_4.predict)=99.79%\n",
      "[ 2018-07-31 16:39:54,153][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_5.predict)=99.79%\n",
      "[ 2018-07-31 16:39:55,116][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_6.predict)=99.37%\n",
      "[ 2018-07-31 16:39:55,835][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_7.predict)=98.74%\n",
      "[ 2018-07-31 16:39:56,552][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_8.predict)=99.79%\n",
      "[ 2018-07-31 16:39:57,297][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_9.predict)=99.37%\n",
      "[ 2018-07-31 16:39:57,522][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_cv.predict)=99.54%\n",
      "[ 2018-07-31 16:39:57,524][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.test.predict)=99.46%\n",
      "[ 2018-07-31 16:39:58,177][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_0.predict)=99.58%\n",
      "[ 2018-07-31 16:39:58,955][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_1.predict)=99.16%\n",
      "[ 2018-07-31 16:39:59,678][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_2.predict)=99.37%\n",
      "[ 2018-07-31 16:40:00,395][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_3.predict)=100.00%\n",
      "[ 2018-07-31 16:40:01,119][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_4.predict)=99.37%\n",
      "[ 2018-07-31 16:40:01,956][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_5.predict)=99.58%\n",
      "[ 2018-07-31 16:40:02,684][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_6.predict)=99.58%\n",
      "[ 2018-07-31 16:40:03,508][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_7.predict)=99.79%\n",
      "[ 2018-07-31 16:40:04,257][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_8.predict)=99.58%\n",
      "[ 2018-07-31 16:40:04,980][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_9.predict)=99.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 16:40:05,203][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_cv.predict)=99.58%\n",
      "[ 2018-07-31 16:40:05,204][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.test.predict)=99.56%\n",
      "[ 2018-07-31 16:40:05,223][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_0.predict)=99.16%\n",
      "[ 2018-07-31 16:40:05,239][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_1.predict)=99.58%\n",
      "[ 2018-07-31 16:40:05,254][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_2.predict)=99.16%\n",
      "[ 2018-07-31 16:40:05,269][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_3.predict)=99.37%\n",
      "[ 2018-07-31 16:40:05,285][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_4.predict)=99.58%\n",
      "[ 2018-07-31 16:40:05,300][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_5.predict)=98.53%\n",
      "[ 2018-07-31 16:40:05,316][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_6.predict)=99.58%\n",
      "[ 2018-07-31 16:40:05,331][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_7.predict)=98.95%\n",
      "[ 2018-07-31 16:40:05,346][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_8.predict)=99.37%\n",
      "[ 2018-07-31 16:40:05,362][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_9.predict)=99.58%\n",
      "[ 2018-07-31 16:40:05,363][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_cv.predict)=99.29%\n",
      "[ 2018-07-31 16:40:05,364][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.test.predict)=99.51%\n",
      "[ 2018-07-31 16:40:05,366][cascade_classifier.calc_accuracy] Accuracy(layer_1 - train.classifier_average)=99.56%\n",
      "[ 2018-07-31 16:40:05,367][cascade_classifier.calc_accuracy] Accuracy(layer_1 - test.classifier_average)=99.61%\n",
      "[ 2018-07-31 16:40:05,369][cascade_classifier.fit_transform] [layer=2] look_indexs=[0], X_cur_train.shape=(4761, 27), X_cur_test.shape=(2041, 27)\n",
      "[ 2018-07-31 16:40:05,921][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_0.predict)=98.53%\n",
      "[ 2018-07-31 16:40:06,670][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_1.predict)=99.58%\n",
      "[ 2018-07-31 16:40:07,531][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_2.predict)=100.00%\n",
      "[ 2018-07-31 16:40:08,631][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_3.predict)=100.00%\n",
      "[ 2018-07-31 16:40:09,719][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_4.predict)=99.79%\n",
      "[ 2018-07-31 16:40:10,790][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_5.predict)=99.16%\n",
      "[ 2018-07-31 16:40:11,770][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_6.predict)=99.37%\n",
      "[ 2018-07-31 16:40:12,907][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_7.predict)=99.79%\n",
      "[ 2018-07-31 16:40:13,844][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_8.predict)=99.16%\n",
      "[ 2018-07-31 16:40:14,632][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_9.predict)=98.95%\n",
      "[ 2018-07-31 16:40:14,863][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_cv.predict)=99.43%\n",
      "[ 2018-07-31 16:40:14,864][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.test.predict)=99.51%\n",
      "[ 2018-07-31 16:40:15,380][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_0.predict)=99.58%\n",
      "[ 2018-07-31 16:40:16,106][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_1.predict)=99.58%\n",
      "[ 2018-07-31 16:40:16,868][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_2.predict)=99.37%\n",
      "[ 2018-07-31 16:40:17,589][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_3.predict)=99.58%\n",
      "[ 2018-07-31 16:40:18,309][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_4.predict)=99.79%\n",
      "[ 2018-07-31 16:40:19,148][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_5.predict)=98.95%\n",
      "[ 2018-07-31 16:40:19,878][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_6.predict)=99.16%\n",
      "[ 2018-07-31 16:40:20,488][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_7.predict)=99.79%\n",
      "[ 2018-07-31 16:40:21,208][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_8.predict)=100.00%\n",
      "[ 2018-07-31 16:40:22,044][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_9.predict)=99.16%\n",
      "[ 2018-07-31 16:40:22,266][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_cv.predict)=99.50%\n",
      "[ 2018-07-31 16:40:22,267][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.test.predict)=99.61%\n",
      "[ 2018-07-31 16:40:22,285][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_0.predict)=99.37%\n",
      "[ 2018-07-31 16:40:22,302][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_1.predict)=99.58%\n",
      "[ 2018-07-31 16:40:22,318][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_2.predict)=99.79%\n",
      "[ 2018-07-31 16:40:22,332][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_3.predict)=99.79%\n",
      "[ 2018-07-31 16:40:22,348][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_4.predict)=99.37%\n",
      "[ 2018-07-31 16:40:22,365][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_5.predict)=99.79%\n",
      "[ 2018-07-31 16:40:22,382][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_6.predict)=99.16%\n",
      "[ 2018-07-31 16:40:22,397][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_7.predict)=99.79%\n",
      "[ 2018-07-31 16:40:22,414][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_8.predict)=99.37%\n",
      "[ 2018-07-31 16:40:22,430][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_9.predict)=99.16%\n",
      "[ 2018-07-31 16:40:22,432][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_cv.predict)=99.52%\n",
      "[ 2018-07-31 16:40:22,433][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.test.predict)=99.51%\n",
      "[ 2018-07-31 16:40:22,434][cascade_classifier.calc_accuracy] Accuracy(layer_2 - train.classifier_average)=99.43%\n",
      "[ 2018-07-31 16:40:22,435][cascade_classifier.calc_accuracy] Accuracy(layer_2 - test.classifier_average)=99.61%\n",
      "[ 2018-07-31 16:40:22,437][cascade_classifier.fit_transform] [layer=3] look_indexs=[0], X_cur_train.shape=(4761, 27), X_cur_test.shape=(2041, 27)\n",
      "[ 2018-07-31 16:40:22,977][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_0.predict)=99.37%\n",
      "[ 2018-07-31 16:40:23,709][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_1.predict)=99.37%\n",
      "[ 2018-07-31 16:40:24,454][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_2.predict)=99.79%\n",
      "[ 2018-07-31 16:40:25,136][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_3.predict)=98.95%\n",
      "[ 2018-07-31 16:40:25,881][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_4.predict)=99.16%\n",
      "[ 2018-07-31 16:40:26,624][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_5.predict)=99.58%\n",
      "[ 2018-07-31 16:40:27,348][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_6.predict)=99.37%\n",
      "[ 2018-07-31 16:40:28,092][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_7.predict)=99.58%\n",
      "[ 2018-07-31 16:40:28,840][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_8.predict)=99.16%\n",
      "[ 2018-07-31 16:40:29,662][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_9.predict)=100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 16:40:29,900][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_cv.predict)=99.43%\n",
      "[ 2018-07-31 16:40:29,905][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.test.predict)=99.46%\n",
      "[ 2018-07-31 16:40:30,689][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_0.predict)=99.16%\n",
      "[ 2018-07-31 16:40:31,607][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_1.predict)=99.58%\n",
      "[ 2018-07-31 16:40:32,714][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_2.predict)=99.58%\n",
      "[ 2018-07-31 16:40:33,479][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_3.predict)=99.58%\n",
      "[ 2018-07-31 16:40:34,204][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_4.predict)=99.58%\n",
      "[ 2018-07-31 16:40:34,933][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_5.predict)=99.37%\n",
      "[ 2018-07-31 16:40:35,776][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_6.predict)=99.58%\n",
      "[ 2018-07-31 16:40:36,505][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_7.predict)=100.00%\n",
      "[ 2018-07-31 16:40:37,227][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_8.predict)=99.16%\n",
      "[ 2018-07-31 16:40:37,949][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_9.predict)=99.58%\n",
      "[ 2018-07-31 16:40:38,176][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_cv.predict)=99.52%\n",
      "[ 2018-07-31 16:40:38,177][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.test.predict)=99.61%\n",
      "[ 2018-07-31 16:40:38,197][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_0.predict)=99.79%\n",
      "[ 2018-07-31 16:40:38,214][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_1.predict)=99.37%\n",
      "[ 2018-07-31 16:40:38,231][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_2.predict)=99.58%\n",
      "[ 2018-07-31 16:40:38,248][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_3.predict)=99.16%\n",
      "[ 2018-07-31 16:40:38,265][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_4.predict)=99.37%\n",
      "[ 2018-07-31 16:40:38,283][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_5.predict)=99.58%\n",
      "[ 2018-07-31 16:40:38,301][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_6.predict)=99.79%\n",
      "[ 2018-07-31 16:40:38,317][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_7.predict)=98.32%\n",
      "[ 2018-07-31 16:40:38,334][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_8.predict)=99.37%\n",
      "[ 2018-07-31 16:40:38,350][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_9.predict)=99.16%\n",
      "[ 2018-07-31 16:40:38,351][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_cv.predict)=99.35%\n",
      "[ 2018-07-31 16:40:38,352][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.test.predict)=99.51%\n",
      "[ 2018-07-31 16:40:38,354][cascade_classifier.calc_accuracy] Accuracy(layer_3 - train.classifier_average)=99.37%\n",
      "[ 2018-07-31 16:40:38,355][cascade_classifier.calc_accuracy] Accuracy(layer_3 - test.classifier_average)=99.61%\n",
      "[ 2018-07-31 16:40:38,357][cascade_classifier.fit_transform] [layer=4] look_indexs=[0], X_cur_train.shape=(4761, 27), X_cur_test.shape=(2041, 27)\n",
      "[ 2018-07-31 16:40:38,852][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_0.predict)=99.37%\n",
      "[ 2018-07-31 16:40:39,592][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_1.predict)=99.37%\n",
      "[ 2018-07-31 16:40:40,337][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_2.predict)=99.37%\n",
      "[ 2018-07-31 16:40:41,082][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_3.predict)=99.16%\n",
      "[ 2018-07-31 16:40:41,822][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_4.predict)=99.37%\n",
      "[ 2018-07-31 16:40:42,543][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_5.predict)=98.53%\n",
      "[ 2018-07-31 16:40:43,403][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_6.predict)=99.58%\n",
      "[ 2018-07-31 16:40:44,121][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_7.predict)=99.79%\n",
      "[ 2018-07-31 16:40:44,833][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_8.predict)=99.37%\n",
      "[ 2018-07-31 16:40:45,696][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_9.predict)=99.37%\n",
      "[ 2018-07-31 16:40:45,934][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_cv.predict)=99.33%\n",
      "[ 2018-07-31 16:40:45,935][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.test.predict)=99.36%\n",
      "[ 2018-07-31 16:40:46,434][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_0.predict)=98.95%\n",
      "[ 2018-07-31 16:40:47,155][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_1.predict)=99.37%\n",
      "[ 2018-07-31 16:40:48,013][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_2.predict)=100.00%\n",
      "[ 2018-07-31 16:40:48,863][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_3.predict)=99.37%\n",
      "[ 2018-07-31 16:40:49,837][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_4.predict)=99.16%\n",
      "[ 2018-07-31 16:40:50,928][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_5.predict)=99.37%\n",
      "[ 2018-07-31 16:40:51,752][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_6.predict)=100.00%\n",
      "[ 2018-07-31 16:40:52,586][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_7.predict)=99.37%\n",
      "[ 2018-07-31 16:40:53,313][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_8.predict)=99.58%\n",
      "[ 2018-07-31 16:40:54,040][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_9.predict)=99.37%\n",
      "[ 2018-07-31 16:40:54,265][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_cv.predict)=99.45%\n",
      "[ 2018-07-31 16:40:54,266][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.test.predict)=99.41%\n",
      "[ 2018-07-31 16:40:54,287][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_0.predict)=99.37%\n",
      "[ 2018-07-31 16:40:54,312][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_1.predict)=99.16%\n",
      "[ 2018-07-31 16:40:54,338][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_2.predict)=99.58%\n",
      "[ 2018-07-31 16:40:54,362][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_3.predict)=99.16%\n",
      "[ 2018-07-31 16:40:54,387][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_4.predict)=99.58%\n",
      "[ 2018-07-31 16:40:54,412][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_5.predict)=99.58%\n",
      "[ 2018-07-31 16:40:54,436][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_6.predict)=99.16%\n",
      "[ 2018-07-31 16:40:54,460][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_7.predict)=99.37%\n",
      "[ 2018-07-31 16:40:54,485][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_8.predict)=99.58%\n",
      "[ 2018-07-31 16:40:54,506][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_9.predict)=99.58%\n",
      "[ 2018-07-31 16:40:54,508][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_cv.predict)=99.41%\n",
      "[ 2018-07-31 16:40:54,509][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.test.predict)=99.56%\n",
      "[ 2018-07-31 16:40:54,511][cascade_classifier.calc_accuracy] Accuracy(layer_4 - train.classifier_average)=99.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 16:40:54,512][cascade_classifier.calc_accuracy] Accuracy(layer_4 - test.classifier_average)=99.51%\n",
      "[ 2018-07-31 16:40:54,513][cascade_classifier.fit_transform] [Result][Optimal Level Detected] opt_layer_num=2, accuracy_train=99.56%, accuracy_test=99.61%\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "# X_enc is the concatenated predict_proba result of each estimators of the last layer of the GCForest model\n",
    "    # X_enc.shape =\n",
    "    #   (n_datas, n_estimators * n_classes): If cascade is provided\n",
    "    #   (n_datas, n_estimators * n_classes, dimX, dimY): If only finegrained part is provided\n",
    "    # You can also pass X_test, y_test to fit_transform method, then the accracy on test data will be logged when training.\n",
    "X_train_enc, X_test_enc = gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test)\n",
    "    # WARNING: if you set gc.set_keep_model_in_mem(True), you would have to use\n",
    "    # gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test) to evaluate your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-07-31 16:40:54,533][cascade_classifier.transform] X_groups_test.shape=[(2041, 21)]\n",
      "[ 2018-07-31 16:40:54,534][cascade_classifier.transform] group_dims=[21]\n",
      "[ 2018-07-31 16:40:54,536][cascade_classifier.transform] X_test.shape=(2041, 21)\n",
      "[ 2018-07-31 16:40:54,538][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(2041, 21)\n",
      "[ 2018-07-31 16:40:58,992][cascade_classifier.transform] [layer=1] look_indexs=[0], X_cur_test.shape=(2041, 27)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GCForest = 99.608035 %\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "y_pred = gc.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy of GCForest = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' Time ', '89.484', ' seconds')\n",
      "[[1996    6]\n",
      " [   2   37]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      2002\n",
      "        1.0       0.86      0.95      0.90        39\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2041\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of DecisionTreeClassifier = 99.559040 %\n",
      "(' Time ', '0.004', ' seconds')\n",
      "[[1995    7]\n",
      " [   2   37]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      2002\n",
      "        1.0       0.84      0.95      0.89        39\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2041\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of DecisionTreeClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of RandomForestClassifier = 99.510044 %\n",
      "(' Time ', '0.481', ' seconds')\n",
      "[[1996    6]\n",
      " [   4   35]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      2002\n",
      "        1.0       0.85      0.90      0.88        39\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2041\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of RandomForestClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of ExtraTreesClassifier = 98.873101 %\n",
      "(' Time ', '0.524', ' seconds')\n",
      "[[2000    2]\n",
      " [  21   18]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      0.99      2002\n",
      "        1.0       0.90      0.46      0.61        39\n",
      "\n",
      "avg / total       0.99      0.99      0.99      2041\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of ExtraTreesClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of AdaBoostClassifier = 99.657031 %\n",
      "(' Time ', '0.513', ' seconds')\n",
      "[[1998    4]\n",
      " [   3   36]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      2002\n",
      "        1.0       0.90      0.92      0.91        39\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2041\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of AdaBoostClassifier = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Naive_bayes  GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GaussianNB = 8.868202 %\n",
      "(' Time ', '0.005', ' seconds')\n",
      "[[ 143 1859]\n",
      " [   1   38]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.07      0.13      2002\n",
      "        1.0       0.02      0.97      0.04        39\n",
      "\n",
      "avg / total       0.97      0.09      0.13      2041\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred= gnb.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of GaussianNB = {:.6f} %\".format(acc * 100))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4284/4284 [==============================] - 1s 338us/step - loss: 0.1325 - acc: 0.9767\n",
      "Epoch 2/50\n",
      "4284/4284 [==============================] - 1s 238us/step - loss: 0.0882 - acc: 0.9799\n",
      "Epoch 3/50\n",
      "4284/4284 [==============================] - 1s 276us/step - loss: 0.0792 - acc: 0.9804\n",
      "Epoch 4/50\n",
      "4284/4284 [==============================] - 1s 247us/step - loss: 0.0739 - acc: 0.9827\n",
      "Epoch 5/50\n",
      "4284/4284 [==============================] - 1s 177us/step - loss: 0.0701 - acc: 0.9837\n",
      "Epoch 6/50\n",
      "4284/4284 [==============================] - 1s 166us/step - loss: 0.0701 - acc: 0.9846\n",
      "Epoch 7/50\n",
      "4284/4284 [==============================] - 1s 169us/step - loss: 0.0662 - acc: 0.9848\n",
      "Epoch 8/50\n",
      "4284/4284 [==============================] - 1s 167us/step - loss: 0.0641 - acc: 0.9851\n",
      "Epoch 9/50\n",
      "4284/4284 [==============================] - 1s 163us/step - loss: 0.0619 - acc: 0.9844\n",
      "Epoch 10/50\n",
      "4284/4284 [==============================] - 1s 168us/step - loss: 0.0614 - acc: 0.9855\n",
      "Epoch 11/50\n",
      "4284/4284 [==============================] - 1s 170us/step - loss: 0.0620 - acc: 0.9855\n",
      "Epoch 12/50\n",
      "4284/4284 [==============================] - 1s 176us/step - loss: 0.0579 - acc: 0.9858\n",
      "Epoch 13/50\n",
      "4284/4284 [==============================] - 1s 168us/step - loss: 0.0591 - acc: 0.9851\n",
      "Epoch 14/50\n",
      "4284/4284 [==============================] - 1s 168us/step - loss: 0.0542 - acc: 0.9865\n",
      "Epoch 15/50\n",
      "4284/4284 [==============================] - 1s 169us/step - loss: 0.0534 - acc: 0.9862\n",
      "Epoch 16/50\n",
      "4284/4284 [==============================] - 1s 167us/step - loss: 0.0529 - acc: 0.9869\n",
      "Epoch 17/50\n",
      "4284/4284 [==============================] - 1s 174us/step - loss: 0.0531 - acc: 0.9865\n",
      "Epoch 18/50\n",
      "4284/4284 [==============================] - 1s 171us/step - loss: 0.0480 - acc: 0.9876\n",
      "Epoch 19/50\n",
      "4284/4284 [==============================] - 1s 169us/step - loss: 0.0501 - acc: 0.9867\n",
      "Epoch 20/50\n",
      "4284/4284 [==============================] - 1s 168us/step - loss: 0.0498 - acc: 0.9872\n",
      "Epoch 21/50\n",
      "4284/4284 [==============================] - 1s 169us/step - loss: 0.0432 - acc: 0.9869\n",
      "Epoch 22/50\n",
      "4284/4284 [==============================] - 1s 171us/step - loss: 0.0454 - acc: 0.9874\n",
      "Epoch 23/50\n",
      "4284/4284 [==============================] - 1s 170us/step - loss: 0.0399 - acc: 0.9872\n",
      "Epoch 24/50\n",
      "4284/4284 [==============================] - 1s 172us/step - loss: 0.0433 - acc: 0.9874\n",
      "Epoch 25/50\n",
      "4284/4284 [==============================] - 1s 192us/step - loss: 0.0391 - acc: 0.9883\n",
      "Epoch 26/50\n",
      "4284/4284 [==============================] - 1s 207us/step - loss: 0.0409 - acc: 0.9867\n",
      "Epoch 27/50\n",
      "4284/4284 [==============================] - 1s 264us/step - loss: 0.0404 - acc: 0.9872\n",
      "Epoch 28/50\n",
      "4284/4284 [==============================] - 1s 266us/step - loss: 0.0353 - acc: 0.9881\n",
      "Epoch 29/50\n",
      "4284/4284 [==============================] - 1s 252us/step - loss: 0.0309 - acc: 0.9893\n",
      "Epoch 30/50\n",
      "4284/4284 [==============================] - 1s 221us/step - loss: 0.0333 - acc: 0.9886\n",
      "Epoch 31/50\n",
      "4284/4284 [==============================] - 1s 172us/step - loss: 0.0326 - acc: 0.9883\n",
      "Epoch 32/50\n",
      "4284/4284 [==============================] - 1s 168us/step - loss: 0.0321 - acc: 0.9895\n",
      "Epoch 33/50\n",
      "4284/4284 [==============================] - 1s 174us/step - loss: 0.0268 - acc: 0.9897\n",
      "Epoch 34/50\n",
      "4284/4284 [==============================] - 1s 174us/step - loss: 0.0283 - acc: 0.9900\n",
      "Epoch 35/50\n",
      "4284/4284 [==============================] - 1s 175us/step - loss: 0.0301 - acc: 0.9911\n",
      "Epoch 36/50\n",
      "4284/4284 [==============================] - 1s 171us/step - loss: 0.0284 - acc: 0.9895\n",
      "Epoch 37/50\n",
      "4284/4284 [==============================] - 1s 173us/step - loss: 0.0287 - acc: 0.9897\n",
      "Epoch 38/50\n",
      "4284/4284 [==============================] - 1s 175us/step - loss: 0.0262 - acc: 0.9900\n",
      "Epoch 39/50\n",
      "4284/4284 [==============================] - 1s 168us/step - loss: 0.0276 - acc: 0.9904\n",
      "Epoch 40/50\n",
      "4284/4284 [==============================] - 1s 171us/step - loss: 0.0256 - acc: 0.9918\n",
      "Epoch 41/50\n",
      "4284/4284 [==============================] - 1s 170us/step - loss: 0.0247 - acc: 0.9923\n",
      "Epoch 42/50\n",
      "4284/4284 [==============================] - 1s 170us/step - loss: 0.0247 - acc: 0.9911\n",
      "Epoch 43/50\n",
      "4284/4284 [==============================] - 1s 181us/step - loss: 0.0243 - acc: 0.9918\n",
      "Epoch 44/50\n",
      "4284/4284 [==============================] - 1s 169us/step - loss: 0.0232 - acc: 0.9911\n",
      "Epoch 45/50\n",
      "4284/4284 [==============================] - 1s 168us/step - loss: 0.0250 - acc: 0.9897\n",
      "Epoch 46/50\n",
      "4284/4284 [==============================] - 1s 170us/step - loss: 0.0258 - acc: 0.9911\n",
      "Epoch 47/50\n",
      "4284/4284 [==============================] - 1s 169us/step - loss: 0.0230 - acc: 0.9916\n",
      "Epoch 48/50\n",
      "4284/4284 [==============================] - 1s 174us/step - loss: 0.0245 - acc: 0.9918\n",
      "Epoch 49/50\n",
      "4284/4284 [==============================] - 1s 185us/step - loss: 0.0238 - acc: 0.9916\n",
      "Epoch 50/50\n",
      "4284/4284 [==============================] - 1s 173us/step - loss: 0.0211 - acc: 0.9921\n",
      "477/477 [==============================] - 0s 82us/step\n",
      "Epoch 1/50\n",
      "4285/4285 [==============================] - 2s 382us/step - loss: 0.1281 - acc: 0.9797\n",
      "Epoch 2/50\n",
      "4285/4285 [==============================] - 1s 312us/step - loss: 0.0877 - acc: 0.9804\n",
      "Epoch 3/50\n",
      "4285/4285 [==============================] - 1s 263us/step - loss: 0.0852 - acc: 0.9804\n",
      "Epoch 4/50\n",
      "4285/4285 [==============================] - 1s 232us/step - loss: 0.0756 - acc: 0.9811\n",
      "Epoch 5/50\n",
      "4285/4285 [==============================] - 1s 174us/step - loss: 0.0750 - acc: 0.9827\n",
      "Epoch 6/50\n",
      "4285/4285 [==============================] - 1s 171us/step - loss: 0.0699 - acc: 0.9837\n",
      "Epoch 7/50\n",
      "4285/4285 [==============================] - 1s 166us/step - loss: 0.0676 - acc: 0.9841\n",
      "Epoch 8/50\n",
      "4285/4285 [==============================] - 1s 171us/step - loss: 0.0652 - acc: 0.9846\n",
      "Epoch 9/50\n",
      "4285/4285 [==============================] - 1s 171us/step - loss: 0.0676 - acc: 0.9853\n",
      "Epoch 10/50\n",
      "4285/4285 [==============================] - 1s 173us/step - loss: 0.0673 - acc: 0.9851\n",
      "Epoch 11/50\n",
      "4285/4285 [==============================] - 1s 170us/step - loss: 0.0635 - acc: 0.9853\n",
      "Epoch 12/50\n",
      "4285/4285 [==============================] - 1s 171us/step - loss: 0.0617 - acc: 0.9855\n",
      "Epoch 13/50\n",
      "4285/4285 [==============================] - 1s 174us/step - loss: 0.0584 - acc: 0.9853\n",
      "Epoch 14/50\n",
      "4285/4285 [==============================] - 1s 173us/step - loss: 0.0598 - acc: 0.9858\n",
      "Epoch 15/50\n",
      "4285/4285 [==============================] - 1s 172us/step - loss: 0.0589 - acc: 0.9862\n",
      "Epoch 16/50\n",
      "4285/4285 [==============================] - 1s 169us/step - loss: 0.0557 - acc: 0.9862\n",
      "Epoch 17/50\n",
      "4285/4285 [==============================] - 1s 178us/step - loss: 0.0528 - acc: 0.9865\n",
      "Epoch 18/50\n",
      "4285/4285 [==============================] - 1s 255us/step - loss: 0.0498 - acc: 0.9867\n",
      "Epoch 19/50\n",
      "4285/4285 [==============================] - 1s 258us/step - loss: 0.0481 - acc: 0.9862\n",
      "Epoch 20/50\n",
      "4285/4285 [==============================] - 1s 290us/step - loss: 0.0495 - acc: 0.9865\n",
      "Epoch 21/50\n",
      "4285/4285 [==============================] - 1s 262us/step - loss: 0.0465 - acc: 0.9874\n",
      "Epoch 22/50\n",
      "4285/4285 [==============================] - 1s 282us/step - loss: 0.0424 - acc: 0.9865\n",
      "Epoch 23/50\n",
      "4285/4285 [==============================] - 1s 233us/step - loss: 0.0441 - acc: 0.9872\n",
      "Epoch 24/50\n",
      "4285/4285 [==============================] - 1s 266us/step - loss: 0.0414 - acc: 0.9879\n",
      "Epoch 25/50\n",
      "4285/4285 [==============================] - 1s 273us/step - loss: 0.0402 - acc: 0.9879\n",
      "Epoch 26/50\n",
      "4285/4285 [==============================] - 1s 290us/step - loss: 0.0392 - acc: 0.9881\n",
      "Epoch 27/50\n",
      "4285/4285 [==============================] - 1s 244us/step - loss: 0.0356 - acc: 0.9886\n",
      "Epoch 28/50\n",
      "4285/4285 [==============================] - 1s 172us/step - loss: 0.0380 - acc: 0.9897\n",
      "Epoch 29/50\n",
      "4285/4285 [==============================] - 1s 171us/step - loss: 0.0354 - acc: 0.9895\n",
      "Epoch 30/50\n",
      "4285/4285 [==============================] - 1s 187us/step - loss: 0.0323 - acc: 0.9893\n",
      "Epoch 31/50\n",
      "4285/4285 [==============================] - 1s 173us/step - loss: 0.0347 - acc: 0.9897\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4285/4285 [==============================] - 1s 205us/step - loss: 0.0276 - acc: 0.9893\n",
      "Epoch 33/50\n",
      "4285/4285 [==============================] - 1s 281us/step - loss: 0.0312 - acc: 0.9902\n",
      "Epoch 34/50\n",
      "4285/4285 [==============================] - 1s 259us/step - loss: 0.0300 - acc: 0.9900\n",
      "Epoch 35/50\n",
      "4285/4285 [==============================] - 1s 211us/step - loss: 0.0283 - acc: 0.9904\n",
      "Epoch 36/50\n",
      "4285/4285 [==============================] - 1s 206us/step - loss: 0.0279 - acc: 0.9900\n",
      "Epoch 37/50\n",
      "4285/4285 [==============================] - 1s 190us/step - loss: 0.0280 - acc: 0.9907\n",
      "Epoch 38/50\n",
      "4285/4285 [==============================] - 1s 196us/step - loss: 0.0265 - acc: 0.9902\n",
      "Epoch 39/50\n",
      "4285/4285 [==============================] - 1s 190us/step - loss: 0.0283 - acc: 0.9909\n",
      "Epoch 40/50\n",
      "4285/4285 [==============================] - 1s 191us/step - loss: 0.0290 - acc: 0.9893\n",
      "Epoch 41/50\n",
      "4285/4285 [==============================] - 1s 198us/step - loss: 0.0261 - acc: 0.9916\n",
      "Epoch 42/50\n",
      "4285/4285 [==============================] - 1s 195us/step - loss: 0.0258 - acc: 0.9904\n",
      "Epoch 43/50\n",
      "4285/4285 [==============================] - 1s 262us/step - loss: 0.0249 - acc: 0.9907\n",
      "Epoch 44/50\n",
      "4285/4285 [==============================] - 1s 254us/step - loss: 0.0225 - acc: 0.9902\n",
      "Epoch 45/50\n",
      "4285/4285 [==============================] - 1s 177us/step - loss: 0.0270 - acc: 0.9902\n",
      "Epoch 46/50\n",
      "4285/4285 [==============================] - 1s 187us/step - loss: 0.0233 - acc: 0.9907\n",
      "Epoch 47/50\n",
      "4285/4285 [==============================] - 1s 180us/step - loss: 0.0232 - acc: 0.9907\n",
      "Epoch 48/50\n",
      "4285/4285 [==============================] - 1s 179us/step - loss: 0.0230 - acc: 0.9928\n",
      "Epoch 49/50\n",
      "4285/4285 [==============================] - 1s 182us/step - loss: 0.0236 - acc: 0.9916\n",
      "Epoch 50/50\n",
      "4285/4285 [==============================] - 1s 179us/step - loss: 0.0236 - acc: 0.9923\n",
      "476/476 [==============================] - 0s 96us/step\n",
      "Epoch 1/50\n",
      "4285/4285 [==============================] - 1s 252us/step - loss: 0.1368 - acc: 0.9718\n",
      "Epoch 2/50\n",
      "4285/4285 [==============================] - 1s 180us/step - loss: 0.0895 - acc: 0.9788\n",
      "Epoch 3/50\n",
      "4285/4285 [==============================] - 1s 172us/step - loss: 0.0835 - acc: 0.9797\n",
      "Epoch 4/50\n",
      "4285/4285 [==============================] - 1s 170us/step - loss: 0.0762 - acc: 0.9816\n",
      "Epoch 5/50\n",
      "4285/4285 [==============================] - 1s 170us/step - loss: 0.0750 - acc: 0.9834\n",
      "Epoch 6/50\n",
      "4285/4285 [==============================] - 1s 174us/step - loss: 0.0725 - acc: 0.9834\n",
      "Epoch 7/50\n",
      "4285/4285 [==============================] - 1s 170us/step - loss: 0.0721 - acc: 0.9837\n",
      "Epoch 8/50\n",
      "4285/4285 [==============================] - 1s 174us/step - loss: 0.0676 - acc: 0.9841\n",
      "Epoch 9/50\n",
      "4285/4285 [==============================] - 1s 172us/step - loss: 0.0677 - acc: 0.9834\n",
      "Epoch 10/50\n",
      "4285/4285 [==============================] - 1s 172us/step - loss: 0.0649 - acc: 0.9841\n",
      "Epoch 11/50\n",
      "4285/4285 [==============================] - 1s 168us/step - loss: 0.0644 - acc: 0.9851\n",
      "Epoch 12/50\n",
      "4285/4285 [==============================] - 1s 168us/step - loss: 0.0639 - acc: 0.9848\n",
      "Epoch 13/50\n",
      "4285/4285 [==============================] - 1s 173us/step - loss: 0.0617 - acc: 0.9853\n",
      "Epoch 14/50\n",
      "4285/4285 [==============================] - 1s 170us/step - loss: 0.0630 - acc: 0.9851\n",
      "Epoch 15/50\n",
      "4285/4285 [==============================] - 1s 171us/step - loss: 0.0602 - acc: 0.9848\n",
      "Epoch 16/50\n",
      "4285/4285 [==============================] - 1s 187us/step - loss: 0.0563 - acc: 0.9855\n",
      "Epoch 17/50\n",
      "4285/4285 [==============================] - 1s 171us/step - loss: 0.0586 - acc: 0.9846\n",
      "Epoch 18/50\n",
      "4285/4285 [==============================] - 1s 169us/step - loss: 0.0562 - acc: 0.9862\n",
      "Epoch 19/50\n",
      "4285/4285 [==============================] - 1s 171us/step - loss: 0.0519 - acc: 0.9860\n",
      "Epoch 20/50\n",
      "4285/4285 [==============================] - 1s 184us/step - loss: 0.0523 - acc: 0.9858\n",
      "Epoch 21/50\n",
      "4285/4285 [==============================] - 1s 188us/step - loss: 0.0484 - acc: 0.9862\n",
      "Epoch 22/50\n",
      "4285/4285 [==============================] - 1s 187us/step - loss: 0.0480 - acc: 0.9867\n",
      "Epoch 23/50\n",
      "4285/4285 [==============================] - 1s 179us/step - loss: 0.0495 - acc: 0.9865\n",
      "Epoch 24/50\n",
      "4285/4285 [==============================] - 1s 181us/step - loss: 0.0449 - acc: 0.9867\n",
      "Epoch 25/50\n",
      "4285/4285 [==============================] - 1s 194us/step - loss: 0.0414 - acc: 0.9876\n",
      "Epoch 26/50\n",
      "4285/4285 [==============================] - 1s 185us/step - loss: 0.0400 - acc: 0.9865\n",
      "Epoch 27/50\n",
      "4285/4285 [==============================] - 1s 195us/step - loss: 0.0438 - acc: 0.9867\n",
      "Epoch 28/50\n",
      "4285/4285 [==============================] - 1s 195us/step - loss: 0.0370 - acc: 0.9867\n",
      "Epoch 29/50\n",
      "4285/4285 [==============================] - 1s 196us/step - loss: 0.0406 - acc: 0.9879\n",
      "Epoch 30/50\n",
      "4285/4285 [==============================] - 1s 184us/step - loss: 0.0361 - acc: 0.9874\n",
      "Epoch 31/50\n",
      "4285/4285 [==============================] - 1s 179us/step - loss: 0.0408 - acc: 0.9879\n",
      "Epoch 32/50\n",
      "4285/4285 [==============================] - 1s 175us/step - loss: 0.0319 - acc: 0.9886\n",
      "Epoch 33/50\n",
      "4285/4285 [==============================] - 1s 178us/step - loss: 0.0380 - acc: 0.9879\n",
      "Epoch 34/50\n",
      "4285/4285 [==============================] - 1s 171us/step - loss: 0.0363 - acc: 0.9883\n",
      "Epoch 35/50\n",
      "4285/4285 [==============================] - 1s 174us/step - loss: 0.0293 - acc: 0.9888\n",
      "Epoch 36/50\n",
      "4285/4285 [==============================] - 1s 173us/step - loss: 0.0305 - acc: 0.9895\n",
      "Epoch 37/50\n",
      "4285/4285 [==============================] - 1s 193us/step - loss: 0.0288 - acc: 0.9890\n",
      "Epoch 38/50\n",
      "4285/4285 [==============================] - 1s 176us/step - loss: 0.0268 - acc: 0.9897\n",
      "Epoch 39/50\n",
      "4285/4285 [==============================] - 1s 181us/step - loss: 0.0261 - acc: 0.9904\n",
      "Epoch 40/50\n",
      "4285/4285 [==============================] - 1s 176us/step - loss: 0.0270 - acc: 0.9902\n",
      "Epoch 41/50\n",
      "4285/4285 [==============================] - 1s 171us/step - loss: 0.0268 - acc: 0.9909\n",
      "Epoch 42/50\n",
      "4285/4285 [==============================] - 1s 169us/step - loss: 0.0251 - acc: 0.9907\n",
      "Epoch 43/50\n",
      "4285/4285 [==============================] - 1s 174us/step - loss: 0.0234 - acc: 0.9907\n",
      "Epoch 44/50\n",
      "4285/4285 [==============================] - 1s 173us/step - loss: 0.0254 - acc: 0.9914\n",
      "Epoch 45/50\n",
      "4285/4285 [==============================] - 1s 176us/step - loss: 0.0217 - acc: 0.9911\n",
      "Epoch 46/50\n",
      "4285/4285 [==============================] - 1s 173us/step - loss: 0.0231 - acc: 0.9930\n",
      "Epoch 47/50\n",
      "4285/4285 [==============================] - 1s 172us/step - loss: 0.0206 - acc: 0.9921\n",
      "Epoch 48/50\n",
      "4285/4285 [==============================] - 1s 173us/step - loss: 0.0184 - acc: 0.9930\n",
      "Epoch 49/50\n",
      "4285/4285 [==============================] - 1s 171us/step - loss: 0.0209 - acc: 0.9921\n",
      "Epoch 50/50\n",
      "4285/4285 [==============================] - 1s 177us/step - loss: 0.0230 - acc: 0.9907\n",
      "476/476 [==============================] - 0s 119us/step\n",
      "Epoch 1/50\n",
      "4285/4285 [==============================] - 1s 256us/step - loss: 0.1321 - acc: 0.9764\n",
      "Epoch 2/50\n",
      "4285/4285 [==============================] - 1s 172us/step - loss: 0.0866 - acc: 0.9795\n",
      "Epoch 3/50\n",
      "4285/4285 [==============================] - 1s 172us/step - loss: 0.0815 - acc: 0.9799\n",
      "Epoch 4/50\n",
      "4285/4285 [==============================] - 1s 173us/step - loss: 0.0772 - acc: 0.9818 0s - loss: 0.0790 -\n",
      "Epoch 5/50\n",
      "4285/4285 [==============================] - 1s 178us/step - loss: 0.0733 - acc: 0.9832\n",
      "Epoch 6/50\n",
      "4285/4285 [==============================] - 1s 180us/step - loss: 0.0724 - acc: 0.9837\n",
      "Epoch 7/50\n",
      "4285/4285 [==============================] - 1s 175us/step - loss: 0.0666 - acc: 0.9839\n",
      "Epoch 8/50\n",
      "4285/4285 [==============================] - 1s 175us/step - loss: 0.0649 - acc: 0.9839\n",
      "Epoch 9/50\n",
      "4285/4285 [==============================] - 1s 180us/step - loss: 0.0641 - acc: 0.9855\n",
      "Epoch 10/50\n",
      "4285/4285 [==============================] - 1s 173us/step - loss: 0.0632 - acc: 0.9846\n",
      "Epoch 11/50\n",
      "4285/4285 [==============================] - 1s 173us/step - loss: 0.0588 - acc: 0.9855\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4285/4285 [==============================] - 1s 171us/step - loss: 0.0571 - acc: 0.9855\n",
      "Epoch 13/50\n",
      "4285/4285 [==============================] - 1s 176us/step - loss: 0.0563 - acc: 0.9855\n",
      "Epoch 14/50\n",
      "4285/4285 [==============================] - 1s 172us/step - loss: 0.0560 - acc: 0.9855\n",
      "Epoch 15/50\n",
      "4285/4285 [==============================] - 1s 170us/step - loss: 0.0525 - acc: 0.9860\n",
      "Epoch 16/50\n",
      "4285/4285 [==============================] - 1s 169us/step - loss: 0.0527 - acc: 0.9858 0s - loss: 0.0525 \n",
      "Epoch 17/50\n",
      "4285/4285 [==============================] - 1s 170us/step - loss: 0.0486 - acc: 0.9860\n",
      "Epoch 18/50\n",
      "4285/4285 [==============================] - 1s 172us/step - loss: 0.0466 - acc: 0.9874\n",
      "Epoch 19/50\n",
      "4285/4285 [==============================] - 1s 178us/step - loss: 0.0456 - acc: 0.9867\n",
      "Epoch 20/50\n",
      "4285/4285 [==============================] - 1s 172us/step - loss: 0.0423 - acc: 0.9867\n",
      "Epoch 21/50\n",
      "4285/4285 [==============================] - 1s 169us/step - loss: 0.0444 - acc: 0.9860\n",
      "Epoch 22/50\n",
      "4285/4285 [==============================] - 1s 171us/step - loss: 0.0390 - acc: 0.9867\n",
      "Epoch 23/50\n",
      "4285/4285 [==============================] - 1s 176us/step - loss: 0.0380 - acc: 0.9872\n",
      "Epoch 24/50\n",
      "4285/4285 [==============================] - 1s 173us/step - loss: 0.0379 - acc: 0.9888\n",
      "Epoch 25/50\n",
      "4285/4285 [==============================] - 1s 179us/step - loss: 0.0304 - acc: 0.9874\n",
      "Epoch 26/50\n",
      "4285/4285 [==============================] - 1s 174us/step - loss: 0.0334 - acc: 0.9893\n",
      "Epoch 27/50\n",
      "4285/4285 [==============================] - 1s 174us/step - loss: 0.0336 - acc: 0.9881\n",
      "Epoch 28/50\n",
      "4285/4285 [==============================] - 1s 172us/step - loss: 0.0308 - acc: 0.9895\n",
      "Epoch 29/50\n",
      "4285/4285 [==============================] - 1s 168us/step - loss: 0.0279 - acc: 0.9904\n",
      "Epoch 30/50\n",
      "4285/4285 [==============================] - 1s 170us/step - loss: 0.0283 - acc: 0.9897\n",
      "Epoch 31/50\n",
      "4285/4285 [==============================] - 1s 173us/step - loss: 0.0372 - acc: 0.9879\n",
      "Epoch 32/50\n",
      "4285/4285 [==============================] - 1s 173us/step - loss: 0.0321 - acc: 0.9897\n",
      "Epoch 33/50\n",
      "4285/4285 [==============================] - 1s 177us/step - loss: 0.0253 - acc: 0.9914\n",
      "Epoch 34/50\n",
      "4285/4285 [==============================] - 1s 173us/step - loss: 0.0284 - acc: 0.9900\n",
      "Epoch 35/50\n",
      "4285/4285 [==============================] - 1s 175us/step - loss: 0.0231 - acc: 0.9909\n",
      "Epoch 36/50\n",
      "4285/4285 [==============================] - 1s 172us/step - loss: 0.0235 - acc: 0.9914\n",
      "Epoch 37/50\n",
      "4285/4285 [==============================] - 1s 174us/step - loss: 0.0244 - acc: 0.9911\n",
      "Epoch 38/50\n",
      "4285/4285 [==============================] - 1s 174us/step - loss: 0.0228 - acc: 0.9914\n",
      "Epoch 39/50\n",
      "4285/4285 [==============================] - 1s 175us/step - loss: 0.0295 - acc: 0.9890\n",
      "Epoch 40/50\n",
      "4285/4285 [==============================] - 1s 170us/step - loss: 0.0276 - acc: 0.9904\n",
      "Epoch 41/50\n",
      "4285/4285 [==============================] - 1s 176us/step - loss: 0.0233 - acc: 0.9909\n",
      "Epoch 42/50\n",
      "4285/4285 [==============================] - 1s 173us/step - loss: 0.0267 - acc: 0.9909\n",
      "Epoch 43/50\n",
      "4285/4285 [==============================] - 1s 173us/step - loss: 0.0205 - acc: 0.9928\n",
      "Epoch 44/50\n",
      "4285/4285 [==============================] - 1s 189us/step - loss: 0.0192 - acc: 0.9925\n",
      "Epoch 45/50\n",
      "4285/4285 [==============================] - 1s 174us/step - loss: 0.0240 - acc: 0.9902\n",
      "Epoch 46/50\n",
      "4285/4285 [==============================] - 1s 178us/step - loss: 0.0208 - acc: 0.9932\n",
      "Epoch 47/50\n",
      "4285/4285 [==============================] - 1s 179us/step - loss: 0.0198 - acc: 0.9918\n",
      "Epoch 48/50\n",
      "4285/4285 [==============================] - 1s 193us/step - loss: 0.0185 - acc: 0.9932\n",
      "Epoch 49/50\n",
      "4285/4285 [==============================] - 1s 185us/step - loss: 0.0271 - acc: 0.9916\n",
      "Epoch 50/50\n",
      "4285/4285 [==============================] - 1s 186us/step - loss: 0.0174 - acc: 0.9942\n",
      "476/476 [==============================] - 0s 148us/step\n",
      "Epoch 1/50\n",
      "4285/4285 [==============================] - 1s 286us/step - loss: 0.1341 - acc: 0.9792\n",
      "Epoch 2/50\n",
      "4285/4285 [==============================] - 1s 200us/step - loss: 0.0899 - acc: 0.9792\n",
      "Epoch 3/50\n",
      "4285/4285 [==============================] - 1s 200us/step - loss: 0.0822 - acc: 0.9792\n",
      "Epoch 4/50\n",
      "4285/4285 [==============================] - 1s 189us/step - loss: 0.0807 - acc: 0.9818\n",
      "Epoch 5/50\n",
      "4285/4285 [==============================] - 1s 193us/step - loss: 0.0753 - acc: 0.9825\n",
      "Epoch 6/50\n",
      "4285/4285 [==============================] - 1s 180us/step - loss: 0.0714 - acc: 0.9834\n",
      "Epoch 7/50\n",
      "4285/4285 [==============================] - 1s 171us/step - loss: 0.0694 - acc: 0.9832\n",
      "Epoch 8/50\n",
      "4285/4285 [==============================] - 1s 177us/step - loss: 0.0704 - acc: 0.9839\n",
      "Epoch 9/50\n",
      "4285/4285 [==============================] - 1s 174us/step - loss: 0.0680 - acc: 0.9837\n",
      "Epoch 10/50\n",
      "4285/4285 [==============================] - 1s 176us/step - loss: 0.0689 - acc: 0.9844\n",
      "Epoch 11/50\n",
      "4285/4285 [==============================] - 1s 180us/step - loss: 0.0685 - acc: 0.9832\n",
      "Epoch 12/50\n",
      "4285/4285 [==============================] - 1s 179us/step - loss: 0.0646 - acc: 0.9844\n",
      "Epoch 13/50\n",
      "4285/4285 [==============================] - 1s 193us/step - loss: 0.0628 - acc: 0.9846\n",
      "Epoch 14/50\n",
      "4285/4285 [==============================] - 1s 181us/step - loss: 0.0609 - acc: 0.9848\n",
      "Epoch 15/50\n",
      "4285/4285 [==============================] - 1s 172us/step - loss: 0.0599 - acc: 0.9858\n",
      "Epoch 16/50\n",
      "4285/4285 [==============================] - 1s 166us/step - loss: 0.0599 - acc: 0.9853\n",
      "Epoch 17/50\n",
      "4285/4285 [==============================] - 1s 170us/step - loss: 0.0562 - acc: 0.9851\n",
      "Epoch 18/50\n",
      "4285/4285 [==============================] - 1s 173us/step - loss: 0.0552 - acc: 0.9848\n",
      "Epoch 19/50\n",
      "4285/4285 [==============================] - 1s 173us/step - loss: 0.0553 - acc: 0.9853\n",
      "Epoch 20/50\n",
      "4285/4285 [==============================] - 1s 174us/step - loss: 0.0530 - acc: 0.9855\n",
      "Epoch 21/50\n",
      "4285/4285 [==============================] - 1s 177us/step - loss: 0.0480 - acc: 0.9860\n",
      "Epoch 22/50\n",
      "4285/4285 [==============================] - 1s 180us/step - loss: 0.0505 - acc: 0.9858\n",
      "Epoch 23/50\n",
      "4285/4285 [==============================] - 1s 173us/step - loss: 0.0469 - acc: 0.9855\n",
      "Epoch 24/50\n",
      "4285/4285 [==============================] - 1s 175us/step - loss: 0.0438 - acc: 0.9858\n",
      "Epoch 25/50\n",
      "4285/4285 [==============================] - 1s 176us/step - loss: 0.0457 - acc: 0.9876\n",
      "Epoch 26/50\n",
      "4285/4285 [==============================] - 1s 172us/step - loss: 0.0396 - acc: 0.9874\n",
      "Epoch 27/50\n",
      "4285/4285 [==============================] - 1s 176us/step - loss: 0.0394 - acc: 0.9872\n",
      "Epoch 28/50\n",
      "4285/4285 [==============================] - 1s 177us/step - loss: 0.0385 - acc: 0.9876\n",
      "Epoch 29/50\n",
      "4285/4285 [==============================] - 1s 177us/step - loss: 0.0338 - acc: 0.9869\n",
      "Epoch 30/50\n",
      "4285/4285 [==============================] - 1s 172us/step - loss: 0.0319 - acc: 0.9881\n",
      "Epoch 31/50\n",
      "4285/4285 [==============================] - 1s 176us/step - loss: 0.0349 - acc: 0.9883\n",
      "Epoch 32/50\n",
      "4285/4285 [==============================] - 1s 177us/step - loss: 0.0344 - acc: 0.9883\n",
      "Epoch 33/50\n",
      "4285/4285 [==============================] - 1s 174us/step - loss: 0.0318 - acc: 0.9883\n",
      "Epoch 34/50\n",
      "4285/4285 [==============================] - 1s 173us/step - loss: 0.0274 - acc: 0.9888\n",
      "Epoch 35/50\n",
      "4285/4285 [==============================] - 1s 172us/step - loss: 0.0285 - acc: 0.9890\n",
      "Epoch 36/50\n",
      "4285/4285 [==============================] - 1s 170us/step - loss: 0.0266 - acc: 0.9897\n",
      "Epoch 37/50\n",
      "4285/4285 [==============================] - 1s 170us/step - loss: 0.0289 - acc: 0.9902\n",
      "Epoch 38/50\n",
      "4285/4285 [==============================] - 1s 169us/step - loss: 0.0279 - acc: 0.9909\n",
      "Epoch 39/50\n",
      "4285/4285 [==============================] - 1s 175us/step - loss: 0.0297 - acc: 0.9900\n",
      "Epoch 40/50\n",
      "4285/4285 [==============================] - 1s 176us/step - loss: 0.0252 - acc: 0.9904\n",
      "Epoch 41/50\n",
      "4285/4285 [==============================] - 1s 175us/step - loss: 0.0243 - acc: 0.9916\n",
      "Epoch 42/50\n",
      "4285/4285 [==============================] - 1s 169us/step - loss: 0.0219 - acc: 0.9909\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4285/4285 [==============================] - 1s 174us/step - loss: 0.0245 - acc: 0.9923\n",
      "Epoch 44/50\n",
      "4285/4285 [==============================] - 1s 171us/step - loss: 0.0330 - acc: 0.9897\n",
      "Epoch 45/50\n",
      "4285/4285 [==============================] - 1s 172us/step - loss: 0.0213 - acc: 0.9930\n",
      "Epoch 46/50\n",
      "4285/4285 [==============================] - 1s 173us/step - loss: 0.0265 - acc: 0.9911\n",
      "Epoch 47/50\n",
      "4285/4285 [==============================] - 1s 172us/step - loss: 0.0237 - acc: 0.9918\n",
      "Epoch 48/50\n",
      "4285/4285 [==============================] - 1s 169us/step - loss: 0.0203 - acc: 0.9930\n",
      "Epoch 49/50\n",
      "4285/4285 [==============================] - 1s 177us/step - loss: 0.0201 - acc: 0.9942\n",
      "Epoch 50/50\n",
      "4285/4285 [==============================] - 1s 174us/step - loss: 0.0211 - acc: 0.9930\n",
      "476/476 [==============================] - 0s 167us/step\n",
      "Epoch 1/50\n",
      "4285/4285 [==============================] - 1s 311us/step - loss: 0.1364 - acc: 0.9725\n",
      "Epoch 2/50\n",
      "4285/4285 [==============================] - 1s 175us/step - loss: 0.0868 - acc: 0.9799\n",
      "Epoch 3/50\n",
      "4285/4285 [==============================] - 1s 173us/step - loss: 0.0807 - acc: 0.9804\n",
      "Epoch 4/50\n",
      "4285/4285 [==============================] - 1s 184us/step - loss: 0.0743 - acc: 0.9825\n",
      "Epoch 5/50\n",
      "4285/4285 [==============================] - 1s 174us/step - loss: 0.0735 - acc: 0.9837\n",
      "Epoch 6/50\n",
      "4285/4285 [==============================] - 1s 172us/step - loss: 0.0683 - acc: 0.9841\n",
      "Epoch 7/50\n",
      "4285/4285 [==============================] - 1s 177us/step - loss: 0.0697 - acc: 0.9841\n",
      "Epoch 8/50\n",
      "4285/4285 [==============================] - 1s 176us/step - loss: 0.0693 - acc: 0.9846\n",
      "Epoch 9/50\n",
      "4285/4285 [==============================] - 1s 180us/step - loss: 0.0665 - acc: 0.9846\n",
      "Epoch 10/50\n",
      "4285/4285 [==============================] - 1s 177us/step - loss: 0.0642 - acc: 0.9844\n",
      "Epoch 11/50\n",
      "4285/4285 [==============================] - 1s 179us/step - loss: 0.0632 - acc: 0.9853\n",
      "Epoch 12/50\n",
      "4285/4285 [==============================] - 1s 175us/step - loss: 0.0628 - acc: 0.9851\n",
      "Epoch 13/50\n",
      "4285/4285 [==============================] - 1s 176us/step - loss: 0.0619 - acc: 0.9851\n",
      "Epoch 14/50\n",
      "4285/4285 [==============================] - 1s 176us/step - loss: 0.0597 - acc: 0.9855\n",
      "Epoch 15/50\n",
      "4285/4285 [==============================] - 1s 175us/step - loss: 0.0593 - acc: 0.9860\n",
      "Epoch 16/50\n",
      "4285/4285 [==============================] - 1s 177us/step - loss: 0.0597 - acc: 0.9855\n",
      "Epoch 17/50\n",
      "4285/4285 [==============================] - 1s 173us/step - loss: 0.0566 - acc: 0.9853\n",
      "Epoch 18/50\n",
      "4285/4285 [==============================] - 1s 175us/step - loss: 0.0561 - acc: 0.9858\n",
      "Epoch 19/50\n",
      "4285/4285 [==============================] - 1s 175us/step - loss: 0.0518 - acc: 0.9860\n",
      "Epoch 20/50\n",
      "4285/4285 [==============================] - 1s 192us/step - loss: 0.0523 - acc: 0.9862\n",
      "Epoch 21/50\n",
      "4285/4285 [==============================] - 1s 172us/step - loss: 0.0502 - acc: 0.9862\n",
      "Epoch 22/50\n",
      "4285/4285 [==============================] - 1s 170us/step - loss: 0.0474 - acc: 0.9869\n",
      "Epoch 23/50\n",
      "4285/4285 [==============================] - 1s 179us/step - loss: 0.0467 - acc: 0.9862\n",
      "Epoch 24/50\n",
      "4285/4285 [==============================] - 1s 181us/step - loss: 0.0436 - acc: 0.9865\n",
      "Epoch 25/50\n",
      "4285/4285 [==============================] - 1s 183us/step - loss: 0.0446 - acc: 0.9865\n",
      "Epoch 26/50\n",
      "4285/4285 [==============================] - 1s 185us/step - loss: 0.0393 - acc: 0.9883\n",
      "Epoch 27/50\n",
      "4285/4285 [==============================] - 1s 180us/step - loss: 0.0354 - acc: 0.9876\n",
      "Epoch 28/50\n",
      "4285/4285 [==============================] - 1s 179us/step - loss: 0.0422 - acc: 0.9883\n",
      "Epoch 29/50\n",
      "4285/4285 [==============================] - 1s 196us/step - loss: 0.0336 - acc: 0.9890\n",
      "Epoch 30/50\n",
      "4285/4285 [==============================] - 1s 192us/step - loss: 0.0342 - acc: 0.9890\n",
      "Epoch 31/50\n",
      "4285/4285 [==============================] - 1s 207us/step - loss: 0.0280 - acc: 0.9900\n",
      "Epoch 32/50\n",
      "4285/4285 [==============================] - 1s 193us/step - loss: 0.0334 - acc: 0.9900\n",
      "Epoch 33/50\n",
      "4285/4285 [==============================] - 1s 201us/step - loss: 0.0311 - acc: 0.9890\n",
      "Epoch 34/50\n",
      "4285/4285 [==============================] - 1s 188us/step - loss: 0.0274 - acc: 0.9907\n",
      "Epoch 35/50\n",
      "4285/4285 [==============================] - 1s 195us/step - loss: 0.0272 - acc: 0.9907\n",
      "Epoch 36/50\n",
      "4285/4285 [==============================] - 1s 177us/step - loss: 0.0287 - acc: 0.9890\n",
      "Epoch 37/50\n",
      "4285/4285 [==============================] - 1s 188us/step - loss: 0.0300 - acc: 0.9900\n",
      "Epoch 38/50\n",
      "4285/4285 [==============================] - 1s 186us/step - loss: 0.0267 - acc: 0.9900\n",
      "Epoch 39/50\n",
      "4285/4285 [==============================] - 1s 182us/step - loss: 0.0304 - acc: 0.9911\n",
      "Epoch 40/50\n",
      "4285/4285 [==============================] - 1s 203us/step - loss: 0.0269 - acc: 0.9918\n",
      "Epoch 41/50\n",
      "4285/4285 [==============================] - 1s 252us/step - loss: 0.0260 - acc: 0.9916\n",
      "Epoch 42/50\n",
      "4285/4285 [==============================] - 1s 282us/step - loss: 0.0302 - acc: 0.9895\n",
      "Epoch 43/50\n",
      "4285/4285 [==============================] - 1s 279us/step - loss: 0.0230 - acc: 0.9928\n",
      "Epoch 44/50\n",
      "4285/4285 [==============================] - 1s 292us/step - loss: 0.0229 - acc: 0.9918\n",
      "Epoch 45/50\n",
      "4285/4285 [==============================] - 1s 229us/step - loss: 0.0207 - acc: 0.9930\n",
      "Epoch 46/50\n",
      "4285/4285 [==============================] - 1s 178us/step - loss: 0.0211 - acc: 0.9921\n",
      "Epoch 47/50\n",
      "4285/4285 [==============================] - 1s 175us/step - loss: 0.0217 - acc: 0.9914\n",
      "Epoch 48/50\n",
      "4285/4285 [==============================] - 1s 175us/step - loss: 0.0286 - acc: 0.9909\n",
      "Epoch 49/50\n",
      "4285/4285 [==============================] - 1s 172us/step - loss: 0.0221 - acc: 0.9932\n",
      "Epoch 50/50\n",
      "4285/4285 [==============================] - 1s 184us/step - loss: 0.0194 - acc: 0.9932\n",
      "476/476 [==============================] - 0s 211us/step\n",
      "Epoch 1/50\n",
      "4285/4285 [==============================] - 1s 283us/step - loss: 0.1307 - acc: 0.9746\n",
      "Epoch 2/50\n",
      "4285/4285 [==============================] - 1s 174us/step - loss: 0.0920 - acc: 0.9795\n",
      "Epoch 3/50\n",
      "4285/4285 [==============================] - 1s 182us/step - loss: 0.0845 - acc: 0.9797\n",
      "Epoch 4/50\n",
      "4285/4285 [==============================] - 1s 201us/step - loss: 0.0807 - acc: 0.9809\n",
      "Epoch 5/50\n",
      "4285/4285 [==============================] - 1s 247us/step - loss: 0.0759 - acc: 0.9811\n",
      "Epoch 6/50\n",
      "4285/4285 [==============================] - 1s 299us/step - loss: 0.0733 - acc: 0.9827\n",
      "Epoch 7/50\n",
      "4285/4285 [==============================] - 1s 301us/step - loss: 0.0728 - acc: 0.9820\n",
      "Epoch 8/50\n",
      "4285/4285 [==============================] - 1s 328us/step - loss: 0.0693 - acc: 0.9839\n",
      "Epoch 9/50\n",
      "4285/4285 [==============================] - 1s 331us/step - loss: 0.0675 - acc: 0.9839\n",
      "Epoch 10/50\n",
      "4285/4285 [==============================] - 1s 284us/step - loss: 0.0672 - acc: 0.9841\n",
      "Epoch 11/50\n",
      "4285/4285 [==============================] - 1s 261us/step - loss: 0.0653 - acc: 0.9839\n",
      "Epoch 12/50\n",
      "4285/4285 [==============================] - 1s 258us/step - loss: 0.0628 - acc: 0.9841\n",
      "Epoch 13/50\n",
      "4285/4285 [==============================] - 1s 177us/step - loss: 0.0648 - acc: 0.9841\n",
      "Epoch 14/50\n",
      "4285/4285 [==============================] - 1s 174us/step - loss: 0.0617 - acc: 0.9844\n",
      "Epoch 15/50\n",
      "4285/4285 [==============================] - 1s 176us/step - loss: 0.0601 - acc: 0.9851\n",
      "Epoch 16/50\n",
      "4285/4285 [==============================] - 1s 175us/step - loss: 0.0612 - acc: 0.9848\n",
      "Epoch 17/50\n",
      "4285/4285 [==============================] - 1s 176us/step - loss: 0.0579 - acc: 0.9848\n",
      "Epoch 18/50\n",
      "4285/4285 [==============================] - 1s 174us/step - loss: 0.0557 - acc: 0.9853\n",
      "Epoch 19/50\n",
      "4285/4285 [==============================] - 1s 173us/step - loss: 0.0542 - acc: 0.9855\n",
      "Epoch 20/50\n",
      "4285/4285 [==============================] - 1s 174us/step - loss: 0.0507 - acc: 0.9860\n",
      "Epoch 21/50\n",
      "4285/4285 [==============================] - 1s 177us/step - loss: 0.0538 - acc: 0.9865\n",
      "Epoch 22/50\n",
      "4285/4285 [==============================] - 1s 180us/step - loss: 0.0481 - acc: 0.9860\n",
      "Epoch 23/50\n",
      "4285/4285 [==============================] - 1s 179us/step - loss: 0.0500 - acc: 0.9867\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4285/4285 [==============================] - 1s 177us/step - loss: 0.0427 - acc: 0.9862\n",
      "Epoch 25/50\n",
      "4285/4285 [==============================] - 1s 169us/step - loss: 0.0438 - acc: 0.9869\n",
      "Epoch 26/50\n",
      "4285/4285 [==============================] - 1s 170us/step - loss: 0.0405 - acc: 0.9867\n",
      "Epoch 27/50\n",
      "4285/4285 [==============================] - 1s 173us/step - loss: 0.0434 - acc: 0.9869\n",
      "Epoch 28/50\n",
      "4285/4285 [==============================] - 1s 174us/step - loss: 0.0423 - acc: 0.9876\n",
      "Epoch 29/50\n",
      "4285/4285 [==============================] - 1s 175us/step - loss: 0.0347 - acc: 0.9883\n",
      "Epoch 30/50\n",
      "4285/4285 [==============================] - 1s 179us/step - loss: 0.0316 - acc: 0.9876\n",
      "Epoch 31/50\n",
      "4285/4285 [==============================] - 1s 173us/step - loss: 0.0333 - acc: 0.9881\n",
      "Epoch 32/50\n",
      "4285/4285 [==============================] - 1s 209us/step - loss: 0.0326 - acc: 0.9886\n",
      "Epoch 33/50\n",
      "4285/4285 [==============================] - 1s 240us/step - loss: 0.0287 - acc: 0.9895\n",
      "Epoch 34/50\n",
      "4285/4285 [==============================] - 1s 239us/step - loss: 0.0305 - acc: 0.9886\n",
      "Epoch 35/50\n",
      "4285/4285 [==============================] - 1s 267us/step - loss: 0.0299 - acc: 0.9886\n",
      "Epoch 36/50\n",
      "4285/4285 [==============================] - 1s 245us/step - loss: 0.0250 - acc: 0.9909\n",
      "Epoch 37/50\n",
      "4285/4285 [==============================] - 1s 188us/step - loss: 0.0302 - acc: 0.9895\n",
      "Epoch 38/50\n",
      "4285/4285 [==============================] - 1s 183us/step - loss: 0.0272 - acc: 0.9893\n",
      "Epoch 39/50\n",
      "4285/4285 [==============================] - 1s 176us/step - loss: 0.0222 - acc: 0.9914\n",
      "Epoch 40/50\n",
      "4285/4285 [==============================] - 1s 176us/step - loss: 0.0262 - acc: 0.9890\n",
      "Epoch 41/50\n",
      "4285/4285 [==============================] - 1s 178us/step - loss: 0.0286 - acc: 0.9888\n",
      "Epoch 42/50\n",
      "4285/4285 [==============================] - 1s 188us/step - loss: 0.0237 - acc: 0.9914\n",
      "Epoch 43/50\n",
      "4285/4285 [==============================] - 1s 191us/step - loss: 0.0252 - acc: 0.9911\n",
      "Epoch 44/50\n",
      "4285/4285 [==============================] - 1s 179us/step - loss: 0.0231 - acc: 0.9930\n",
      "Epoch 45/50\n",
      "4285/4285 [==============================] - 1s 172us/step - loss: 0.0193 - acc: 0.9930\n",
      "Epoch 46/50\n",
      "4285/4285 [==============================] - 1s 176us/step - loss: 0.0213 - acc: 0.9918\n",
      "Epoch 47/50\n",
      "4285/4285 [==============================] - 1s 174us/step - loss: 0.0217 - acc: 0.9921\n",
      "Epoch 48/50\n",
      "4285/4285 [==============================] - 1s 177us/step - loss: 0.0225 - acc: 0.9916\n",
      "Epoch 49/50\n",
      "4285/4285 [==============================] - 1s 184us/step - loss: 0.0203 - acc: 0.9918\n",
      "Epoch 50/50\n",
      "4285/4285 [==============================] - 1s 171us/step - loss: 0.0219 - acc: 0.9923\n",
      "476/476 [==============================] - 0s 228us/step\n",
      "Epoch 1/50\n",
      "4285/4285 [==============================] - 1s 333us/step - loss: 0.1325 - acc: 0.9790\n",
      "Epoch 2/50\n",
      "4285/4285 [==============================] - 1s 175us/step - loss: 0.0899 - acc: 0.9790\n",
      "Epoch 3/50\n",
      "4285/4285 [==============================] - 1s 175us/step - loss: 0.0825 - acc: 0.9792\n",
      "Epoch 4/50\n",
      "4285/4285 [==============================] - 1s 189us/step - loss: 0.0769 - acc: 0.9816\n",
      "Epoch 5/50\n",
      "4285/4285 [==============================] - 1s 207us/step - loss: 0.0741 - acc: 0.9825\n",
      "Epoch 6/50\n",
      "4285/4285 [==============================] - 1s 279us/step - loss: 0.0699 - acc: 0.9834\n",
      "Epoch 7/50\n",
      "4285/4285 [==============================] - 1s 245us/step - loss: 0.0675 - acc: 0.9837\n",
      "Epoch 8/50\n",
      "4285/4285 [==============================] - 1s 271us/step - loss: 0.0679 - acc: 0.9841\n",
      "Epoch 9/50\n",
      "4285/4285 [==============================] - 1s 248us/step - loss: 0.0668 - acc: 0.9844\n",
      "Epoch 10/50\n",
      "4285/4285 [==============================] - 1s 187us/step - loss: 0.0635 - acc: 0.9848\n",
      "Epoch 11/50\n",
      "4285/4285 [==============================] - 1s 178us/step - loss: 0.0620 - acc: 0.9844\n",
      "Epoch 12/50\n",
      "4285/4285 [==============================] - 1s 177us/step - loss: 0.0616 - acc: 0.9851\n",
      "Epoch 13/50\n",
      "4285/4285 [==============================] - 1s 176us/step - loss: 0.0582 - acc: 0.9855\n",
      "Epoch 14/50\n",
      "4285/4285 [==============================] - 1s 178us/step - loss: 0.0595 - acc: 0.9853\n",
      "Epoch 15/50\n",
      "4285/4285 [==============================] - 1s 174us/step - loss: 0.0561 - acc: 0.9853\n",
      "Epoch 16/50\n",
      "4285/4285 [==============================] - 1s 179us/step - loss: 0.0534 - acc: 0.9862\n",
      "Epoch 17/50\n",
      "4285/4285 [==============================] - 1s 172us/step - loss: 0.0574 - acc: 0.9851\n",
      "Epoch 18/50\n",
      "4285/4285 [==============================] - 1s 178us/step - loss: 0.0524 - acc: 0.9855\n",
      "Epoch 19/50\n",
      "4285/4285 [==============================] - 1s 174us/step - loss: 0.0487 - acc: 0.9874\n",
      "Epoch 20/50\n",
      "4285/4285 [==============================] - 1s 176us/step - loss: 0.0459 - acc: 0.9867\n",
      "Epoch 21/50\n",
      "4285/4285 [==============================] - 1s 181us/step - loss: 0.0436 - acc: 0.9865\n",
      "Epoch 22/50\n",
      "4285/4285 [==============================] - 1s 179us/step - loss: 0.0431 - acc: 0.9862\n",
      "Epoch 23/50\n",
      "4285/4285 [==============================] - 1s 182us/step - loss: 0.0412 - acc: 0.9879\n",
      "Epoch 24/50\n",
      "4285/4285 [==============================] - 1s 179us/step - loss: 0.0394 - acc: 0.9872\n",
      "Epoch 25/50\n",
      "4285/4285 [==============================] - 1s 175us/step - loss: 0.0410 - acc: 0.9874\n",
      "Epoch 26/50\n",
      "4285/4285 [==============================] - 1s 179us/step - loss: 0.0367 - acc: 0.9874\n",
      "Epoch 27/50\n",
      "4285/4285 [==============================] - 1s 174us/step - loss: 0.0349 - acc: 0.9888\n",
      "Epoch 28/50\n",
      "4285/4285 [==============================] - 1s 176us/step - loss: 0.0320 - acc: 0.9893\n",
      "Epoch 29/50\n",
      "4285/4285 [==============================] - 1s 202us/step - loss: 0.0345 - acc: 0.9876\n",
      "Epoch 30/50\n",
      "4285/4285 [==============================] - 1s 233us/step - loss: 0.0335 - acc: 0.9893\n",
      "Epoch 31/50\n",
      "4285/4285 [==============================] - 1s 257us/step - loss: 0.0315 - acc: 0.9890\n",
      "Epoch 32/50\n",
      "4285/4285 [==============================] - 1s 265us/step - loss: 0.0285 - acc: 0.9904\n",
      "Epoch 33/50\n",
      "4285/4285 [==============================] - 1s 244us/step - loss: 0.0290 - acc: 0.9893\n",
      "Epoch 34/50\n",
      "4285/4285 [==============================] - 1s 210us/step - loss: 0.0297 - acc: 0.9893\n",
      "Epoch 35/50\n",
      "4285/4285 [==============================] - 1s 172us/step - loss: 0.0272 - acc: 0.9897\n",
      "Epoch 36/50\n",
      "4285/4285 [==============================] - 1s 170us/step - loss: 0.0242 - acc: 0.9918\n",
      "Epoch 37/50\n",
      "4285/4285 [==============================] - 1s 175us/step - loss: 0.0270 - acc: 0.9897\n",
      "Epoch 38/50\n",
      "4285/4285 [==============================] - 1s 174us/step - loss: 0.0224 - acc: 0.9921\n",
      "Epoch 39/50\n",
      "4285/4285 [==============================] - 1s 174us/step - loss: 0.0258 - acc: 0.9907\n",
      "Epoch 40/50\n",
      "4285/4285 [==============================] - 1s 170us/step - loss: 0.0241 - acc: 0.9909\n",
      "Epoch 41/50\n",
      "4285/4285 [==============================] - 1s 174us/step - loss: 0.0290 - acc: 0.9907\n",
      "Epoch 42/50\n",
      "4285/4285 [==============================] - 1s 177us/step - loss: 0.0230 - acc: 0.9918\n",
      "Epoch 43/50\n",
      "4285/4285 [==============================] - 1s 180us/step - loss: 0.0190 - acc: 0.9935\n",
      "Epoch 44/50\n",
      "4285/4285 [==============================] - 1s 181us/step - loss: 0.0256 - acc: 0.9921\n",
      "Epoch 45/50\n",
      "4285/4285 [==============================] - 1s 178us/step - loss: 0.0249 - acc: 0.9921\n",
      "Epoch 46/50\n",
      "4285/4285 [==============================] - 1s 186us/step - loss: 0.0199 - acc: 0.9916\n",
      "Epoch 47/50\n",
      "4285/4285 [==============================] - 1s 177us/step - loss: 0.0236 - acc: 0.9923\n",
      "Epoch 48/50\n",
      "4285/4285 [==============================] - 1s 170us/step - loss: 0.0246 - acc: 0.9925\n",
      "Epoch 49/50\n",
      "4285/4285 [==============================] - 1s 174us/step - loss: 0.0275 - acc: 0.9923\n",
      "Epoch 50/50\n",
      "4285/4285 [==============================] - 1s 172us/step - loss: 0.0210 - acc: 0.9928\n",
      "476/476 [==============================] - 0s 244us/step\n",
      "Epoch 1/50\n",
      "4285/4285 [==============================] - 1s 290us/step - loss: 0.1364 - acc: 0.9757\n",
      "Epoch 2/50\n",
      "4285/4285 [==============================] - 1s 190us/step - loss: 0.0885 - acc: 0.9797\n",
      "Epoch 3/50\n",
      "4285/4285 [==============================] - 1s 211us/step - loss: 0.0807 - acc: 0.9802\n",
      "Epoch 4/50\n",
      "4285/4285 [==============================] - 1s 270us/step - loss: 0.0769 - acc: 0.9823\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4285/4285 [==============================] - 1s 286us/step - loss: 0.0731 - acc: 0.9830\n",
      "Epoch 6/50\n",
      "4285/4285 [==============================] - 1s 250us/step - loss: 0.0688 - acc: 0.9839\n",
      "Epoch 7/50\n",
      "4285/4285 [==============================] - 1s 222us/step - loss: 0.0693 - acc: 0.9844\n",
      "Epoch 8/50\n",
      "4285/4285 [==============================] - 1s 190us/step - loss: 0.0670 - acc: 0.9844\n",
      "Epoch 9/50\n",
      "4285/4285 [==============================] - 1s 181us/step - loss: 0.0649 - acc: 0.9846\n",
      "Epoch 10/50\n",
      "4285/4285 [==============================] - 1s 198us/step - loss: 0.0618 - acc: 0.9848\n",
      "Epoch 11/50\n",
      "4285/4285 [==============================] - 1s 199us/step - loss: 0.0617 - acc: 0.9846\n",
      "Epoch 12/50\n",
      "4285/4285 [==============================] - 1s 193us/step - loss: 0.0595 - acc: 0.9853\n",
      "Epoch 13/50\n",
      "4285/4285 [==============================] - 1s 177us/step - loss: 0.0611 - acc: 0.9851\n",
      "Epoch 14/50\n",
      "4285/4285 [==============================] - 1s 177us/step - loss: 0.0578 - acc: 0.9858\n",
      "Epoch 15/50\n",
      "4285/4285 [==============================] - 1s 174us/step - loss: 0.0554 - acc: 0.9860\n",
      "Epoch 16/50\n",
      "4285/4285 [==============================] - 1s 169us/step - loss: 0.0549 - acc: 0.9851\n",
      "Epoch 17/50\n",
      "4285/4285 [==============================] - 1s 175us/step - loss: 0.0536 - acc: 0.9858\n",
      "Epoch 18/50\n",
      "4285/4285 [==============================] - 1s 180us/step - loss: 0.0548 - acc: 0.9860\n",
      "Epoch 19/50\n",
      "4285/4285 [==============================] - 1s 186us/step - loss: 0.0494 - acc: 0.9865\n",
      "Epoch 20/50\n",
      "4285/4285 [==============================] - 1s 184us/step - loss: 0.0480 - acc: 0.9872\n",
      "Epoch 21/50\n",
      "4285/4285 [==============================] - 1s 180us/step - loss: 0.0480 - acc: 0.9869\n",
      "Epoch 22/50\n",
      "4285/4285 [==============================] - 1s 177us/step - loss: 0.0464 - acc: 0.9874\n",
      "Epoch 23/50\n",
      "4285/4285 [==============================] - 1s 180us/step - loss: 0.0456 - acc: 0.9876\n",
      "Epoch 24/50\n",
      "4285/4285 [==============================] - 1s 176us/step - loss: 0.0410 - acc: 0.9876\n",
      "Epoch 25/50\n",
      "4285/4285 [==============================] - 1s 180us/step - loss: 0.0413 - acc: 0.9872\n",
      "Epoch 26/50\n",
      "4285/4285 [==============================] - 1s 197us/step - loss: 0.0399 - acc: 0.9879\n",
      "Epoch 27/50\n",
      "4285/4285 [==============================] - 1s 241us/step - loss: 0.0348 - acc: 0.9872\n",
      "Epoch 28/50\n",
      "4285/4285 [==============================] - 1s 265us/step - loss: 0.0356 - acc: 0.9890\n",
      "Epoch 29/50\n",
      "4285/4285 [==============================] - 1s 266us/step - loss: 0.0344 - acc: 0.9888\n",
      "Epoch 30/50\n",
      "4285/4285 [==============================] - 1s 253us/step - loss: 0.0335 - acc: 0.9888\n",
      "Epoch 31/50\n",
      "4285/4285 [==============================] - 1s 229us/step - loss: 0.0306 - acc: 0.9888\n",
      "Epoch 32/50\n",
      "4285/4285 [==============================] - 1s 179us/step - loss: 0.0286 - acc: 0.9890\n",
      "Epoch 33/50\n",
      "4285/4285 [==============================] - 1s 176us/step - loss: 0.0301 - acc: 0.9888\n",
      "Epoch 34/50\n",
      "4285/4285 [==============================] - 1s 178us/step - loss: 0.0287 - acc: 0.9888\n",
      "Epoch 35/50\n",
      "4285/4285 [==============================] - 1s 184us/step - loss: 0.0320 - acc: 0.9900\n",
      "Epoch 36/50\n",
      "4285/4285 [==============================] - 1s 184us/step - loss: 0.0366 - acc: 0.9888\n",
      "Epoch 37/50\n",
      "4285/4285 [==============================] - 1s 183us/step - loss: 0.0330 - acc: 0.9883\n",
      "Epoch 38/50\n",
      "4285/4285 [==============================] - 1s 178us/step - loss: 0.0230 - acc: 0.9921\n",
      "Epoch 39/50\n",
      "4285/4285 [==============================] - 1s 178us/step - loss: 0.0243 - acc: 0.9907\n",
      "Epoch 40/50\n",
      "4285/4285 [==============================] - 1s 176us/step - loss: 0.0227 - acc: 0.9909\n",
      "Epoch 41/50\n",
      "4285/4285 [==============================] - 1s 173us/step - loss: 0.0245 - acc: 0.9904\n",
      "Epoch 42/50\n",
      "4285/4285 [==============================] - 1s 176us/step - loss: 0.0262 - acc: 0.9914\n",
      "Epoch 43/50\n",
      "4285/4285 [==============================] - 1s 185us/step - loss: 0.0283 - acc: 0.9900\n",
      "Epoch 44/50\n",
      "4285/4285 [==============================] - 1s 182us/step - loss: 0.0231 - acc: 0.9916\n",
      "Epoch 45/50\n",
      "4285/4285 [==============================] - 1s 178us/step - loss: 0.0256 - acc: 0.9918\n",
      "Epoch 46/50\n",
      "4285/4285 [==============================] - 1s 177us/step - loss: 0.0215 - acc: 0.9916\n",
      "Epoch 47/50\n",
      "4285/4285 [==============================] - 1s 175us/step - loss: 0.0220 - acc: 0.9928\n",
      "Epoch 48/50\n",
      "4285/4285 [==============================] - 1s 176us/step - loss: 0.0241 - acc: 0.9925\n",
      "Epoch 49/50\n",
      "4285/4285 [==============================] - 1s 173us/step - loss: 0.0238 - acc: 0.9916\n",
      "Epoch 50/50\n",
      "4285/4285 [==============================] - 1s 184us/step - loss: 0.0236 - acc: 0.9925\n",
      "476/476 [==============================] - 0s 308us/step\n",
      "Epoch 1/50\n",
      "4285/4285 [==============================] - 2s 544us/step - loss: 0.1337 - acc: 0.9748\n",
      "Epoch 2/50\n",
      "4285/4285 [==============================] - 1s 273us/step - loss: 0.0879 - acc: 0.9804\n",
      "Epoch 3/50\n",
      "4285/4285 [==============================] - 1s 243us/step - loss: 0.0819 - acc: 0.9804\n",
      "Epoch 4/50\n",
      "4285/4285 [==============================] - 1s 180us/step - loss: 0.0750 - acc: 0.9820\n",
      "Epoch 5/50\n",
      "4285/4285 [==============================] - 1s 178us/step - loss: 0.0721 - acc: 0.9834\n",
      "Epoch 6/50\n",
      "4285/4285 [==============================] - 1s 251us/step - loss: 0.0721 - acc: 0.9841\n",
      "Epoch 7/50\n",
      "4285/4285 [==============================] - 1s 320us/step - loss: 0.0682 - acc: 0.9839\n",
      "Epoch 8/50\n",
      "4285/4285 [==============================] - 1s 181us/step - loss: 0.0665 - acc: 0.9844\n",
      "Epoch 9/50\n",
      "4285/4285 [==============================] - 1s 205us/step - loss: 0.0651 - acc: 0.9846\n",
      "Epoch 10/50\n",
      "4285/4285 [==============================] - 1s 193us/step - loss: 0.0648 - acc: 0.9851\n",
      "Epoch 11/50\n",
      "4285/4285 [==============================] - 1s 189us/step - loss: 0.0615 - acc: 0.9851\n",
      "Epoch 12/50\n",
      "4285/4285 [==============================] - 1s 185us/step - loss: 0.0608 - acc: 0.9851\n",
      "Epoch 13/50\n",
      "4285/4285 [==============================] - 1s 182us/step - loss: 0.0612 - acc: 0.9848\n",
      "Epoch 14/50\n",
      "4285/4285 [==============================] - 1s 192us/step - loss: 0.0592 - acc: 0.9853\n",
      "Epoch 15/50\n",
      "4285/4285 [==============================] - 1s 193us/step - loss: 0.0573 - acc: 0.9860\n",
      "Epoch 16/50\n",
      "4285/4285 [==============================] - 1s 190us/step - loss: 0.0587 - acc: 0.9860\n",
      "Epoch 17/50\n",
      "4285/4285 [==============================] - 1s 277us/step - loss: 0.0564 - acc: 0.9858\n",
      "Epoch 18/50\n",
      "4285/4285 [==============================] - 1s 283us/step - loss: 0.0522 - acc: 0.9862\n",
      "Epoch 19/50\n",
      "4285/4285 [==============================] - 1s 196us/step - loss: 0.0506 - acc: 0.9865\n",
      "Epoch 20/50\n",
      "4285/4285 [==============================] - 1s 185us/step - loss: 0.0493 - acc: 0.9867\n",
      "Epoch 21/50\n",
      "4285/4285 [==============================] - 1s 179us/step - loss: 0.0536 - acc: 0.9862\n",
      "Epoch 22/50\n",
      "4285/4285 [==============================] - 1s 181us/step - loss: 0.0492 - acc: 0.9862\n",
      "Epoch 23/50\n",
      "4285/4285 [==============================] - 1s 186us/step - loss: 0.0463 - acc: 0.9867\n",
      "Epoch 24/50\n",
      "4285/4285 [==============================] - 1s 176us/step - loss: 0.0416 - acc: 0.9869\n",
      "Epoch 25/50\n",
      "4285/4285 [==============================] - 1s 178us/step - loss: 0.0435 - acc: 0.9872\n",
      "Epoch 26/50\n",
      "4285/4285 [==============================] - 1s 178us/step - loss: 0.0429 - acc: 0.9872\n",
      "Epoch 27/50\n",
      "4285/4285 [==============================] - 1s 195us/step - loss: 0.0387 - acc: 0.9879\n",
      "Epoch 28/50\n",
      "4285/4285 [==============================] - 1s 187us/step - loss: 0.0372 - acc: 0.9876\n",
      "Epoch 29/50\n",
      "4285/4285 [==============================] - 1s 188us/step - loss: 0.0407 - acc: 0.9881\n",
      "Epoch 30/50\n",
      "4285/4285 [==============================] - 1s 202us/step - loss: 0.0358 - acc: 0.9883\n",
      "Epoch 31/50\n",
      "4285/4285 [==============================] - 1s 193us/step - loss: 0.0353 - acc: 0.9881\n",
      "Epoch 32/50\n",
      "4285/4285 [==============================] - 1s 209us/step - loss: 0.0322 - acc: 0.9881\n",
      "Epoch 33/50\n",
      "4285/4285 [==============================] - 1s 200us/step - loss: 0.0317 - acc: 0.9893\n",
      "Epoch 34/50\n",
      "4285/4285 [==============================] - 1s 202us/step - loss: 0.0328 - acc: 0.9893\n",
      "Epoch 35/50\n",
      "4285/4285 [==============================] - 1s 191us/step - loss: 0.0287 - acc: 0.9895\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4285/4285 [==============================] - 1s 204us/step - loss: 0.0289 - acc: 0.9904\n",
      "Epoch 37/50\n",
      "4285/4285 [==============================] - 1s 188us/step - loss: 0.0325 - acc: 0.9902\n",
      "Epoch 38/50\n",
      "4285/4285 [==============================] - 1s 205us/step - loss: 0.0263 - acc: 0.9904\n",
      "Epoch 39/50\n",
      "4285/4285 [==============================] - 1s 176us/step - loss: 0.0326 - acc: 0.9897\n",
      "Epoch 40/50\n",
      "4285/4285 [==============================] - 1s 177us/step - loss: 0.0327 - acc: 0.9888\n",
      "Epoch 41/50\n",
      "4285/4285 [==============================] - 1s 179us/step - loss: 0.0290 - acc: 0.9918\n",
      "Epoch 42/50\n",
      "4285/4285 [==============================] - 1s 177us/step - loss: 0.0258 - acc: 0.9916\n",
      "Epoch 43/50\n",
      "4285/4285 [==============================] - 1s 176us/step - loss: 0.0236 - acc: 0.9909\n",
      "Epoch 44/50\n",
      "4285/4285 [==============================] - 1s 178us/step - loss: 0.0259 - acc: 0.9918\n",
      "Epoch 45/50\n",
      "4285/4285 [==============================] - 1s 262us/step - loss: 0.0217 - acc: 0.9904\n",
      "Epoch 46/50\n",
      "4285/4285 [==============================] - 1s 249us/step - loss: 0.0254 - acc: 0.9902\n",
      "Epoch 47/50\n",
      "4285/4285 [==============================] - 1s 288us/step - loss: 0.0207 - acc: 0.9918\n",
      "Epoch 48/50\n",
      "4285/4285 [==============================] - 1s 276us/step - loss: 0.0255 - acc: 0.9909\n",
      "Epoch 49/50\n",
      "4285/4285 [==============================] - 1s 260us/step - loss: 0.0207 - acc: 0.9923\n",
      "Epoch 50/50\n",
      "4285/4285 [==============================] - 1s 204us/step - loss: 0.0210 - acc: 0.9916\n",
      "476/476 [==============================] - 0s 304us/step\n",
      "Accuracy mean: 0.989077832541\n",
      "Accuracy variance: 0.00396409674454\n",
      "(' Time ', '423.999', ' seconds')\n",
      "[[ 143 1859]\n",
      " [   1   38]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.07      0.13      2002\n",
      "        1.0       0.02      0.97      0.04        39\n",
      "\n",
      "avg / total       0.97      0.09      0.13      2041\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# estimators \n",
    "# Evaluating the ANN\n",
    "t0 = time()\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 1024, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n",
    "    classifier.add(Dense(units = 512, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 50)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance))\n",
    "\n",
    "tt = time() - t0     \n",
    "print (\" Time \",format(round(tt,3)),\" seconds\")\n",
    "# Matrix de confusion\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
